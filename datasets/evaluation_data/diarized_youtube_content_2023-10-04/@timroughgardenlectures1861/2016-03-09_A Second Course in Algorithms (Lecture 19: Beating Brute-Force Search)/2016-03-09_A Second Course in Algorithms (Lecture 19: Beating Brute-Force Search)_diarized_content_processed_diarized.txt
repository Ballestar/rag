00:00:00.410 - 00:00:28.178, Speaker A: Okay, so the point of today's lecture is doing better than brute force search for NP hard problems. So just to remind you, we've been talking about NP hard problems for a couple of weeks, but we've been focusing on approximation algorithms where you insist on polynomial time and therefore you have to relax, correctness? So we're looking at approximate correctness, always being close to the optimal solution. So this time we're actually going to insist on full correctness.
00:00:28.178 - 00:00:50.390, Speaker A: We're going to ask for algorithms that are always correct. Now, for an NP hard problem, you don't expect it to run in polynomial time, so you'd like it to run as fast as possible and at the very least, you'd like to run faster than brute force search. Okay? And again, the first time you sort of learn MP completeness, often you're sort of taught to think of MP completeness as meaning you can't beat brute force search, but reality is a little more nuanced.
00:00:50.390 - 00:01:07.062, Speaker A: So actually there's a lot of problems where there are exponential time that are algorithms which are significantly faster than brute force search. And then in this lecture we'll revisit three old friends and see that concretely. So the vertex cover problem and then the traveling salesman problem, and finally three Sat.
00:01:07.146 - 00:01:07.780, Speaker B: Okay?
00:01:10.950 - 00:01:24.422, Speaker A: So that's the point of the lecture. You can often beat brute force search and you sort of already know a lot of the ideas necessary to do so. So we talked a lot about vertex cover.
00:01:24.422 - 00:01:29.826, Speaker A: On Thursday we're going to talk about it again. Now it's actually going to be a special case. We're going to look at of those no weights.
00:01:29.826 - 00:01:47.370, Speaker A: So in other words, the cost of every vertex is one. So remember, in general, the vertex cover problem, I give you an undirected graph, non negative cost on vertices, you want a min cost vertex cover. So here you just want a minimum cardinality vertex cover where again, a vertex cover is a subset of the vertices that includes at least one endpoint from each edge of the graph.
00:01:47.450 - 00:01:47.982, Speaker B: Okay?
00:01:48.116 - 00:02:20.294, Speaker A: So same problem as on Thursday, except all costs equal to one. And actually, we're going to look at even more of a special case, which is, rather than computing the minimum size of a vertex cover, I'm going to give you a target, K, and I just want you to figure out. Is there or is there not a vertex cover of size and most k now, in general, this isn't really that much simpler a problem.
00:02:20.294 - 00:02:42.186, Speaker A: If you could solve this problem, you could just run through all values of k and see what's the sort of smallest one for which you can find a vertex cover. So here the special case is we're going to be thinking of k as small it okay? So if you kind of like having some concrete numbers in your mind, think of k as say, like between ten and 20. And the graph has maybe hundreds of nodes or thousands of nodes.
00:02:42.186 - 00:02:45.678, Speaker A: So you want to know if it has sort of like a really nice small vertex cover.
00:02:45.764 - 00:02:46.410, Speaker B: Okay.
00:02:46.580 - 00:02:50.434, Speaker A: And so for this problem we're going to do better than brute force search.
00:02:50.552 - 00:02:51.220, Speaker B: Okay?
00:02:55.110 - 00:03:32.366, Speaker A: All right, so what's the line in the sand? So how long does it take to do brute force search? For the most naive brute force search to check is a vertex cover of size k or less, like as a function of n and k, what's it going to be roughly and choose k. That's right. So given an alleged vertex cover, it's easy to verify it whether or not it is a vertex cover or not.
00:03:32.366 - 00:03:37.266, Speaker A: So the obvious thing to do is try all possibilities for a size k or less vertex cover.
00:03:37.368 - 00:03:37.874, Speaker B: Okay.
00:03:37.992 - 00:03:57.394, Speaker A: So brute force is going to be proportional to n. Choose k, the number of subsets of size k of the vertices, which in the small k case is basically n raised to the k, n to the k power. Now strictly speaking, for any constant k, this is a polynomial time algorithm.
00:03:57.394 - 00:04:12.518, Speaker A: But if you think about actually running this, I mean you can't run this algorithm unless k is super small, like two or three or something like that. Okay, so even k equal ten, forget it, you could never run this algorithm. Okay, so we want to do better than this.
00:04:12.518 - 00:04:29.662, Speaker A: And so just a comment about context. So this idea of having an algorithm for an NPR problem that runs fast when some parameter is small like the optimal solution. What you're seeing here is just a glimpse of a much broader field called parameterized algorithms and parameterized complexity.
00:04:29.662 - 00:04:49.654, Speaker A: There's a whole course on that topic, CS two hundred and twenty six, taught here at Stanford, usually by my colleague Ryan Williams. So you can see a lot more examples like this in CS two hundred and twenty six. So we're just going to have this one example so you can get a taste for it, but know that there's kind of a very vibrant research field around these kind of parameterized running time bounds.
00:04:49.654 - 00:05:11.934, Speaker A: It's been actually quite lively over the last ten years or so. Okay, so by beating brute force search, what do we expect? What would we like to do? Okay, so well, we'd like the dependence on n, the graph size to be polynomial no matter what k is. Okay, so some polynomial on n.
00:05:11.934 - 00:05:33.286, Speaker A: Now we're not expecting a polynomial time algorithm for all k. That would imply p equals NP. So there's going to be some dependence on k and maybe the dependence on k is going to be not so good like exponential, but better than n to the k would be a running time bound where the terms involving n and the terms involving k are different, are separated from each other.
00:05:33.286 - 00:05:37.446, Speaker A: So in particular k does not appear in the exponent of n is what we'd like.
00:05:37.548 - 00:05:38.200, Speaker B: Okay?
00:05:38.970 - 00:06:08.898, Speaker A: And again, because we don't expect really sub exponential time algorithms for vertex cover. We would expect F to be at least exponential in k, although hopefully not worse than that or even MP. Hardness does not preclude a running time with a form polynomial in the graph size plus some presumably exponential function of the size of the set that we're looking for.
00:06:08.984 - 00:06:11.700, Speaker B: Okay? All right.
00:06:13.990 - 00:06:34.534, Speaker A: Okay, and so running times. So algorithms of this type or problems of this type are called fixed parameter tractable or FPT. So that's a buzword.
00:06:34.534 - 00:07:01.060, Speaker A: You can always look up fixed parameter tractable algorithms. Okay, so for the vertex cover problem, okay, so it turns out there's some problems which seems to admit algorithms of this form, some problems and parameters where you get algorithms of this form and some where you don't. For vertex cover, I'm going to show you next, we do get a running time of this form, even of this better one, okay? Polynomial on n, even essentially linear in n plus an exponential function of k.
00:07:01.060 - 00:07:18.390, Speaker A: And again this doesn't contradict p equal NP or anything like that because in general in the vertex cover problem, the optimal size of a vertex cover might be big, it might be like n over two. And so then if F is exponential in k, we're not getting a sub exponential time algorithm for general vertex cover. We're just doing much better when we're checking for small vertex covers.
00:07:18.470 - 00:07:19.100, Speaker B: Okay?
00:07:20.190 - 00:07:21.850, Speaker A: Any questions about the setup?
00:07:26.270 - 00:07:27.020, Speaker B: Okay.
00:07:37.250 - 00:07:46.660, Speaker A: So here's going to be the algorithm. So again, we're given an undirected graph, all costs are unit. We want to see if there's a small vertex cover or not.
00:07:46.660 - 00:08:05.400, Speaker A: So the first thing we're going to do is we're going to look at the degrees of all of the vertices, okay? And any vertex with degree at least k plus one, we're just going to put in our vertex cover so far.
00:08:06.250 - 00:08:07.000, Speaker B: Okay?
00:08:08.810 - 00:08:47.542, Speaker A: So again we're looking for say, a vertex cover of size ten, any vertex with degree eleven or more, we just sort of right up front put that in the set S, and that's without loss of generality. Do you see why it's we're checking for a vertex cover? Okay, so if we want to know if there's a vertex cover that only has ten vertices and we don't pick some vertex with degree eleven, well then to cover all of those eleven incident edges we have to pick all of their other endpoints. But that would be eleven vertices in the vertex cover and we don't have the budget for that.
00:08:47.542 - 00:09:25.150, Speaker A: Okay, so if there's a vertex cover with size at most k, it must include all vertices with degree at least k plus one. Okay, so sort of a preprocessing step. So two more preprocessing steps.
00:09:25.150 - 00:09:46.658, Speaker A: We've argued that we have no choice but to take all the vertices in S, and that means that we now don't have to worry about covering any of the edges incident to vertices in S. Okay? They're already going to be covered because we pick all of S. So to get the residual vertex cover problem, we just delete the vertices S that we've already chosen from the graph along, of course, with all of their incident edges.
00:09:46.658 - 00:10:00.410, Speaker A: So all of the edges that we delete, we've already covered all of the edges that are left in G prime we haven't covered. So the residual problem is to supplement the vertices in S by a vertex cover of G prime.
00:10:00.910 - 00:10:01.754, Speaker B: Okay?
00:10:01.952 - 00:10:13.358, Speaker A: That's where we are. All right, so the third step just says, well, G prime probably know after we've deleted all of S there might be some isolated nodes, vertices with degree zero.
00:10:13.524 - 00:10:14.142, Speaker B: Okay?
00:10:14.276 - 00:10:32.614, Speaker A: So there's no reason to pick those, right? That just means that all of the edges incident to that vertex are already covered by vertices in S, so there's literally no reason to pick this isolated vertex. It's totally redundant with our previous commitments in the set S. All right, so just like without loss of generality, we take S.
00:10:32.614 - 00:10:39.142, Speaker A: Given that we're taking S without loss of generality, we can remove all isolated nodes from G prime, call the result G double prime.
00:10:39.286 - 00:10:39.980, Speaker B: Okay.
00:10:48.590 - 00:11:32.314, Speaker A: So now we see how big G double prime is, and if it has more than k squared edges, then we assert that there's no vertex cover of size at most k. Do you see why that's true? So what's the degree of every vertex that's left in G double prime? Well, we removed all the ones with degree at least k plus one, so everybody left in G double prime has degree k or less. The degree of a vertex is exactly how many edges it covers when you pick it, assuming no redundancies with other people.
00:11:32.314 - 00:11:51.582, Speaker A: So each vertex in G prime can only cover k edges. You're only allowed to pick k of them given the budget on your vertex cover size, so there better be at most k squared edges, otherwise there is no hope. Okay, so so far so good.
00:11:51.582 - 00:12:15.030, Speaker A: So now we get to kind of like the real problem, which is G double prime. So we have part of our vertex cover S, we need to pick the rest of the vertices from G double prime, so that we cover all the edges in G double prime, which is just the vertex cover problem, but it's the vertex cover problem in a much smaller graph. So how are we going to solve it? We're going to solve it by brute force search in the smaller graph.
00:12:19.070 - 00:12:19.386, Speaker B: And.
00:12:19.408 - 00:12:45.700, Speaker A: At the end of the day we return yes, if and only if g double prime has a vertex cover of size at most k minus S. Okay? And we implement five just by brute force search, literally enumerating over all subsets of the vertices of G double prime of this size, and checking if it's a vertex cover or not.
00:12:46.550 - 00:12:47.300, Speaker B: Okay.
00:12:49.510 - 00:13:17.254, Speaker A: So that's the whole algorithm. So I've already sort of talked through the correctness so I'm not really going to write anything more down formally, but so just to review, the first claim was that any, if there does exist a vertex cover of size of most K, it has to include all the vertices in S, so without loss we can restrict attention to that. Those edges are already covered, so without loss we can delete all the edges.
00:13:17.254 - 00:13:33.214, Speaker A: Incident, to S, isolated vertices don't cover any edges. So without loss we can delete all the isolated vertices from G double prime. We're correct if we actually halt in step four again, because with that many edges and such small degrees, there's no way you could have a small vertex cover.
00:13:33.214 - 00:13:53.350, Speaker A: And then finally, the vertex covers of size of most k of the original graph are precisely S plus any vertex cover of size of most k minus size of S in the reduced graph g double prime. And we solved that by brute force search, so that's clearly correct. Okay, so any questions about that? I wasn't planning on really saying more about correctness.
00:13:53.350 - 00:14:27.042, Speaker A: Okay, all right, so what about the running time? So the running time follows from this claim if we reach step five, and of course we may not, I guess, one sort of edge case I didn't really mention. So it's possible this is negative if S had k plus one or more vertices, but then it's sort of clearly a no, right? So you need all of the high degree vertices. If there's more than k high degree vertices, then clearly there's no vertex cover of size of most k.
00:14:27.042 - 00:14:34.500, Speaker A: Okay, so if this is negative, then just think of this as being an automatic no. All right, so in step five.
00:14:36.890 - 00:14:37.206, Speaker B: The.
00:14:37.228 - 00:14:45.842, Speaker A: Size of G double prime is O of k squared. First you're saying, wait, this is obvious. It's like by definition.
00:14:45.842 - 00:14:57.926, Speaker A: Okay, but what do I mean by size? So definitely the number of edges in G double prime is at most k squared. Okay, that's because otherwise we halt. And moreover, remember, g double prime has no isolated vertices.
00:14:58.118 - 00:14:58.810, Speaker B: Okay?
00:14:58.960 - 00:15:17.278, Speaker A: So that actually means with only k squared edges it can have at most two k squared vertices. The sparsest it could be is just a perfect matching on the nodes. Okay? So the size of the graph is k squared, which means brute force search is just going to be two to the k squared, two to the O of k squared.
00:15:17.278 - 00:15:38.070, Speaker A: We pick all subsets potentially of G double prime. So the final runtime straightforward implement in O of m plus O of two to the let me do it this way two to the O of k squared.
00:15:39.790 - 00:15:40.540, Speaker B: Okay?
00:15:41.390 - 00:15:56.314, Speaker A: And this is of the promised form, okay? So polynomial time plus a function that depends only on k, the polynomial that depends on the input size is as good as it could be. It's linear time. We knew that F was going to be exponential realistically.
00:15:56.314 - 00:16:05.298, Speaker A: Otherwise we'd have a sub exponential time algorithm for vertex cover. So the best exponential, you might want an exponential that's like two to the k or even 1.5 to the k.
00:16:05.298 - 00:16:07.598, Speaker A: So here we're getting two to the O of k squared.
00:16:07.694 - 00:16:08.050, Speaker B: Okay?
00:16:08.120 - 00:16:12.882, Speaker A: So you'd like that to be better, but still just an exponential function in.
00:16:12.936 - 00:16:13.540, Speaker B: K.
00:16:15.430 - 00:16:35.894, Speaker A: A nice homework problem. So I didn't ask it to all of you this quarter, but a nice homework problem is to use some of the linear programming techniques that we were discussing last lecture and you can actually get this down to O of k. So that's sort of a really best case scenario in parameterized algorithms, right? So you get linear time in terms of the graph and just a single exponential function in terms of the parameter.
00:16:36.022 - 00:16:36.700, Speaker B: Okay?
00:16:41.330 - 00:17:06.862, Speaker A: And so this is actually a particular type of FPT algorithm. So this graph, g double prime that we constructed in fixed parameter tractable language is called a kernel. And the point is that you can take a vertex cover problem on an arbitrary graph as big as you want, and you can reduce it to the same problem on an instance size, which depends only on the parameters.
00:17:06.926 - 00:17:07.106, Speaker B: Okay?
00:17:07.128 - 00:17:25.290, Speaker A: So in this case, we reduce it to the vertex cover problem on a graph with only O of k squared vertices, you again get a kernel which is linear size in this homework problem. And so that gives you the two O of k. You only wind up doing brute force search on a graph with a linear and k number of vertices.
00:17:25.290 - 00:17:43.466, Speaker A: So this is one way of beating brute force search. And again, I just want to emphasize N to the k, which was brute force search. I mean, that's really unrealistic for any problem instance you could imagine this algorithm, you're not going to be able to solve large instances.
00:17:43.466 - 00:18:00.598, Speaker A: It's an NPR problem, so it's not surprising, but really, at least it does sort of push the tractability region quite a bit further past brute force search. Two to the k is really much, much better than n to the k. If you think of N as being even 100, it's a big, big difference.
00:18:00.764 - 00:18:01.480, Speaker B: Okay.
00:18:04.090 - 00:18:23.494, Speaker A: So various NP hard problems and various parameters, some of them have algorithms like this, some of them seem not to. So there's also sort of a subpart of complexity theory where they prove analogs of NP completeness for fixed parameter tractability. So you show things like, for example, clique and independence.
00:18:23.494 - 00:18:37.690, Speaker A: Ed is one example which is thought to not have a fixed parameter tractable algorithm. So you have these things known as w one hardness and w two hardness analogous to NP hardness, such that if you had an FBT algorithm, it would cause some other collapses which are thought to be unlikely.
00:18:37.770 - 00:18:38.014, Speaker B: Okay?
00:18:38.052 - 00:18:54.520, Speaker A: So again, I'm not going to talk about any of this, but just know that there's kind of a sort of rich literature out there, which you can see more about in CS. Two hundred and sixty six. Any questions about that? So that's the first of the three problems wanted to talk about.
00:18:57.710 - 00:18:58.460, Speaker B: Okay?
00:19:03.310 - 00:19:26.302, Speaker A: All right, so next we're going to visit the traveling salesman problem, and actually I'm going to give you an algorithm which even works in the nonmetric case, okay? So remember, the traveling salesman problem is the input is a complete graph. Undirected, every edge has a non negative cost. Your responsibility is to find a minimum cost.
00:19:26.302 - 00:19:42.530, Speaker A: Tsp tour. What's a Tsp tor? It's a simple cycle which visits every vertex exactly once. And in general, for the general version of the problem, what we saw was that it was NP hard to even approximate it to any factor alpha.
00:19:42.530 - 00:19:58.006, Speaker A: So when we talked about Tsp, what did we do? We looked at the metric special case, so we assumed that the edges satisfied the triangle inequality, and then we were able to give good approximation algorithms. We had the MST heuristic or two approximation. We have Christophe's algorithm, which was a three halves approximation.
00:19:58.006 - 00:20:16.610, Speaker A: Okay? So here we're even dealing with a non metric case. We're not going to assume that the edge costs satisfied the triangle inequality, and we're going to solve it optimally, okay? Now, of course, it's going to be an exponential time, but again, it'll be faster than brute force search. So if you have n vertices.
00:20:18.870 - 00:20:19.186, Speaker B: What.
00:20:19.208 - 00:20:43.882, Speaker A: Kind of running time are you going to get from brute force search for traveling salesman problem, it's like two to the n factorial, right? So pretty much the feasible solutions are all orderings in which to visit the vertices, and that's going to be a factorial number, and n factorial is a lot bigger than two to the n. Okay? N factorial is more like n to the n. It's not quite that bad, but it's close.
00:20:43.882 - 00:21:00.320, Speaker A: We'll talk more about that a little later. So n factorial is brute force. And what I'm going to show you next is I'm going to show you a dynamic programming algorithm which has running time n squared times two to the n.
00:21:00.320 - 00:21:17.314, Speaker A: Okay? So with n factorial, if you're on your laptop, you could probably handle input sizes with n equal to twelve, maybe to 13. And with this, you're still not going to be able to go that big, but you're going to be able to get into the 20s with this algorithm.
00:21:17.362 - 00:21:17.526, Speaker B: Okay?
00:21:17.548 - 00:21:22.038, Speaker A: So again, it extends the tractability frontier for this sort of very hard problem.
00:21:22.204 - 00:21:22.920, Speaker B: Okay?
00:21:23.930 - 00:22:08.600, Speaker A: One drawback to the dynamic programming algorithm is that it also uses exponential space. I guess two to the n space is enough, and brute force search, of course, does not, right? Brute force search is easy to implement polynomial, even near linear space. And it's actually an open question whether for the Tsp problem or even for the special case of the Hamiltonian cycle problem, whether or not there exists an algorithm with running time of the form two to the n or even four to the n or even ten to the n, some constant to the n, and simultaneously running in polynomial space.
00:22:08.600 - 00:22:13.720, Speaker A: That would be nice. We don't know if one exists. Interesting open question.
00:22:13.720 - 00:22:30.560, Speaker A: Okay, so that's the plan and again sort of the two takeaways from this of this exercise. So first of all, it's another example where it's a famous MBR problem and actually brute force search is not what you're stuck with. You can do better there.
00:22:30.560 - 00:22:39.134, Speaker A: But also it's going to be a dynamic programming algorithm. So in principle it's a little more complicated than the ones you do in CS one hundred and sixty one. But in principle you could teach this in 161.
00:22:39.134 - 00:22:45.054, Speaker A: So it's again an example where all the sort of tools in your algorithmic toolbox that you've been developing, they're just useful everywhere.
00:22:45.102 - 00:22:45.314, Speaker B: Okay?
00:22:45.352 - 00:22:51.506, Speaker A: It doesn't matter if you're doing exact algorithms that are polynomial faster, exponential time algorithms, approximation algorithms, or whatever.
00:22:51.608 - 00:22:52.260, Speaker B: Okay.
00:22:54.070 - 00:23:24.190, Speaker A: Good. So how do I want to do this? So I want to do a new board and I'm sure all of you know, last problem set due tonight at midnight. There is no exercise set number ten.
00:23:24.190 - 00:24:02.374, Speaker A: Okay? So the final just covers exercise sets one through 19. So algorithm for notational purposes, let's call the vertices of the instance one up to n. It's a dynamic programming algorithm.
00:24:02.374 - 00:24:17.422, Speaker A: So there's going to be an array that corresponding to a bunch of subproblems that we're going to populate systematically. So it's going to be a two dimensional array because as you'll see, our subproblems are indexed by two different things.
00:24:17.556 - 00:24:18.240, Speaker B: Okay?
00:24:19.170 - 00:24:42.434, Speaker A: Now as you know, sort of in dynamic programming, once you've figured out the right collection of subproblems to study so that you can solve the bigger subproblems quickly, given the solutions to the smaller sub problems, you're pretty much done. So usually you're struggling with a dynamic programming solution and then finally it all clicks when you figure out the right set of subproblems. But I'm just going to cut to the chase and sort of tell you what are the right subproblems that give you this algorithm?
00:24:42.482 - 00:24:43.080, Speaker B: Okay?
00:24:44.330 - 00:24:54.650, Speaker A: All right. So semantics of a sub problem. So again, there are two indices.
00:24:54.650 - 00:25:31.910, Speaker A: On the one hand you have a subset of v, and then on the other hand you have a vertex and in fact a vertex of S. Okay? So a sub problem is indexed by a subset of vertices s plus a vertex j. And what we want to populate this array entry with is the length of the min cost path.
00:25:31.910 - 00:26:03.540, Speaker A: So at the end of the day we want tour, but we're going to build up paths length of the min cost path such that it visits every vertex of S exactly once and it doesn't visit anyone else. So visits each k in S exactly once. It's going to start at vertex one.
00:26:03.540 - 00:26:36.860, Speaker A: So all paths begin at vertex one, and then j indicates the final vertex on this Min cost path, okay, ends at j. Now, for this to make sense, it better be the case that vertex one belongs to the set S, and it better be the case that vertex j belongs to S. Okay, so S is the vertices that you visited so far.
00:26:36.860 - 00:26:49.646, Speaker A: You're keeping track of the start point vertex one. You're keeping track of the endpoint vertex j, but you're allowing optimization over whatever order you want to visit the rest of the vertices of S in.
00:26:49.828 - 00:26:50.462, Speaker B: Okay?
00:26:50.596 - 00:27:07.480, Speaker A: So that you're sort of not keeping track of, that's what the sub problem is supposed to do. So among all ways, you can visit precisely the vertices of S in some order, starting from one ending a j. What is the minimum cost such path? Okay, so the definition of that sub problem clear.
00:27:07.480 - 00:27:21.870, Speaker A: Okay, now for subproblems to sort of work out, you need a few different things going on. Oh, I should say so. Most of the dynamic programming algorithms that you've seen are probably polynomial time algorithms.
00:27:21.870 - 00:27:36.394, Speaker A: This is an NB hard problem, so we're not expecting it to be polynomial. And so therefore, we're maybe not surprised to notice that the number of subproblems is exponential in N. So if you think about S, there are two to the N, different possibilities for the subset S of vertices.
00:27:36.394 - 00:28:15.794, Speaker A: But again, two to the N, n for all choices of J, two to the N for all choices of S. Okay, so one thing that better be true about the subproblems is that if we solve all the subproblems, we should have solved the original problem. I e the min cost tsp tor.
00:28:15.794 - 00:28:23.770, Speaker A: Okay, but in fact, the cost of the Min cost Tsp tor is easy to read off from the solutions of the biggest subproblems, where S is equal.
