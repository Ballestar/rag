00:00:00.250 - 00:00:06.910, Speaker A: Hi, everyone. Welcome to this video that accompanies section 20.4 of the book algorithms Illuminated part four.
00:00:06.910 - 00:00:29.160, Speaker A: It's a section about the two hop heuristic for the Tsp. So NP hardness is always a drag, but at least in those last few problems that we studied. So make span minimization the maximum coverage problem and the influence maximization problem, at least in all three cases, we did have fast heuristic algorithm that enjoyed approximate correctness guarantees that had an insurance policy.
00:00:29.160 - 00:01:04.990, Speaker A: Unfortunately, there's a bunch of other NP hard problems, including the traveling salesman problem, where we don't expect there to be fast algorithms with such approximate correctness guarantees, where in fact, such an algorithm would refute the P not equal to NP conjecture. So if that's the kind of problem you're dealing with and you really want a fast algorithm, your only choice is to design a heuristic algorithm that, while having no insurance policy, at least performs well on most or all of the inputs that arise in your application. So local search, along with its many variants, is one of the most powerful and flexible techniques of this type.
00:01:04.990 - 00:01:19.730, Speaker A: So I'm not going to tell you what I mean by local search just yet. Instead, what I want to do is in this pair of videos, I want to develop from scratch a heuristic algorithm for the traveling salesman problem. And it's going to force us to develop a number of new ideas.
00:01:19.730 - 00:01:45.040, Speaker A: Then in the next pair of videos, I want to zoom out and we'll identify the ingredients of that TSB heuristic algorithm that exemplify the principles of local search. Then, armed with a template for applying local search along with a specific instantiation for the traveling salesman problem, you'll be well positioned to apply this technique in your own projects. So let me just remind you real quick about the definition of the traveling salesman problem.
00:01:45.040 - 00:02:00.180, Speaker A: So the input to the problem is a complete undirected graph. So there's some number N of vertices and all N choose two undirected edges are present. Moreover, each of those edges has a real valued cost, just like in, say, the minimum spanning tree problem.
00:02:00.180 - 00:02:16.790, Speaker A: And the goal then is to compute a tour. And by a traveling salesman tour, what we mean is we mean a cycle that visits every vertex exactly once. So you start somewhere, then over the course of N hops, you visit all of the rest of the vertices and come back to where you started.
00:02:16.790 - 00:02:34.430, Speaker A: And of all the tours, you want to identify the one that minimizes the sum of the edge costs. So the traveling salesman problem, the Tsp, it's a very famous problem. So if you're wondering why we never discussed it in the first three parts of this book series, well, it's because, unfortunately, it's an NP hard problem.
00:02:34.430 - 00:03:01.960, Speaker A: We will actually prove this ourselves once we get to the relevant part of the video playlist corresponding to chapter 22. But for now, let's take it on faith that Tsp is NP hard, we're going to need to compromise on either correctness or speed. So to get a feel for how we might come up with a heuristic algorithm for the Tsp, let's in this quiz explore maybe the simplest one you might think about sort of an analog of prim's algorithm but for the Tsp problem.
00:03:01.960 - 00:03:29.710, Speaker A: So it's going to be a greedy heuristic and it's a heuristic known as the nearest neighbor heuristic for the Tsp. So you just start wherever you want at your favorite vertex, call it little A, and then you just build up a tour one edge at a time in the greedy kind of myopic way. So from the starting vertex A, you have N minus one of the vertices you can travel to next, and you just go to the one which is closest to you, the one for which the corresponding edge has the smallest possible cost.
00:03:29.710 - 00:03:40.098, Speaker A: At that point you visited two vertices, there's N minus two left. Among all those N minus two vertices you go to the one that's closest. So the one where the edge is as small as possible and then you just repeat that.
00:03:40.098 - 00:03:57.126, Speaker A: So after you've repeated it N minus one times, at that point you have a path that visits every vertex exactly once. And then of course, in the final step you got to go back to where you started so that's the nearest neighbor heuristic for the Tsp. So next I would like you to work out what the nearest neighbor heuristic is going to do.
00:03:57.126 - 00:04:16.110, Speaker A: In this five vertex example, I'm going to draw on the right part of the slide. In addition to figuring out the output of the nearest neighbor heuristic, I'd like you to figure out what is the best the minimum cost traveling salesman tour. So take a few seconds, work both of them out, and then we'll discuss the solution.
00:04:16.110 - 00:04:47.578, Speaker A: So the answer is A, the minimum possible torque cost is 23 and the tor cost of the nearest neighbor heuristic is 29. Let's see those two facts in reverse order. So let's start with the nearest neighbor heuristic.
00:04:47.578 - 00:05:09.510, Speaker A: So the nearest neighbor heuristic is going to start at the vertex A and it looks at the other four vertices and it says, hey, the cheapest edge in the whole graph is adjacent to me and it takes me to B. So that's certainly what I'm going to be taking in the first iteration of the nearest neighbor heuristic. Now, once the tor reaches B, it has to decide whether it's going to go to C or D or E.
00:05:09.510 - 00:05:25.354, Speaker A: Next. Amongst those three vertices, B is closest to C, cost only two to get to C, whereas it would have cost three or six to get to D or E, respectively. Now that the tour is at C, there's only two options left.
00:05:25.354 - 00:05:47.714, Speaker A: It has to go next to either vertex D or vertex E, neither one's that great an option but the better of the two options is to go to E next along the edge, that has cost seven. And from here on out, the tour is the choices are forced. So there's only one unvisited vertex at this point, so it's got to go from E to D, and then, of course, it has to return to the starting point.
00:05:47.714 - 00:06:08.162, Speaker A: So finally, it goes from D to A. So the nearest neighbor heuristics tour just follows the perimeter, and its overall cost, if you add it up, is indeed 29. So how about the optimal tour? Well, it's not necessarily immediately obvious, but if nothing else, there's only twelve options.
00:06:08.162 - 00:06:29.136, Speaker A: So you can just do exhaustive search over the twelve. And there is one that has cost 23, and I'll trace that out here in Magenta. So what's the takeaway from this quiz? Well, we see in this concrete example that the nearest neighbor heuristic need not compute a minimum cost traveling salesman tour.
00:06:29.136 - 00:06:37.448, Speaker A: We're hardly surprised by that fact. I've told you that the Tsp problem, that the Tsp is NP hard. This algorithm obviously runs in polynomial time.
00:06:37.448 - 00:06:59.320, Speaker A: So if it were always correct, that would refute to P, not equal to NP conjecture. We're not expecting that to happen. However, unlike the three heuristic algorithms we've seen so far, which had good approximate correctness guarantees, this greedy algorithm may be nowhere near the best possible tour to see that, remember that the last hop of this tour was forced.
00:06:59.320 - 00:07:30.520, Speaker A: So even if that last hop from D to E had cost a billion, this tour still would have wound up taking that edge because that was the only option left to it after it traversed the rest of the perimeter. So that would be a pretty terrible example for the nearest navy heuristic. Now, you could imagine using a more sophisticated greedy algorithm to escape this particular example, but unfortunately, all greedy algorithms, indeed all polynomial time algorithms, seem to suffer a similar fate in more complicated instances of the Tsp.
00:07:30.520 - 00:08:21.530, Speaker A: So can we do better? Well, here's one natural idea, which is who says we have to stop as soon as the nearest neighbor heuristic ends? What if we take that heuristic's tour as a starting point and greedily look for ways to improve it further? So, to understand how that might work in this quiz, I want you to think about what is the minimal modifications you could make to a tour to get a different tour. So the answer to this quiz is the third one. So two tours of N vertices can share n minus two edges, but no more than that.
00:08:21.530 - 00:08:45.742, Speaker A: So why can't they share n minus one edges? Well, it's because once I tell you n minus one of the edges of a tour, it uniquely determines what the last one must be, right? The only way to turn it into a tour is to take two endpoints and connect them directly. So if two tours share n minus one edges, they have to actually share all edges and are not distinct. On the other hand, you can have distinct tours that differ in only two edges.
00:08:45.742 - 00:08:56.390, Speaker A: So let's see an example on a five vertex instance. So on the one hand, you could imagine a five cycle. So this is like going around the perimeter of our example in the previous quiz.
00:08:56.390 - 00:09:10.300, Speaker A: Or you could have this light blue tour, which uses three of the edges on the outer perimeter and uses two that are sort of internal crossing edges. So that would be two different tours, both the five vertices with three edges in common. And that's the most you can have.
00:09:10.300 - 00:09:38.840, Speaker A: So remember the point of this quiz, right, we sort of weren't happy with the nearest neighbor heuristic, but then we asked, why do we have to stop with its output? Why can't we just greedily improve it further? So we wanted to know the minimal change that might lead us to a better tour. And in that quiz, we saw that two edges you might be able to remove and then put in a different pair of edges that conceivably could give you a better tour. So that type of modification, taking two edges out and putting two different ones back in, that's known as a two change.
00:09:38.840 - 00:09:54.570, Speaker A: So how exactly does a two change work where you're given some initial tor, capital T, and you're just going to remove two edges from it and then plug into different edges. So you want to pick two edges, they should all have different endpoints. So one edge was going to be V comma w, the other one's going to be U comma x.
00:09:54.570 - 00:10:02.862, Speaker A: So four distinct endpoints, you're going to take them out. That will disconnect your tour into two paths. So four endpoints total.
00:10:02.862 - 00:10:17.940, Speaker A: Between the two paths, there's a total of three different ways to pair up four vertices. One of them will give you the tour you started from, one of them will give you two disjoint cycles, which is not a tour. And then the third one will give you a new tour and that's the one that you want.
00:10:17.940 - 00:10:37.670, Speaker A: So for example, in this cartoon I've shown on the slide, right, v currently is paired with W. And so the two candidate changes are to pair V instead with x or to pair V instead with U. If we pair V with X and therefore pair U with W, then we get a new tor using these two magenta edges.
00:10:37.670 - 00:10:49.258, Speaker A: But if we pair V with U and then being forced to pair W with X and we add these green edges, then we don't get a feasible solution. So we just get two disjoint cycles. So that's certainly not what we want to do.
00:10:49.258 - 00:10:59.966, Speaker A: So that's what a two change is. You take these two blue edges and then you put in the corresponding magenta edges to get a new tour. So naturally, modifying a tour can change its total cost.
00:10:59.966 - 00:11:21.446, Speaker A: So what is the drop in tor cost that we get from a given two change? Well, the good news is that we remove the edges v comma w and U comma x. So the torque cost is going to drop by whatever the cost of those edges were that we were paying before. On the other hand, we've plugged in these new edges, in the example at least, u comma w and V comma x.
00:11:21.446 - 00:11:37.638, Speaker A: So those are edges that we now have to pay for. So those gets subtracted off of the decrease in torque cost. So we're interested in two changes where this decrease is positive, where the sort of benefit of the edges that we've removed outweighs the cost of the new edges that we added.
00:11:37.638 - 00:11:57.710, Speaker A: If you have a two change with that property, a two change that strictly decreases the torque cost, we're going to call that an improving two change. So now you can probably guess what the two opt heuristic for the TSB is. You just initialize it with an arbitrary tor, for example, maybe the output of the nearest neighbor greedy heuristic.
00:11:57.710 - 00:12:13.750, Speaker A: And then you keep greedily improving the tour further as long as you can, where in each improvement you make the minimal modification necessary to get a new tour. That is, you make a two change and the two change should be improving. Meaning the cost of the edges that you remove should exceed the cost of the edges that you stick in.
00:12:13.750 - 00:12:30.714, Speaker A: You keep doing that for as long as you can. When there's no more improving two changes, you stop and return that as your final tour. So in the pseudocode by two change, I mean the subroutine that takes in as input a tour and two edges of that tour that share no endpoints and then executes the corresponding two change.
00:12:30.714 - 00:12:44.510, Speaker A: So removes the given edges v comma w and U comma x and then adds the pair of edges that gives you a new tour. So pairing up V either with U or with X and then with the other one, whichever one gives you a new tour. Bye.
