00:00:00.330 - 00:00:11.114, Speaker A: Today we're going to begin a series of lectures on clustering. So this is one of the motivating problems that I mentioned back in the very first lecture. Informally, the goal is to somehow find meaningful clusterings.
00:00:11.114 - 00:00:34.054, Speaker A: And the hope is that in instances that we care about where meaningful clusterings exist, we can have novel algorithms that exploit the structure that the existence of those clusterings implies. So today we're going to talk about results from a paper of Bulk, blum and Gupta, there's actually been an explosion of work on this topic over the past five years. We'll be serving not all of it, but some of the rest of it over the next couple lectures as well.
00:00:34.054 - 00:00:53.520, Speaker A: But this is the one that we'll focus on today. So we're going to be thinking about metric spaces, so meaning points that have a notion of distance between them. So the computational problem is going to be defined by an endpoint metric space.
00:00:53.520 - 00:01:07.602, Speaker A: So there's a set capital x. These are the points, and then there's a distance function, D. Okay, so D assigns a non negative real number to every pair from x.
00:01:07.602 - 00:01:27.000, Speaker A: So, for example, maybe x, maybe that's a bunch of images. Maybe D is some function you've concocted which says how similar or dissimilar two images are. Okay, so remember, in a metric space, really the key property is the triangle inequality, which just says that the shortest distance between any two points is a straight line.
00:01:27.000 - 00:01:39.366, Speaker A: So adding an intermediary stop z between x and y can only make things take longer. So we'll use the triangle inequality several times in today's lecture. The other things are just it's symmetric.
00:01:39.366 - 00:01:47.726, Speaker A: So the distance from x to y is the same as the distance from Y to x. And then usually you say that the distance is zero if and only if the two objects are identical. That's not really going to be important.
00:01:47.726 - 00:02:02.558, Speaker A: So triangle equality is really the thing to remember. Okay, all right, so how do we formalize this idea of finding meaningful clusterings? When you talk about algorithms, you talk about optimization. Sometimes they're objective functions.
00:02:02.558 - 00:02:17.960, Speaker A: They're optimization problems, which you can take very literally. So sometimes really the problem you're trying to solve for the company is to figure out the minimum cost way of accomplishing some task over a set of feasible ways of doing it. And then you literally care about that objective function value.
00:02:17.960 - 00:02:40.030, Speaker A: Then there are other problems like clustering, where the goal is more qualitative. You more want coherent groupings of points that make sense, right? So you want to throw in a bunch of images to an algorithm, and you want it to tell you which are the cats and which are the dogs. You want to throw in a bunch of proteins, and you want it to correctly tell you you want it to group these proteins by their function.
00:02:40.030 - 00:02:56.360, Speaker A: So there's not a numerical objective function that you might obviously define for that problem, or rather, there's several you could try. So the point here so the goal is qualitative. I'm not going to write it down again since it's right here.
00:02:56.360 - 00:03:20.842, Speaker A: Compute meaningful clusterings. And if you approach this problem, as many people do, by positing an objective function, positing an optimization problem and then solving it, you care about the solution to that problem only inasmuch as it comes back with a meaningful clustering. You do not care about the objective function value of the solution per se.
00:03:20.842 - 00:03:30.270, Speaker A: You could care less. Conversely, if you solve it optimally and the optimal clustering under the objective function is meaningless, you don't care.
00:03:30.340 - 00:03:30.526, Speaker B: Okay.
00:03:30.548 - 00:03:51.430, Speaker A: It does you no good. Basically, that would just tell you that you phrased the wrong question. Okay, so how are we going to grapple with this? So how can we have some kind of theory which strives to find these meaningful clusterings? Well, here's the first assumption.
00:03:51.430 - 00:04:02.566, Speaker A: We're going to assume that along with this metric space which we know, there is something which we don't know, namely a target clustering or a ground truth.
00:04:02.678 - 00:04:03.340, Speaker B: Okay?
00:04:06.910 - 00:04:20.778, Speaker A: So we're going to assume that this exists. We don't know what it is, and we'd like to find it given this distance information. Okay, so that's the first major assumption.
00:04:20.874 - 00:04:21.520, Speaker B: Okay.
00:04:25.350 - 00:04:45.426, Speaker A: All right, again, for example, you really want maybe there is some division into cats and dogs, proteins by function, et cetera. And really historically, in pure optimization, this isn't so much how people think. So one of the contributions of Balkan, Blume and Gupta, they weren't the first to do this, but they really kind of highlighted this point, which is, look, in other fields there are these notions of ground truth.
00:04:45.426 - 00:05:06.494, Speaker A: Let's try that in the sort of formal theory of algorithms and see if we get interesting questions. And we do. Okay, so so the goal then is we want an algorithm, a polynomial time algorithm that approximately ideally, we'd love to recover this.
00:05:06.494 - 00:05:10.698, Speaker A: Exactly. Realistically, we're going to try to recover it approximately.
00:05:10.794 - 00:05:11.440, Speaker B: Okay?
00:05:16.710 - 00:05:34.182, Speaker A: So that's what we want. Now, for an algorithm to have any hope of accomplishing this goal, there have to be some clues in the input. There has to be some relationship between the input that you're given and what the ground truth clustering is.
00:05:34.182 - 00:05:51.918, Speaker A: If it's just some secret that has nothing to do with the input, you're not going to be able to just guess it out of thin air. Okay, so we need to then introduce a relationship between what the input looks like and what the ground truth clustering is. So the big assumption, or like the key definition, is a formal link between these two.
00:05:51.918 - 00:06:07.140, Speaker A: All right, so I'll state it informally first. So the assumption is going to be that every near optimal clustering and here when I say near optimal, I mean in the sense of some objective function. And I'll tell you the objective function in a second.
00:06:07.140 - 00:06:10.770, Speaker A: So with respect to an objective.
00:06:11.190 - 00:06:11.940, Speaker B: Okay.
00:06:13.750 - 00:06:51.550, Speaker A: So every near optimal clustering is close to the target in the sense that it clusters the points in almost exactly the same way. Okay, so what the assumption is saying, it's saying if you compute a clustering which is numerically according to some objective function almost as good as the ground truth clustering, then that implies that structurally it is also almost as good as the ground truth clustering. Okay, so approximation of a numerical objective implies approximation in the structural sense, the classification sense.
00:06:51.620 - 00:06:51.854, Speaker B: Okay?
00:06:51.892 - 00:07:05.902, Speaker A: So that's an assumption. One way to think about this or a very cartoonish way to think about this, is we somehow want the right answer to stick out. We don't want there to be any kind of second best alternatives that might confuse us too badly.
00:07:05.902 - 00:07:40.046, Speaker A: So if you really just think about sort of plotting a single function, and again, this is just a cartoon, but you somehow imagine that different points on the x axis are structurally similar, and you imagine that this is some objective function that we want to maximize. Well, clearly the highest this gets is right here. But importantly, the only way you can get close to the maximum, so say anywhere above this curve is to be somewhere in the domain which is close to the maximum point.
00:07:40.046 - 00:07:45.594, Speaker A: There is no, for example, local maximum that's almost as good very far away from the global maximum.
00:07:45.642 - 00:07:45.806, Speaker B: Okay.
00:07:45.828 - 00:07:49.118, Speaker A: There are other local maximum, but they're kind of quite a bit worse than the global maximum.
00:07:49.214 - 00:07:49.810, Speaker B: Okay?
00:07:49.960 - 00:08:04.854, Speaker A: So this is one way you can just, in a very cartoonish way, think about this. All right? So if you get close to the maximum, you get close in value, you get close to the optimal in structure. Okay, so that's the idea.
00:08:04.972 - 00:08:05.574, Speaker B: All right? Yeah.
00:08:05.612 - 00:08:08.162, Speaker C: So the target is also the global maximum.
00:08:08.306 - 00:08:14.154, Speaker A: It actually doesn't matter. So it's not going to matter. Go ahead and think of it that way.
00:08:14.154 - 00:08:20.780, Speaker A: And I'll actually just explicitly assume it, but it's really for ease of exposition. So think of the target as being the optimal for optimization problem.
00:08:21.490 - 00:08:33.650, Speaker C: Something like clustering cats and dogs. Seems like the optimal is not so much better than all the other solutions. Like if you're off by one cat or two cats or three cats.
00:08:36.230 - 00:08:43.614, Speaker A: That's a good comment. Excellent comment. This is exactly why we want to have all these approximations.
00:08:43.614 - 00:08:57.218, Speaker A: It's an excellent comment, which is if you take the best clustering and then I just kind of move it a little bit, it's still going to be a great clustering. It's also still going to have a great numerical objective function value for reasonable objective functions. So a different way of saying it is it's clear that you can't.
00:08:57.218 - 00:09:15.006, Speaker A: So a stronger statement would be you have one optimal clustering numerically and nothing else is even close to it numerically. You'd love to just say, oh, as long as you have this huge gap and your argument has shown that's too strong. If you take an optimal clustering and you perturb it a little bit, you're going to get something which is almost as good.
00:09:15.006 - 00:09:31.810, Speaker A: So that's why we need to kind of say the only way you can be almost as good is through that kind of perturbation process. The only linear optimal solutions are small perturbations of what we want, as opposed to taking the optimal solution, doing some massive rearrangement of everything and then getting something almost as good. That's exactly what we want to exclude.
00:09:34.310 - 00:09:35.060, Speaker B: Okay.
00:09:37.130 - 00:09:50.386, Speaker A: So this is not math yet. So first of all, this definition only makes sense once you've settled on an objective function. So we're going to use one of the standard clustering objective functions.
00:09:50.386 - 00:09:54.442, Speaker A: There are analogous results for other objective functions, other popular ones as well.
00:09:54.496 - 00:09:54.666, Speaker B: Okay?
00:09:54.688 - 00:10:05.110, Speaker A: But for this lecture we're just going to focus on one of them, which is called the k median objective. Basically the k median objective is the sum of the nearest neighbor distances.
00:10:05.190 - 00:10:05.446, Speaker B: Okay?
00:10:05.488 - 00:10:13.886, Speaker A: So we're going to be picking k clusters. Each cluster has a center. Every point gets assigned to its nearest neighbor cluster, and then we just add up the resulting nearest neighbor distances.
00:10:13.886 - 00:10:31.190, Speaker A: We want that to be as small as possible. So formally the goal is we choose a set s of k centers. So these are points from the metric space that we now designate specially as centers.
00:10:31.190 - 00:10:53.760, Speaker A: And then we look at the rest of the points, or we look at all of the points and we look at the sum of the nearest neighbor distances. Okay, so for a given x, I look at the minimum over all of the centers of the distance between x and that center. So this is the objective function.
00:10:53.760 - 00:11:07.490, Speaker A: You want to choose s. You want to choose these case centers so that if everybody's assigned to centers in the obvious way by shortest distance, then the sum of the distances is as small as possible. Okay, so we want these like tightly knit clusters.
00:11:07.490 - 00:11:21.478, Speaker A: So we want all these distances to be small. That means then they're in these tiny little clumps. Okay, so there is no sort of unique vast clustering objective function, but this is definitely amongst the top two or three most commonly used ones.
00:11:21.564 - 00:11:22.054, Speaker B: Okay?
00:11:22.172 - 00:11:53.570, Speaker A: So if you're a fan of k means instead you can also derive results. The details are different, but the same theory can be executed for something like the k means objective function. So any questions so far? All right, so let's continue making this idea precise, that numerical approximation of now we know the k median objective function, we want to translate to structural approximation.
00:11:53.570 - 00:12:47.060, Speaker A: So here's the formal statement of the key definition, that of being c epsilon stable. So we say that a given target clustering, okay? So we have a metric space, we have a target clustering. We're thinking about the K median objective, and we say that the target clustering is C Epsilon stable if here C here is at least one if every C approximates K clustering, meaning every solution to this problem where the objective function value is no more than a C times the minimum possible.
00:12:47.060 - 00:13:01.030, Speaker A: Every C approximate K clustering agrees with the target on almost all of the points, namely a one minus epsilon fraction.
00:13:05.690 - 00:13:06.246, Speaker B: Okay?
00:13:06.348 - 00:13:10.810, Speaker A: So I'll also occasionally say this is an epsilon accurate cluster.
00:13:12.430 - 00:13:13.180, Speaker B: Okay.
00:13:19.550 - 00:13:29.326, Speaker A: So one quick detail. So a k clustering just means a partition of the point set into k groups. Okay, that's what I mean by a k clustering, I should say.
00:13:29.326 - 00:13:47.234, Speaker A: So for this whole lecture, we're going to be thinking of k, the number of clusters as known, which one often does in practice. Perhaps you have domain knowledge, so you have a guess of what k should be you're looking for really just two groups or and again, this is done in practice a lot. You just run an algorithm for many different choices of k and see which one give you the best results.
00:13:47.282 - 00:13:47.446, Speaker B: Okay?
00:13:47.468 - 00:14:08.410, Speaker A: You basically do it 20 times and look at which one seems the most sensible. All right, so think of k as known throughout this lecture. So one detail is so what does it mean that two k clusterings classify the points in almost the same way? So suppose I give you one group of k clusters and another group of k clusters.
00:14:08.410 - 00:14:26.478, Speaker A: So if you think about it where you're like, okay, let's match them up, let's find the correspondence so that they agree as much as possible. So you basically find a matching between this partition into k groups and this partition into k groups. And if two clusters are matched, you get one point for each data point which is in common to both of those clusters.
00:14:26.478 - 00:14:42.742, Speaker A: Okay, so you basically just take the correspondence between the two sets of k groups that maximizes the number of commonly classified points. So that's what I mean by correctly classifying a one minus epsilon fraction. There's a way to associate the clusters in the first clustering with the clusters in the second clusterings, say, labeling them one through k.
00:14:42.742 - 00:14:53.980, Speaker A: So that for a one minus epsilon fraction of the points, it gets exactly the same label in both of the two clusterings. Okay, so that's what I formally mean by being epsilon accurate. Good.
00:14:53.980 - 00:15:23.102, Speaker A: So quick question. So does this definition or this requirement, does it get more or less stringent as I increase c more? So as I increase c, there are more and more clusterings that have to satisfy this epsilon accuracy condition. Okay, so there's more three approximate clusterings than there are two approximate clusterings.
00:15:23.102 - 00:15:45.718, Speaker A: So I'm insisting on this condition for more and more things. How about as I bring epsilon up, does the definition get more or less stringent less? Right, because you can misclassify more things. Okay, so it's harder instances are less likely to satisfy this definition the more you ratchet up c and the sort of more you ratchet down epsilon.
00:15:45.814 - 00:15:46.460, Speaker B: Okay.
00:15:47.550 - 00:16:00.526, Speaker A: Any other questions about that? So I hope you see the correspondence. This is the numerical closeness and this is the structural closeness. An instance may or may not satisfy this property.
00:16:00.526 - 00:16:15.446, Speaker A: We're positing I'll say more about this, we're positing that hopefully real world instances have this property, the ones that we would like to solve, and secondly, instances that satisfy this property are somehow easier than worst case instances. Okay, that's sort of the high level point.
00:16:15.548 - 00:16:16.200, Speaker B: Okay.
00:16:18.010 - 00:16:50.000, Speaker A: All right, so one question is to what extent is this a reasonable definition, a reasonable condition? Oh, yeah, I should give you some parameters you might want to think of these as representing. So these are just generic everything we say today, you can instantiate with whatever values you want. I always like to keep concrete instantiations in my mind when I'm in a lecture like this.
00:16:50.000 - 00:16:56.762, Speaker A: C, maybe think of C as 1.1. Okay, so you're talking about 10% numerical error.
00:16:56.826 - 00:16:57.054, Speaker B: Okay.
00:16:57.092 - 00:17:01.762, Speaker A: Clusterings think of epsilon. I actually want you to think of epsilon as quite small. Okay.
00:17:01.762 - 00:17:16.822, Speaker A: I actually want you to think of epsilon as going to zero as the point set goes to infinity. So if there's n points, think of epsilon as like one over root n. Okay, so misclassifying an epsilon fraction of the points, that means misclassifying epsilon times n points.
00:17:16.822 - 00:17:29.466, Speaker A: So if epsilon is one over root n, that's misclassifying root n points. If n is a million, it means I allow you to misclassify 1000 points. Okay, so those are some numbers you want to keep it might want to keep in mind c 1.1,
00:17:29.466 - 00:17:57.362, Speaker A: n equal 1000 and then epsilon equal one over 1000. Okay, so to what extent is this definition reasonable? To what extent is this definition useful? So the first question might just be do you expect real data to satisfy this condition? Okay, and there's sort of different interpretations of that question. So first, for a lot of parameter values, this is a pretty strong condition, actually, and we'll sort of exploit that as we go through the lecture.
00:17:57.362 - 00:18:20.422, Speaker A: So if you mean do we expect real data to literally satisfy exactly this definition, yeah, maybe not. Maybe not completely. What's worse if you wanted to criticize it, is you're not going to be able to check if a given data set meets this condition or not because it's referencing these optimal solutions, which I'll say more about this in a second, which is empty, hard to compute.
00:18:20.422 - 00:18:32.266, Speaker A: Okay, so there's a strong analogy here with the recoverable value for independent sets. We talked about Monday. The parameter there, the condition there was basically saying the optimal independent set should have low degrees.
00:18:32.266 - 00:18:49.078, Speaker A: Of course, we didn't know what the optimal independent set was. So it's sort of a faith based analysis. We're just saying, well, whenever the instance has this property, and maybe for other instances as well, but certainly whenever the instance has this property we'll do well, okay, so those are some criticisms, is that taken literally, it's pretty strong and you can't really check it.
00:18:49.078 - 00:19:14.358, Speaker A: Now, on the other hand, and it's several things in its defense. Again, like the recoverable value, there is at least some kind of plausible narrative about why real world instances might at least be kind of nudging in the direction of a condition like this. Okay, so what would it mean if this is false for something doesn't have the stability property? It means you can have two structurally very different clusterings that give you basically the same objective function value.
00:19:14.358 - 00:19:42.034, Speaker A: And the claim is that probably wasn't the kind of clustering instance you were hoping to set up and solve, right? If you're trying to classify cats and dogs and there's a 10% of the cats which if you put with the dogs and then conversely, 10% of the dogs should go with the cats and that's just as good an objective clustering according to your objective function as the perfect classification of cats and dogs. You probably screwed up the problem formulation or your data is quite noisy. Okay, so that's sort of the plausibility argument.
00:19:42.034 - 00:20:05.786, Speaker A: When this fails, it doesn't really gel with our intuition about kind of the target clusterings that we have in mind in our clustering formulations. The other thing I want to mention is just like with a recoverable value for whatever criticisms it has, at the end of the day, it naturally led us to design this completely new algorithm. This algorithm where we took the random permutation and then we sort of had this forest, and then we computed exactly in the forest.
00:20:05.786 - 00:20:29.106, Speaker A: No one had ever thought of that algorithm before. I'm not going to argue you need the recoverable value to come up with that algorithm, but it definitely led people to a new algorithm that seems potentially useful for a 50 year old problem. So remember, at the end of the day, the way to evaluate some kind of condition like this is you say, does it help us, first of all, understand existing algorithms better? We won't really do that with this definition.
00:20:29.106 - 00:21:00.286, Speaker A: Second of all, does it guide you to potentially useful algorithmic ideas? And in that sense, I'll try to convince you that this has been a good definition. Okay, so that's the sort of merits and demerits of this, I think, on the reasonableness access. Okay, so what should we be shooting for? What would be an interesting result about recovering clusterings in C epsilon stable instances? Well, let me show you what's easy to do.
00:21:00.286 - 00:21:35.130, Speaker A: Okay, so suppose you have just off the shelf, suppose you just sort of Googled K median approximation algorithms and checked out some nice algorithms people designed in the last decade that run in polynomial time, because this is an empty hard problem. I'll say more about that in a second. But so there are algorithms that run in polynomial time and are guaranteed to output a solution that's at most C times this than the minimum possible for reasonable constant C, c like three, okay? Even a little bit less so if you run one of these algorithms.
00:21:35.130 - 00:21:48.030, Speaker A: So suppose you run a C approximation algorithm. So again, this means guaranteed to always produce a solution no more than C times as costly as the optimum. If you run such an algorithm.
00:21:49.810 - 00:21:50.126, Speaker B: On.
00:21:50.148 - 00:22:18.490, Speaker A: A c epsilon stable instance, well, then by the definition of C epsilon stability, you're going to get back almost the target clustering just by definition, okay? We've assumed that all such solutions in this instance are epsilon accurate, so yields an epsilon accurate clustering.
00:22:22.030 - 00:22:22.780, Speaker B: Okay?
00:22:23.790 - 00:22:38.414, Speaker A: So think of C as like three for this state, okay? So that's a general purpose algorithm. It gives you a three approximation whether it's a stable instance or not. It just so happens that if you input a stable instance, you get this very nice interpretation of what it does.
00:22:38.414 - 00:23:10.102, Speaker A: So for this, we don't have to do anything, okay? This is really just a reinterpretation of known results. So if we really want to say that this definition led us to come up with new algorithms in the spirit of the recoverable value, what seems like the interesting what kind of would be interesting would be to get would be to recover target clusterings for even smaller values of c than what general purpose approximation algorithms can.
00:23:10.236 - 00:23:11.000, Speaker B: All right.
00:23:13.550 - 00:23:49.190, Speaker A: And there is hope that specialized algorithms tailored to stable instances could go beyond general purpose algorithms because there are barriers to how well you can approximate k median. On worst case instances, it is known for k median to be NP, hard to approximate better than one plus two over E, where here E is 2.718, et cetera.
00:23:49.190 - 00:24:11.866, Speaker A: Okay, so this is probably something like 2.74 or something, sorry, 1.74. Okay, it's not known how to get 1.74,
00:24:11.866 - 00:24:15.470, Speaker A: but we can get pretty close. Okay, it is known how to get 2.7 or something like that.
00:24:15.470 - 00:24:19.038, Speaker A: One plus root three, if you must know, is what's known on the upper bound side.
00:24:19.124 - 00:24:19.854, Speaker B: Okay?
00:24:20.052 - 00:24:45.858, Speaker A: But so the point is if you say, well, so remember, the bigger C is, the more stringent the assumption, okay? So there's going to be instances which are 1.5 epsilon stable for some value of epsilon and are not two comma epsilon stable, okay? And if you're only 1.5 epsilon stable, this basically says you're out of luck.
00:24:45.858 - 00:25:04.030, Speaker A: There will never be general purpose k median instances so that it'll guarantee recovery of your target clustering. Your stability condition just isn't strong enough, okay? So using general purpose algorithms gets stuck at 1.74. So if we want to be able to recover below 1.74,
00:25:04.030 - 00:25:25.458, Speaker A: we need necessarily, unless we're going to prove p equal NP, we need to develop algorithms that are just, they have to be new, okay? They have to be tailored to take advantage of whatever's special about stable instances, okay? And again, we had nanologue on Monday where we had this recoverable value. We had the randomized greedy algorithm. It got a constant of one.
00:25:25.458 - 00:25:31.960, Speaker A: It was no better than one. To beat one, we had to come up with a new algorithm. We're seeing exactly the same thing unfold here.
00:25:33.210 - 00:25:33.622, Speaker B: Okay?
00:25:33.676 - 00:25:37.830, Speaker A: So that's the goal. So that's what we want to do. This lecture.
00:25:49.890 - 00:25:50.640, Speaker B: It.
00:25:58.530 - 00:26:16.834, Speaker A: And I'll show you that we can actually do this for arbitrarily small fixed constants c, as long as N is going to infinity and epsilon is going to zero with n. Okay? So we can do 1.1, for example, which there's no way you can do it via general purpose algorithms.
00:26:16.834 - 00:26:29.660, Speaker A: Okay, so that's the really good news. All right, so any questions about what we're trying to do?
00:26:30.430 - 00:26:33.610, Speaker C: Yeah, it's pretty much like agnostic of epsilon.
00:26:34.910 - 00:26:44.590, Speaker A: Good question. The answer is subtle, so I'll answer that explicitly, but let me get there. Yeah, good.
00:26:44.740 - 00:26:45.102, Speaker B: Right.
00:26:45.156 - 00:26:56.298, Speaker A: So in our minds we're thinking that we're only operating on these stable instances. The hope why we might do better. Well, if there's a meaningful clustering, presumably that means there's extra structure in the instance.
00:26:56.298 - 00:27:16.150, Speaker A: Maybe we can detect it in the algorithm and exploit it to do better than on worst case instances. That's what we're hoping is true. I want to just digress briefly to compare and contrast what we're doing right now and what we're doing in this lecture with the parameterized analysis I was talking about in the last couple of lectures.
00:27:16.150 - 00:27:51.406, Speaker A: It's similar, but there's a slight difference, especially in just kind of mindset that I want to be clear about. So for Parameterized analysis, think as a canonical example our discussion of LRU, and when we parameterized page requests by their locality and then gave a page fault rate upperbound that was parameterized by the locality. So the LRU algorithm, we didn't need to define that locality measure to come up with the LRU algorithm.
00:27:51.438 - 00:27:51.586, Speaker B: Okay?
00:27:51.608 - 00:27:57.262, Speaker A: People came up with the LRU algorithm a long, long, long time ago, and that parameter was like ten years old.
00:27:57.336 - 00:27:57.958, Speaker B: Okay?
00:27:58.124 - 00:28:16.860, Speaker A: So you can't say that the LRU algorithm is in any way depends on that parameter or is tailored to that parameter. The algorithm more so it's clearly well defined and correct on every single page request sequence. It just sort of auto tunes to whatever degree of locality the page request sequence has.
00:28:16.860 - 00:28:28.878, Speaker A: In other words, the parameter that alpha sub f of K. We used it only in the analysis of the algorithm, not in its description or its design today will be different.
00:28:29.044 - 00:28:29.760, Speaker B: Okay?
00:28:30.850 - 00:28:43.710, Speaker A: I've defined a property, I've posited a possible property of real world data, but we're actually going to design an algorithm which we basically probably would never have come up with had we not written down this definition.
00:28:43.790 - 00:28:44.034, Speaker B: Okay?
00:28:44.072 - 00:29:12.218, Speaker A: So there's a sense, an informal sense in which the algorithm we'll discuss today really is explicitly exploiting structure and data rather than being well defined everywhere. And sort of auto tuning to any structure that there might happen to be in data. So with parameterized analysis, I talked about how it's basically like a projection of the input space onto a line where the line indicates the easiness or difficulty of the input and then you just have whatever performance you have as a function of that parameter.
00:29:12.218 - 00:29:50.070, Speaker A: And really a few of the algorithms we're going to see now, including today, this is a little bit overstating, but it's almost as if we have the instances that satisfy whatever condition we have in mind, c epsilon stability. We're going to analyze our algorithm only here, okay? So our mindset is like our responsibility as an algorithm designer is only to do a good job on the instances that meet this definition because we're thinking of these as the important instances and for the other instances, basically we're allowed to SEG fault. In effect.
00:29:50.070 - 00:30:02.026, Speaker A: I mean, the algorithm will behave much better than that. But in our mind we think, you know, if you gave us something else, you violated the promise that this was all I had to do. So all bets are off about the execution of my algorithm.
00:30:02.026 - 00:30:06.494, Speaker A: And indeed, these are actually often called promise problems in complexity theory for that reason.
00:30:06.612 - 00:30:07.280, Speaker B: Okay?
00:30:07.650 - 00:30:23.300, Speaker A: So that's a real shift in mindset, all right? We're articulating structure of real world data not to explain empirical performance of some algorithm, but rather to exploit explicitly an algorithm we're going to design.
00:30:25.290 - 00:30:31.494, Speaker C: Is it only P to compute an.
00:30:31.532 - 00:30:52.698, Speaker A: Instant type of table, right? So that was the discussion over here. So no, clearly not because it references the optimal solution. So just like for the recoverable value on Monday, that was an uncheckable condition in polynomial time because it was talking about the optimal solution, our algorithm, then our algorithm kind of like if we get a bad solution, good.
00:30:52.698 - 00:30:57.898, Speaker A: So here's the good news. So here's the good news. So the good news, you're right, this point is worth making explicitly.
00:30:57.898 - 00:31:14.542, Speaker A: So we have this kind of faith based belief in effect that the world looks like this, that these are the instances we're responsible for. Now suppose we can actually determine whether our algorithm succeeded or failed and that's actually going to depend on the algorithm and depend on the problem. But the easy case is when we can tell whether or not we succeeded or failed.
00:31:14.542 - 00:31:37.690, Speaker A: All right? So we run the algorithm on an instance. We don't know whether or not it satisfied the promise, but either our algorithm works and we're happy, or it SEG faults. And then we know that it was not one of those inputs, okay, because we guaranteed correct good performance on all of those inputs well, but we're not deciding it either way.
00:31:37.690 - 00:31:48.462, Speaker A: We might work well despite the fact that the input does not satisfy that condition. But the point is we'll work well on only a superset of what we proved. Yeah.
00:31:48.462 - 00:31:58.010, Speaker A: So it. Works out in our favor. So, again, in many problems and many that we'll see, this is a very fruitful approach.
00:31:58.010 - 00:32:17.906, Speaker A: It's really you get a lot of mileage out of defining conditions like this, explicitly designing algorithms that make use of them, improving guarantees on the subset of instances where the membership you cannot check. I just want everyone to be totally clear on that. There are these sort of I don't even know if I want to call them drawbacks, but just there's things you should be aware of about the approach.
00:32:17.906 - 00:32:26.502, Speaker A: But like I said, the ends can justify the means. If you get better understanding about algorithms or new algorithmic ideas, it was a worthy exercise, whatever the flaws.
00:32:26.566 - 00:32:29.900, Speaker B: Okay, good.
00:32:30.450 - 00:32:45.650, Speaker A: All right, so I'll leave that there for a second. So that's the goal. I'm going to show you an algorithm that recovers the target clustering up to epsilon.
00:32:45.650 - 00:32:54.580, Speaker A: Basically, no matter how small C is, c should be bigger than one. Think of it as, again, 1.1 as one typical value.
00:32:57.850 - 00:32:58.680, Speaker B: All right?
00:32:59.450 - 00:33:13.946, Speaker A: So before I describe anything about the algorithm, I want to examine some consequences of this stability assumption we're making about our input. Okay? So here's the thing, right there's a stability condition. We're assuming it's true, but we can't check it.
00:33:13.946 - 00:33:36.480, Speaker A: So we need to somehow build a bridge between this uncheckable condition and stuff that our polynomial time algorithm can actually make use of. So what we're going to do is we're actually going to examine logical consequences of the condition, which our algorithm can notice clues about what these unknown optimal clusters are. So let me give you some preliminaries about what that structure is, then we'll talk about how the algorithm can make use of them.
00:33:41.490 - 00:33:42.480, Speaker B: All right?
00:33:43.890 - 00:33:53.282, Speaker A: So consider a stable instance. I hope you'll permit me a change of variable. C will become one plus alpha.
00:33:53.282 - 00:33:55.300, Speaker A: Okay, so C was at least one, alpha is at least zero.
