00:00:00.330 - 00:00:13.278, Speaker A: Hi, everyone, and welcome to this video that accompanies Section 23.1 of the book Algorithms Illuminated, part four. This is the first section of chapter 23, a chapter about P-N-P and all that.
00:00:13.278 - 00:00:50.454, Speaker A: So in the videos we've had in this playlist up to this point, corresponding to chapters 19 to 22, those actually have covered pretty much everything you really need to know about NP hardness if you're just sort of a pure algorithm designer it. So you've learned, first of all, what does MP hardness mean? What are its algorithmic implications if someone tells you that a problem is MP hard? Secondly, you've now learned this rich toolbox of algorithmic techniques you can throw at NP hard problems that come up in your own projects or that are handed to you by your boss. And then third, if you're the boss, if you're actually in charge of the project, you've learned how to spot NP hard problems when they show up in the wild.
00:00:50.454 - 00:00:59.306, Speaker A: You've learned how to prove problems NP hard using that two step recipe. Now, throughout those videos, we didn't really need a completely rigorous definition of NP.
00:00:59.338 - 00:01:00.750, Speaker B: Hardness, so I didn't give you one.
00:01:00.820 - 00:01:17.694, Speaker A: We had a provisional definition of an NP hard problem as one for which a polynomial time algorithm would refute this P not equal to NP conjecture. We discussed informally what the P zero equal to NP conjecture was. Basically that checking someone's work can be fundamentally easier than coming up with your own solution from scratch.
00:01:17.694 - 00:01:46.080, Speaker A: But again, we never really gave you the precise mathematical definitions. So the point of this optional part of the playlist is to fill in those missing foundations, these optional videos corresponding to chapter 23. They're, in effect, an introduction to a deep and beautiful field known as computational complexity theory, a field that studies the amount of resources like, say, the amount of time or the amount of memory or the amount of randomness that's necessary to carry out various computational tasks as a function of the input size.
00:01:46.080 - 00:01:49.994, Speaker A: Throughout our discussions of computational complexity theory.
00:01:50.042 - 00:01:53.166, Speaker B: We will maintain a ruthless focus on.
00:01:53.188 - 00:02:08.886, Speaker A: The algorithmic implications of that theory. And because of that particular viewpoint, it's going to be a treatment of the topic that might be a little bit different than what you'd find in a typical complexity theory book or, frankly, even in a typical algorithms textbook. For those of you looking for a.
00:02:08.908 - 00:02:11.686, Speaker B: More traditional and or deeper introduction to.
00:02:11.708 - 00:02:19.530, Speaker A: Computational complexity theory on YouTube, I highly recommend the videos by Ryan O'Donnell, who's a professor at Carnegie Mellon University.
00:02:20.030 - 00:02:22.666, Speaker B: Let's get started by outlining our plan.
00:02:22.768 - 00:02:29.820, Speaker A: To amass evidence of computational intractability of a problem by reducing lots of other problems to it.
00:02:31.630 - 00:02:57.780, Speaker B: Consider a problem like the traveling salesman problem, which is long thought to be computationally intractable. As we mentioned in the opening video sequence, jack Edmunds already back in 1967, before the concept of MP hardness was formalized. Already back in 67, Edmunds was conjecturing that there's no polynomial time algorithm for the Tsp, not even with running time n to the 100 when you have n vertices, not even with running time big O of n to the 10,000.
00:02:58.470 - 00:03:00.078, Speaker A: To this day, we do not know.
00:03:00.104 - 00:03:01.062, Speaker B: Whether this is the case.
00:03:01.116 - 00:03:02.482, Speaker A: We do not know whether there exists.
00:03:02.546 - 00:03:44.740, Speaker B: A polynomial time algorithm for the traveling salesman problem. But if we wanted to adopt as a working hypothesis that there isn't, how might we amass evidence for that hypothesis? The fact that so many brilliant minds have tried and failed to solve the traveling salesman problem over the last 70 years, that is circumstantial evidence that the problem may well be impossible to solve efficiently. But can we do better? Can we somehow amass stronger evidence than that? The key idea is to show that a polynomial time algorithm for the traveling salesman problem would not just solve the one unsolved problem, not just solve the Tsp, but any such solution would automatically solve thousands of unsolved problems.
00:03:44.740 - 00:03:59.958, Speaker B: In other words, we can build evidence for the intractability of the Tsp in two steps. So, first of all, we identify a massive collection of computational problems. Let's call that collection of problems script C.
00:03:59.958 - 00:04:17.200, Speaker B: And then in step two, we show that every single problem in that big set script C reduces to the traveling salesman problem. So a polynomial time algorithm for the traveling salesman problem would then automatically translate to one for each of those problems in that massive set script C.
00:04:19.970 - 00:04:20.346, Speaker A: We've.
00:04:20.378 - 00:04:55.526, Speaker B: Been saying, and we'll continue to say, that a problem A reduces to a problem B. If you can solve problem A using only a polynomial number of invocations to a subroutine for B plus a polynomial amount of additional work outside of the subroutine calls to B, this is the most appropriate definition of a reduction for our purposes, given that we're focused on algorithmic implications. These are exactly the sort of reductions that transfer computational tractability from one problem to another, and, as we've seen, transfers computational intractability in the opposite direction.
00:04:55.526 - 00:05:05.950, Speaker B: Now, these kinds of reductions actually have a specific name, a couple specific names. We're going to be calling them Cook Reductions. You also hear them called polynomial time Turing Reductions.
00:05:05.950 - 00:05:27.426, Speaker B: And again, Cook reduction is just giving a name to something we've been using all along. So this is just where when you're reducing a problem A to a problem B, you have to show how, given a magenta box that solves B, you can build the light blue box that solves A. You may well wonder, how else would you define a reduction? This kind of seems like the obvious definition for it.
00:05:27.426 - 00:05:37.138, Speaker B: But there are more restricted forms of reductions. For example, things called leaven reductions and carp reductions. We'll see those at the very end of this chapter when we discuss NP completeness.
00:05:37.138 - 00:05:52.426, Speaker B: Until then, do not worry about these distinctions. We're just going to be talking about Cook reductions as we have been throughout this entire playlist. That's our plan for amassing evidence of intractability for the traveling salesman problem, to show that lots and lots and lots of computational problems reduced to it.
00:05:52.426 - 00:06:17.140, Speaker B: And therefore any polynomial time algorithm for the Tsp would automatically translate to one for all of those problems in a really big set script c. Or, if you want to think about it another way, what this would mean. Is that if even one of the problems in Script C is intractable cannot be solved by a polynomial time algorithm, well, then that's enough to conclude that the Tsp cannot be solved by any polynomial time algorithm, either.
00:06:17.140 - 00:06:54.574, Speaker B: Note that the bigger the set script C of problems that is, the more problems you're able to reduce to the Tsp, the stronger the case you've built that the Tsp is an intractable problem. So we would like to carry out this plan with script C as big as possible. How should we choose this set script C? Which problems should we be trying to reduce to the traveling salesman problem? Well, for starters, why not reach for the stars and take C as big as we possibly could? Why not take script C to be the set of all computational problems in the world? That's not what we're going to be doing.
00:06:54.574 - 00:07:20.406, Speaker B: We're going to be taking script C to be just a subset of all possible computational problems, because taking script C to be everything, that's just too ambitious. Hard as the traveling salesman problem may be, there are computational problems out there in the world that are much, much harder than the Tsp and can't possibly reduce to it. Some problems are even undecidable, which means that they're unsolvable by computer.
00:07:20.406 - 00:07:24.346, Speaker B: No matter how much time I give you, you can't solve them in an.
00:07:24.368 - 00:07:25.354, Speaker A: Exponential amount of time.
00:07:25.392 - 00:07:35.194, Speaker B: You can't solve them in a doubly exponential amount of time, and so on. Maybe the most famous undecided problem, maybe it's one you've heard of is the halting problem. Very simple problem.
00:07:35.194 - 00:07:51.874, Speaker B: To state, I just hand you a program, so think like a thousand lines of Python, and I just want you to answer the yes no question. Will this program eventually halt, or will it get stuck in an infinite loop? And that's all I want to know. The halting problem cannot be solved by computer.
00:07:51.874 - 00:08:13.494, Speaker B: The obvious approach is to just simulate the program that you're given through an interpreter. Only problem being is that suppose you simulated for 100 years and it hasn't halted yet. How do you know if it's in an infinite loop or if tomorrow is going to be the magical day where it actually halts? You might hope that with some algorithmic ingenuity, you could shortcut rote simulation.
00:08:13.494 - 00:08:44.350, Speaker B: And certainly for special cases of the problem, you can. But for the fully general version of the problem, as proved by Alan Turing back in 1936, there is, in fact, no finite time algorithm for the Halting problem. Speaking of Alan Turing's 1936 paper, many computer scientists, including myself, feel that Turing's paper should really be regarded as the birth of computer science as an intellectual discipline.
00:08:44.350 - 00:08:48.174, Speaker B: And for this reason, many of us feel that Alan Turing's name should be.
00:08:48.212 - 00:08:51.730, Speaker A: As widely recognized as, say, Albert Einstein.
00:08:52.390 - 00:09:07.154, Speaker B: So what made Alan Turing's 1936 paper so important? Well, two things. So, first of all, Turing introduced a formal mathematical model of what computers can do. It's a model that we now refer to as a Turing machine.
00:09:07.154 - 00:09:41.680, Speaker B: Now, mind you, this is a good ten years before anyone had ever built a general purpose computing device. Second, by defining what computers can do, turing was able to study what they can't do and to prove, in a precise sense that computers cannot solve the Halting problem. Thus, from literally day one of computer science as a scientific discipline, we have been acutely aware of the limitations of computers and the necessity of compromise when tackling difficult computational problems.
00:09:41.680 - 00:10:09.610, Speaker B: After this digression about the Halting problem, the traveling salesman problem no longer seems that bad. We may not know how to solve it in polynomial amount of time, but we certainly know how to solve it in a finite, albeit exponential, amount of time just using exhaustive search. So that means there's no way the Halting problem can reduce to the traveling salesman problem, because if it did, that would give a finite algorithm for the Halting problem, which proterring we know does not exist.
00:10:09.610 - 00:10:19.018, Speaker B: Let's go back to the drawing board. We have to figure out which problem script C we're going to reduce to the Tsp. We want to take script C to be as big as possible.
00:10:19.104 - 00:10:21.750, Speaker A: Bigger sets mean stronger evidence of intractability.
00:10:21.910 - 00:10:50.260, Speaker B: But now we understand that we can't take script C to be everything, but we still want to take it to be as big as possible. Well, if what's limiting the traveling salesman problem from capturing computational problems like the Halting problem is that the Tsp is solvable by naive, exhaustive search, maybe we can at least take script C to be all the problems equally well solvable by naive, exhaustive search. Those are the problems that might plausibly reduce to the traveling salesman problem.
00:10:50.260 - 00:11:04.602, Speaker B: That may all sound nice and reasonable in English. All problems equally well solvable by naive, exhaustive search. But what does that actually mean? Can we really have a mathematical definition that formalizes that idea? Yes, we can.
00:11:04.602 - 00:11:10.710, Speaker B: And in the next video, we'll start laying the groundwork for the formal mathematical definition. I'll see you there. Bye.
