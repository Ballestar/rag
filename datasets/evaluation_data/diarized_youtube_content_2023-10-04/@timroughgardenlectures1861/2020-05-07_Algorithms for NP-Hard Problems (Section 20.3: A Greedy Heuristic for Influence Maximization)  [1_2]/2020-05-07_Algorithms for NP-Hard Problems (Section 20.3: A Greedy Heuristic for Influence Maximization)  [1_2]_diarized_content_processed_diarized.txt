00:00:00.570 - 00:00:10.638, Speaker A: Hi everyone and welcome to this video that accompanies section 20.3 of the book Algorithms Illuminated part four. It's a section about the influence maximization problem.
00:00:10.638 - 00:00:26.978, Speaker A: Now both of the last couple videos we were looking at the greedy coverage algorithm, which is a fast heuristic algorithm for the maximum coverage problem. And that's a pretty classic algorithm, it's from the late seventy s. And originally people were motivated by old school applications like where to locate factories.
00:00:26.978 - 00:00:53.050, Speaker A: But in an interesting twist in the 21st century, generalizations of that algorithm have actually found applications, new applications in some emerging subfields of computer science. And so in these videos I want to discuss a representative example concerning the analysis of social networks and specifically cascades in social networks. So for the purposes of this section, we can just think of a social network as a directed graph.
00:00:53.050 - 00:01:18.894, Speaker A: The vertices of the graph correspond to people and directed edges correspond to one person influencing another. So for example, you might have a directed edge from a person v to a person W if W follows v on a social network such as Instagram or Twitter. So a cascade model posits how information like, say, a news article or a meme how it propagates through a social network.
00:01:18.894 - 00:01:27.222, Speaker A: There's a lot of different well studied cascade models for social networks. Let's just look at a very simple one. It's parameterized by what's called an activation probability p.
00:01:27.222 - 00:01:50.650, Speaker A: So it's a real number between zero and one and also a subset of the vertices, which we're going to call seed vertices. So in this cascade model, every vertex is going to have a status and that status will either be active or inactive. You can think of active as maybe like a person who actually clicked on a link to a news article, and an inactive person who is someone who has not clicked on a link to a given news article.
00:01:50.650 - 00:02:03.934, Speaker A: Initially the seed vertices, they're all going to be active. So these are the people that sort of initially read a news article without any prompting. All of the vertices are initially inactive, so vertices will never go from active to inactive.
00:02:03.934 - 00:02:25.238, Speaker A: If at some point you clicked on the link, then hey, you clicked on the link. But vertices can go from inactive to active, right? So maybe a person eventually does click on a link to a certain news article. So what's the process by which that happens, by which vertices become activated? Well, currently active vertices have the opportunity to activate any inactive vertices that they influence.
00:02:25.238 - 00:02:38.122, Speaker A: Now each vertex v only gets one shot at activating the vertices that it influences. So we're also going to associate a status with each edge and all the edges. Initially we're going to call unflipped.
00:02:38.122 - 00:02:56.622, Speaker A: So whenever you have an active vertex v and v influences some other vertex W, and the edge from v to W has not yet been flipped. That is an edge that is eligible to be flipped in this iteration of the main while loop. So these activations are going to continue as long as there are opportunities.
00:02:56.622 - 00:03:16.170, Speaker A: So as long as there's an currently active vertex V, and there's some outgoing edge from V, so some W that V influences such that that edge hasn't been flipped yet, such that that opportunity to influence W hasn't been taken yet. The formal model involves this activation probability. So you might want to think of the activation probability as say 20%, something like that.
00:03:16.170 - 00:03:27.006, Speaker A: So you choose some activation opportunities. So an active V and an unflipped outgoing edge v comma W and you flip a coin and the coin is going to be a biased coin. It's going to come up heads with probability P.
00:03:27.006 - 00:03:43.854, Speaker A: So in our example, it comes up heads 20% of the time, 80% of the time it's going to come up tails. Now if the coin comes up heads, that means that V successfully did influence W. So for example, if V tweeted with some link and then W clicked on it, that would be a successful activation.
00:03:43.854 - 00:03:57.510, Speaker A: So that would correspond to heads. If W just ignored that link and never clicked on it, that would be the 80% case tails. So in the event that this coin comes up heads, we need to change the status of both the edge and possibly the vertex W.
00:03:57.510 - 00:04:09.798, Speaker A: So the edge is obviously no longer unflipped. So we're going to call it active. Because the coin came up heads, w may have been active already, they may have already clicked on that link before they saw the Tweet from V, in which case fine, they stay active.
00:04:09.798 - 00:04:24.218, Speaker A: Or if they were previously inactive and this was the first time they clicked on the link, now their status changes to active. So meanwhile, if the coin comes up tails, that's a failed influencing opportunity. Again, we want to record the fact that the edges coin has been flipped.
00:04:24.218 - 00:04:36.162, Speaker A: So we change the edges status from unflipped to inactive because it didn't work and W status stays whatever it was before. So if it was already active, it's still active, if it was inactive, it's still inactive. So that's how this process works.
00:04:36.162 - 00:04:48.642, Speaker A: More and more vertices keep getting activated until at some point all of the edges going from an activated vertex to some other vertex, they've all been flipped. That's when the process stops. Notice that a vertex can have multiple activation opportunities.
00:04:48.642 - 00:05:03.578, Speaker A: It has one for each of its activated influencers. And for example, maybe the first two times that two of your friends recommend you to go see a new movie, you kind of don't pay attention. But then suddenly when you get the recommendation from the third friend, that's what triggers you to go see it.
00:05:03.578 - 00:05:17.170, Speaker A: So let's look at a simple example. So we're going to look at a social network that just has four people in it, A-B-C and D. In general, you can have more than one seed vertex, but in this example, we're only going to have one seed vertex and that'll be A.
00:05:17.170 - 00:05:27.418, Speaker A: So as promised, A starts out with its status as active. The other three vertices are inactive. And of course, initially all five of the edges have not yet been flipped.
00:05:27.418 - 00:05:43.082, Speaker A: So when the cascade process starts, it says, okay, so is there an active vertex with unflipped outgoing edges? Yes, there is. A is active and none of its outgoing edges have been flipped yet. So A has the opportunity to influence each of B, C and D.
00:05:43.082 - 00:05:56.650, Speaker A: So suppose the process flips each of those three coins in turn. And suppose the first coin comes up heads so that's the edge from A to B. But the coins corresponding to A to D and A to C come up tails.
00:05:56.650 - 00:06:07.330, Speaker A: Here's how the picture changes. So first the edge from A to B that goes from unflipped to active. It's active because the coin came up heads.
00:06:07.330 - 00:06:23.010, Speaker A: Now B, B used to be inactive, but we just had a successful activation event, a successful influencing opportunity, so B is going to become active. At this point, the coins for edges AC and Ad come up tails. So no change to the status of either C or D, they stay inactive.
00:06:23.010 - 00:06:32.490, Speaker A: But of course we want to record that those coins have been flipped. So we change the status of the two edges to inactive. So you'll notice that at this point there's no hope of ever activating the vertex C.
00:06:32.490 - 00:06:46.974, Speaker A: The only opportunity was from A, and that didn't work out. However, there's still a chance that D could be activated, can't happen from A. That attempt failed, but maybe the second activation opportunity now that B is active will work out.
00:06:46.974 - 00:06:58.050, Speaker A: So that corresponds to choosing the edge from B to D and flipping a coin. And if the coin covers up heads, then indeed D does become active. And of course the edge becomes active as well.
00:06:58.050 - 00:07:06.902, Speaker A: So that's how the process stops. At this point, there's nothing more to do. There's only one unflipped edge remaining and it emanates from an inactive vertex, C.
00:07:06.902 - 00:07:31.210, Speaker A: So c being inactive has no opportunity to activate D. So optionally, if we're sort of annoyed by these unflipped edges that remain, we can add a post processing step that flips coins for any remaining unflipped edges and updates their statuses accordingly as active or inactive. And importantly, in this post processing step, while we change the status of edges, we make no changes to the statuses of any vertices.
00:07:31.210 - 00:07:44.650, Speaker A: So for example, in our running example, maybe we flip that final coin for the edge going from C to D. Maybe it comes up heads. We make the edge active just to reflect that the coin came up heads but C stays inactive.
00:07:44.650 - 00:08:18.410, Speaker A: D was already active, but if D had been inactive, it would stay inactive despite the fact that CD came up heads and in general. The thing to notice is that whether or not you have this postprocessing step, the vertices that wind up activated at the end of the process are precisely the vertices that are reachable from a seed vertex by a directed path of activated edges. So in this example, we only have the one seed vertex A, and we see that A can indeed reach B via directed path of active activated edges.
00:08:18.410 - 00:08:42.046, Speaker A: It can also reach D by a two ha path of activated edges. But you'll notice there's no path of activated edges from A to C, and so that's why it's exactly B and D that have the status active in this process. So basically, if there wound up being some directed path from a seed vertex to U, where the path comprises only active edges, then you wind up active.
00:08:42.046 - 00:09:06.070, Speaker A: If not, if there's no path of active edges from a seed vertex to you, then you stay inactive. So now I can tell you about the influence maximization problem, the input to the problem, it's just a social network in the way we've been talking about a directed graph along with a seed vertex and then also a budget k, which is a positive integer. And I forgot to mention, just like in our cascade model, part of the input is an activation probability.
00:09:06.070 - 00:09:26.400, Speaker A: So it's a real number P between zero and one. So informally, the goal in the influence maximization problem is to choose a bounded number of vertices to designate as the seed vertices. And you want to do it in a way to influence as many people as possible to have as many vertices activated by our cascade process as possible.
00:09:26.400 - 00:09:37.650, Speaker A: Now, it's a little tricky because the number of vertices that get activated, that's a random variable. It's going to depend on how the coin flips come up. So sometimes it'll be big, sometimes it'll be not so big.
00:09:37.650 - 00:09:59.318, Speaker A: So it's a random variable and we'll do the sort of most straightforward thing and we'll focus on its average value, that is the expected value of the random variable, which is equal to the number of vertices that eventually get activated in the cascade model. So a little notation to make this idea precise by capital A of S. So here capital S is a subset of seed vertices.
00:09:59.318 - 00:10:15.540, Speaker A: Capital A of S means the set of vertices that eventually wind up getting activated from this seed vertex set, capital S. Now this is random again, so this will depend on how the coin flips come up. So you'll get different sets with different random experiments, even with the same seed set.
00:10:15.540 - 00:10:37.890, Speaker A: So let's define the influence of a group of variables as the expected number of vertices activated when those are the vertices chosen as the seeds. We're here the expectation, the averaging that's over the coin flips that are part of the cascade model. So another way to think about it is imagine you designate these ten vertices as seeds.
00:10:37.890 - 00:11:00.218, Speaker A: You could imagine now just sort of running a simulation like where you literally just flip these coins and see what happens, and then you count how many vertices eventually get activated. You could imagine repeating that experiment a million times and taking the average value that's going to be basically this expectation. So the average value of the number of activated vertices, given that you choose this subset, capital S, is the seed vertices.
00:11:00.218 - 00:11:15.810, Speaker A: So this influence, this is going to be our objective function. We are going to want to choose the seed vertices to make this influence the expected number of activated vertices as big as possible. So that's the influence maximization problem, very cool problem.
00:11:15.810 - 00:11:52.282, Speaker A: And this one actually is from the 21st century, just barely, but it is from the 21st century. Unlike almost everything we've talked about in these videos so far, the definitive research paper on this problem, the one that introduced it and also gave the analysis we'll be discussing, came out in 2001 by David Kempy, John Kleinberg and Ava Tardosh. So if you want to have a concrete example of an influence maximization type problem in mind, you could imagine that you've been given by your employer k copies of a product to give away for free, and you want to choose the recipients of those products in a way that maximize its eventual adoption.
00:11:52.282 - 00:12:15.554, Speaker A: So then you want to give it to people who are likely to trigger many other people to adopt the product and you're facing an influence maximization problem. So if you watch the past couple of videos on the Maximum Coverage problem, you may have noticed some similarities between influence maximization and Maximum Coverage. Especially if you looked at the example of Maximum Coverage, where we were talking about choosing people to maximize attendance at an event like a concert.
00:12:15.554 - 00:12:32.278, Speaker A: That should have felt the influence maximization problem should remind you of that. And indeed, and I'll leave this for you to do in the privacy of your own home, the maximum coverage problem is in fact a special case of the influence maximization problem. Influence maximization is only more general.
00:12:32.278 - 00:12:45.478, Speaker A: Now even the special case is NP hard, as we discussed. So the more general problem, influence maximization, is certainly NP hard as well. The best case scenario would be a fast and approximately correct heuristic algorithm.
00:12:45.478 - 00:12:56.338, Speaker A: Is there one? Yes, there is. And again, it will be a natural greedy algorithm. So the greedy algorithm will look very similar to the one we saw for the maximum coverage problem.
00:12:56.338 - 00:13:03.602, Speaker A: There's again, K things to choose k vertices. So we're going to be picking them one by one. We don't care about coverage, we care about influence.
00:13:03.602 - 00:13:40.670, Speaker A: But again, in each iteration of the greedy algorithm, we're going to be myopic, we're going to pick the vertex that increases the current influence as much as possible. So that is the KKT algorithm for influence maximization and it is the one we will be analyzing in the rest of this video. Unlike the other greedy algorithms we've discussed, the running time of the KKT algorithm is actually, there's some subtle stuff going on, so let's think that through in the next quiz.
00:13:40.670 - 00:14:02.700, Speaker A: Specifically, I'd like you to choose the tightest upper bound on the running time of a straightforward implementation of the KKT algorithm that you believe is correct. Take a few seconds to think about it. All right, so this quiz is a little tricky.
00:14:02.700 - 00:14:17.132, Speaker A: I'd be willing to accept either C or D as a correct answer. So let's talk through the running time. Right there's, k iterations of the main loop, each of which involves computing a maximum over the N vertices.
00:14:17.132 - 00:14:59.112, Speaker A: So in other words, the running time of the straightforward implementation is big O of K times n, the number of iterations times the number of vertices times the number of operations required to compute the additional influence you would get by adding one additional vertex to your current solution. That in turn boils down to evaluating the influence of two different sets. So how many operations do you need for that to compute the influence of a given set of vertices? Well, unlike for the coverage objective function we were working with last section, the answer isn't obvious because of the pesky expectation and the definition of influence.
00:14:59.112 - 00:15:18.152, Speaker A: Let me remind you what it is. So for a given subset of vertices, remember we look at the set of vertices that wind up being activated and how many there are. That's a random variable.
00:15:18.152 - 00:15:31.152, Speaker A: The number of activated vertices depends on the results of the coin flips. And so we were just doing the most straightforward thing and looking at the average or the expected number of activated vertices for a given set of seeds. That was the influence function.
00:15:31.152 - 00:16:02.308, Speaker A: Now, unfortunately, what this expectation is over is two to the m different possibilities, where here m denotes the number of edges, right? Because for each edge you might flip heads or you might flip tails. So there's two to the m possible things that could happen, and this expectation is averaging over those two to the m things. So if you compute this expectation in the most naive way, just as a sum over two to the M terms, then you're going to get a running time like in the answer C, big O of K times N for the number of times you have to compute influence.
00:16:02.308 - 00:16:13.772, Speaker A: Times two to the M, the time required to compute influence. In this naive way, you may be wondering whether or not you really need to do the exponentially big sum. So that's why I'd be totally sympathetic if you chose answer D.
00:16:13.772 - 00:16:24.704, Speaker A: Just thought it was unclear what was the running time of this algorithm. Now maybe you're saying, wait a minute, hold on. Why am I even telling you about this algorithm? If you have to sort of evaluate these sums of an exponential number of things.
00:16:24.704 - 00:16:46.420, Speaker A: This isn't the whole point of everything we're doing in this chapter to avoid using exponential time. Well, actually, this greedy algorithm is still completely implementable useful. It is true that the influence of a set of vertices can be difficult to compute exactly to arbitrary precision, but it's pretty easy to estimate the influence of a set of seed vertices using random sampling.
00:16:46.420 - 00:16:59.080, Speaker A: So basically, you just flip coins for all of the edges. You see what happens, you count up the number of activated vertices and then you just average that over a bunch of different independent random trials. That won't be exactly the influence, but that'll be pretty close to the influence.
00:16:59.080 - 00:17:10.464, Speaker A: And then you can just run the same greedy algorithm using these estimates of the influence that you got through this sampling procedure. That's how you'd actually implement it in practice. So that's what I wanted to say about the running time.
00:17:10.464 - 00:17:31.764, Speaker A: Now let's go back to the original version of the KKT algorithm where you're not doing the sampling business, you're just somehow computing these expectations, computing the influence. And let's analyze the solution quality of the seed set output by that greedy heuristic. Happily, the guarantee for this greedy heuristic is just as good as the approximate correctness guarantee we had before for greedy coverage.
00:17:31.764 - 00:17:46.072, Speaker A: For the maximum coverage problem. That's right. The output of this algorithm is guaranteed to be at least a one minus quantity, one minus one over k raised to the k fraction of the maximum possible influence of any set of K seed vertices.
00:17:46.072 - 00:18:12.628, Speaker A: And we should be very, very happy about this guarantee. The reason is, remember, that we can actually think of maximum coverage problem as a special case of influence maximization. So influence maximization being at least as hard and general as maximum coverage, that means the best case scenario we could possibly hope for is to do just as well for the more general influence maximization problem as we've done for the more special maximum coverage problem.
00:18:12.628 - 00:18:35.900, Speaker A: And that is exactly what this guarantee is saying. So I will give you a full proof of this approximate correctness guarantee if you just want sort of one line of intuition about why this is true. Well, we observed in the past that there is a pretty close connection between influence maximization and maximum coverage, especially in that example we discussed about maximizing event attendance by recruiting people who are then going to recruit all of their friends.
00:18:35.900 - 00:19:05.552, Speaker A: So basically what's going to be going on is that the influence of a set of seed vertices is going to be nothing more than a weighted average of different event attendance problems, one for each possible subset of the vertices that might have been activated. So all we have to do really is go back and check that our analysis for the maximum coverage problem, which applies in particular to event attendance, we just need to make sure that that same analysis works. If we're looking at a weighted average of event attendance problems rather than just one.
00:19:05.552 - 00:19:07.540, Speaker A: But as we'll see, it does indeed extend.
