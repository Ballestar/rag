00:00:00.490 - 00:00:16.682, Speaker A: So in this video, we'll continue discussing approaches to proof of stake random sampling. So remember, that means we're going to have a list of public keys along with associated stake amounts. This is going to be basically the contents maintained by some designated staking contract.
00:00:16.682 - 00:00:29.414, Speaker A: And the goal is to select one of those public keys in the contract at random with probability proportional to the stake amounts. Now, in the last video, we saw an actual pretty simple solution to this problem. So in some sense, we've already solved it.
00:00:29.414 - 00:00:46.970, Speaker A: But as we mentioned, there were sort of two pretty big issues with the solution we gave last time. The really obvious issue is that we were making an unreasonably strong assumption of access to an ideal randomness beacon. So basically, we were assuming the periodically perfect randomness falls from the sky and that everybody can see it.
00:00:46.970 - 00:01:01.662, Speaker A: Obviously, in any concrete deployment of a proof of stake protocol, you're going to have to talk about what concrete approximation of that randomness beacon are you going to use in your protocol. And we'll get to that, not in this video, the next video, but in the one after that. In this video and the next.
00:01:01.662 - 00:01:26.854, Speaker A: I want to focus on our second critique of the sampling solution we saw in the last video, which is a lack of secrecy. So what I mean by a lack of secrecy is that in that solution, in the last video, literally everybody finds out the output of the sampling procedure at exactly the same time. Both the public key, the owner of the public key that's actually selected, and everybody else, right? New randomness RCIB T falls from the sky as soon as everybody sees it.
00:01:26.854 - 00:01:47.070, Speaker A: Everybody knows who the leader of the next round is going to be. So why is that potentially a problem? Well, on the one hand, whoever it is who's selected so the owner of the selected public key, they're presumably now responsible for assembling a block and proposing it to others. And so you got to give them at least a little bit of time to get that block together.
00:01:47.070 - 00:01:58.782, Speaker A: Not a lot. Maybe it's tens of milliseconds, maybe it's hundreds of milliseconds. But they need a little time to be able to put a block together to propose to everybody else, which means there is going to be this small window of opportunity for attackers.
00:01:58.782 - 00:02:42.842, Speaker A: So as an attacker, as soon as you learn who the leader is, if you, for example, launch a denial of service attack on them and basically disconnect them, in effect, from the network before they have a chance to propose a block, well, then you've actually successfully attacked the liveness of the consensus protocol, right? You actually had an honest node, say, as a leader, but they were unable to propose a block because they were attacked in the window, after which their identity became known. So in this video, we're going to pursue more sophisticated ways of doing proof of stake random sampling that do have this additional secrecy property. Meaning we want a random sampling procedure such that whichever public key is selected, the owner of that public key should know that they got selected.
00:02:42.842 - 00:02:52.046, Speaker A: But only the owner of that public key should know that they got selected. No one else should be aware of that. That way, whoever owns that public key, presumably they need to assemble a block.
00:02:52.046 - 00:03:12.890, Speaker A: They can do that without anyone knowing that they're going to be the next one to propose a block. Only at the time of their block proposal with which they're going to submit their credentials, sort of proving that they are indeed the leader of the current round. Only once other nodes hear about their block proposal, only then will they know the identity of the leader of that round.
00:03:12.890 - 00:03:26.058, Speaker A: And that would be pleasingly similar to how Nakamoto Consensus works. Sort of proof of work where there again you can be happily mining away trying to solve crypto puzzles and sort of prepare a block. Nobody else even knows you exist.
00:03:26.058 - 00:03:47.934, Speaker A: No one's ever heard of you until you submit your block along with the solved crypto puzzle to the communication network. So as I said in this video and the next, we're going to retain our assumption of access to an ideal randomness beacon. Unlike the last video where it maybe felt like it kind of trivialized the problem a little bit, it really does not trivialize the problem when you have this extra secrecy requirement.
00:03:47.934 - 00:04:08.506, Speaker A: As we'll see, it's actually quite challenging to get this even if you have access to an ideal randomness beacon. And then again, after we talk about these two videos about verifiable random functions, at that point we'll revisit it and ask, okay, what would be a practical approximation of one of these ideal randomness beacons? So zoom in on one particular time step, little T. All the time steps are going to work exactly the same way.
00:04:08.506 - 00:04:27.220, Speaker A: So some time step T, this assumed to be perfect randomness R sub T falls from the sky. Let's think about how we might go about achieving the secrecy property that we want. Now there's no secrets in R sub T, right? By assumption, this randomness R sub T, this is viewable to everybody.
00:04:27.220 - 00:04:55.994, Speaker A: So fundamentally, I guess what we want to have happen at time T is that an owner of a public key by owner of a public key, I mean whoever it is who has knowledge of the corresponding private key. The owner of a public key can perform some computation using perhaps the shared randomness r sub t as an input. And it's a computation that cannot be performed by people who are not owners of the public key, people who don't know the corresponding private key.
00:04:55.994 - 00:05:26.066, Speaker A: So it should be some computation performable only by the person who knows the right private key. Okay, well, that's actually, if you think about it, pretty suggestive. Right, there's a very familiar cryptographic primitive with exactly that property that we've talked about many times, namely digital signature schemes, right? The defining properties of a digital signature scheme is that if you have the private key corresponding to a public key, you can create signatures that anyone else can verify, knowing only the public key.
00:05:26.066 - 00:05:57.950, Speaker A: Whereas people who don't know the private key cannot, at least for all practical purposes, cannot forge signatures, cannot do the same computation that the owner of that private key could do. So that's the first kind of very simple, but maybe even most important kind of idea and intuition behind verifiable random functions, which is like we want someone to do a computation that only it can do and other people who don't know the private key can't do well, let's just have them sign something using their private key. And again, remember, everybody knows the corresponding public key that's just sitting there in the designated Staking contract.
00:05:57.950 - 00:06:24.470, Speaker A: So the next question then is, okay, if we're going to have people signing things, what are they signing? Are they just signing something constant like the empty message? Well, no, that doesn't really make sense, right, because we want to be doing sort of new, basically independent random sampling at every time step. So they should be doing different computation at each time step. What is differing across time steps? Well, most obviously the most recent emission from the random beacon is different.
00:06:24.470 - 00:06:51.898, Speaker A: So the simplest thing you might want to sign, which is naturally then going to change from timestep to time step is you just have everybody sign the current randomness R sub T. So the notation here, SK sub I, that's meant to indicate the private key that corresponds to the public key PK sub I that's registered in the Staking contract. And SIG for the moment just means an arbitrary secure digital signature scheme.
00:06:51.898 - 00:07:04.114, Speaker A: We've already been assuming all along that these things exist kind of for two different reasons. One, if you think about nodes running a consensus protocol, right, we wanted the PKI assumption. We wanted nodes to be able to vote in kind of a credible way.
00:07:04.114 - 00:07:30.780, Speaker A: And so they do that by signing whenever they submit a vote. This would be in a protocol like tendermint, for example, and then also sort of zooming out if you think about sort of state machine replication where you have nodes running the protocol and then clients or end users submitting transactions to be included in the running log. Well, end users, they're generally also going to be signing their transactions to make sure it's clear to everybody that they have in fact authorized, for example, a payment from their account to some other account.
00:07:30.780 - 00:07:38.798, Speaker A: So we've been using digital signatures all along. We're using them again here. It is really for different reasons, I would say here.
00:07:38.798 - 00:07:59.750, Speaker A: So here what we care about is just having a computation that can be done in secret, but at the same time, you can convince everybody else of the output. That matches perfectly onto kind of the, on the one hand, ease of generating signatures when you know the private key and ease of verifying signatures when you know the public key. All right, so that seems like a promising starting point.
00:07:59.750 - 00:08:28.062, Speaker A: Just stand on the shoulders of digital signatures to get the secrecy property. But we're clearly not done because it's like, okay, so you've signed today's randomness. Like, what do you do next? Really, we want kind of answer a binary question which know, is PKI selected or not? So one very natural approach for turning the signature into a predicate, it's either going to be yes or no is to follow the exact same approach we used in Nakamoto Consensus and with proof of work.
00:08:28.062 - 00:08:59.980, Speaker A: Right? So you remember back in Nakamoto Consensus we had a difficulty threshold and a nonce or sort of in general block metadata constituted a crypto puzzle solution if and only if the hash of that input was sufficiently close to zero was less than the difficulty parameter. So we could do exactly the same thing here. We could say we're going to declare that the public key PKI gets selected if and only if its signature sort of viewed as a number, is sufficiently small, sufficiently close to zero.
00:08:59.980 - 00:09:44.680, Speaker A: So a little more formally, at a given time, step T, given owner of a public key PKI, they're by definition going to be a selected public key if and only if the signature using the corresponding private key on the randomness of that day. That's the left hand side of this blue inequality, the signature using the private key corresponding to PKI of today's randomness viewed as a number between zero and one. Right? So if that's say like 256 bits, just think of that as an integer and then divide by two to the 256 to scale it down to the interval zero comma one, PKI is going to be defined as selected if and only if the output the signature is sufficiently close to zero.
00:09:44.680 - 00:09:56.662, Speaker A: And what I mean by sufficiently small is summarized in this blue inequality. And I want you to think about both sides of this inequality as being numbers between zero and one. So numbers that lie in the unit interval.
00:09:56.662 - 00:10:13.870, Speaker A: Like if signatures under your scheme have say, 256 bits, just view that as an integer and then divide by two to the 256. And that maps all possible signatures down to the interval zero comma one. On the right hand side, we have an expression involving two parameters, both of which I'll say more about.
00:10:13.870 - 00:10:22.574, Speaker A: But again, you should think of the right hand side as some number between zero and one. Generally, actually quite close, quite close to zero. So tau, that's the difficulty threshold.
00:10:22.574 - 00:10:42.582, Speaker A: It's playing a similar, not exactly the same, but similar role to the difficulty threshold that we use in Nakamoto Consensus in proof of work. So over there we were sort of tuning tau according to how much hash rate was being provided to the protocol. And similarly here tau is going to be tuned according to the total amount of locked up stake.
00:10:42.582 - 00:11:00.538, Speaker A: So the more the locked up stake, then the smaller you're going to want to have tau. And that's analogous to how in Nakamoto Consensus, the more the overall hash rate being contributed to the protocol, the smaller you would want tau. Back then it was to target a particular rate of block production.
00:11:00.538 - 00:11:15.730, Speaker A: Here we're actually going to be targeting a particular rate of the sampling of public keys. Now, there's also this function, Little f, which I'll say much more about toward the end of Next video. But let me say at least a little bit about it now so that you're not confused by its presence.
00:11:15.730 - 00:11:38.346, Speaker A: So the first thing to say is we definitely need something in this inequality to depend on the stake amount Q sub I because we're trying to sample with probability proportional to stake. Now notice the left hand side of the blue inequality that is independent of Q sub i, right? Whatever your Q is, you have the same secret key either way. So you're going to be producing the same signature either way.
00:11:38.346 - 00:11:56.400, Speaker A: So if there's going to be dependence on Q, it's got to be on the right hand side. What dependence do we want? Well, the probability with which you're sampled should be increasing with your stake amount. So that means on the right hand side, it shouldn't just be tau, right? It should be tau times an increasing function.
00:11:56.400 - 00:12:15.000, Speaker A: So the bigger the stake is, the bigger the Q sub i. We want the bigger the right hand side so that it is easier for the left hand side to be less than the right hand side. So it definitely makes sense that we want something on the right hand side, which is an increasing function of the stake amount, and that is this function little f.
00:12:15.000 - 00:12:29.950, Speaker A: For now, before we get into some gory details at the end of the next video, I encourage you to just think of f as the identity function. So think of the right hand side as just scaling linearly with the stake amount. So if you have twice as much stake associated with your public key, that makes the right hand side twice as big.
00:12:29.950 - 00:12:39.966, Speaker A: Big hopefully makes it twice as likely you're going to wind up being selected. It turns out that's not quite right. That's almost right, but it doesn't quite give us the civil resistance property that we want.
00:12:39.966 - 00:13:01.894, Speaker A: So at the end of the next video, we're going to actually just sort of take civil resistance as a requirement and then using that, we'll be able to derive exactly what this function little f should be. But again, for the moment, just think of it as the identity function. All right? So let's just pause and notice that we seem to be on the right track as far as the secrecy property that we're after.
00:13:01.894 - 00:13:16.826, Speaker A: So if we look at this blue inequality, the right hand side, anybody can compute, okay, everybody knows tau that's part of the protocol, the function f, that's part of the protocol. The stake amounts are all encoded in this publicly visible Staking contract. So everybody knows the right hand side.
00:13:16.826 - 00:13:34.562, Speaker A: On the other hand, the left hand side, right, that's a signature. It could only assuming a secured digital signature scheme, the left hand side can only be computed by someone who knows the private key corresponding to the registered public key, PK sub i. So this can be computed by the owner of the public key i.
00:13:34.562 - 00:13:42.786, Speaker A: It cannot be computed, at least for all practical purposes, by anyone else. So that's great. So the result is secret in that sense.
00:13:42.786 - 00:14:11.754, Speaker A: Furthermore, it's verifiable, right? If you want to actually then tell people that you were selected, for example, you're proposing a block and you want to also broadcast credentials that you've earned the right to propose that block, then you can easily convince everybody else just by saying what your signature is. Everybody else knows your public key that's encoded in the Staking contract, so they can verify that the signature is the correct signature for the message R sub T. And again, everybody knows the right hand side, so everybody can evaluate that inequality just for themselves.
00:14:11.754 - 00:14:26.274, Speaker A: So only the owner of public key I, can compute the left hand side and evaluate this predicate. But if the inequality holds, they can easily convince anybody else that it holds just by reporting their signature. So that all sounds like good news.
00:14:26.274 - 00:15:05.630, Speaker A: So what might we be worried about? The first thing I want to think about is obviously this blue inequality is really important, right? And owners of public keys sort of want this inequality to be true. And so we need to ask the question, are they in a position to pull off any shenanigans that make it more likely that the inequality is going to hold? Can they manipulate the probability with which they're going to be selected and let's in particular focus on the left hand side? So the first piece of good news is that the message to be signed R sub T, that just by assumption cannot be manipulated by anybody, right? We're working with an ideal randomness beacon r sub T just falls from the sky. It's perfect randomness.
00:15:05.630 - 00:15:26.818, Speaker A: There's nothing more to say now. Later, when we talk about replacing the randomness beacon with something that's a pseudorandom approximation, we will have to revisit this issue and ask whether anyone is able to manipulate R sub T. But for now, for this video and the next, or assuming an ideal randomness beacon, we don't have to worry about that.
00:15:26.818 - 00:15:43.114, Speaker A: So RT definitely cannot be manipulated. So if there's a manipulation of the left hand side, it has to involve the signature of that message. So here's maybe the first thing you might be worried about an attacker doing basically grinding through possible private keys that it might have.
00:15:43.114 - 00:15:56.174, Speaker A: So imagine an attacker and in advance of the protocol. So just kind of as a preprocessing step, they generate and put in a database a ton of public private key pairs, like a million or a billion key pairs. And again, anybody could do that.
00:15:56.174 - 00:16:10.162, Speaker A: You can costlessly generate basically unbounded number of public private key pairs. So the attacker is sitting there with this big database of key pairs. And then one day, right, so the randomness R sub T falls from the sky and the attacker says, oh, cool.
00:16:10.162 - 00:16:42.170, Speaker A: All I need to do is come up with one of my key pairs so that if I use that key pair, if I use that particular private key, then the signature on this message is going to be sufficiently small, it's going to be less than the right hand side. One piece of terminology you might want to know that's used a lot in the context of proof of stick protocol design any attack like this, where basically you try a whole bunch of different possibilities hoping to win a lottery with one of the possibilities. Kind of analogous to what happens in proof of work that's sometimes known as a grinding attack.
00:16:42.170 - 00:16:53.998, Speaker A: So when I say try multiple key pairs, one might also say grinding over key pairs. So that would indeed be an issue for a poorly designed proof of stake protocol. The good news is there's a very simple fix.
00:16:53.998 - 00:17:18.178, Speaker A: Basically you just make sure that validators are forced to commit to their public key private key pair well before they ever see the message RSH of T that they're going to need to sign. And so that would happen automatically, for example, if you used a warm up period. So remember back when we talked about staking mechanics, we talked about how there's this time interval that commences with a deposit and ends with a withdrawal.
00:17:18.178 - 00:17:42.574, Speaker A: And the best practices are to have a sub interval where only in a sub interval is the owner of that public key allowed to participate in validation and block production. So there's a warm up period where the contract has your stake but you're not yet allowed to participate in consensus. And then there's a cooldown period where you've initiated the withdraw but the contract hangs onto it for a period of time before giving it back to you.
00:17:42.574 - 00:17:57.326, Speaker A: So in the staking mechanics video we talked then about why the cooldown period is usually a good idea. Like you want some period of time just in case some validator has been behaving badly. You want a period of time where they can't actually influence consensus, but you still have control over their stake.
00:17:57.326 - 00:18:17.350, Speaker A: And here we're seeing a really good motivation for having a warm up period as well. In effect, you force validators to commit to the public private key pair they're going to use before they know about any, for example, messages that they might be signing with their private key. So we've made some progress, right, thinking about whether an attacker might be able to manipulate the left hand side of this blue inequality.
00:18:17.350 - 00:18:37.546, Speaker A: They can manipulate R sub T that's by assumption, and they're forced now with the warm up period to commit to their public key private key pair in advance. So at the time they know RT, they also are stuck with whatever private key that they're using. So it should seem like we're done, right? RT is fixed, Ski is fixed.
00:18:37.546 - 00:18:56.614, Speaker A: So I guess the left hand side is fixed as well. Either it's below the threshold or it's above and there's nothing anyone can do about it. Okay, well, sort of that would be true if in fact the left hand side, if that SIG sub ski was a sort of unit valued function, which is how I wrote it, so you'd be natural to interpret it that way.
00:18:56.614 - 00:19:22.010, Speaker A: But in fact, for many signature schemes, there's actually more than one potential valid signature for a fixed message. So SIG sub ski could actually take on a number of different outputs, all of which would be accepted by the verification procedure with the corresponding public key. So while an attacker is no longer in a position to grind over public key private key pairs, those had to be fixed in advance.
00:19:22.010 - 00:19:47.160, Speaker A: It is still in a position to grind over all of the possible valid signatures for the message R sub T. So in many applications, the fact that there's more than one valid signature for a given message, that can actually be a feature in some cases. Here it's definitely a bug, here it's kind of an avenue by which an attacker could manipulate the sampling procedure by just trying lots of signatures and looking for one that's as close to zero as possible.
00:19:47.160 - 00:19:58.540, Speaker A: Fortunately, given the cryptographic state of the art, the fix is straightforward. While some digital signature schemes do not have unique signatures, some do. So just use one of those.
00:19:58.540 - 00:20:27.140, Speaker A: So when I write DSS here on the slide, that's just an acronym for Digital Signature Scheme, which we defined and discussed at some length back in lecture number one. Some of the most familiar signature schemes used in the blockchain world, like ECDSA, do not actually have the unique signatures property, but we are seeing a shift toward ones that do. So, for example, BLS being one notable, increasingly popular signature scheme in the blockchain world that does have this unique signatures property.
00:20:27.140 - 00:20:54.538, Speaker A: So with these fixes, we seem in good shape in the sense that an attacker is just stuck with the value on the left hand side, whatever it may be. It has no control over R sub T that falls from the sky, it has no control over ski, it had to commit to that long in advance, and it has no control over the signature that it can produce because there's only one that would work. A third issue concerns statistical properties of the signatures on the left hand side, right? So the message being signed RC T, that's random just by assumption, right? That's just coming out of the ideal randomness beacon.
00:20:54.538 - 00:21:26.658, Speaker A: But is it the case that just because the message to be signed is random, the signature itself is also random? So this is not going to be true in general, just by knowing that a digital signature scheme is secure, you can't immediately conclude that its signatures and random messages will themselves look random. Which makes sense, right? I mean, the point of a digital signature scheme is just to have unforgivable signatures or signatures that are for all practical purposes, unforgivable. There's no reason to expect you would also have some kind of uniform at random type properties.
00:21:26.658 - 00:21:37.100, Speaker A: That said, some signature schemes. It does sort of appear that the signatures are close enough to random, at least for practical purposes. The BLS signature scheme that I mentioned being one example.
00:21:37.100 - 00:22:19.106, Speaker A: The other good news is that if you're not confident that the signatures coming from your signature scheme look sufficiently random, you can always pass it through a cryptogyphic hash function, some function for which you're comfortable making the random oracle assumption. So that will take the signature and then it will map it to something that really is, for all practical purposes, like a uniformly random draw from the unit interval zero comma one. All right, so let's just put all of these things together, all of these fixes, and review, okay? What is the computation that the owner of some public key is going to do to, in a secret way, figure out whether or not it's been selected as a leader? All right, so this is the same as the blue inequality we had in version two of the idea, except with two fixes.
00:22:19.106 - 00:22:35.802, Speaker A: So first of all, we want to be clear that the signature scheme has unique signatures. And then the other change is we're actually now feeding this signature through a cryptographic hash function. And again, that's a step you can skip if the signatures themselves, you already believe are sufficiently close to being uniformly at random.
00:22:35.802 - 00:22:57.458, Speaker A: If you're not confident in that, then you can pass it through a function for which you are comfortable making the random oracle assumption. So some cryptographic hash function, maybe it's shot 256, maybe it's something else. Passing the signature through a cryptographic hash function in this way actually preserves the secrecy and verifiability properties we were so happy with, with version two of the idea.
00:22:57.458 - 00:23:34.260, Speaker A: So looking now at the upper right part of the slide and the left hand side of this blue inequality, we see that, first of all, the owner of PKI, meaning someone who knows the corresponding private key, is in a position to check whether that public key has been sampled or not efficiently, right? Everybody knows the right hand side, tau and F are public, r sub t is public, and someone who knows the corresponding private key can compute the signature. And then, of course, they can just hash it and check this predicate. So if you know the right private key, you can certainly yourself determine whether or not your registered public key is selected or not.
00:23:34.260 - 00:23:49.574, Speaker A: So second, anybody else, anybody who doesn't know the corresponding private key, who doesn't know SK sub I is unable to determine whether this predicate holds or not. They know the right hand side, that's public. They know R sub t, that's public.
00:23:49.574 - 00:24:08.442, Speaker A: But because they don't know Ski, and because the signature scheme is secure, they cannot generate this signature on the random message R sub t. And if they can't generate that signature, they don't know on what input to evaluate the hash function. So they have no idea what the output of this left hand side is.
00:24:08.442 - 00:24:27.498, Speaker A: That's the second key property. Third key property is that if the owner of public key I is selected and wants to convince other people of that fact. So, for example, they want to make a block proposal and they want to include credentials that show that they have the rights to make a block proposal, that they're a leader of the current round that is easy to do.
00:24:27.498 - 00:24:34.594, Speaker A: So all you need to do is provide your signature on the message R sub t. Everybody knows R sub t. Everybody knows the right hand side.
00:24:34.594 - 00:24:48.566, Speaker A: Everybody knows your public key. So everybody can invoke the verification algorithm for the signature scheme to check that your signature is indeed the right one. And then, of course, everybody can evaluate the hash function themselves and check whether or not it's sufficiently close to zero.
00:24:48.566 - 00:25:01.018, Speaker A: So those are the three key properties we had. So this predicate is easy to evaluate by the owner of the private key corresponding to P sub ki. It's for all practical purposes impossible to evaluate by anybody else.
00:25:01.018 - 00:25:23.710, Speaker A: But if selected, you can quickly convince other people of that fact because they know your public key. So those three key properties we more or less inherit from properties of digital signature schemes. And then a fourth property, which is just that, the left hand side is for all practical purposes a uniformly random number from the interval zero comma one that follows from our standard assumptions around cryptographic hash functions.
00:25:23.710 - 00:25:48.070, Speaker A: And by putting all these things together, you have now learned about a fundamental cryptographic primitive, what this is. So what this sort of hash of SIG, of RT, what that is, is known as a verifiable random function or a VRF. So on the top of the next slide, let me just sort of summarize the definition, which is, again, the properties that we just enumerated.
00:25:48.070 - 00:25:57.326, Speaker A: All right, so just to make sure you can connect this notation to what we had on the previous slide. So the argument to this VRF. That's going to be whatever the current randomness is.
00:25:57.326 - 00:26:14.494, Speaker A: So that's going to be R sub T. That's what in our current context, we're going to be feeding into these verifiable random functions. And where we used to write sort of H of SIG, where H was a cryptographic hash function and SIG was the signing algorithm of some secure digital signature scheme with unique signatures.
00:26:14.494 - 00:26:39.850, Speaker A: Rather than writing h of SIG, I'm just writing VRF. So some people might question my pedagogy here because I'm introducing a cryptographic primitive verifiable random functions VRFs and I've kind of done it through a specific construction, right, namely through digital signatures, possibly also with a cryptographic hash function applied. And that's not what you're supposed to do when you teach and learn cryptographic primitives.
00:26:39.850 - 00:27:07.800, Speaker A: They're really defined fundamentally by the properties that they're supposed to satisfy and then you can separately talk about different constructions that might at least under assumptions, meet all of the desired properties. So here I kind of started you with the concrete implementation using signature schemes and cryptographic hash functions. But again, more generally, what's a VRF? It's anything that satisfies those same kind of secrecy and verifiability properties that we mentioned.
00:27:07.800 - 00:27:35.050, Speaker A: So first of all, to whoever knows the appropriate private key, this is a straightforward function to compute. Second, for people who don't know that private key, who don't know Ski but do at least know the corresponding public key PKI, they're in a position to quickly verify that the function was computed correctly. Just analogous to how in a digital signature scheme knowledge of the public key is sufficient to be able to verify whether a signature was generated correctly.
00:27:35.050 - 00:27:57.522, Speaker A: So because these people don't know Ski, they're not going to be able to compute this VRF from scratch. But if someone else who does know Ski computes it and reports their output, then anyone knowing the public key can check that that is indeed the output it's supposed to be. And finally, if you neither know the private key nor does anybody tell you the answer, you're in no position to actually evaluate this function.
00:27:57.522 - 00:28:10.562, Speaker A: It is hard to compute if the only thing you know is the public key. So here by hard I mean exactly the same thing I meant in our discussion around digital signature schemes. You can go back to lecture one if you want to review that somewhat detailed discussion.
00:28:10.562 - 00:28:33.230, Speaker A: But basically a polynomial bounded attacker should not be able to compute the VRF output except with negligible probability. And finally the property you get if you pass it through a cryptographic hash function for which you're willing to make the random oracle assumption. You want the output of the VRF to be indistinguishable for all practical purposes from true uniform randomness.
00:28:33.230 - 00:28:56.520, Speaker A: So property four is what allows us to take sort of the output of a VRF, maybe it's a 256 bit string, interpret it as a number between zero and one. Basically think of as an integer and dividing by two to the 256. And then for the purposes of analysis, assuming as if that is in fact a uniformly random draw from the interval zero comma one, that's more or less being driven by this fourth property here.
00:28:56.520 - 00:29:23.470, Speaker A: So those are the defining characteristics of this cryptographic primitive of verifiable random functions, or VRFs. If you're the type of person that sort of likes to sort of remember the properties, these are the properties you should remember. If you're the type of person that actually prefers to sort of remember the concept by proxy through a concrete implementation, then you should keep in mind kind of the digital signatures and perhaps hashes of digital signatures that we talked through on the previous slide.
00:29:23.470 - 00:29:32.826, Speaker A: All right, so this is a really good checkpoint in our progress, right? So we thought about proof of stake sampling. We wanted these secrecy properties. We realized we wanted something kind of akin to digital signatures.
00:29:32.826 - 00:29:43.846, Speaker A: We thought through a bunch of the details that led to this important notion of verifiable random functions, or VRFs. So we're going to stop this video here. But I do want to warn you, we're definitely not done.
00:29:43.846 - 00:29:56.020, Speaker A: So there's definitely still some tricky issues that come up when you use VRFs for proof of stake sampling. So we're going to talk through some of those challenges and some of the solutions to those challenges in the next video. I'll see you there.
