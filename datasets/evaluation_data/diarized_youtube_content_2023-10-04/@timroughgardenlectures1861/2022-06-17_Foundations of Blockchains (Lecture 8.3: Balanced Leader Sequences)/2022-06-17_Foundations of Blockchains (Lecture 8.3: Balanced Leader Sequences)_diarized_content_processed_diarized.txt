00:00:00.410 - 00:00:15.018, Speaker A: We concluded last video with by pointing out two limitations of what we might possibly be able to prove about longest chain consensus limitation. Number one. We argued we were doomed unless we have a strict majority of honest notes.
00:00:15.018 - 00:00:36.866, Speaker A: So we're going to be thinking about at minimum, we have something like 51% of the notes honest at most 49% Byzantine. Limitation number two is we noticed that it's very easy for just a couple of dishonest leaders in a row to mess around and change the ends of the longest chain. So it seemed clear that we should not consider the last few blocks of the longest chain to be confirmed.
00:00:36.866 - 00:01:01.630, Speaker A: They should be regarded as still under negotiation. So what then would be the coolest thing that might be true? What is the strongest statement we could try to prove? We could try to prove that as long as you have at least 51% honest nodes, then in fact, the blocks in the longest chain, except for the last few, can in fact be regarded as finalized, will never in fact, be rolled back later. And I've got good news.
00:01:01.630 - 00:01:20.022, Speaker A: This is exactly what we're going to be proving over the next few videos. We will, of course, have to work out exactly how big K needs to be, but there will be a K such that we actually get this finality property. All right, so let's give some notation to this idea of the blocks on a longest chain, except for the last K.
00:01:20.022 - 00:01:47.018, Speaker A: Let's call that B sub K of G, where G just corresponds to the current entry, all of the blocks that are currently known. So, for example, if we set K equal to two and look at this orange entry on the right part of this slide, well, then B sub two of that particular entry would just be the genesis block and the second of the two blocks that extend it. So a couple possible points of confusion.
00:01:47.018 - 00:02:02.974, Speaker A: So number one, this parameter k telling you sort of how many blocks at the end of the longest chain you should consider still under negotiation, that parameter K, that's not part of the protocol description. So remember the description of longest chain protocol. You have this entry nodes are elected as leaders.
00:02:02.974 - 00:02:30.886, Speaker A: They add a new block and grow the entry by one additional node, right? Nothing in that protocol description references a parameter K, rather the parameter k. It's really about how to interpret the entry that's grown over the course of the longest chain consensus protocol. It's really, frankly, sort of in the eye of the beholder, right? So as a user of the blockchain, you can kind of pick your own K and decide how large a prefix of the longest chain you want to consider finalized.
00:02:30.886 - 00:02:52.980, Speaker A: So, for example, if you sell someone a cup of coffee, maybe you're totally comfortable taking K equal to three because you don't care that much if it gets rolled back at some point. Whereas if you're selling someone a Tesla, maybe you wait until maybe you take k equal to 100. So you will wait for 100 extensions of the longest chain before you let the customer drive off with the tesla because you want to be absolutely sure it's never going to be rolled back.
00:02:52.980 - 00:03:11.798, Speaker A: The second point of confusion, which frankly you should be wondering about, is you should be asking whether b sub k of g is actually well defined. I've told you that the way you get b sub k of g is you take a longest chain and you lop off the last k blocks. The problem is you may have more than one longest chain.
00:03:11.798 - 00:03:38.450, Speaker A: And so if you start from different longest chains and lop off the last k blocks, you might conceivably get different things. So for example, in the second entry on the bottom right part of the slide, b, one of g would not be well defined for that particular entry right there's, two longest chains, and even if you lop off the last block of each, you still wind up with different things. So that's what I mean by beaks of k of g potentially not being well defined.
00:03:38.450 - 00:04:02.826, Speaker A: The hope then, and indeed what our first theorem is going to be, is that as long as you have at least 51% honest nodes, then in fact, as long as you pick k sufficiently large, b sub k of g actually is well defined. So there may be sort of multiple longest chains, but the different longest chains are going to wind up disagreeing only in their final k blocks. So if you take two different longest chains, throw out their last k blocks, you actually get the same thing.
00:04:02.826 - 00:04:20.334, Speaker A: So all longest chains have a shared common prefix which extends all the way up to the last k blocks on each of the chains. So really there's sort of three different things we want to prove about longest chain consensus, and I'll state these guarantees all on the next slide. So we want to prove this common prefix property.
00:04:20.334 - 00:04:28.174, Speaker A: So b sub k of g actually is well defined. All longest chains agree with each other, except possibly for their last k blocks. We want to prove finality.
00:04:28.174 - 00:04:52.730, Speaker A: So we want to prove that once a block is considered confirmed, that is, once it has been extended k times on the longest chain, in fact, it won't ever be rolled back at any point in the future. And we want to prove liveness, we want to prove that eventually transactions get added to a block that's confirmed to a finalized block. Now, all three of those results are only going to be true under our standing assumption that at least 51% of the nodes are honest.
00:04:52.730 - 00:05:22.770, Speaker A: So you should be asking yourself, okay, how is that hypothesis going to enter into the proofs of these three guarantees? So I want to make the analysis as modular as possible. So what I'm going to do is on the second half of this slide I'm going to state a definition, a property that a sequence of leaders may or may not have. And then we're going to show that this is a sufficient condition for all three things that we want the common prefix property, the sort of finality property and liveness.
00:05:22.770 - 00:05:55.502, Speaker A: Then having established that the sufficient condition I'm about to write down gives us everything that we want, then we turn our attention to understanding when is that sufficient condition actually going to hold? And that will be the part of the proof where we use the fact that we have at least 51% honest notes. The sufficient condition I'm going to write down on this slide there is like literally no hope this would ever be true if you did not have a majority honest nodes. Before I state the formal definition, let me just remind you that we actually foreshadowed this definition toward the end of the last video.
00:05:55.502 - 00:06:17.250, Speaker A: What we saw there is that an obstruction to being able to finalize blocks would be sort of sequences of leaders where the number of dishonest leaders is bigger than the number of honest leaders. Whenever you have a window with more dishonest than honest, they're in a position to actually cancel some of the blocks at the end of the longest chain. So presumably key to the analysis is going to be the property that that doesn't happen.
00:06:17.250 - 00:06:32.454, Speaker A: That as long as you look at a long enough sequence of leaders, in fact there's going to be more honest leaders than dishonest leaders. And that's exactly what this definition is going to capture. So we're going to want to consider a sequence of A's and H's.
00:06:32.454 - 00:06:48.634, Speaker A: So here A just means some round in which a Byzantine node is chosen as the leader. And H just means some round in which an honest node is a leader. Notice, you know, in analyzing the behavior of the longest chain consensus protocol, we don't have to differentiate between nodes other than whether or not they're honest or adversarial.
00:06:48.634 - 00:06:53.386, Speaker A: Otherwise we really don't care. All honest nodes are acting exactly the same way. They're just following the protocol.
00:06:53.386 - 00:07:04.430, Speaker A: They're just extending along its chain. Different honest nodes might tiebreak differently from each other, but we're assuming nothing about tiebreaking, so that doesn't matter. Adversarial nodes, remember, byzantine nodes we always assume are conspiring against us anyways.
00:07:04.430 - 00:07:16.354, Speaker A: So it really doesn't matter if it's just the same Byzantine node over and over again or if you're sort of cycling through a bunch of different ones. The behavior is exactly the same. So we're going to call such a sequence W balanced here, W is a parameter.
00:07:16.354 - 00:07:42.346, Speaker A: The W is meant to stand for window and the condition states that for every window of length at least W. So for every at least W consecutive rounds, it should be the case that a strict majority of the leaders chosen in those rounds are honest. Now, what's of interest to us is to identify the smallest value of this parameter, W, such that the leader sequences we're interested in are going to wind up being W balanced.
00:07:42.346 - 00:07:54.334, Speaker A: We're certainly not going to get that for like W equals one. Because even if you have a single Byzantine leader ever, that's going to be an A, that's going to be a length one window where you have 0% honest nodes. So you're not going to satisfy this condition.
00:07:54.334 - 00:08:10.540, Speaker A: Same thing W equals two. As soon as you have one adversarial node, you have a length two window with a 50 50 split of honest and dishonest. But there's definitely still hope of if at least 51% of the overall nodes are honest, perhaps we're W balanced for W sufficiently large.
00:08:10.540 - 00:08:45.300, Speaker A: I mean, indeed, notice that if somehow honest nodes were like perfectly evenly represented in this leader sequence, then we'd actually be fine, right? Suppose there's 51% honest nodes. If you considered any sort of window of length 1000, you would be expecting 510 of the 1000 to be honest, a strict majority. That would be if honest nodes were perfectly evenly represented in this sequence.
00:08:45.300 - 00:09:12.648, Speaker A: So that's the definition of a W balanced leader sequence. This is going to be a very important definition for us for the rest of lecture eight. And what we saw at the end of the last video is that if you're running longest chain consensus and the sequence of leaders that you're seeing does not satisfy this condition is not W balanced, then you've got problems, right? Because that means in sort of big windows you're actually seeing more dishonest leaders than honest leaders.
00:09:12.648 - 00:09:34.496, Speaker A: We saw last video that whenever that happens, the dishonest leaders can cancel some number of blocks off of the longest chain, meaning you wouldn't be safe to finalize those blocks. So what's not at all obvious, what we have to prove, and will prove over the coming slides, is that the converse is also true. So it's not just that we're screwed if we don't satisfy the definition, it's also that we're good if we do satisfy the definition.
00:09:34.496 - 00:10:05.080, Speaker A: So if we can generate a sequence of leaders that's W balanced for reasonable W, then we will get everything we want, the common prefix, property, finality properties and liveness. So let's go ahead and state those three guarantees formally. So on this slide we'll be assuming that the definition on the previous slide holds that we're W balanced for a reasonable value of W and we will be concluding everything we want, the common prefix property finality and liveness.
00:10:05.080 - 00:10:25.480, Speaker A: Now, to really capture the essence of these arguments in the simplest way possible, I'm going to make an assumption. It's going to seem strong, it's actually not that strong, but this is going to make our lives easier if we assume we're in what I'm going to call the super synchronous model. And what I mean by super synchronous is there's going to be literally zero message delay.
00:10:25.480 - 00:10:43.328, Speaker A: So this is like the synchronous model with the delta the maximum delay bound equal to zero. So as soon as an honest node speaks in that exact instant all the other nodes will hear about. Now just as a warning supersynchronous, that's not a standard term, I totally just made that up for this lecture.
00:10:43.328 - 00:11:02.632, Speaker A: But what I mean is instant message delivery. So delta equals zero in the synchronous model. Now I totally appreciate this assumption might really bother you, especially given the lectures leading up to this one because at the beginning when I introduced the state machine replication problem I said the goal was to keep various sort of machines in sync with each other.
00:11:02.632 - 00:11:27.792, Speaker A: And the reason they might be out of sync, right, is because of Metz's delays. So by virtue of having all the honest nodes be able to instantly communicate all the information they know to all the other honest nodes, haven't we sort of trivialized consistency? Isn't it kind of like automatic that all of the honest nodes will sort of have exactly the same local history? So the short answer is yes. I mean it is the case that all honest nodes will now have exactly identical information.
00:11:27.792 - 00:11:37.040, Speaker A: So they'll all know about the same entry, they'll all have the same view of the blockchain. However, there's really two types of consistency. There's consistency across different machines.
00:11:37.040 - 00:12:01.292, Speaker A: That's the type that we've trivialized in the supersynchronous model. But consistency should also mean consistency with your future self in the sense that whatever sort of you believe is confirmed now, your future self should also believe that all of those transactions are confirmed. Now, in all of our discussions of state machine replication protocols we kind of didn't have to make this explicit because we just said that each node maintains an appendonly local history.
00:12:01.292 - 00:12:10.796, Speaker A: And so by calling it append only, we are sort of by definition only allowing things to be added. Things can never be rolled back. With longest chain protocols.
00:12:10.796 - 00:12:39.320, Speaker A: On the other hand, we know that we do have to worry about blocks potentially being rolled back especially if we're too eager to confirm them. And this second type of consistency, consistency with one's future self that is not at all trivialized by this supersynchronous assumption. And so just to make it clear like which type of consistency I'm talking about at a given time, if I mean this self consistency, consistency with one's future self like you never roll back transactions, I'll refer to that property as finality.
00:12:39.320 - 00:12:59.490, Speaker A: So I have three defenses for introducing this seemingly unrealistic supersynchronous model. So first of all, all of the guarantees that I mentioned on the last slide that we want to prove so common prefix, property and finality and liveness, none of those are trivial in the supersynchronous model. Those are all going to require some work.
00:12:59.490 - 00:13:30.920, Speaker A: My second defense is that not only are the proofs nontrivial but somehow in the supersynchronous model, we reduce clutter that would otherwise obscure the essential ideas and the arguments. So in the supersynchronous model it's easiest to see fundamentally why these guarantees really are true. My final defense is that it doesn't really matter in the sense that basically the same results hold in the sort of usual synchronous model where there's some nonzero maximum message delay delta known in advance to the protocol.
00:13:30.920 - 00:13:50.780, Speaker A: These extensions to the synchronous model, they're not trivial. I mean they are a good homework exercise if you have a little time. If you've made it through this far in the lecture series, you're certainly capable of sort of understanding and working through these extensions.
00:13:50.780 - 00:14:20.146, Speaker A: Let me also write on the slide a couple research papers which include those details in case you're interested. So the main issue that comes up in extending these results to the synchronous model is that in addition to the sort of deliberate forking by byzantine nodes that we're going to be concerned with because there's now nonzero message. Delays.
00:14:20.146 - 00:14:45.360, Speaker A: You also sometimes have inadvertent forks caused just by honest nodes because basically one of them didn't hear about the other one's block before it proposed its own block. In effect, this means you have these sort of occasional periods where one honest block accidentally cancels out another one. So in the analysis you basically have to argue that that doesn't happen very much and as a result it doesn't really change the basic analysis we're going to do in the supersynchronous model.
00:14:45.360 - 00:15:20.122, Speaker A: And it turns out, and I think it's also kind of intuitive that this will happen rarely, only rarely will sort of two different honest blocks be produced at roughly the same time as long as the rate of block production is slow relative to the maximum message delay. So for example, in bitcoin you might say, okay, the maximum message delay under normal operating conditions is at most, let's say 10 seconds, which is pretty generous. And it turns out because bitcoin blocks are only generated once every ten minutes, the probability that a block it's generated in a ten second window is less than 2%.
00:15:20.122 - 00:15:39.340, Speaker A: So that's what I mean by the rate of block production being slow relative to the maximum message delay. All right, so that's all I want to say about the synchronous model. So from now on we'll proceed in the supersynchronous model.
00:15:39.340 - 00:16:06.950, Speaker A: Just know that for longest chain consensus, the supersynchronous model is actually a really good proxy for the real results in the normal synchronous model with nonzero message delays. All right? So here's the main result. So we are going to assume that the definition, the condition on the last slide holds, we're going to assume that somehow we've produced a sequence of leaders that is W balanced for a reasonable value of W.
00:16:06.950 - 00:16:24.616, Speaker A: So the first consequence of balancedness is going to be the common prefix property. So this means that our notation b sub k of G is well defined. So formally, we're going to be considering a leader sequence, which is two K balanced.
00:16:24.616 - 00:16:45.984, Speaker A: So the parameter w here we're setting equal to two K. And now we want to consider every possible sequence of entries that could possibly arise given this leader sequence. In other words, we're going to be ranging over all possible choices that the chosen Byzantine nodes and chosen honest nodes in this sequence might make.
00:16:45.984 - 00:17:00.096, Speaker A: Now, the Byzantine nodes, as we've discussed, can do a lot of different things. So, for example, they can extend blocks that are not the end of the longest chain. Even the honest nodes do have some flexibility because we're allowing them to break ties between different longest chains arbitrarily.
00:17:00.096 - 00:17:17.640, Speaker A: So when I say for any possible sort of sequence of entries we might see, I mean no matter what the Byzantine nodes do and no matter how the honest nodes happen to tiebreak. So property number one, the common prefix property. In other words, our notation b sub K of G is well defined.
00:17:17.640 - 00:17:36.770, Speaker A: Any two longest chains can differ only in their last K blocks. It is, of course, the same K, right? So in the hypothesis, we're considering a leader sequence which is two K balanced. And then in the hypothesis, we're saying that if you lop off the last K blocks of any longest chain, you'll get the same thing.
00:17:36.770 - 00:17:49.830, Speaker A: So now let's move on to consistency and liveness. And again, for consistency, in the supersynchronous model, we're not worried about the different honest nodes being out of sync with each other. We're just worried about blocks getting rolled back.
00:17:49.830 - 00:18:12.088, Speaker A: So the second property asserts that that can't ever happen. In other words, once a block has been finalized, once it appears in a longest chain with K blocks following it, that will continue to be the case forevermore. And finally, we have liveness.
00:18:12.088 - 00:18:40.292, Speaker A: I'm going to prove the same version of liveness that we stated for the tendermint protocol, namely that if a transaction at some point is known to all of the honest nodes, then at some point that transaction will be confirmed. So it won't merely just appear eventually in the longest chain, it'll appear in the longest chain with K blocks after it. Okay, so this is the main result of lecture eight about longest chain consensus, saying that as long as we can somehow come up with a reasonably balanced sequence of leaders, then we're good.
00:18:40.292 - 00:18:50.648, Speaker A: We are guaranteed to get everything we want. The common prefix property, finality and liveness. Now, you probably have two questions at the front of your mind.
00:18:50.648 - 00:19:10.590, Speaker A: One question would just be like, why is theorem true? We argued that balancedness should be a necessary condition to get stuff that we want. How come it's a sufficient condition to get all of the properties we want? Common prefix property inconsistency and liveness. So I will show you the proofs of all three of those statements, not in the next video, but in the videos after that.
00:19:10.590 - 00:19:27.936, Speaker A: So in the next video we're going to consider the case of randomly chosen leaders. So each round, each of the N nodes is going to have a one over N probability of being that round's leader. So hopefully, even in the permission setting, this seems like a not that crazy thing to do, right? We want things to be balanced.
00:19:27.936 - 00:19:44.570, Speaker A: We want things to be sort of sort of proportionally represented in our leader sequence. So sort of random choices you might hope would more or less satisfy that property. But even more importantly, the case of randomly chosen leaders will extend really gracefully into the permissionless setting that we're going to discuss in lecture nine.
00:19:44.570 - 00:20:01.704, Speaker A: And what we'll see in the next video is that randomly chosen leaders do, with high probability, generate a reasonably balanced leader sequence. Exactly how balanced, you're wondering? Well, we'll talk about that in the next video. But just in case you skip it, I'll mention that it depends on various parameters.
00:20:01.704 - 00:20:13.260, Speaker A: So it depends on exactly what fraction of the nodes are honest. It depends on sort of what duration of time you want to look at. If you just want to have some number for k in your mind going forward, you might want to think about the low double digits.
00:20:13.260 - 00:20:30.890, Speaker A: So say k in the dozens. In practice, depending on the sort of value of the transaction in question, you may not want to wait that long until you do see more aggressive values of k being used. In some cases, like famously for bitcoin, the rule of thumb is to take k equal to six.
00:20:30.890 - 00:20:49.128, Speaker A: So that's the plan going forward. There's sort of five relatively short videos left in lecture eight. In the next one, we'll argue that randomly chosen leaders tend to generate decently balanced sequences of leaders and therefore sort of all of the conclusions of the theorem then apply to randomly chosen leaders.
00:20:49.128 - 00:21:12.132, Speaker A: Then the next three videos will have one for each of these three properties, common prefix, property, finality and liveness. And then we'll wrap up the discussion of longest chain consensus by saying what happens if be stress tested using the partially synchronous model. And compare and contrast the properties of longest chain consensus with those of the BFT type protocols that we studied in lectures two through seven.
00:21:12.132 - 00:21:15.460, Speaker A: So I'll see you in the next video to talk about randomly chosen leaders.
