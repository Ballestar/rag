00:00:00.330 - 00:00:13.770, Speaker A: Hi everyone, and welcome to this video that accompanies section 21.2 of the book algorithms Illuminated part Four. This is a section about computing a long path in a graph using a technique known as color coding.
00:00:13.770 - 00:00:30.470, Speaker A: So graphs are omnipresent in the study of algorithms because you really hit this sweet spot between expressivity and tractability. As we've seen, there's a lot of operations you can do on a graph efficiently. You can search them efficiently, you can compute their connected components, you can compute shortest paths and so on.
00:00:30.470 - 00:00:50.390, Speaker A: We've also seen that there's lots of different application domains that are well modeled by graphs, everything from road networks to the World Wide Web to social networks. So in this section, we're going to see yet another example. It's going to be a killer application of dynamic programming combined with randomization to the problem of detecting meaningful structure in biological networks.
00:00:50.470 - 00:00:51.500, Speaker B: Let's get started.
00:00:53.230 - 00:01:08.110, Speaker A: So before we jump into the problem definition, let me just tell you a little bit about the biological motivation behind this problem. Most of the work that takes place in a cell is carried out by proteins, meaning chains of amino acids. And these proteins often act in concert.
00:01:08.110 - 00:01:35.846, Speaker A: So for example, a series of proteins might transmit a signal that arise at the cell membrane to the proteins that regulate the transcription of the cell's DNA to RNA. Understanding such signaling pathways and how they get rewired by genetic mutations, that's an important step in developing new drugs to combat diseases. Now, interactions between proteins are quite naturally modeled as a graph known as a protein Protein Interaction network or PPI network.
00:01:35.846 - 00:02:11.110, Speaker A: So the vertices of this graph are going to correspond to proteins, and there's going to be an edge between any pair of proteins that are believed to interact. So the simplest type of pathway, and probably the first one you'd want to look for, is a linear pathway which is going to correspond to a path in this PPI network. The problem of finding a linear pathway in a PPI network that can be cast as the minimum cost kpath problem we're here by a kpath, I mean a path in a graph which is simple, so there's no cycles in it and it has k minus one edges and therefore visits k different vertices.
00:02:11.110 - 00:02:24.410, Speaker A: So formally, the input in the minimum cost kpath problem has a bunch of familiar ingredients. There's going to be an undirected graph, capital G. Each edge of that graph is going to have a real valued edge cost C sub E.
00:02:24.410 - 00:02:28.294, Speaker A: And then there's also going to be the target path length we're looking for. So that's going to be a positive.
00:02:28.342 - 00:02:30.998, Speaker B: Integer k. So the output then it's.
00:02:31.014 - 00:02:37.018, Speaker A: Going to be a k path. So again, that means k minus one edges visiting k distinct vertices. So cycles are disallowed.
00:02:37.018 - 00:02:58.470, Speaker A: And amongst all kpaths in the graph, you'd like the one that minimizes the sum of the costs of the k minus one edges in it. If it so happens that the input graph G actually doesn't have any kpaths at all, then the algorithm is responsible for correctly reporting that fact. Going back to the biological motivation, the edge costs reflect the uncertainties inevitable in noisy biological data.
00:02:58.470 - 00:03:16.134, Speaker A: And you should interpret a higher edge cost as meaning a lower confidence that the corresponding pair of proteins really do interact. So missing edges effectively have a cost of plus infinity in a PPI network. The minimum cost kpath then corresponds to the most plausible linear pathway of a given length.
00:03:16.134 - 00:03:25.998, Speaker A: In realistic instances you might want to think about k, the path length being maybe ten or 20, while the number of vertices of the graph might be in the thousands or even perhaps in.
00:03:26.004 - 00:03:27.390, Speaker B: The tens of thousands.
00:03:27.730 - 00:03:40.002, Speaker A: So for example, suppose the input is our favorite running example with five vertices, then the minimum cost of any four path would be the path that goes from C to A to B to.
00:03:40.056 - 00:03:43.714, Speaker B: E. So that particular four path has.
00:03:43.752 - 00:03:59.286, Speaker A: Total cost eight one plus three plus four. To see that it's the minimum possible, note that any four path is going to have three edges and there's only actually a couple triples of edges in this graph that have total costs less than eight. You could look at the one, the two and the three, but that's not a four path, that's a star.
00:03:59.286 - 00:04:05.734, Speaker A: Or you could look at the one and the two and the four, but that's also not a kpath, that's a cycle. So the next best thing is the one, the three and the four.
00:04:05.772 - 00:04:10.014, Speaker B: That's the minimum cost four path of this graph. So at this stage of the book.
00:04:10.092 - 00:04:23.022, Speaker A: Will not be surprised to hear me say that this is in fact an NP hard problem. Actually, if you think about it, this is really a generalization more or less of the traveling salesman problem. And since the traveling salesman problem is NP hard, then certainly this more general.
00:04:23.076 - 00:04:25.300, Speaker B: Problem is NP hard as well.
00:04:26.630 - 00:04:53.450, Speaker A: So how might we go about solving the minimum cost kpath problem? Well, we could reason by analogy, right? So we just looked at the traveling salesman problem in the last couple of videos and the two problems have a very similar feel. The main difference between the two is that in the minimum cost kpath problem you've got A-K-A positive integer, the path length that you're looking for. Whereas in the traveling salesman problem you're looking for a tor, which is basically a path of length n minus one plus one additional edge.
00:04:53.450 - 00:05:21.506, Speaker A: So that very strong similarity would suggest that maybe we should approach the problem in exactly the same way, meaning use dynamic programming. And then even in our dynamic program, why don't we just use the exact same types of subproblems that served us so well for the Tsp? So in other words, we're again going to have a family of subproblems with two parameters. One of the parameters is the endpoint of the path, we're calling that v and then it's also going to be parameterized by a vertex subset, capital S.
00:05:21.506 - 00:05:23.346, Speaker A: Those are precisely the vertices that are.
00:05:23.368 - 00:05:25.250, Speaker B: Visited by this path.
00:05:25.670 - 00:05:48.426, Speaker A: And then the definition of the subprobleblem corresponding to a choice of Capital S and a choice of little V is just to compute the minimum possible cost of any path that ends at V and visits exactly the vertices in Capital S. One minor difference from the Tsp is here a K path could start anywhere. It doesn't have to start at some designated vertex like vertex one.
00:05:48.426 - 00:05:56.586, Speaker A: So that's why we say any path at all starting wherever, ending at v and visiting exactly the vertices of capital S, we want to know the minimum.
00:05:56.618 - 00:05:59.166, Speaker B: Cost of a path of that form.
00:05:59.348 - 00:06:12.338, Speaker A: So we have one such sub problem for each choice of each sensible choice of capital S. And since we're talking about K paths, we only need to worry about sets capital S with K vertices or less. And then also for each choice of a vertex of E drawn from the.
00:06:12.344 - 00:06:15.486, Speaker B: Set capital S. If we successfully solve.
00:06:15.518 - 00:06:28.742, Speaker A: All of these subproblems, then we're going to be done. So the best meaning the least cost of all of the biggest subproblems corresponding to sets capital S with k vertices, the best of those subproblems is going to be the answer. It's going to be the minimum cost.
00:06:28.796 - 00:06:30.410, Speaker B: Of a kpath in the graph.
00:06:30.750 - 00:06:59.046, Speaker A: So that now brings us to this quiz. What I'd like you to think about is, okay, I've told you these candidate subproblems, exactly how many subproblems are there? So the correct answer is the second one. The strongest of these bounds that's correct is big O of k times N.
00:06:59.068 - 00:07:01.238, Speaker B: To the k. The bound is the.
00:07:01.244 - 00:07:12.234, Speaker A: Product of two terms corresponding to the two parameters indexing the subproblems. So the k, of course that just comes from all the different choices of V. So for a given capital S, there's at most k choices of little v.
00:07:12.234 - 00:07:23.966, Speaker A: So that's where the k comes from. The end of the K comes from the number of sensible choices of capital S, the number of subsets that have at most K elements in them. K vertices so that's the empty set which is N.
00:07:23.966 - 00:07:33.694, Speaker A: Choose two plus. Singleton vertices that's n choose one plus pairs of vertices, n choose two plus all the way up to subsets of exactly K vertices, of which there are.
00:07:33.732 - 00:07:36.382, Speaker B: N choose K. So how big is that?
00:07:36.436 - 00:07:46.278, Speaker A: The sum of these K plus one binomial coefficients? Well, it's not too hard to convince yourself that the sum is big o of N to the k. So the total number of subsets of size of most k is big o of N.
00:07:46.284 - 00:07:47.878, Speaker B: To the k. Now, that's going to.
00:07:47.884 - 00:08:01.862, Speaker A: Be an overestimate when K is very big. Like if k equals N, there's actually only two to the N subsets of any size, not N to the N subsets. But when k is small, which is the regime we're going to be interested in, actually there's a matching lower bound up to constant factors.
00:08:01.862 - 00:08:06.906, Speaker A: So for small k, the number of subsets with size of most k really is a constant times n to the.
00:08:06.928 - 00:08:09.382, Speaker B: K. So how should we feel about this bound?
00:08:09.446 - 00:08:29.854, Speaker A: I mean it seems like things are going well, right? It seems like this is a lot like what was happening in the traveling salesman problem back then. We had n times two to the n subproblems n for each of the choices of the endpoints and two to the n for each of the choices of the subset. Here we have the same form k the different choices for an endpoint and n to the k the different choices for a subset with at most k vertices.
00:08:29.854 - 00:08:44.690, Speaker A: So that looks pretty good. And remember back in the Tsp we were happy because even though our running time was exponential, it was better than exhaustive search. Exhaustive search was n factorial and we had a running time which was two to the n times n squared times a polynomial factor.
00:08:44.690 - 00:09:25.226, Speaker A: So here we're going to get a dynamic programming algorithm which has sort of end to the k running time times a polynomial factor. So how does that compare to exhaustive search? So the answer to the quiz is the second one, big O of k times n to the k, that is the running time of the most straightforward version of exhaustive search.
00:09:25.408 - 00:09:27.322, Speaker B: So the simplest version of exhaustive search.
00:09:27.376 - 00:09:53.118, Speaker A: Doesn'T sort of explicitly enumerate paths, rather it just enumerates ordered tuples of k vertices. So vertex 17 followed by vertex four followed by vertex 23, et cetera. Then once you have your list of k vertices, you can just check in linear time if it's actually a path in the graph, and then if it is, you make a note of its cost and then you just remember the smallest cost you ever see of any of the tuples that wind up corresponding to kpaths.
00:09:53.118 - 00:09:59.094, Speaker A: So there's end of the k choices for those k tuples and then it's going to take linear and k work.
00:09:59.132 - 00:10:00.534, Speaker B: To check each one.
00:10:00.732 - 00:10:23.678, Speaker A: So this quiz spells trouble. It says we actually should not be pleased at all with the bound on the number of subproblems that we had in the first quiz because the bound on the number of subproblems was O of k times n to the k, exactly the same as the running time of exhaustive search anyways. So unlike in the Tsp, where those subproblems gave us a speed up over exhaustive search from n factorial to more like two to the n.
00:10:23.678 - 00:10:39.150, Speaker A: Here we're getting no speed up at all exhaustive search or dynamic programming. The running time is going to be n to the k times some polynomial factor and mind you, n to the k. For the types of graphs we're talking about, say, like at least 1000 vertices, that's a totally useless algorithm.
00:10:39.150 - 00:10:44.678, Speaker A: Certainly already when k equals five. So that's kind of a disaster. We're not beating exhaustive search.
00:10:44.678 - 00:10:58.906, Speaker A: To do that, we're going to need another idea. So why is it exactly that we're using so many subproblems? Well, it's because through the parameter capital s we're keeping track of the exact set of vertices that's been visited so.
00:10:58.928 - 00:11:00.086, Speaker B: Far by a path.
00:11:00.198 - 00:11:32.862, Speaker A: And with there being at most k vertices, that means there's roughly end of the k possible choices of what's been visited so far. We inherited this idea, this parameter capital s, from our solution to the traveling salesman problem where we kept track of the exact subset that a path had visited thus far. Why were we doing that in the Tsp? Well, it's because when we had a solution to a smaller sub problem, a path, and we wanted to extend it to an optimal solution to a bigger sub problem by adding one edge at the end, we needed to make sure that that edge wasn't visiting some vertex.
00:11:32.926 - 00:11:34.606, Speaker B: Previously visited by the path.
00:11:34.718 - 00:11:36.546, Speaker A: That would create a cycle that would.
00:11:36.568 - 00:11:37.398, Speaker B: Be a no no.
00:11:37.484 - 00:11:52.790, Speaker A: So the motivation for tracking exactly which vertices a path visited so far was to make sure that we never visited a vertex more than once. So that sounds important. Also, for the minimum cost kpath problem, right, we also are required to have cycle free paths.
00:11:52.790 - 00:12:00.574, Speaker A: Still, you got to wonder, can we track less information than literally the entire subset of vertices that's been visited so.
00:12:00.612 - 00:12:01.802, Speaker B: Far on a path?
00:12:01.946 - 00:12:04.542, Speaker A: So we can using an inspired idea.
00:12:04.676 - 00:12:06.810, Speaker B: Known as color coding.
00:12:06.970 - 00:12:16.814, Speaker A: So there are two steps to color coding. In the first step that's going to be a vertex partitioning step. So we've got our vertex set capital v, we've got our target path length.
00:12:16.862 - 00:12:18.846, Speaker B: Little k. And in step one we're.
00:12:18.878 - 00:12:24.642, Speaker A: Going to split the vertex set into k different groups. So for example, if k equals four.
00:12:24.696 - 00:12:26.840, Speaker B: We might get a cartoon like this one.
00:12:27.210 - 00:12:45.242, Speaker A: And the reason this technique is called color coding is because we can visualize this grouping as assigning every vertex a color. So here v one would be the red vertices, v two the green vertices, v three the blue vertices, and v four would be the yellow vertices. So I'll tell you exactly how we do this vertex partitioning in a little bit.
00:12:45.242 - 00:13:05.410, Speaker A: The main property we're going to need is that it should be the case that some optimal solution, so some minimum cost kpath should have the property that it is panchromatic under this coloring, under this partitioning. That is, each of its k vertices should have a different color. Or if you prefer, each of the k vertices of this optimal kpath should belong to a different group.
00:13:05.410 - 00:13:42.852, Speaker A: So for example, we might have a panchromatic path that begins in v two before proceeding to v three and then a vertex in v one and concluding with a vertex in v four. The second step of color coding solves the minimum cost kpath problem, but with a twist, with the twist that you only want to look for panchromatic paths. So in your graph, given the vertex partitioning, given the vertex coloring among all of the panchromatic kpaths in the graph.
00:13:42.916 - 00:13:45.930, Speaker B: Your responsibility is to compute the minimum cost one.
00:13:46.780 - 00:14:02.920, Speaker A: Now notice while a panchromatic path is automatically a kpath automatically has k vertices in it, the converse is not true. There's going to be kpaths that are not panchromatic. So for example, here's one that starts and ends at v four and skips v two entirely.
00:14:02.920 - 00:14:09.624, Speaker A: So if we can carry out both of these steps, we definitely would have solved the problem. We care about the minimum cost kpath.
00:14:09.672 - 00:14:11.744, Speaker B: Problem because after all the second step.
00:14:11.782 - 00:14:20.336, Speaker A: It'S computing a minimum cost panchromatic path, while the first step ensures that the minimum cost panchromatic path is in fact a minimum cost k path of the.
00:14:20.358 - 00:14:23.924, Speaker B: Original graph g. Now, I totally understand.
00:14:24.042 - 00:14:48.344, Speaker A: If you're rather skeptical of this idea. So first of all, looking at the second step, you're like, well, why should this problem of computing a minimum cost panchromatic path be any easier than the one we started with computing a minimum cost k path without the pancromatic constraint? But even more bafflingly, look at this first step. How on earth are we going to get a vertex partitioning with this property when we don't even know anything about what the minimum cost k paths look like?
00:14:48.382 - 00:14:50.252, Speaker B: The whole point is to compute one of them.
00:14:50.386 - 00:15:03.056, Speaker A: So let me respond to those two sources of skepticism in order. So let me first show you that in fact we can, using dynamic programming, compute a minimum cost pancreatic path faster than any of our attempts to just.
00:15:03.078 - 00:15:05.730, Speaker B: Directly solve the minimum cost kpath problem.
00:15:06.500 - 00:15:31.474, Speaker A: Then once after we've seen how to implement step two, we will turn to step one and I'll explain how exactly we compute this vertex partitioning. Spoiler alert, it's going to involve randomization. Now let's discuss and solve the minimum cost panchromatic path problem.
00:15:31.474 - 00:15:40.402, Speaker A: So like before, we're given an unretched graph where the edges have real valued costs. But now we're additionally given a partitioning of the vertex set into k groups.
00:15:40.466 - 00:15:41.762, Speaker B: V one up to VK.
00:15:41.906 - 00:15:55.478, Speaker A: Or if you prefer, think of it as a coloring of the vertices in k colors. Our responsibility is then to among all of the panchomatic paths in the graphs. Remember, these are paths with exactly one vertex in each of the groups.
00:15:55.478 - 00:16:16.734, Speaker A: Among all the panchromatic paths in the graph, we should compute the one with the minimum cost. Or if there are no panchromatic paths in the graph, we should correctly report that fact. So why is this pancreatic constraint helpful? Why does it allow us to design a faster algorithm? Well, remember the reason we had this end of the k subproblems in the original minimum cost Kpath.
00:16:16.734 - 00:16:20.414, Speaker A: Problem is because we kept track of exactly what vertices a path had visited.
00:16:20.462 - 00:16:22.994, Speaker B: So far, the big savings you get.
00:16:23.032 - 00:16:48.446, Speaker A: In the pancrematic case is you do not have to remember the identities of the vertices that you've seen so far, you only have to remember the colors of the vertices that you've seen thus far. So as we'll see, subproblems are going to be indexed not by subsets of vertices, but subsets of colors. While there are roughly N to the K subsets of at most K vertices, there's only two to the K subsets of colors, and two to the K is much, much better than N to.
00:16:48.468 - 00:16:50.910, Speaker B: The K. So moving on to the.
00:16:50.980 - 00:17:07.362, Speaker A: Formal definition of the subproblems, I need one quick piece of terminology. So by an S path here, S means a subset of colors, so a subset of one two up to K. So an S path is going to mean a path that visits vertices with colors in capital S.
00:17:07.362 - 00:17:13.782, Speaker A: Exactly. One vertex with each of the colors in S and does not visit any vertices that do not have colors inside.
00:17:13.836 - 00:17:16.774, Speaker B: Of S. So, for example, if S.
00:17:16.812 - 00:17:32.586, Speaker A: Corresponds to the colors red, Yellow, and Blue, an S path would be a path that visits exactly one Yellow vertex, exactly one Red vertex and exactly one Blue vertex. Note that K paths correspond exactly to the capital S paths, where capital S is the set of all colors, the.
00:17:32.608 - 00:17:34.300, Speaker B: Set of all of one through K.
00:17:34.830 - 00:17:47.262, Speaker A: So, like in our first attempt, and like in the Tsp, the subproblems are going to be indexed by two parameters, as in the previous cases. The second of those parameters is the final vertex visited by the path. So that's what we're calling v here.
00:17:47.262 - 00:18:10.950, Speaker A: But as we said, we're not going to be tracking exactly which vertices a path has seen, only which colors it has seen. So we'll have one subpath for each choice of a subset capital s of colors and each choice of the ending vertex v and the sub problem's job is then to compute the minimum cost of any path that is an S path, so it visits vertices exactly with the colors in capital S and moreover.
00:18:11.450 - 00:18:15.034, Speaker B: Ends at the vertex v. Now, in.
00:18:15.072 - 00:18:34.846, Speaker A: What sense are optimal solutions to these subproblems composed of optimal solutions to smaller subproblems? Well, here things will proceed exactly as they did in the Tsp. Consider an optimal solution to a subprop. So for some choice of v and some color is capital S, look at the minimum cost S path ending at.
00:18:34.868 - 00:18:37.680, Speaker B: The vertex v. Call that path P.
00:18:38.230 - 00:18:44.306, Speaker A: As usual, we consider the final decision made by that optimal solution. So the final hop, say from some.
00:18:44.328 - 00:18:47.746, Speaker B: Vertex W to the vertex v. What.
00:18:47.768 - 00:19:04.450, Speaker A: We'Re expecting is that once you know the final hop, once you know the penultimate vertex W, then the prefix of the path should be optimal for the appropriate smaller subproblem. And that is in fact the case for exactly the same reasons we saw in the Tsp. So what is the subproblem? Well, obviously this path prefix p prime.
00:19:04.450 - 00:19:20.442, Speaker A: Now it ends at the vertex W, so that's going to be the value of that parameter. And moreover, we know the colors it visits should be exactly the colors visited by the original path capital P minus the color that v happened to be. So in this cartoon I've shown v as having the color yellow.
00:19:20.442 - 00:19:36.286, Speaker A: So this prefix path P prime is going to be optimal for the color subset capital S minus yellow comma w. If you wanted to prove this formally, you'd proceed by contradiction, just as we have many times in the past. So you'd say, well, suppose P prime wasn't actually optimal for its subproblem.
00:19:36.286 - 00:19:55.434, Speaker A: Suppose there was a still better path P double prime that had even less cost. Well, then you would take P double prime, you would tack on that final hop w comma v to the end of it, and you get a new path that has smaller cost than P, and so therefore would be a better solution to P's problem than P itself. But that can't happen because we started.
00:19:55.472 - 00:19:58.586, Speaker B: With an optimal solution, P. So what.
00:19:58.608 - 00:20:10.606, Speaker A: This means is that there's only a very limited number of candidates vying to be the optimal solution to a sub problem. Once you know the final hop of the optimal solution, the penultimate vertex W, you know what the rest of the.
00:20:10.628 - 00:20:12.094, Speaker B: Path has to look like.
00:20:12.212 - 00:20:28.402, Speaker A: So our recurrence then is just going to perform exhaustive search over the possibilities for the penultimate Vertex W. So there'll be one possible choice of W for each edge incident to the Vertex V. So this recurrence looks almost identical to the recurrence that we had for the traveling salesman problem.
00:20:28.402 - 00:20:45.506, Speaker A: Which is not surprising, because we came about it via the exact same reasoning. Only difference is here subsets of colors are substituting for what had been subsets of vertices. And as always with dynamic programming, once you've figured out the right subproblems and the recurrence that links their solutions, you're done.
00:20:45.506 - 00:20:55.830, Speaker A: The algorithm just writes itself. So we're just going to call the algorithm panchromatic path. Remember, this algorithm, in addition to the graph and the edge costs, it is given a coloring or a vertex partitioning.
00:20:55.830 - 00:21:02.254, Speaker A: So I'm going to use the notation sigma of v to denote the color that is assigned to the vertex v.
00:21:02.292 - 00:21:04.106, Speaker B: And again, that's part of the input.
00:21:04.298 - 00:21:17.474, Speaker A: As usual, we start with our subproblem array, capital A. It's going to be two dimensional reflecting the two parameters that index our subproblems. So the first parameter is the subset of colors, any non empty subset of colors we have to deal with.
00:21:17.474 - 00:21:41.888, Speaker A: So that's two to the k minus one choices for capital S, and then there's N choices for the ending vertex little v, or by N I mean the number of vertices. So next we proceed to the base cases. subproblem size here corresponds to the number of colors in capital S.
00:21:41.888 - 00:21:53.568, Speaker A: So the base cases, the smallest subproblems, that's where capital S has size one, so it contains only one color in it. So we have one subproblem for each possible choice of a color I and for each possible choice of the endpoint.
00:21:53.664 - 00:21:56.760, Speaker B: V. Here the subproblem is asking for.
00:21:56.830 - 00:22:17.320, Speaker A: For example, the minimum cost length of a path that visits exactly one red vertex and nothing else, and ends at vertex number 17. And there's two cases, right? Either vertex number 17 happens to be red, in which case the empty path fits the bill and has cost zero. Or if vertex number 17 is not red, if it's like green, well then no path of that type exists.
00:22:17.400 - 00:22:19.820, Speaker B: So the subproblem solution is plus infinity.
00:22:20.420 - 00:22:40.484, Speaker A: Now we move on to solving all of the subproblems systematically from smallest to largest. So we're going to have an outer for loop which keeps track of the subproblem size, so little S, that'll be the number of colors in the sets capital S that we're currently looking at. Then we have another for loop, which enumerates over these subsets of colors with the target size with size little s.
00:22:40.484 - 00:22:50.600, Speaker A: And then we have another for loop to search over the second parameter over all possible choices for the endpoint V once you've specified all those things. We know what subproblem we're talking about. Capital S, little V.
00:22:50.600 - 00:23:05.196, Speaker A: And we just invoke the recurrence to compute its solution. The last step is to extract the final solution from the solutions to our largest subproblems. You'll notice there are N different largest subproblems ones for each choice of V.
00:23:05.196 - 00:23:27.210, Speaker A: So that subproblem solution corresponds to the minimum cost panchromatic path that happens to end at the vertex v. In the problem statement, we don't care where the path ends, so we want to search exhaustively over the end choices of v and return the best of those subproblem solutions. So that's the pseudocode for the pancromatic path problem.
00:23:27.210 - 00:23:48.478, Speaker A: So once again, the input there was a graph with real valued edge costs and also a partitioning of the vertex set into k groups, or if you like, a coloring of the vertices of the graph into k different colors. And that algorithm computes the minimum cost of any panchromatic path, a path that has k vertices with each color represented exactly once. Let's talk about the algorithm's properties.
00:23:48.478 - 00:24:03.106, Speaker A: So, first of all, correctness as usual with dynamic programming, there's not a lot to say. Correctness follows by induction, induction on the subproblem size. So for the inductive step, you have to argue you solve a sub problem correctly, given that you've already solved all of the smaller ones correctly.
00:24:03.106 - 00:24:20.822, Speaker A: So that's really justifying the recurrence. And the way you justify the recurrence is through our optimal substructure reasoning. So we showed that the optimal solution to a sub problem can only be one of a limited number of candidates, our recurrence exhaustively searches over all of those candidates, the best of which must indeed be the optimal solution.
00:24:20.822 - 00:24:39.886, Speaker A: So correctness of the recurrence drives the inductive step, which drives the correctness of the pancreatic path algorithm. As usual with dynamic programming, I've just showed you the basic version which does the forward pass through the sub problem solution array. So this algorithm would be fine if you just cared about knowing the value of the minimum cost pancreatic path.
00:24:39.886 - 00:24:52.982, Speaker A: It doesn't give you the path itself, but as usual, it's simple to add a post processing reconstruction step that traces back through the array and gives you a minimum cost pancreatic path. And it's going to be linear time.
00:24:53.036 - 00:24:55.640, Speaker B: Linear even in the path length k.
00:24:56.170 - 00:25:03.106, Speaker A: The running time analysis is a little more interesting and should give you, hopefully pleasant flashbacks to our running time analysis.
00:25:03.138 - 00:25:04.810, Speaker B: Of the Bellman Ford algorithm.
00:25:05.310 - 00:25:25.454, Speaker A: So how much time does it take to solve a single subproblem? So say a sub problem corresponding to the color subset capital S and the endpoint v. Well, the recurrence has to do exhaustive search over all possible final hops of an optimal solution. And so there's one candidate for each edge w comma v incident to v.
00:25:25.454 - 00:25:33.986, Speaker A: So in other words, the number of different cases the recurrence has to search over using constant time for each is the degree of the vertex, the number.
00:25:34.008 - 00:25:36.722, Speaker B: Of incident edges, so that's the running.
00:25:36.776 - 00:25:53.574, Speaker A: Time of a single iteration of the triple for loop. Now let's take a step back and let's ask for a fixed setting of the parameters in the first two for loops, the subproblem size and the specific set capital S of that size. Let's ask how much time is done in total by solving the n subproblems.
00:25:53.702 - 00:25:55.430, Speaker B: In that third for loop.
00:25:55.590 - 00:26:22.750, Speaker A: Well, each of these subproblems gets solved in time proportional to that vertex's degree. So solving all of these n subproblems is going to be proportional to the sum of the vertices degrees. So you may know another name for the sum of the degrees of the vertices of an undirected graph, that other name being two m, twice the number of edges m, right, because each edge of an undirected graph, it contributes one, exactly one to the degree of each of its two endpoints.
00:26:22.750 - 00:26:25.906, Speaker A: So the contributions over all m edges, the sum of all the degrees is.
00:26:25.928 - 00:26:28.466, Speaker B: Just equal to two m. So what.
00:26:28.488 - 00:26:37.206, Speaker A: That means is that the running time of all of the subproblems corresponding to a particular color subset capital S runs in linear time. So O of m time, where m.
00:26:37.228 - 00:26:38.754, Speaker B: Is the number of edges in the graph.
00:26:38.882 - 00:26:50.630, Speaker A: Probably, to be precise, I should write O of m plus n here just in case the graph is disconnected. But let's ignore that, let's just call it O of m time. To solve all of the subproblems corresponding to a particular color subset capital.
00:26:50.710 - 00:26:53.482, Speaker B: S. That means the overall running time.
00:26:53.536 - 00:27:04.446, Speaker A: Is just the number of choices of capital S times O of M. And there are, of course, two to the K choices of the color subset, capital S. So that gives us a final running time of two to the K.
00:27:04.548 - 00:27:07.182, Speaker B: Times M. So how should we feel.
00:27:07.236 - 00:27:25.490, Speaker A: About this running time? Well, maybe mixed feelings. I mean, on the one hand, it's too bad to see there is this exponential factor in the running time two raised to the number of colors k. But then you think about it, you're like, we're dealing with exact algorithms here for NPR hard problem, so we got to expect some kind of exponent to show up somewhere.
00:27:25.490 - 00:27:43.466, Speaker A: And then you think more about it and you're like, well, actually, we're beating the pants off of exhaustive search. Remember, for these Kpath problems you have to enumerate all k tuples of ordered k tuples of vertices of which there's roughly N to the K. So instead of a running time scaling as N to the K we're getting a running time scaling more like two to the.
00:27:43.488 - 00:27:45.506, Speaker B: K. And for the kinds of parameter.
00:27:45.558 - 00:28:04.686, Speaker A: Choices that we're interested in, where K might be ten or 20 and N might be in the hundreds or thousands, this is a massive, massive difference. Huge savings over exhaustive search. So the final piece of bad news is that this actually isn't the problem that we originally set out to solve.
00:28:04.686 - 00:28:24.614, Speaker A: We originally wanted to solve the minimum cost kpath problem. What we've shown is that with this weird extra constraint, this pancromatic constraint, with that twist, we can solve the problem much, much faster than exhaustive search. But how is this subroutine useful for the problem? We really care about minimum cost kpath without the pancreatic constraints.
00:28:24.614 - 00:28:29.110, Speaker A: Well, enter randomization. That's coming up next. Bye.
