00:00:00.170 - 00:00:12.138, Speaker A: We're going to finish up the discussion, the proof of LP decoding from last lecture. And then we're not going to do any hard technical stuff, but I'll give you sort of the high level goals of smooth analysis. That's what we'll do in the second half of the lecture.
00:00:12.138 - 00:00:30.466, Speaker A: So let me help you page back in where we left off last time. The good news is, almost everything we did Monday, we can just sort of accept as true and then sort of just proceed from there, which is what were we doing? So we were considering to coding. So we talked about these families of codes, which you can define using a graph, a Bipartite graph.
00:00:30.466 - 00:00:48.550, Speaker A: So on the left hand side, you have variables, on the right hand side, you have these parity checks. So each parity check just consists of a subset of the variables and is asking that an even number of that subset of variables is equal to one. And the code words are exactly those vectors that satisfy every single one of those parity checks.
00:00:48.550 - 00:01:05.946, Speaker A: And so we proved last time on Monday information theoretically, that these codes have good distance if you use a Bipartite graph that has expansion. So that was this short proof we did that, used the fact that many parity checks have a unique neighbor if you have a bunch of corruptions. And then we shifted attention to focusing.
00:01:05.946 - 00:01:22.390, Speaker A: Okay, how can we do it computationally efficiently? We don't just want to know that it's possible in principle to decode. We want a polynomial time algorithm to do it. And like several previous lectures we're studying in particular, when does linear programming work? What does it mean by work? Well, we write down the linear relaxation for this NP hard problem.
00:01:22.390 - 00:01:32.794, Speaker A: Okay, so we started with an integer program, which was exactly the problem of finding the nearest code word to a given message, z. We looked at a linear relaxation. Sometimes it's going to be fractional because the problem is NP hard.
00:01:32.794 - 00:01:43.786, Speaker A: But we're asking for sufficient conditions under which we solve the linear program in polynomial time. And it gives us back on a silver platter the nearest code word. Okay, so extra conditions under which we get the exact solution.
00:01:43.786 - 00:02:04.660, Speaker A: And we made a lot of progress on Monday. So specifically, we identified a sufficient condition under which the unique optimal solution to this linear program is indeed what we want is indeed the nearest code word to the corrupted code word that we were given. So let me just remind you sort of what that condition was.
00:02:04.660 - 00:02:15.494, Speaker A: Okay? So here's theorem we're trying to prove. So all of this is exactly the same terminology and notation as Monday. So this is all in your notes or on the video from last time.
00:02:15.494 - 00:02:23.690, Speaker A: So we're thinking about a Bipartite graph that satisfies three conditions. The first two conditions basically just says it's bounded degree. So that's the low density part of the low density parity check.
00:02:23.690 - 00:02:32.406, Speaker A: In particular, every node on the left hand side has degree D. And think of D as maybe like twelve. So that's the number of parity checks in which each variable participates.
00:02:32.406 - 00:02:44.242, Speaker A: The right hand side I e the number of variables in a parity check that's also constant, maybe twice as big, 25, something like that. The third condition is the expansion condition. So I've written that here so that you can remember.
00:02:44.242 - 00:03:09.382, Speaker A: So this is what says that on the left hand side, if on the left hand side of the bipartite graph, you take a constant fraction of the vertices S, so most delta times n, where delta is some constant, then the number of distinct neighbors of S and of course it's bipartisan. So the neighbors are on the right hand side. The number of distinct neighbors of nodes of S is almost as big as it could possibly be.
00:03:09.382 - 00:03:17.450, Speaker A: Every node on the left hand side has degree D. So the most number of labels neighbors you could possibly have is D times capital S. You have 75% of that at least.
00:03:17.450 - 00:03:24.862, Speaker A: And that's true for every sufficiently small set s all the way up to a constant fraction of the nodes, all the way up to delta N nodes. So that's condition three.
00:03:24.996 - 00:03:25.630, Speaker B: Okay?
00:03:25.780 - 00:03:43.314, Speaker A: So we're trying to prove that whenever you have a code defined by such a bipartite graph, then this linear program and you suffered sufficiently few errors. So last time I wrote delta naught times n, I'm just taking delta naught to be delta over two. So if you suffered at most delta N over two errors, then the LP is exact.
00:03:43.314 - 00:04:05.030, Speaker A: And we proved that if there exists feasible edge weights for the bipartite graph, and I'll tell you what that means, but we proved if there exists feasible edge weights, then we get the conclusion we want, then we get exactness of the LP. So we reduced the proof of the theorem to the proof under the same hypotheses of the existence of a certain family of edge weights.
00:04:05.110 - 00:04:05.450, Speaker B: Okay?
00:04:05.520 - 00:04:31.598, Speaker A: So that's what we accomplished on Monday. So the remaining action item, the remaining thing to do is to show that under these hypotheses, we really can exhibit weights that satisfy these conditions, okay? And so that's we're going to do for the next 20 or 30 minutes or so, right? So the proof of that, that's what we did at the end of last lecture, that was just this weak duality argument, which is sort of, kind of very algebraic, but you just follow your nose and it works out in some sense. Really, you should think of it.
00:04:31.598 - 00:04:44.710, Speaker A: The reason these things are defined, the way they're defined is, is exactly so that proof at the end of last lecture works. I mean, really the way you think about is you start with the proof that you want and then you reverse engineer the condition. And this is just the condition that pops out it's a special case of weak duality.
00:04:44.710 - 00:04:55.286, Speaker A: All right, so what is a feasible edge weight? This is what we actually got to have to exhibit this lecture. So we have this graph. So we're going to assign a weight to every single edge of the graph.
00:04:55.286 - 00:05:13.418, Speaker A: That's wij could be positive or negative. And the first two conditions basically say it gives us a budget on the total edge weight that can be incident to a node on the left hand side. So if we think about some node on the left hand side and its various neighbors.
00:05:13.418 - 00:05:33.698, Speaker A: All right, so one other thing to remember also on the homework, and we mentioned this Monday, by a shifting argument to prove the theorem, we can focus on the case where the code word we want to recover is all zeros, which is definitely a member of the code. So in our mind we think of that the sender sent the code word zero. There were at most this many errors.
00:05:33.698 - 00:05:42.726, Speaker A: So we get a vector with at most this many ones. Everything else is zero. And we want to solve this LP and have it solved to the all zeros solution.
00:05:42.726 - 00:05:51.306, Speaker A: Okay, so capital I denotes the coordinates with no corruption. So these denote the zeros, j denotes the ones. So there aren't that many of these.
00:05:51.306 - 00:06:01.338, Speaker A: This is where we got a bit flip. Okay, feasible edge weights. That means that for all of the uncorrupted coordinates, you get a budget of one on the sum of these edge weights.
00:06:01.338 - 00:06:04.554, Speaker A: But for the corrupted coordinates, these have to on average be negative.
00:06:04.602 - 00:06:04.814, Speaker B: Okay?
00:06:04.852 - 00:06:22.530, Speaker A: So the sum of these edge weights has to be less than minus one. So those are the first two conditions. Then we also have this condition on pairs, which says on the other hand, if you think about it from the right hand side of the graph, if so you look at any two variables that participate in a parity check j, then the sum of their edge weights should be non negative.
00:06:22.530 - 00:06:32.714, Speaker A: Okay, so we actually needed this for all even cardinality sets. But then we observed at the end of last lecture, if you have this for pairs, you have it for all even cardinality sets, just automatically. Okay, so that's where we were.
00:06:32.714 - 00:06:43.210, Speaker A: So we want to prove that under these conditions these always exist. And the proof is I'm just going to show you the weights. So any questions about what we're doing or why? That's the missing lima.
00:06:43.210 - 00:07:00.850, Speaker A: All right then let's do it. So proof. All right, so J is the errors, remember, and there aren't too many of them and that's obviously going to have to be used somewhere.
00:07:00.850 - 00:07:20.838, Speaker A: So here's the first step. So we're going to exhibit these weights and we're going to have to make sure that both A and B hold and somehow right on the borderline, we're going to have to have still a third argument. So the first step is we're almost going to have to take a closure operation over the corrupted coordinates.
00:07:20.838 - 00:07:46.980, Speaker A: So we're going to supplement the corrupted coordinates j by extra coordinates which weren't themselves corrupted, but somehow they're almost like corrupted by osmosis, by other corruptions that they share a lot of parity checks with. Okay, so precisely I'm going to define a set k of coordinates. So, again, coordinates I-E-A bunch of vertices on the left hand side.
00:07:46.980 - 00:08:04.354, Speaker A: So these are coordinates which are not themselves corrupted, so they belong to i, but at least 50% of their parity checks do have a corrupted variable.
00:08:04.482 - 00:08:05.160, Speaker B: Okay.
00:08:07.050 - 00:08:33.218, Speaker A: So in other words, have neighbors in j. All right, so the picture you want to have in mind is so here are all the flipped coordinates. J and they have some neighbors, and you always want to think of sort of the parity checks that these variables appear in are polluted in some sense.
00:08:33.218 - 00:08:55.974, Speaker A: So they've got some things going wrong. And K so Vertex and K is somebody for whom a lot of their parity checks contain some other corrupted variable. All right, so that's the definition, and you'll sort of see why we use this definition in a second.
00:08:55.974 - 00:09:19.086, Speaker A: But the first thing I want to prove is that actually, even if we throw in k, it doesn't blow up the sort of size of coordinates we have to argue about by very much. So k is sort of not much bigger than j. So the claim is that if we look at j and k together, so the corrupted coordinates plus these kind of corrupted by relationship coordinates, it's still at most delta n.
00:09:19.086 - 00:09:22.958, Speaker A: Delta is the same delta as in the expansion condition.
00:09:23.054 - 00:09:23.700, Speaker B: Okay?
00:09:25.110 - 00:10:12.420, Speaker A: So that's the first thing I want to prove. So this will be the first, but not the last time that we use the expansion condition. So proof of claim, we're going to proceed by contradiction, and the contradiction will be eventually to the expansion condition that g allegedly satisfies.
00:10:12.420 - 00:10:27.300, Speaker A: So suppose in fact, this is bigger than delta n. I want to choose a subset that's exactly size delta n. The reason I want that size is because I want the expansion condition to actually apply to this subset, and this only goes up to sets of size delta n.
00:10:27.300 - 00:10:49.616, Speaker A: Okay, so choose a bunch of coordinates. So, again, we're dealing with left hand side vertices here. So that on the one hand, basically what we do is we take the corrupted coordinates j, and we just supplement them by these corrupted by one hop coordinates up until the size of delta n.
00:10:49.616 - 00:11:16.112, Speaker A: Okay, so j union k, and the size of S is exactly delta times n. Okay? So in this picture over here, I'm taking all of j and part of k. All right? So I want to show that this condition is violated, and that's my contradiction.
00:11:16.112 - 00:11:24.248, Speaker A: So what does this condition say? Ask about the neighbors of s. Okay, so basically I'm going to want to say that actually, if J union k is too big, then here's a set that doesn't expand.
00:11:24.344 - 00:11:24.828, Speaker B: All right?
00:11:24.914 - 00:11:32.904, Speaker A: So to talk about it not expanding, I need to count its neighbors. I need to say the number of distinct neighbors is not too big. So let's try to figure out how many neighbors does S have.
00:11:33.042 - 00:11:33.536, Speaker B: Okay?
00:11:33.638 - 00:11:48.580, Speaker A: And intuitively, if you look about the definition of k, k is defined as basically saying it already has a lot of redundant neighbors with the people already in J. So that's sort of where the contradiction is going to come from. There's just too many neighbors in common, given that this thing is an expander.
00:11:48.580 - 00:12:09.384, Speaker A: But to really prove that, we need a short calculation. So to count the neighbors of S, let's first count the neighbors of just the corrupted coordinates. And then let's count the extra neighbors, distinct neighbors.
00:12:09.384 - 00:12:25.000, Speaker A: That the vertices that we picked from K. So the vertices in K intersect S contribute to the set. Okay, so this is going to be the neighbors of, let's see, S intersect K.
00:12:25.000 - 00:12:34.610, Speaker A: So this is just the vertices of S that we haven't already counted in J. But again, we just want to count distinct neighbors. So we're going to subtract back out the ones we already counted that the neighbors of J.
00:12:35.400 - 00:12:36.150, Speaker B: Okay?
00:12:38.840 - 00:12:56.264, Speaker A: So again, we're just breaking up the neighbors, babes, by those who are a neighbor of somebody in J and those who aren't a neighbor of somebody in J. So now again, we want to say this is not too big, so we want an upper bound. So to upper bound, this first thing, we're just going to use it as deregular on the left hand side.
00:12:56.264 - 00:13:05.740, Speaker A: Okay, so this contributes to most D times the number of corrupted coordinates. And of course, this we have control over. This is the number of errors, and we're assuming there's not too many.
00:13:05.740 - 00:13:14.784, Speaker A: Okay, so that's fine. We have an upper bound on that. And then the second step, we're just going to have an upper bound by the definition of k, the fact that k already has a lot of their neighbors already covered by J.
00:13:14.902 - 00:13:15.520, Speaker B: Okay?
00:13:15.670 - 00:13:36.890, Speaker A: So in particular, for each vertex, each coordinate of k, at least half of its neighbors are redundant with those we've already counted. So they're each contributing at most D over two to the number of neighbors, given that we've already counted J. So plus D over two times the cardinality of S intersect k.
00:13:36.890 - 00:13:54.750, Speaker A: So any questions about that step? So again, this pervertex is trivial. This the pervertex contribution is by the definition of k. All right, so we know J can't be too big.
00:13:54.750 - 00:14:09.010, Speaker A: We're assuming that there's at most delta N over two errors. The set overall has size delta n. So whatever is remaining is in here.
00:14:09.010 - 00:14:25.430, Speaker A: So this is at least delta n over two. And for the purposes of an upper bound, since these are contributing less than this. The worst case for our upper bound is that basically this and this have the same, exactly the same size, delta N over two.
00:14:25.430 - 00:14:41.710, Speaker A: That's as big as this could get. As if this is as large as possible and this is as small as possible. So what if it were actually the case that this was delta N over two and this was delta N over two? Then it would just give us D delta N.
00:14:41.710 - 00:15:03.060, Speaker A: So basically, you do this computation, the dust settles and you get that this is at most three quarters D delta N. Okay? Delta N over two, delta N over two. You add these, you get 3D over two.
00:15:03.060 - 00:15:05.636, Speaker A: So two times two of the denominator gives you the four.
00:15:05.818 - 00:15:06.550, Speaker B: Okay?
00:15:07.560 - 00:15:25.656, Speaker A: And now we're done because delta N is just equal to the size of S. So we've just counted up the neighbors and proved that it's strictly less than 75% of D times the size of S. And that's the reason I left this expansion condition up here.
00:15:25.656 - 00:15:29.820, Speaker A: So you can see that's an immediate contradiction. That's exactly what this asserts can't happen.
00:15:29.970 - 00:15:30.670, Speaker B: Okay.
00:15:36.000 - 00:15:55.430, Speaker A: It is not. I'm sort of toying with the idea of putting on the homework, asking you what is the minimum value for which everything in these proofs work? So it's a value which is not too far from the minimum possible for which the proof works, and subject to that, keeps the numbers nice throughout lecture. I'm looking out for you guys.
00:15:55.430 - 00:16:16.200, Speaker A: All right, so that's sort of a preliminary step that we need. Okay. When we want to verify the feasibility condition, it's convenient to not just have a dichotomy between corrupted and uncorrupted coordinates, but in fact have a trichotomy, which includes this third case coordinates which are sort of not themselves corrupted, but share lots of stuff with these.
00:16:16.200 - 00:16:18.488, Speaker A: Share lots of parity checks with corrupted variables.
00:16:18.584 - 00:16:18.988, Speaker B: Okay.
00:16:19.074 - 00:16:26.940, Speaker A: But it's not a big deal because this isn't too big. Okay, so good. So now I can just tell you the weights.
00:16:26.940 - 00:16:31.020, Speaker A: Um.
00:16:32.720 - 00:16:48.916, Speaker C: The set k actually has an intuitive intuitive meaning too, because if you were doing a local search method to try to reconstruct the code word right, these are the variables where they would say, hey, I should be flipped, right? Because half of my parity checks say.
00:16:48.938 - 00:16:57.012, Speaker A: I should be flipped, potentially. I mean, it sort of depends on exactly how many. It depends on the parity of the number of flipped variables that you share the parity check with.
00:16:57.012 - 00:17:12.744, Speaker A: So that would be true if you were sort of the only one who was flipped or if an even number of other people were flipped. But absolutely. Somehow you'd think that if lots of your parity checks are shared with corrupted variables, you'd sort of expect most of your parity checks to be messed up intuitively.
00:17:12.744 - 00:17:21.228, Speaker A: Really proving that is not obvious, but that's definitely good intuition. Yeah. You'd sort of expect it to.
00:17:21.228 - 00:17:36.260, Speaker A: Right? So certainly if most of your parity checks, certainly the converse. If most of your parity checks do not have corrupted variables, then you're going to look locally quite good for sure. And it's good intuition to think about the converse as just holding, even though that direction requires a proof and uses the expansion condition.
00:17:36.260 - 00:17:40.020, Speaker A: Okay, so let me just define for you the weights.
00:17:41.560 - 00:17:42.310, Speaker B: Okay?
00:17:43.880 - 00:17:51.530, Speaker A: And this is pretty slick. So this is actually not the first proof. This was sort of a slightly simpler version of the original proof by Feldman and all that came along a few years later.
00:17:51.530 - 00:18:11.748, Speaker A: And yeah, it's flicks. Let's just go through the so here's the plan, right? So these are the three conditions we need and the one which looks to me intuitively, I kind of have the least feel for is the third one. So what we're going to do is we're going to define the weight.
00:18:11.748 - 00:18:18.096, Speaker A: So the third condition just obviously holds. Okay? That won't be the problem. And then we'll have to check that A and B hold.
00:18:18.096 - 00:18:30.288, Speaker A: Okay. This third constraint is talking about the right hand side. Correspondingly, we'll define the weights J by J independently.
00:18:30.288 - 00:18:48.700, Speaker A: So in some sense each parity check J will specify what the weights are for all of its edges with the variables that it includes. So here's how it works. So each parity check picks a favorite, favorite variable.
00:18:48.700 - 00:19:11.148, Speaker A: So I'm going to use a notation v of j for the variable chosen by j. It's got to be one of the variables in it. And there's going to be a nontrivial constraint, which is that if you're a corrupted coordinate.
00:19:11.148 - 00:19:25.750, Speaker A: Or if you're one of these friends of corrupted coordinates in K, you have to be chosen by lots and lots of parity checks. That's going to be a requirement. So chosen at least three quarters D times.
00:19:25.750 - 00:19:47.390, Speaker A: Now of course you can only be chosen by parity checks in which you participate, and you only participate in D parity checks, okay? So there's no way you're chosen by more than D people. And the insistence is that at least for these coordinates in J and K, you better be chosen close to the maximum number of times. 75% of your parity checks better choose you.
00:19:47.390 - 00:20:09.988, Speaker A: Now, if you think about it, it's not obvious you can do that because a given parity check has lots of variables and actually maybe even a given parity check has lots of corrupted variables. I can only pick one of them, okay? And that could totally happen. So remember, we might have 1% of the things being errors, right? And a parity check has a constant number of variables, like 20.
00:20:09.988 - 00:20:17.088, Speaker A: So maybe there's a million coordinates, 10,000 are corrupt and a given parity check has 20 variables. For all we know, all 20 are corrupted.
00:20:17.184 - 00:20:17.540, Speaker B: Okay?
00:20:17.610 - 00:20:27.800, Speaker A: So it has to pick only one and those other 19 will not be chosen by this parity check. So the hope, of course is then that well then hopefully there's most of those variables, other parity checks can choose them.
00:20:27.950 - 00:20:28.456, Speaker B: Okay?
00:20:28.558 - 00:20:41.004, Speaker A: Now that wouldn't work if somehow those 19 variables showed up in all of these other parity checks together. But now, intuitively, if it's got this expander condition and everything's kind of totally scrambled all over the place, maybe that doesn't happen. Okay, that'd be the hope.
00:20:41.004 - 00:20:57.548, Speaker A: Okay, that's true, and actually, it's not that hard to prove, it turns out, especially if you know Hall's theorem. So who knows Hall's theorem? Raise your hand, you should know Hall's theorem. Okay, so Hall's theorem, who knows max Flowman cut? Okay, so Hall's theorem is a corollary of max Flowman cut.
00:20:57.548 - 00:21:11.000, Speaker A: Okay, actually quite easy, corollary it would be a great like, 261 problem set question to just deduce Hall's theorem from max Flowman cut. But here's what it's but Hall's theorem came first. Actually, it's from the think, so it's about matchings.
00:21:11.000 - 00:21:38.476, Speaker A: So let's just talk about perfect matchings for a second. So suppose you had a bipartite graph and you're wondering whether or not it has a perfect matching, okay? So to convince you that it does have a perfect matching, really easy, I'll show you the matching. So if you like, matching is in NP, but it's actually quite easy to put in co NP using Hall's theorem.
00:21:38.476 - 00:21:56.980, Speaker A: I mean, we know it's in polynomial time, but forget about that for a second. So certainly one way I could convince you that there isn't a perfect matching is if I showed you a constricting set. So, suppose I showed you ten variables on the left hand side so that the number of distinct neighbors of these ten nodes was a set of only eight nodes.
00:21:56.980 - 00:22:07.092, Speaker A: You should then be convinced that there will not be a perfect matching of this graph. In a perfect matching, any set of k variables has k mates. They're distinct.
00:22:07.092 - 00:22:13.656, Speaker A: So if you don't have ten distinct neighbors of this set of ten variables, no way can you have a perfect matching.
00:22:13.768 - 00:22:14.380, Speaker B: Okay?
00:22:14.530 - 00:22:31.852, Speaker A: So it's clear that a necessary condition for a perfect matching is that every single subset of k vertices on the left hand side has at least k distinct neighbors on the right hand side. If you don't have that property, you certainly don't have a perfect matching. Hall's theorem asserts the converse.
00:22:31.852 - 00:22:40.752, Speaker A: If it is the case that every single subset of k vertices on the left hand side has at least k distinct neighbors, then there does in fact exist a perfect matching.
00:22:40.896 - 00:22:41.636, Speaker B: Okay?
00:22:41.818 - 00:22:54.920, Speaker A: And so this again, you can deduce it just from max flow min cut. All right, so the flows give you the matchings and the min cuts. If you don't have a perfect matching, then the min cut of the graph will basically exhibit for you one of these constricted sets.
00:22:54.920 - 00:23:15.552, Speaker A: So this I'll put on the homework. I'll just let you take Hall's theorem as a black box, though again, you basically already know how to prove it. But using Hall's theorem, it is then quite straightforward to show that because the graph is an expander, which of course talks exactly about the number of distinct neighbors that any subset of the left hand side has.
00:23:15.552 - 00:23:53.340, Speaker A: Because the graph is an expander and the number of distinct neighbors is at least zero 75 D times the size of the set, you can find sort of a union of zero 75 times D matchings, which is the same thing as basically saying each node on the left hand side is chosen three quarters times D times. Okay, so it's not obvious, but if you think about Hall's theorem a little bit and you use the fact it's expander, it's just true. Any questions about that? For the rest of the proof I'm just going to assume that we have such a okay, but again here again we are using the expansion property of the graph.
00:23:53.340 - 00:23:55.710, Speaker A: Questions?
00:23:57.600 - 00:23:58.350, Speaker B: Okay.
00:24:00.580 - 00:24:28.410, Speaker A: All right, so every parity check picks a favorite variable and the constraint is that any corrupted variable or friend of corrupted variables, anybody in J and K is picked lots of times. Okay, so maybe think of D as like twelve, everybody gets picked nine times, everybody in J or K. All right, so what are the weights? So, homework, this is possible.
00:24:28.410 - 00:24:41.228, Speaker A: All right, so here's how we define the weights. We define them differently depending on if the chosen variable is corrupted or not.
00:24:41.394 - 00:24:42.110, Speaker B: Okay?
00:24:42.640 - 00:25:08.576, Speaker A: So if the chosen variable is corrupted, which sort of makes sense if you think about it, right? Because I mean C is going to be we're just going to define these so that C holds, but we also are eventually going to have to worry about A and B. And it's really that the corrupted variables impose a pretty nasty restriction on these weights. So we basically have to have lots of negative weights next to a corrupted coordinate, but at the same time we have to have these non negative pairs.
00:25:08.768 - 00:25:09.316, Speaker B: Okay?
00:25:09.418 - 00:25:38.984, Speaker A: So that's why we're going to treat them differently. So for a chosen variable that is corrupted, we're going to have the corresponding edge have a negative value. So we set the weight of the edge between the favorite variable and this parity check to be equal to minus two over d minus epsilon, where epsilon is don't worry about epsilon, that's just like a tiebreaking epsilon.
00:25:38.984 - 00:25:45.020, Speaker A: So epsilon is an arbitrarily small constant minus two over the degree D of the left hand side nodes.
00:25:45.100 - 00:25:45.392, Speaker B: Okay?
00:25:45.446 - 00:25:57.024, Speaker A: So the two is probably a little mysterious right now. The two is some slack that we need the reciprocal in D. We actually mentioned this very briefly last time when I tried to develop your intuition about the weights.
00:25:57.024 - 00:26:25.150, Speaker A: So let me go through that discussion again. So intuitively, because existence of the weights implies exactness of this linear program, we're sort of thinking that, we're thinking that the exhibiting feasible weights should get harder and harder as there are more and more errors as j is bigger and bigger. And remember, if j was empty, so if you literally had no errors at all, then this is a trivial problem because you just set all the W's to be equal to zero.
00:26:25.760 - 00:26:26.510, Speaker B: Okay?
00:26:27.120 - 00:26:56.256, Speaker A: And then we also argue that, well, and at least it's a vaguely robust argument is that if j is still super small, if j is so small that no parity check has more than one corrupted variable, then it's also really easy to exhibit feasible weights. Basically just for each, basically what you do is just next to each corrupted variable, you just give all the edges the weight like minus one over d, so it has to have a total of minus one. You just spread it equally among the d adjacent edges.
00:26:56.256 - 00:27:11.400, Speaker A: So that's minus one over d next to corrupted variables. And then to make sure you have this pairs condition next to uncorrupted variables, you just have a one over D on all of the d edges. And as long as no single parity check has two corrupted variables, then this condition is going to be satisfied.
00:27:11.400 - 00:27:37.052, Speaker A: Of course that's not good enough for what we're trying to prove because again we might have a parity check which is entirely corrupted variables, right? So we're doing some more clever version of the argument, but we actually have seen this one over d before. That's basically saying we're trying to get a negative contribute, we're not trying to get the minus one from just one edge, that would be crazy. We're trying to get this minus one contribution to the edges incident to corrupted variable like roughly equally from the incident edges.
00:27:37.052 - 00:27:42.192, Speaker A: Okay, so we can't have it exactly equally, but we can have it up to a factor two roughly equally from the incident vertices.
00:27:42.336 - 00:27:43.060, Speaker B: All right?
00:27:43.210 - 00:28:07.448, Speaker A: So that's why you shouldn't be too shocked to see this reciprocal and D show up. Okay, now but if we want C to be satisfied, it's actually pretty obvious what the rest of the edges incident to J better have their weights defined as. So remember condition C says that any pair of edges with the same right hand side vertex have to have some of weights non negative.
00:28:07.448 - 00:28:16.028, Speaker A: I just slapped down a negative weight so that lower bounds the weight of everything else incident to j to the negative of that to two over d minus epsilon.
00:28:16.204 - 00:28:16.930, Speaker B: Okay.
00:28:20.420 - 00:28:28.020, Speaker A: So set the other W-I-J-S equal to two over d minus epsilon.
00:28:29.400 - 00:28:32.070, Speaker B: Okay? Clear?
00:28:47.840 - 00:29:15.856, Speaker A: Okay, so there remains what to do for parity checks whose favorite vertex is not corrupted. So if the chosen vertex does not belong to j, then we just set wij to be equal to zero for all incident edges. Okay, I want you to observe.
00:29:15.856 - 00:29:23.828, Speaker A: So a subtle point is these friends of corrupted vertices, vertices in k also are in that second case.
00:29:23.994 - 00:29:24.660, Speaker B: Okay?
00:29:24.810 - 00:29:32.504, Speaker A: So if I'm a parity check j and I choose a variable. Which is not corrupted, even if it's a friend of corrupted variables, I still have everything be zero.
00:29:32.702 - 00:29:33.064, Speaker B: Okay?
00:29:33.102 - 00:29:44.700, Speaker A: So it's sort of important. So again, these vertices and K are kind of walking a fine line between being treated as corrupted sometimes and uncorrupted as others. So those are the weights.
00:29:44.700 - 00:29:55.760, Speaker A: Is that clear? Is the definition clear? Is it also obvious that condition C holds the third condition of the feasible weights?
00:29:59.460 - 00:30:00.112, Speaker B: Yeah.
00:30:00.246 - 00:30:05.604, Speaker C: Why can't you have all corrupted bits go into one parity check or like 20 corrupted bits going one parity check?
00:30:05.642 - 00:30:06.468, Speaker A: You absolutely can.
00:30:06.554 - 00:30:06.852, Speaker B: What?
00:30:06.906 - 00:30:08.196, Speaker A: You absolutely can.
00:30:08.378 - 00:30:08.772, Speaker B: Okay.
00:30:08.826 - 00:30:09.140, Speaker A: Yeah.
00:30:09.210 - 00:30:11.344, Speaker C: Why is condition C satisfied?
00:30:11.392 - 00:30:38.572, Speaker A: Condition C is satisfied because we force each parity check to pick a single favorite variable and the negative weight only gets to go between the parity check and its favorite variable. So if you have a parity check with 20 variables, all of which are corrupted, one of those corrupted variables for this parity check will pick up a negative. The rest will actually pick up a positive, which is kind of crazy because those corrupted variables have to have they only have a budget of minus one.
00:30:38.572 - 00:30:57.692, Speaker A: So we're making backward progress as far as getting it down to minus one. But that's kind of punting the problem down a little bit, right? So eventually we have to verify B. And you should definitely be wondering, why does B hold even A? The factor of two can even make you nervous about property A, actually.
00:30:57.692 - 00:31:13.252, Speaker A: But C, which was the one that maybe seemed the hardest to control, that's the one we just kind of said, well, let's make sure we do C and then suffer the consequences later. Okay, everyone ready to verify A and B?
00:31:13.386 - 00:31:14.068, Speaker B: Yeah.
00:31:14.234 - 00:31:28.740, Speaker A: All right, let's do it. Three cases. So let's start with the corrupted case, which is sort of the one we're kind of worried about a little bit because the budget is so stringent.
00:31:28.740 - 00:31:33.930, Speaker A: Minus one. All right, so in this case.
00:31:36.720 - 00:31:37.036, Speaker B: So.
00:31:37.058 - 00:31:45.624, Speaker A: This is what we need to compute. So we define the weights from the right hand side of the graph. But now to verify A and B, we have to think about things from the left hand side of the graph.
00:31:45.624 - 00:31:56.690, Speaker A: So we fixed I and we're thinking about all of its outgoing edges. So we have a budget of minus one here. So a question for you.
00:31:56.690 - 00:32:04.644, Speaker A: So notice that the weights take on only three distinct values, okay? Zero, positive or negative. And there's only one positive value. There's only one negative value.
00:32:04.644 - 00:32:26.374, Speaker A: How many of those three values are candidates for a wij when J is a corrupted coordinate? So if I don't tell you anything else other than I, j is a node in the graph and I was corrupted. Anything else? Could it be zero?
00:32:26.572 - 00:32:28.840, Speaker C: No, it's only four of its not elements of J.
00:32:29.690 - 00:32:48.940, Speaker A: Why could it not be zero? So remember, just because you're corrupted doesn't mean that every parody tech chose you, it means that, like, nine out of twelve chose you. But there's also three that maybe didn't choose you. And if you weren't chosen, maybe somebody who wasn't corrupted was chosen instead.
00:32:48.940 - 00:33:12.510, Speaker A: In which case you're going to be zero, actually. So this could be any of the three values. Okay, now, what we do have going for us is that by virtue of being a corrupted coordinate in a parity check j, for which I is the favorite chosen variable v of J, then by definition, that edge weight is negative.
00:33:12.510 - 00:33:18.080, Speaker A: Okay, that's the first thing I have going for us. If we're chosen that edge weight is negative, the second thing we have going for us.
