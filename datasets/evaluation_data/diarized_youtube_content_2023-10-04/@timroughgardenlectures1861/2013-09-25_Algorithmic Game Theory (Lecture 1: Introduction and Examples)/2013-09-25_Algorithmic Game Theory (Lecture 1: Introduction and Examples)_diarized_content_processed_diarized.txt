00:00:00.250 - 00:00:00.894, Speaker A: Thanks.
00:00:01.092 - 00:00:32.742, Speaker B: So I want to welcome you to CS 364 A. This is a course on algorithmic game theory, which very loosely is a survey of topics on the interface of, on the one hand, computer science, especially, though not only theoretical computer science, algorithms and economics, comics, especially game theory. So the plan for today's lecture is I'm just going to give you sort of a taste of what the course is going to be about.
00:00:32.742 - 00:00:47.002, Speaker B: The course is loosely organized around three themes, and I'll give you an example for each of the three themes. And if this is stuff you find interesting and exciting, then I hope you'll stick with me for the rest of the quarter. For those of you just coming in, there are sign up sheets going around.
00:00:47.002 - 00:01:02.702, Speaker B: So before you leave, please put your name on the sign up sheet with your email. All right? So let me say what the course goal is for each of the three themes of the course, one at a time. So the first course goal is a little bit of a mouthful, but I'll give you an example.
00:01:02.702 - 00:01:19.080, Speaker B: So it's about designing systems where you have participants and the participants are both autonomous and strategic. They have their own interests, not necessarily the same as yours as a designer. And despite their strategic behavior, you want the system to function well.
00:01:19.080 - 00:01:34.300, Speaker B: So let me give you an example. Really, frankly, it's more of a nonexample, a sort of cautionary tale of how when you don't take into account strategic behavior, things can go wrong. It's a pretty recent example.
00:01:34.300 - 00:01:57.106, Speaker B: It's from the Olympics last year in London. Like every Olympics, this one had its fair share of scandals. But one of the scandals was in a sport which is not really known for its scandals, not known know, failing drug tests and that sort of thing.
00:01:57.106 - 00:02:11.880, Speaker B: Can anyone guess what I might mean? Badminton. Specifically, women's doubles badminton. So let me tell you what happens.
00:02:11.880 - 00:02:36.990, Speaker B: So let me tell you how the tournament is designed for how you decide who gets the gold, silver and bronze medal in women's doubles badminton in the Olympics in 2012. The tournament structure is familiar to any of you who follow World Cup, although there are only half as many teams. So there are two phases, a round robin phase followed by a knockout stage.
00:02:36.990 - 00:03:07.458, Speaker B: So phase one was the round robin. Specifically, there were 16 teams overall, so they were organized into four groups of four teams each groups ABC and D. Round robin just means that whatever group you're in, you play the other three teams in your group and you don't play any of the twelve teams in the other groups.
00:03:07.554 - 00:03:08.200, Speaker A: Okay?
00:03:08.730 - 00:03:22.320, Speaker B: And the way it works is in each group the top two teams advance to phase two to the knockout tournament. So we begin with 16 teams. After the round robin matches, we will have narrowed it down to eight.
00:03:22.320 - 00:03:26.240, Speaker B: This is a good time to come in.
00:03:44.890 - 00:03:45.590, Speaker A: Them.
00:03:45.740 - 00:03:58.838, Speaker B: So those of you who've taken classes from me before are probably the only ones not shocked by the handwriting quality. You can always ask me for clarifications. I give you a promise right now.
00:03:58.838 - 00:04:07.958, Speaker B: I will never get upset if you can't read something I read on the board. Ask me as much as you want. So, from each of the four teams, the top two teams of the group advance.
00:04:07.958 - 00:04:20.186, Speaker B: So those eight teams make it to phase two, which is the knockout. Knockout just means you lose once and you're out. So you start with eight teams.
00:04:20.186 - 00:04:24.618, Speaker B: Those are the quarterfinals. The four losers are out. The other four teams make it to the semis.
00:04:24.618 - 00:04:32.286, Speaker B: They're the two losers get knocked out. They play the bronze medal game, and then the two teams that make it to the final play for the gold and the silver.
00:04:32.398 - 00:04:33.060, Speaker A: Okay.
00:04:39.050 - 00:05:34.390, Speaker B: Now let me explain why this is not necessarily a system designed to function well with strategic participants. My claim is that in this tournament structure, there is a fundamental misalignment, or at least there can be a misalignment between, on the one hand, what the participants want, and on the other hand, what the tournament designer wants. So a misalignment between the participant goals and the designer goals, and when this happens, you have trouble.
00:05:34.390 - 00:05:44.970, Speaker B: So what do the participants want? Well, that answer is straightforward. Every team wants the best medal that it can get.
00:05:45.120 - 00:05:45.820, Speaker A: Okay.
00:05:58.210 - 00:06:23.270, Speaker B: What does the tournament designers want? First of all, who is that? So it's basically the Olympic committee. So what's their objective? Well, in hindsight, it looks like they didn't actually think about that question very carefully, frankly. But in hindsight, certainly what they claim to care about, among other things, is that every team tries as hard to win every match in which it plays.
00:06:23.270 - 00:06:46.320, Speaker B: Let's say I want best effort from all teams in all matches. Yes.
00:06:49.170 - 00:06:52.190, Speaker C: What they really want is the best team get the best battle.
00:06:53.570 - 00:07:06.462, Speaker B: They may want that as well. Okay, so I'm not claiming this is even their primary objective, but at least certainly something they explicitly stated after the scandal unfolded. Now, do they want yeah, I don't think they thought about it in advance, frankly.
00:07:06.462 - 00:07:20.410, Speaker B: But let's just take on face value what they said afterwards. What they said afterwards was not that this is necessarily the primary objective, but that certainly it was unacceptable if this criterion was not met. So they stated that explicitly.
00:07:20.410 - 00:07:36.894, Speaker B: All right, now if you didn't read about this scandal at the time, you'd be right to scratch your head. You'd be right to say, where is the misalignment between these two things? As a team, you want to do as well as possible. The designer wants people to try to win.
00:07:36.894 - 00:07:59.110, Speaker B: Why would you not try to win? In other words, how would losing ever help you in this tournament? For example, consider a knockout tournament like phase two. I mean, what does losing do for you? Losing gets you out of the tournament. It is obvious in a Knockout Tournament that you better try as hard to win every match, because losing kicks you out immediately.
00:07:59.110 - 00:08:32.800, Speaker B: So, question, how could losing help a team? And it's sort of subtle, but the teams in the tournament were very smart. And so here's what triggered the problem. What triggered the problem is what, as far as a non expert like me can tell, is just a truly kind of random fluke event which was in Group D.
00:08:32.800 - 00:08:59.174, Speaker B: On the last day of round robin play, there was a shocking upset, namely the Danish team. And I'm not going to embarrass myself trying to spell or pronounce these last names, so I'll just use initials. The Danish team PJ upset.
00:08:59.174 - 00:09:06.650, Speaker B: The team that everybody believed was by far the best team in the world, team from China, QW.
00:09:11.010 - 00:09:14.350, Speaker A: Okay, what do you mean by upset?
00:09:16.130 - 00:09:39.750, Speaker B: By upset, I mean everybody expected QW to win. And moreover, my interpretation is that even in light of this upset, of this new information, again, people believed if they'd play again, 99 times out of 100, QW would win. People did not seem to believe that QW was not, in fact, the much better team, even in light of this upset.
00:09:39.750 - 00:10:04.062, Speaker B: Yeah, so let's write, even though I'll just write QW much better. But of course, what I mean is QW believed to be much better. Just to lend some credence to that, let me just state now that at the end of the day, when the tournament finally completed, QW did indeed win the gold medal.
00:10:04.062 - 00:10:10.454, Speaker B: So it seems like this was a justified belief. Now it turned out. So this is round robin play.
00:10:10.454 - 00:10:22.282, Speaker B: And remember, two groups, two teams from each group make it to the Knockout. Now, QW lost this match, but they still made it to the Knockout Tournament. As a result of this match, PJ won Group D.
00:10:22.282 - 00:10:43.620, Speaker B: They were the top team. QW came in second in Group D, and again, both of them therefore proceeded to the Knockout Tournament. So this happened in the morning on the final day of round robin play.
00:10:43.620 - 00:11:17.514, Speaker B: Now, here was the next match, and this was the first of the two controversial matches. There was another Chinese Team XY, that was not thought to be as good as QW, and it was playing the South Korean Team KH. And they were both two and O in Group A play.
00:11:17.514 - 00:11:30.974, Speaker B: So they were both assured of proceeding to the Knockout Tournament. And this match between the two of them would just decide which of them was the Group A winner and then which of them the loser of this match would be the second best team in Group D. Sorry, in Group A.
00:11:30.974 - 00:12:03.580, Speaker B: So Knockout was assured this was just to determine the seating. And here was the issue. So here was the fact, just the way the Knockout Tournament was arranged, which led these two teams to think carefully about what they wanted to do in this match.
00:12:03.580 - 00:12:28.020, Speaker B: So the winner of Group A, that is, the winner of this match between X, Y and KH in the knockout tournament, would potentially meet this extremely fearsome Team QW in the semifinals. It wouldn't be their first match, but it would be their second match, assuming they won. And assuming QW won.
00:12:28.020 - 00:13:01.920, Speaker B: On the other hand, the second best team in Group A, the loser of this match, would not have to face this fearsome Team QW until the final. And the difference between meeting QW in the semifinals, whereupon losing then means a bronze medal, is the best case scenario versus meeting them not till the final, at which time a silver is assured. That difference was apparently viewed by both teams to be such a big difference that both deliberately tried to lose this match.
00:13:01.920 - 00:13:27.080, Speaker B: If you're having trouble envisioning what it looks like when two badminton teams are at the same time trying to lose a match, I'm here to tell you I found the match on YouTube, and there's a link to it from the course web page.
00:13:46.290 - 00:13:47.040, Speaker A: It.
00:14:01.510 - 00:14:23.458, Speaker B: So the same thing happened in a second match between the other South Korean team and an Indonesian team for exactly the same reason. Question. So the second team here was Chinese.
00:14:23.554 - 00:14:25.334, Speaker C: And they didn't want to face their.
00:14:25.372 - 00:14:40.302, Speaker B: Own team until so there's a good question here which is, is it relevant that two of the teams involved are Chinese or not? That's a good question. I can first tell a story under the assumption that it was irrelevant. I'm not claiming that's true.
00:14:40.302 - 00:14:57.140, Speaker B: What I'm claiming it's just a useful thought experiment to proceed through to first order from. Again, the sort of amateur perspective of myself. I thought all teams were reasoning as if QW would just win every match that it played, and that was just a given.
00:14:57.140 - 00:15:26.362, Speaker B: The behavior that people exhibited was indistinguishable from that explanation. And if you know you're going to lose to QW, then your first order optimization problem is to meet QW as late in the tournament as possible, because that dictates how high you're going to place. Now, an interesting twist is that the QW team was Chinese and also one of the teams in the first controversial match, XY, was the other Chinese team.
00:15:26.362 - 00:15:53.314, Speaker B: And there is apparently lots of history with when you have more than one team from China in the same tournament, they work hard to meet each other, ideally not at all, but if necessary, as late as possible. So obviously in the final, there's no other you know, you get asked the question, was it relevant whether they're from China or not? It's hard for me to really answer that in unequivocal way. I just want to make the point the incentives are a problem.
00:15:53.314 - 00:16:06.266, Speaker B: Even if all of these teams were from different countries, I think both teams sabotage.
00:16:06.298 - 00:16:07.680, Speaker C: This next one is.
00:16:11.660 - 00:16:13.050, Speaker B: QW have said.
00:16:13.580 - 00:16:17.630, Speaker C: XY loses, then QW should sabotage his next match.
00:16:18.400 - 00:16:23.600, Speaker B: QW's next match is in the knockout. Yeah. QW's next match is the quarterfinals.
00:16:23.600 - 00:16:39.750, Speaker B: Okay. All right. So again, the result X-Y-K-H both try to lose the match.
00:16:39.750 - 00:16:52.730, Speaker B: So this is what resulted in derision scandal and ultimately the disqualification of the four teams involved in the two controversial matches that I mentioned. Question.
00:16:58.140 - 00:17:08.084, Speaker D: Is the idea that QW lost on purpose, thinking that the creative state wouldn't realize that this was their strategy, but then XYZ was on purpose.
00:17:08.212 - 00:17:17.664, Speaker B: Well, I think the question mean, how does KH view the situation? QW never threw any match.
00:17:17.862 - 00:17:19.820, Speaker D: I thought the whole thing would be upset.
00:17:19.980 - 00:17:22.288, Speaker B: I said upset. I did not say tank. Yeah.
00:17:22.288 - 00:17:37.768, Speaker B: So the first thing I said was, as far as I can tell, and actually, just for the record, as a very diligent instructor, I watched some of that match as well. I'll tell you, it was close. And again, it may just be that they were better at throwing the match, but I really don't think so.
00:17:37.768 - 00:17:58.584, Speaker B: My belief, some people actually criticize these Fortis golf side teams not for throwing the match, but for doing it so artlessly anyways. So my belief, I'd bet a small amount of money, not a large amount of money. I'd bet a small amount of money that the Danish win is actually an upset.
00:17:58.584 - 00:18:06.428, Speaker B: It's just simply a rare event, and it does happen. Any of us who follow sports know that sometimes there are upsets. It seems like a legitimate upset.
00:18:06.428 - 00:18:18.630, Speaker B: Also, again, trying to teach you to think strategically. Suppose you're the best team, right? You should just win, right? You rightfully deserve the gold medal. You expect to beat anybody you meet along the way.
00:18:18.630 - 00:18:32.040, Speaker B: And again, the other thing is, their match was first, so there was no way for if QW wanted to help out XY, they probably thought winning was doing them a favor, so they probably wanted to win that match, even from an incentive perspective.
00:18:36.380 - 00:18:39.528, Speaker D: Was stronger than the Danish team. So it's like one less strong.
00:18:39.614 - 00:18:51.010, Speaker B: I mean, again, there's no way I can make unequivocal statements about who meant to do what. All I can do is watch the matches. My belief is that QW did not throw their match, but I don't know what it would mean to prove that.
00:18:51.010 - 00:19:14.016, Speaker B: So the point is that when you're designing a system, like a tournament or like an auction or like a computer network, and you have participants that are strategic, the rules of the game matter. You cannot expect participants to behave in a way other than in their own interests. That is an unreasonable assumption of the designer.
00:19:14.016 - 00:19:30.300, Speaker B: You must account for strategic behavior. If you don't do it carefully, you will get unexpected and often undesirable consequences. And the first, almost 50% of the class will be on principles for system design that properly take into account strategic behavior.
00:19:30.300 - 00:20:04.600, Speaker B: So the rules matter and the name of the field is mechanism design. And again, the goal of the mechanism design is exactly what I said our first course goal was. How do you design systems when you have strategic participants so that the end result is something you want? Okay, this is a desirable outcome from the designer perspective.
00:20:04.600 - 00:20:24.510, Speaker B: So this is a theory course, and I'm not going to apologize for it. There'll be plenty of theorems and proofs and so on. That said, we will occasionally look at some detailed case studies, and in particular for mechanism design.
00:20:24.510 - 00:20:41.360, Speaker B: So where does this stuff get used? So killer apps include Internet search auctions. If you want to know how Google made all their money, this is how they do it. Did it, frankly, to first order using auction theory and Internet advertising.
00:20:41.360 - 00:21:26.764, Speaker B: If you want to know how it came to be that television stations own so much less of the spectrum and telecom companies own so much more to service your wireless devices, that's also through carefully crafted spectrum auctions to reassign that public goodbye. It's been used for now 60 years to assign medical residents to hospitals, similarly school children to elementary schools, and even to figure out kidney exchange. So this is when you have two pairs of incompatible donors, but there are cross compatibilities.
00:21:26.764 - 00:21:53.576, Speaker B: So how do you do that, taking into account strategic behavior, mechanism design gives you tools to answer that question and design appropriate systems. So this is a well developed field in microeconomics, and along the way, we'll certainly be covering some of the traditional econ approach to mechanism design. This is a computer science class, however, and so there will be a consequent emphasis, first of all, on the applications I choose.
00:21:53.576 - 00:22:25.200, Speaker B: I'll choose some of the killer applications from the computer science side. But even in the theorems that we prove, I'll be studying recent contributions by computer science with a focus on robust guarantees and also on computational efficiency to properties that have been largely ignored on the economic side. Now, sometimes you don't have the luxury of designing the rules of a game from scratch.
00:22:25.200 - 00:22:41.640, Speaker B: Rather, there's a game that's occurring in the wild, and maybe it's in the Internet, maybe it's in a road network, but it's a system. It's out there. You want to understand it and maybe improve it's.
00:22:41.640 - 00:23:11.010, Speaker B: And the perspective we're going to focus on for these games in the wild that we want to understand is we're going to want to understand the consequences of strategic behavior. Maybe it leads to some degradation in system performance, but maybe selfish behavior is essentially benign. Again, this will be more clear with an example.
00:23:11.010 - 00:23:40.220, Speaker B: So let me tell you about Grace's Paradox. This is a very nice counterintuitive example. It's been around 668, amaze your friends at your next cocktail party.
00:23:40.220 - 00:24:04.304, Speaker B: So we're going to have a network that can model a lot of things, but just think about cars on the road that's probably the simplest thing to think about. So think about this as a flow network for those of you who are familiar with them. So a bunch of traffic, morning rush hours, say, all leaves S at the same time.
00:24:04.304 - 00:24:12.900, Speaker B: This is thousands of cars and these are autonomous drivers. They can take whatever path they want. I've given them a network with only two paths, the upper route and the lower route.
00:24:12.900 - 00:24:27.108, Speaker B: So there are four roads in this network. Two of them are very simple to understand. Two of them you should think of as being sort of long highways, lots of lanes.
00:24:27.108 - 00:24:37.164, Speaker B: They never get congested. At least up till like, 2010, I would have counted highway 280 in this category. So officially we have a function.
00:24:37.164 - 00:24:50.210, Speaker B: X is the fraction of traffic that's using this road, and this is the travel time in hours. So this is a constant function. This says no matter how congested this road gets, that traffic experiences an hour of travel time.
00:24:50.210 - 00:25:08.152, Speaker B: Okay, so the other roads are more interesting. They're more like what you're used to, where the more traffic uses a road, the longer it takes any of that traffic to get from the beginning to the end. So for simplicity, let's just say it's the identity function.
00:25:08.152 - 00:25:26.910, Speaker B: So what this means is that if 100% of the traffic uses such a road, it takes a full hour. If only half of the traffic uses this road, it takes a half an hour, and so on. X is the fraction of the drivers that are using that road.
00:25:27.600 - 00:25:28.350, Speaker A: Okay.
00:25:32.640 - 00:25:33.790, Speaker D: What'S the data?
00:25:36.900 - 00:25:41.330, Speaker B: Yeah, everyone starts at S. Let me write down a little more stuff.
00:25:43.160 - 00:25:43.476, Speaker A: Just.
00:25:43.498 - 00:25:57.930, Speaker B: To make it precise. So lots of cars leave S for T at same time. Each one can pick either route that it wants.
00:25:57.930 - 00:26:14.444, Speaker B: Now, I'm not going to give you any formal definitions today. We'll have plenty in the weeks to come. But you all probably have a vague sense of what an equilibrium should be, a steady state where nobody wants to move.
00:26:14.444 - 00:26:25.468, Speaker B: So what seems like the sensible steady state in this network. So imagine these are the same people commuting at 08:00 a.m. Day after day from Stanford to San Francisco.
00:26:25.468 - 00:26:32.050, Speaker B: Where do you expect this to settle down? What do you expect the distribution of the traffic over the two routes to be?
00:26:32.500 - 00:26:34.304, Speaker D: Half people go the upper and half.
00:26:34.342 - 00:26:39.830, Speaker B: People go the lower. Excellent. At steady state, your intuition should be that they're split 50 50.
00:26:39.830 - 00:26:58.344, Speaker B: Why? Well, neither one is better or worse than the other, right? So each one has a combined travel time of one plus X. And so if there's more than 50% on one of them, that's going to be slower than the one that has less than 50%. You listen to the traffic report on the way to work.
00:26:58.344 - 00:27:08.350, Speaker B: You're like, oh, man, tomorrow I'm going to take that other route. It was less loaded, it was faster. Okay, so I'm going to just leave you with this hand wavy explanation for today.
00:27:08.350 - 00:27:32.944, Speaker B: It's correct, though. The sensible equilibrium in this network is to have a 50 50 split. So how long does it take everyone to get to work then? It what's the common commute time that everyone experiences? Hour and a half.
00:27:32.982 - 00:27:33.570, Speaker A: Right.
00:27:36.620 - 00:27:55.550, Speaker B: So commute time, three halves. So what you should be saying is, doesn't seem that paradoxical, right? Oh, I forgot that I wrote Brace's example. It's called Brace's Paradox, and there's no reason you should be impressed up to this point.
00:27:55.550 - 00:28:15.844, Speaker B: But I heard about the newest thing coming out of Google X. It's a teleporter. So we're going to do is we're going to put one at V that lets you go instantaneously to W.
00:28:15.844 - 00:28:34.680, Speaker B: And not only that, it has enough capacity for everybody. So we change the network. In effect, we add this new road, this teleporter going from V to W instantaneously.
00:28:35.020 - 00:28:38.590, Speaker A: Okay, cool.
00:28:40.640 - 00:29:09.706, Speaker B: All right, so now we got to say, all right, so what's going to change? What's the new traffic routing that we expect? So here's the first question, right? So consider the very first day that this thing gets installed, all right? And you're one of these drivers, and you've been going on the upper route all along. Are you going to still use the upper route? Yeah. You want to use this new Fangled device not just because it's cool, but because it saves you a half an hour.
00:29:09.706 - 00:29:17.242, Speaker B: At least. If you think of nobody else changing, it saves you a half an hour. So currently it's taking you half 30 minutes and then 60 minutes.
00:29:17.242 - 00:29:28.830, Speaker B: But if you switch to the Zigzag, all of a sudden it's 30 minutes plus zero plus 30 minutes. Just an hour. Okay, so you shave 30 minutes off your commute by using the teleporter.
00:29:28.830 - 00:29:45.650, Speaker B: All right, so the only issue though, is you're not the only person in the world, right? You're not the only one who wants to use a teleporter. Now, maybe you're thinking, yeah, but the teleporter can accommodate everybody. So what? There's no congestion of the teleporter.
00:29:45.650 - 00:29:53.900, Speaker B: It's not so simple. Everybody is going to switch to use the teleporter. There's no reason not to.
00:29:53.900 - 00:30:13.310, Speaker B: So you'll agree that that gives us this traffic pattern. Everybody on the zigzag. Are we better off? What's our commute time? Now it takes 2 hours.
00:30:13.310 - 00:30:24.820, Speaker B: Now everybody takes this congestible route. That's an hour. Teleport is free for everybody, but now everybody's stuck on this WT edge, and that also takes an hour, 2 hours.
00:30:24.820 - 00:30:37.894, Speaker B: But it's not like people were reasoning incorrectly in this network with a teleporter, it is a brain dead strategy to use the Zigzag path. You should always do it. It's always better than the other two alternatives, no matter what everyone's doing.
00:30:37.894 - 00:30:51.350, Speaker B: That's called a dominant strategy, okay? It's a foolproof for you individually to take the Zigzag, but everybody does it. There's lots of congestion, and it's worse than when you didn't have the teleporter at all. That's braces paradox.
00:30:55.410 - 00:30:56.160, Speaker A: It.
00:31:04.850 - 00:32:03.302, Speaker B: So corollary of Brace's paradox, which is much more intuitive, is that selfish behavior by everybody doesn't always give the best thing for everybody. So in this context, selfish routing need not minimize the commute time, right? So with the teleporter installed, if instead of everybody picking routes just by themselves, if instead there was some altruistic dictator that could just tell people which routes they absolutely had to take and they had no choice, you could do better. If nothing else, you could just reinvent that 50 50 split and go back to the 90 minutes commute.
00:32:03.302 - 00:32:14.662, Speaker B: And in fact, if you think about it, there's actually nothing better you could do. There's no way to make use of the teleporter in a helpful way. So in that augmented network, selfish routing gives you a two.
00:32:14.662 - 00:32:36.406, Speaker B: An altruistic dictator could give you a three hats. So you could improve the commute time by 25% with centralized control. And there's a concept from computer science called the Price of Anarchy, which is exactly this measure.
00:32:36.406 - 00:32:56.740, Speaker B: So you look at what's the performance of a system with strategic behavior, you take as a hypothetical benchmark the best possible system performance, even if you could control everybody's actions. And you look at the ratio. So in this braces network, it's two over three halves, also known as four three.
00:32:57.590 - 00:32:58.340, Speaker A: Okay?
00:32:59.830 - 00:33:17.180, Speaker B: When the Price of Anarchy is one, that's the very happy situation where strategic behavior gives you exactly what you wanted. Anyways. The closer the Price of Anarchy is to one, the more robust your system is to strategic behavior, the more essentially benign selfish behavior is in that system.
00:33:17.180 - 00:33:42.450, Speaker B: So from an engineering perspective, then, the well motivated question is, well, okay, we certainly want to understand when is the Price of Anarchy equal to one? That's the best case scenario. But it turns out this theory has much wider reach. When you study which application domains and what conditions allow you to guarantee the Price of Anarchy is close to one, say, something like four thirds.
00:33:42.450 - 00:34:29.074, Speaker B: So the goal of the weeks of the class, which we study this concept, will be for what applications and with which conditions is the Price of Anarchy close to one? And believe it or not, despite the fact that people have been thinking about Equilibria for decades, if not centuries, and certainly we've known about the inefficiency of things like Nash Equilibria forever, since well before I was born. It wasn't until computer science got interested in this that they proposed the Price of Anarchy and started proving theorems about it, that people really started quantifying the inefficiency of Equilibria. That's a contribution, it turns out, from the computer science world.
00:34:29.074 - 00:34:44.520, Speaker B: So I'm going to talk about that for a few weeks, sort of in the middle of the classroom. So killer applications. I will talk about network routing, scheduling problems.
00:34:44.520 - 00:35:11.822, Speaker B: It has applications for simple auction formats and why they do well even in complex situations and so on. For example, one thing we'll learn is that a modest amount of over provisioning of network capacity. So for example, just keeping a telecommunication network at a max link utilization of 90%, that is condition that's already strong enough to guarantee that the price of anarchy is close to one.
00:35:11.822 - 00:35:16.240, Speaker B: And so we'll give the rigorous theorems establishing that later on in the course.
00:35:17.730 - 00:35:27.650, Speaker D: Are we ever going to talk about situations when strategic agents aren't so short sighted? Like what if they were game theoreticians? Is that even reasonable or is that just too absurd?
00:35:28.310 - 00:35:37.254, Speaker B: No, I have to say, I mean, embrace this paradox. This is a real phenomenon. No?
00:35:37.452 - 00:35:47.500, Speaker D: Are there ever times when our selfish agents see the consequences of oh, if I do this and everyone else does this, then the dominant strategy leads to this bad situation.
00:35:56.830 - 00:36:14.258, Speaker B: You're basically saying how can you have some kind of collusion, either explicit or implicit? And you do see that coming up. For example, when you study repeated games you get sort of a much richer set of equilibria which can include one of the most common places people study. This is the Prisoner's Dilemma, which is really the distillation of the problem that's going on here.
00:36:14.258 - 00:36:30.486, Speaker B: And especially when you look at an iterated version of the prisoner's Dilemma, the dominant strategy becomes more and more absurd. So then it's well motivated to ask what's a better behavioral model that explains what you see in real life? Honestly, there's been experiments with Braces paradox like issues in real life. This is what happens.
00:36:30.486 - 00:36:39.142, Speaker B: So I would argue here we don't need a better behavioral model. Simplistic though that it is, it's very predictive. That said, in other applications it is a relevant question.
00:36:39.142 - 00:37:03.692, Speaker B: I don't think we're going to wind up seeing it in the course though. But it's a good question. No, you can't do better than optimal.
00:37:03.692 - 00:37:16.250, Speaker B: So we've sort of concocted it so that it can't be better than one. So we've put on the bottom the best thing that could happen even if we had full control over the system. So just by definition it has to be at least one.
00:37:16.250 - 00:37:30.716, Speaker B: Yeah, it would make sense. You can't do better than optimal. Yes.
00:37:30.898 - 00:37:37.596, Speaker C: I think my question is related to the first one. If we have their dominant strategy in the system and we assume that our.
00:37:37.618 - 00:37:40.524, Speaker A: Participants are all strategic, then is it.
00:37:40.562 - 00:37:43.540, Speaker C: True that everyone is going to take the dominant strategy?
00:37:43.640 - 00:38:10.664, Speaker B: Okay, so the question was about dominant strategies and do we assume what is our behavioral model? And pretty much in this class, so we want to do analysis of systems with strategic participants and to do that we need some kind of behavioral model. We need to have some model about what people actually do when faced with some decision to make. And we will always at the very least assume that if players have an obvious dominant strategy, then.
00:38:10.664 - 00:38:26.300, Speaker B: They will take it. In fact, there'll be taught. So a focus of this course which again, sort of differentiates to a large extent the computer science approach versus a more traditional approach is trying to push toward weaker and weaker behavioral models, making as few assumptions as possible.
00:38:26.300 - 00:38:49.604, Speaker B: So at times in the course, I will make assumptions like we're going to assume players play the national equilibrium under that assumption. The following things are true, but also there'll be a big push in the course to weaken the assumptions significantly. And it's hard to get much weaker than assuming that when you have a dominant strategy, which again means it's always the best thing for you, it doesn't matter what everyone else is doing.
00:38:49.604 - 00:39:00.810, Speaker B: That's what a dominant strategy is. It's hard to get a weaker model than assuming that when that strategy exists, people will play it. That'll be sort of our best case scenario as far as how weak the behavioral model will ever get.
00:39:00.810 - 00:39:28.668, Speaker B: So I think I have time for a quick aside. So a little over 20 years ago, conan Horowitz wrote just a two page observation in Nature, very cute observation, which points out that Braces paradox, it's not really about traffic networks. It's really something much more fundamental.
00:39:28.668 - 00:40:02.376, Speaker B: You don't need traffic. They propose the following physical experiment involving strings and springs. So you take some fixed base, something like this, and from it, from below, you attach a spring to the bottom of that spring.
00:40:02.376 - 00:40:09.180, Speaker B: You attach a very short string. That's a string right there. Then another spring.
00:40:09.180 - 00:40:30.900, Speaker B: And at the bottom you have a heavy weight. Okay? And so when you hang this weight from below, of course, it stretches out both of the springs and it pulls that little tiny string taut. I am also going to attach two strings that the moment seems superfluous.
00:40:30.900 - 00:40:48.984, Speaker B: The first one from the top of the top spring to the top of the bottom spring. The second one from the bottom of the top spring down to the weight, okay? So they're going to be just long enough so they have a tiny bit of slack.
00:40:49.112 - 00:40:49.790, Speaker A: Okay?
00:40:51.760 - 00:41:03.330, Speaker B: But here's what's interesting. Suppose now I take a pair of scissors and I go up to that little taut string in the middle, and I go snip I cut.
00:41:12.120 - 00:41:12.676, Speaker A: It.
00:41:12.778 - 00:41:25.690, Speaker B: This contraption will reposition itself somehow. And the weight, right? Three things could happen. Could stay in the same place, could go up, could go down.
00:41:25.690 - 00:41:39.580, Speaker B: So who thinks it stays in the same place? The weight. When I cut the string, who thinks it goes up? Who thinks it goes down?
00:41:41.630 - 00:41:51.210, Speaker A: All righty.
00:42:04.090 - 00:42:23.354, Speaker B: It properly implemented. The weight actually levitates off of the ground. Despite the fact it seems like you made this system weaker, there's two arguments you can use to see why that's true.
00:42:23.354 - 00:42:27.126, Speaker B: One is a reduction. One is direct. The reduction is to the traffic network.
00:42:27.126 - 00:42:50.900, Speaker B: We just saw the same equations that govern the physical position of these systems in strings and springs are those that govern the traffic equilibrium in these networks. The analogy is force through the strings and springs corresponds to traffic flow through the traffic network. Travel time on the right corresponds to distance on the left.
00:42:50.900 - 00:43:18.230, Speaker B: Cutting that taut string corresponds to removing the teleporter from Braces Paradox, recovering the superior equilibrium with 25% less commute time. In principle, you can build this contraption so that this levitates to mere 75% of its previous base to weight distance. This is not just a theoretical exercise.
00:43:18.230 - 00:43:33.938, Speaker B: Last time I taught this class, I offered extra credit for students who would build a demonstration and upload it to YouTube. At least three students did it, maybe more, but I found three. You can find links from the course web page, so it can be done.
00:43:33.938 - 00:43:59.820, Speaker B: No one has reached 25% decrease, but I think someone got 10% or so. So have a look if you think you can improve on last year's submissions on any dimension that you see fit, be it either production, dramatic content, how far up it goes, any of those things. Again, there's an extra credit redeemable by the end of the class if you like.
00:43:59.820 - 00:44:37.540, Speaker B: So, Brace's Paradox not just about traffic networks. So let me tell you about the third biggest theme of the class, which we will be talking about just for the final few weeks, and it's going to be the most computer sciencey part of this algorithmic game theory class. We're going to see what we can say about a very fundamental question.
00:44:37.540 - 00:45:06.974, Speaker B: Equilibria. We always talk about them, we analyze them. How do we get there? Do we get there are systems, equilibriums are easy to play.
00:45:06.974 - 00:45:14.110, Speaker B: We talked about Brace's Paradox with the teleporter. We talked how using the teleporter is a dominant strategy. There's no reason not to do it.
00:45:14.110 - 00:45:25.000, Speaker B: That game is easy to play. Some games are not so easy to play. If you come on Wednesday, we'll talk a little bit about first price auctions and you'll see just how hard some games are to play.
00:45:25.000 - 00:45:47.340, Speaker B: Given that, how do in possibly complex games, players reach an equilibrium? Even more fundamentally, do they even reach an equilibrium? And what can complexity theory, computational complexity theory tell us about this fundamental question?
00:46:01.030 - 00:46:07.490, Speaker A: It's.
00:46:10.230 - 00:46:17.630, Speaker B: So let me talk a little bit about equilibrium. Again, I don't want to be too formal with the definitions. Now, I'm sure you all have a vague sense of what it means.
00:46:17.630 - 00:46:36.134, Speaker B: It's just a system or a game as an equilibrium if for each participant, if everyone else keeps doing what they do, I'm going to keep doing what I do. Now, some games, it's actually a little tricky to define. Equilibria, so hopefully most of you know the game Rock, Paper, Scissors.
00:46:36.134 - 00:46:52.880, Speaker B: Okay? But maybe just to remind you, who's up for a few rounds? Anybody who wants to play a few rounds of rock, paper? Okay, ready? 123-12-3123. Okay. Job.
00:46:52.880 - 00:47:19.080, Speaker B: All right. Starting any of those tournaments. Man, have you seen that you know about rock, Paper, scissors tournaments? Yeah, I think it's like pool where it's like you get these people and then they claim like they just are better the more they drink, but really they just are less aware of how badly they're losing the more they drink.
00:47:19.080 - 00:47:23.676, Speaker B: I love betting those people. Yeah. Okay, so to remind you.
00:47:23.676 - 00:47:35.250, Speaker B: So Rock, Paper, scissors, three strategies, two players and one person wins, one person loses. So that's easy to encode in what's called buy matrix game format. All right, so let me put it up on the board for you.
00:47:35.250 - 00:47:50.816, Speaker B: So when there's two players, you just call one the row player. You call the other one a column player. Rock, paper, scissors.
00:47:50.816 - 00:48:00.052, Speaker B: So in our first two rounds we tied. And when you tie, you both get zero payoff. And then there's the cases where one beats the other, right? So paper beats rock.
00:48:00.052 - 00:48:08.590, Speaker B: So the first number is the row player's payoff. The second one is the column player's payoff. Scissors beats rock and you know the deal.
00:48:08.590 - 00:48:21.656, Speaker B: Okay, so in general, in a bi matrix game, you have rows, you have columns. Each matrix entry has a pair of numbers. The first number is the row players payoff.
00:48:21.656 - 00:48:53.800, Speaker B: If that's the outcome, the other number is the column players payoff. Now what's pretty clear in Rock, Paper, Scissors is there's no deterministic equilibrium it. So if we each pick a single action, at least one of us would want to change.
00:48:53.800 - 00:49:01.132, Speaker B: Assuming they stayed the same thing. If we both pick rock, actually both of us want to change. Assuming the other one does not, we want to change to paper.
00:49:01.132 - 00:49:24.530, Speaker B: If we play different things, then whoever's the loser wants to switch to the action, that would beat the other player. So defining deterministic Equilibria, you could try to do it, but you're not going to get any in this game. So what's really important in Nash Equilibria, by the way, I hope no one here thinks they know what a Nash equilibrium is because they watched a movie A Beautiful Mind.
00:49:24.530 - 00:49:31.444, Speaker B: Are y'all like too young to have seen that movie? It's getting old. Now who's seen A Beautiful Mind?
00:49:31.642 - 00:49:36.150, Speaker A: Wow. All right.
00:49:38.460 - 00:50:08.208, Speaker B: On the first exercise set there'll be a question asking you to explain why they do not correctly explain Nash equilibrium in that movie. All right, so a really key idea then in defining Nash Equilibria is allowing randomization, which actually makes sense, right, if you're playing rock, Paper, Scissors against somebody else, to me my opponent looks randomized. I'm just trying to guess kind of which is the most likely action they're going to play next.
00:50:08.208 - 00:50:23.920, Speaker B: So in Nash Equilibria you allow players to it's called mixing mixed strategies or randomized strategies. And in rock, Paper, Scissors, there is an equilibrium if you allow randomization.
00:50:24.080 - 00:50:24.790, Speaker A: Okay.
00:50:28.140 - 00:50:54.000, Speaker B: So if each player randomizes uniformly, then I claim you get a Nash equilibrium and then sometimes people say mixed just to emphasize that you can randomize.
00:50:58.980 - 00:50:59.440, Speaker A: It.
00:50:59.510 - 00:51:23.656, Speaker B: So what do I mean by this? Well if I'm picking a row uniformly at random and my opponent's picking a column uniformly at random, what you should check is that my expected payoff is zero. That's an easy computation, you don't have to see it in real time but trust me, it's an easy computation. And actually no matter what I switch to, if my opponent just keeps randomizing uniformly, doesn't matter what I do, I'm going to get expected payoff zero no matter what I do.
00:51:23.656 - 00:51:35.630, Speaker B: Okay, so in this sense if they keep doing what they're doing, I may as well keep doing what I'm doing. In that sense it's an equilibrium. In fact, as I'll ask you to verify on the exercise set, it's a unique equilibrium in the Rock, Paper, Scissors game.
00:51:35.630 - 00:51:41.180, Speaker B: Randomizes?
00:51:41.520 - 00:51:42.270, Speaker A: Yeah.
00:52:00.600 - 00:52:14.484, Speaker B: The randomization. That's a good question. I look forward to seeing your research report on the topic firsthand.
00:52:14.484 - 00:52:32.024, Speaker B: Experiments of course. Well then you can be like the null hypothesis. All right, so Rock Paper, Scissors has an equilibrium in that sense, right? That's pretty limited.
00:52:32.024 - 00:52:48.980, Speaker B: Right? So this is not why Nash got the Nobel prize. He got it because he showed actually, forget about Rock, Paper, Scissors, every game, every game, not just rock Paper, Scissors has a Nash equilibrium. Might have many, but it's definitely going to have one.
00:52:49.130 - 00:52:49.830, Speaker A: Okay.
00:53:00.140 - 00:53:08.156, Speaker B: I'm just going to state a special case here. Every bi matrix game, meaning a game of this form with any numbers at.
00:53:08.178 - 00:53:08.750, Speaker A: All.
00:53:12.000 - 00:53:19.500, Speaker B: Has a Nash equilibrium. In fact Nash's theorem applies with any finite number of players. Doesn't have to be two players.
00:53:19.500 - 00:53:36.790, Speaker B: No but basically everyone plays a mixed strategy and holding everyone else fixed. If you do anything else your expected payoff can only go down. So if everyone else keeps doing what they're doing, you want to keep doing what you're doing.
00:53:36.790 - 00:54:06.056, Speaker B: Okay, but we're going to be our scientists, right? Give us something we can use. Don't just tell me that it's there, tell me how to find it. So there's more good news, which will I'll give you the proofs for this in due course, which is for zero sum games.
00:54:06.056 - 00:54:17.870, Speaker B: So that's like here. Notice in every single matrix entry the two numbers sum to zero. In zero sum games not only is there a natural equilibrium, but we can find one efficiently, meaning in polynomial time.
00:54:17.870 - 00:54:56.600, Speaker B: So one way to do this is linear programming. That's relatively heavy machinery. If you're willing to compute something which is almost an equilibrium, then in fact very simple iterative learning strategies can be used to compute an approximate Nash equilibrium.
00:54:56.600 - 00:55:17.332, Speaker B: And that's very suggestive that this is a sort of meaningful equilibrium concept. Not only is it out there, but if players learn in a natural way over time they'll actually be able to compute it on their own and again details in due course. So NASA's theorem is 51.
00:55:17.332 - 00:55:44.220, Speaker B: This has been known for a long time, decades and decades, but a relatively recent and just quintessentially computer sciency contribution to this line of work is a negative result, saying that in general, if it's not zero sum, then under suitable complexity theoretic assumptions. In fact, there is no efficient algorithm for computing an Ash equilibrium. Such an algorithm does not exist.
00:55:44.220 - 00:56:29.208, Speaker B: So this is just from 2006, cannot compute one in polytime in general. Now, as usual, whenever some computer scientist says something about some algorithm not existing, unless you're talking about the halting problem or undecided ability or something like that, usually what they mean is under some complexity assumption, algorithms don't exist, right? So, like an NP complete problem often will in a cavalier manner say there's no polytime algorithm. Of course we mean assuming P not equal to NP, there's no polytime algorithm.
00:56:29.208 - 00:56:44.800, Speaker B: So the situation here is similar, although interestingly, this theorem is not NP complete. Or let me phrase it as more of a mindbender to make it actually true. This problem is not NP complete unless NP equals co NP.
00:56:44.800 - 00:57:00.550, Speaker B: So it's unlikely to be NP complete, but it's also unlikely to be NP. And there are rigorous statements of all of those. We're not going to go through all the proofs, the proofs get pretty hairy, but I'll give you the vocabulary so that you're totally literate in what the formal statements are and what they mean.
00:57:00.550 - 00:57:25.630, Speaker B: Okay, so it's not NP hard. There's a different, really, until recently very obscure complexity class called PPAD, which has been resurrected by this Nash equilibrium computation problem. Because PPAD turns out to be the complexity class, it was sort of defined to be the one for which this is complete.
00:57:25.630 - 00:57:35.804, Speaker B: And again, I will demystify all of this in the last couple of weeks of the class. But here's the point, here's why this is interesting. Here's why you should care.
00:57:35.804 - 00:58:19.870, Speaker B: Two reasons. First of all, and this is just really for the hardcore computer scientists among you. On a technical level, this means that Nash equilibrium has furnished us with something very rare, a natural computational problem intermediate to P and NP complete.
00:58:19.870 - 00:58:44.144, Speaker B: And in your studies I'll bet you've seen very, very few problems of that type. You take your 100 level classes, even your two and 300 level classes, everything inside the class, NP seems to fall neatly into one of these two classes, p and NP complete. Who knows if some things conjectured to be in the middle? Anyone? Sort of two quite famous examples other than this factoring.
00:58:44.144 - 00:58:58.914, Speaker B: Good. Any others? Graph isomorphism is another one you might have heard about. The point is, computing Nash equilibria, the most fundamental concept in game theory furnishes a third.
00:58:58.914 - 00:59:43.650, Speaker B: And it is this result that establishes this fact, proving it's pped hard says there's unlikely to be any polynomial time algorithm. So that's pretty cool. So intermediate to P and NP, it seems, but on a conceptual level it really suggests that we take a closer look at the notion of Nash equilibrium as a predictor for human behavior, at least in all game theoretic scenarios.
00:59:43.650 - 01:00:12.026, Speaker B: Most of us don't believe that humans can do computations systematically faster than Turing machines. So if there's no polynomial time algorithm for solving a problem in general, in the worst case, many of us don't foresee human behavior solving that same problem, say within our lifetimes. So if computers cannot find natural equilibria in general, in the worst case, perhaps strategic participants can't either.
01:00:12.026 - 01:01:02.090, Speaker B: So this casts doubt on using the Nash equilibrium as a universal predictor of the outcome of strategic behavior because of an intractability critique. Now, there are, of course, many, many complaints that people have had about Nash equilibria ever since they were defined, starting with the fact that they're not unique. So this is by no means the first, nor even necessarily the most important critique of Nash equilibria, but it's an important one, and it's one that computer science is uniquely situated to make.
01:01:02.090 - 01:01:24.980, Speaker B: And that's why I want to highlight this negative result in that final section of the course. Okay, so that concludes what I wanted to say by way of introduction. I wanted to wrap up by just telling you a little bit about expectations, how the course is going to work and taking any questions you might have.
01:01:24.980 - 01:01:36.120, Speaker B: So what do I want from you? So you can take this course in three different ways. I welcome auditors, and then of course, I expect nothing. Show up when you feel like it or not.
01:01:36.120 - 01:01:44.838, Speaker B: I did that with many courses in my student time, even as a professor. I do that sometimes. You can take it past fail and you can take it for a letter.
01:01:44.838 - 01:01:50.742, Speaker B: There'll be two types of assignments. There'll be what I call exercise sets. They will be weekly.
01:01:50.742 - 01:02:07.838, Speaker B: They'll go out every Wednesday, they'll go out the following Wednesday. My goal for the exercise sets is modest. In any graduate course like this one, I think the most important thing to do is spend some time afterwards going back through the notes slowly to make sure you understand it.
01:02:07.838 - 01:02:23.022, Speaker B: This is the kind of class where perhaps depending on what kind of undergrad you were, you may have an experience with following classes in real time, even in depth. That's very difficult to do with advanced classes like this. So it's really key you reinforce the lecture material afterwards.
01:02:23.022 - 01:02:34.850, Speaker B: The exercise sets are literally just a mechanism for me to force you to do that. They are going to be working out examples, filling in proofs that I skip in class, and so on. They are not meant to be especially time consuming.
01:02:34.850 - 01:02:44.554, Speaker B: They will be weekly. However, they'll be graded just on a plus check, minus kind of system. If you do all of the exercise sets, that's already going to be good enough for a B.
01:02:44.554 - 01:02:56.270, Speaker B: In particular, if you take the class pass fail that's all you got to do. So what's the rest of the work? There's going to be biweekly problem sets. These will be more difficult.
01:02:56.270 - 01:03:09.730, Speaker B: They're meant not to reinforce the lecture material, but to actually extend it. That is, I intend to teach you some new things relevant to the course. Of course, for new things through these problem sets, probably they'll have the format where you choose K out of N problems.
01:03:09.730 - 01:03:18.258, Speaker B: So maybe I'll give you six problems. I want you to do three. They're also meant to be solved collaboratively, so that's not mandated, but that's strongly encouraged.
01:03:18.258 - 01:03:27.734, Speaker B: So you can form groups of up to three to work on the problem sets. And we're only going to accept a single write up from each group. So there'll be five of those overall.
01:03:27.734 - 01:03:43.150, Speaker B: The fifth one, we'll just go ahead and call it a take home final. Why not? So those are the expectations I have for you. The floor is open for questions, either on the lecture content or on the course mechanics.
01:03:43.150 - 01:03:55.234, Speaker B: Oh, boy. In the back, there is a course website. The easiest way to find it right now is probably just go to my website and there's a link toward the top of my homepage and definitely keep an eye on the course.
01:03:55.234 - 01:04:12.118, Speaker B: So I will be posting readings for each lecture on the website. This reminds me of a couple of other things. The lectures are being videotaped that's really just there aren't a lot of courses like this one, and so I just wanted to kind of there's nothing fancy that.
01:04:12.118 - 01:04:26.058, Speaker B: We're literally just plopping a camcorder in the back pointed at the blackboard, and it's to make sure people who aren't at Stanford can watch these lectures if they want. But obviously a side effect. If you happen to miss a class, then you're obviously welcome to watch that later.
01:04:26.058 - 01:04:37.066, Speaker B: Hopefully they'll be posted just within a few days of the actual lecture itself. I'm also hoping to generate lecture notes, though that's less of a promise, that's more of just a goal. The videos will actually appear course notes.
01:04:37.066 - 01:04:44.690, Speaker B: I've written them for this lecture. As time permits, I'll post them as well to the website. So keep an eye on the website for those extra materials and the readings.
01:04:44.690 - 01:04:59.610, Speaker B: Yeah, they'll go out Wednesday. It'll go out in two days. Yes.
01:04:59.610 - 01:05:22.044, Speaker B: Oh, right. On some level, I don't care what your background is, but to be useful, let me kind of tell you who my kind of archetypal student is that I'm talking to. So when I prepare the lectures and I think about what level to explain things at, I sort of have in mind a master's student.
01:05:22.044 - 01:05:47.140, Speaker B: Maybe a first year PhD student, not necessarily with a theory concentration, but certainly someone who didn't hate theory and sort of enjoyed their theory classes as undergrad as much as any of the other ones. I will assume basic undergrad CS theory, meaning algorithms and MP completeness not much beyond that. Not assuming anything in economics or game theory.
01:05:47.140 - 01:06:11.316, Speaker B: Conversely, this class certainly won't substitute for a proper course in game theory or microeconomics. We'll learn it only on a need to know basis. So we'll only get sort of small pieces of those traditional fields, correct? Oh, yeah.
01:06:11.316 - 01:06:23.544, Speaker B: So my office hours will be after class. So I'll start by just hanging out around here after lecture, and then I'll make my way over to my office in Gates 462. Those will go till 430 on Monday, Wednesday.
01:06:23.544 - 01:06:39.632, Speaker B: This is also up on the web page, by the way. Oh, and then I should introduce the Tas so you can stand up, guys. All right, so on the left is Oka and his office hours, when are they? Tuesday, one to four, tuesday, one to 424 A.
01:06:39.632 - 01:06:47.988, Speaker B: And then Costas is on the right in the black shirt, and he's thursdays, nine to noon. Also in Gates B, 24 A. I will have office hours this week.
01:06:47.988 - 01:06:51.910, Speaker B: They will not. Okay. So theirs start next week, mine start today.
01:06:51.910 - 01:06:55.830, Speaker B: And that's all on the website. Other questions.
01:07:00.070 - 01:07:01.546, Speaker D: Are we using piazza?
01:07:01.678 - 01:07:11.846, Speaker B: Oh, yeah. How are we using piazza? We are. So there's a Piazza website, there's a link to it from the course homepage.
01:07:11.846 - 01:07:24.970, Speaker B: And to be honest, I will be looking at it not every day. So certainly when it's important that I respond to something on it, I will do so. But the Tas will be monitoring it relatively closely.
01:07:24.970 - 01:07:38.270, Speaker B: So, in addition to the office hours, piazza is a great way to clarify lecturer homework issues. Yeah, thanks. Well, I want to see potentially.
01:07:38.270 - 01:07:43.326, Speaker B: So let me ask the question again. So who here? This would be good. A b testing.
01:07:43.326 - 01:08:01.808, Speaker B: I should have counted before the lecture and after the lecture. What a great way to kind of evaluate the quality of your first lecture. So who is at least 95% sure that they're going to attend most of the lectures in this class? Okay.
01:08:01.808 - 01:08:14.970, Speaker B: Who is less than 95% sure they're going to attend most of the lectures in the rest of this class? Yeah, I'm going to wait a lecture or two before deciding on the room. To be honest. I've already done some groundwork, and it's bleak with the room.
01:08:14.970 - 01:08:39.776, Speaker B: I'm hoping we kind of fit, but if it stays at this size, I'll have to find something else to do. But if we drop, say, ten people from this, I think maybe it's vaguely tolerable it's easy for me, I'm at the front right, with all this space. Let me put it this way.
01:08:39.776 - 01:08:43.616, Speaker B: If you're uncomfortable with the room, please ask me again. Okay. The jury is out.
01:08:43.616 - 01:08:54.560, Speaker B: That's the answer for the room. Other questions? Yeah. So the first exercise set will go out Wednesday, and it'll be due a week from Wednesday.
01:08:54.560 - 01:09:07.552, Speaker B: And that will have some of these questions about just from lecture. So, like today, I'll ask you to there are a couple of things I mentioned in the course of class. So, like, prove that the unique equilibrium of rock paper, scissors is randomizing, uniformly.
01:09:07.552 - 01:09:17.150, Speaker B: So just basic stuff filling in the holes. And then the first problem set will also go out Wednesday, probably. I'll give you about two and a half weeks to do the problem sets, so that'll be for a while.
01:09:17.150 - 01:09:22.776, Speaker B: Okay, so I'll stick around after class for more people who have further questions. But that's it for today. Hopefully.
01:09:22.776 - 01:09:23.240, Speaker B: See you Wednesday.
