00:00:00.410 - 00:00:12.426, Speaker A: So let's go ahead and pick up where we left off at the end of the last slide. We're looking at that model of the repeated Prisoner's dilemma. So Alice and Bob playing prisoner's dilemma over and over again, adding up their payoffs across all of the stages.
00:00:12.426 - 00:00:24.240, Speaker A: And we're looking at the model where there's a random number of stages. So after each stage there's some probability P, with which that winds up being the last stage. For example, P being equal to 5%.
00:00:24.240 - 00:00:39.026, Speaker A: The goal now is to show that in this model, cooperation is justified. Cooperation is a sensible thing to do. So the plan is we're going to posit a particular very interesting and natural strategy for Alice called the tit for tat strategy.
00:00:39.026 - 00:00:51.926, Speaker A: And then we'll look at what are Bob's incentives? How should Bob respond if Alice is playing tit for tat? And we'll see that what Bob should do should be to cooperate. So let's go through that derivation. Now, the Tit for tat strategy is very easy to describe.
00:00:51.926 - 00:01:11.246, Speaker A: Stage one, cooperate to start optimistically. And then in every stage after the first, you're just going to copy exactly what the other player did in the most recent stage, in the previous stage. So if you're at stage 17 and you're, Alice and Bob cooperated in stage 16, then you, Alice, are going to cooperate in stage 17.
00:01:11.246 - 00:01:37.270, Speaker A: Whereas if Bob defected in stage 16, then you, Alice, are going to defect in stage 17. So in other words, the tip for tat strategy starts optimistically, punishes immediately and forgives quickly. And it turns out that's a great way to play the repeated Prisoner's dilemma, maybe also a pretty good strategy for life.
00:01:37.270 - 00:01:54.362, Speaker A: Start optimistically, punish quickly, forgive quickly. Now, the first thing that should be clear is that if both players happen to use the Tit for tat strategy, then they wind up always cooperating, right? Because stage one, they both start optimistically, they both cooperate. And now they just keep copying that over and over again until the end of time.
00:01:54.362 - 00:02:09.274, Speaker A: So notice the initialization is crucial if you change Tit for Tat so that it defected in the first stage and then you had two copies of that strategy against each other, notice that would defect at all stages. But that's not how Tit for tat is defined. It's defined by starting optimistically.
00:02:09.274 - 00:02:20.146, Speaker A: And so that leads to cooperation if you're facing another player who's using Tit for tat. But let's now instead ask a different question. Suppose Alice is doing Tit for Tat and maybe even sort of commits to it.
00:02:20.146 - 00:02:41.420, Speaker A: And so Bob knows that. What should Bob do in response? Should Bob cooperate? Should Bob play Tit for? Know what's the sensible thing to do? So the claim is that as long as P is at most one half, as long as the probability that you continue to another stage is at least 50%, then in fact Bob should cooperate. So let's see why that's true.
00:02:41.420 - 00:02:53.210, Speaker A: I'm going to make the argument just for stage one. But then if you think about it, once it holds for stage one, it's going to hold for all of the subsequent stages also. So Bob knows he's playing against tit for tat.
00:02:53.210 - 00:03:11.186, Speaker A: He knows Alice is going to start optimistically and cooperate in this first stage. What should Bob do in response? So we're going to put ourselves in Bob's shoes and we're just going to do a cost benefit analysis. So we're going to say, well, let's suppose we cooperated in stage one.
00:03:11.186 - 00:03:49.946, Speaker A: What would be our payoff right now in stage one and what would be the payoff we expect to get in future stages? And then on the other hand, what if we defected right now? What would be the payoff we'd get immediately at stage one? And then what would we be expecting to get in stages two? And onward? As we do this cost benefit analysis, we're going to want to keep the original payoff matrix in mind from the file transfer game. So let me just put that payoff matrix, remind you of it in the upper left corner of this slide. So just to remind you, the two rows of this payoff matrix correspond to Alice's two strategies to cooperate or to defect, or equivalently to upload or not upload.
00:03:49.946 - 00:04:00.926, Speaker A: The two columns correspond to Bob's possible strategies. Again, to cooperate or to defect. And then each entry in the payoff matrix specifies a pair of numbers that payoffs to Alice and Bob respectively.
00:04:00.926 - 00:04:17.900, Speaker A: So remember, the way we set it up in the file transfer game is that there's a benefit of three from downloading the file you want from the other player and there's a cost of one uploading the file that you have to the other player. So if both of them upload, they both get a payoff of two. If both don't load, they both get a payoff of zero and so on.
00:04:17.900 - 00:04:35.514, Speaker A: Now, let's return to the cost benefit analysis that Bob wants to do under the assumption that Alice is playing the tit for tat strategy. So Bob's, looking at stage one, says, well, should I cooperate or should I defect? And it's very clear what the payoffs are going to be in stage one for each of those consequences. So we just look in the payoff matrix.
00:04:35.514 - 00:04:46.862, Speaker A: So given that Alice is cooperating, remember, Alice is playing tit for tat and this is stage number one. So Alice is starting optimistically he's going to cooperate. So we're looking at the upper row of the payoff matrix.
00:04:46.862 - 00:05:17.686, Speaker A: So Bob's decision then is either to cooperate, also getting a payoff of two, or to defect, thereby getting a higher payoff of three. On the other hand, let's think of the ramifications of Bob's action at stage one in stage two. Should stage two actually occur, given that Alice is playing the tit for tat strategy? Well, if Bob chooses to cooperate in stage one, then if there is a Stage Two, alice will cooperate mimicking Bob's Stage One action.
00:05:17.686 - 00:05:37.170, Speaker A: So that means the expected payoff that Bob expects to get is the probability that they live to see another day, the probability that there actually is a Stage Two. So that's one minus P or 95% in a running example. And then if there is a Stage Two, well then for sure Bob is going to get a payoff of at least two.
00:05:37.170 - 00:05:46.182, Speaker A: Sort of depends on what he does. Either he gets a two or a three in Stage Two, depending on whether he cooperates or defects. But no matter what, because Alice is going to be cooperating in Stage Two.
00:05:46.182 - 00:05:56.946, Speaker A: Should Stage Two happen, Bob will get a payoff of at least two. On the other hand, suppose that Bob defects in Stage One. Well then Alice is playing tit for tat.
00:05:56.946 - 00:06:11.210, Speaker A: So Alice is going to defect in stage two. And now all of a sudden, Bob is going to get a much lower payoff in Stage Two because Alice is defecting. He'll either get a payoff of zero or minus One, depending on whether he defects or cooperates.
00:06:11.210 - 00:06:28.180, Speaker A: But in any case, he's going to be getting a payoff of zero or worse in Stage Two. So what's the upshot? Well, let's look at the combined payoff that Bob expects to get for each of its possible Stage One strategies. If it defects, it's going to get three in Stage One.
00:06:28.180 - 00:06:39.800, Speaker A: Maybe there's no Stage Two, in which case the payoff is effectively zero. But if there is a Stage Two, in this case, bob will get payoff at most zero in Stage Two. So that's a combined payoff of at most three.
00:06:39.800 - 00:07:13.264, Speaker A: Whereas meanwhile, if Bob chooses to cooperate, he will be getting a payoff of two in the Stage One. And with probability one minus P, he'll be getting a payoff also of at least two in Stage Two. So combining those two together, we get that Bob's expected payoff if he cooperates in Stage One is at least two times quantity two minus P, where again, P is the probability that any given stage is the last one.
00:07:13.264 - 00:07:45.084, Speaker A: So what we see from this calculation is that P equals one half is sort of the tipping point. So if P is less than a half, which means that the continuation probability is bigger than 50%, but you go on to the next stage, if P is less than a half, then two minus P is going to be bigger than three halves and so double that is going to be bigger than three. And what that means is that in this case, where the continuation probability is more than 50%, actually Bob should cooperate in Stage One.
00:07:45.084 - 00:08:08.702, Speaker A: He could defect, he'd get a short term gain in Stage One, but that would be outweighed by the long term cost because it would trigger Alice's future defection. So I've done this argument only focusing on the first two stages. Bob's decision in stage one and then the ramifications for what happens in stage two.
00:08:08.702 - 00:08:19.714, Speaker A: But the argument sort of holds completely generally. So you can use this argument to argue that Bob should cooperate in the first stage. Given that you move on to the second stage, you realize you're in the same situation you were before.
00:08:19.714 - 00:08:40.582, Speaker A: So if it made sense to cooperate in stage one, it certainly makes sense to get him to cooperate in stage two and so on. So if Alice is playing tit for tat, bob's just going to cooperate at every single time step, assuming that P is less than a half, assuming a continuation probability bigger than 50%. And then, of course, with Alice playing tit for tat and Bob always cooperating, alice will respond by always cooperating.
00:08:40.582 - 00:09:15.214, Speaker A: So we get the best case scenario that no matter how many stages there are, the two players will cooperate and get the pareto optimal outcome. That two comma two every single stage. And overall, I think this is a fairly satisfying mathematical story for why cooperation does appear in repeated Prismas dilemma type situations in real life, right? So the number of repetitions usually is known or in effect, random, in real life applications of the repeated prisoner's dilemma, you don't necessarily know what will be the very last interaction with some other party.
00:09:15.214 - 00:09:37.798, Speaker A: And furthermore, the tit for tat strategy, it does resemble plausible real life behavior in these kinds of situations. I can think of people who really do seem to play life more or less like some variation of tit for tat. The last thing I want to tell you about on this slide is the starring role that this tit for tat strategy has played in experiments on the repeated prisoners dilemma.
00:09:37.798 - 00:10:17.234, Speaker A: So a long time ago, about 40 years around 1980, robert Axelrod invited friends and colleagues to enter into a tournament for computer programs playing the repeated Prisoners Dilemma, right? So all of these contestants, they wrote a computer program which said, as a function of what's happened in the past, should you cooperate or should you defect in a given stage. So there were 15 contestants and they did a full blown round robin tournament. So each of the 15 programs, each of the 15 contestants was paired up, had basically 14 matches, one match with each of the other 14 contestants for a given pair of programs.
00:10:17.234 - 00:10:30.170, Speaker A: What they did is they paid repeated prisoners dilemma with 200 stages, so a fixed number of stages. So each program had played in 14 matches, each one for 200 stages. So that's 2800 stages overall of playing Prisoners Dilemma.
00:10:30.170 - 00:10:58.520, Speaker A: And then the overall payoff of a program was just its average payoff in those 2800 stages. So the winning entry submitted by Anatol Rapapur was, you guessed it, the winner out of the 15 was tit for tat. Tit for tat also had the distinction of being the shortest entry, meaning the fewest lines of code, lots of the other 14 programs were trying to be sophisticated and sort of learning what the other program was doing and so on.
00:10:58.520 - 00:11:18.470, Speaker A: What makes the victory of Tit for Tat kind of even more remarkable, like, just kind of amazing, is if you think about a little bit, tit for Tat actually never wins in any head to head match. It does not matter what program you put up against Tit for Tat. Tit for Tat will do at most as well as its opponent.
00:11:18.470 - 00:11:34.942, Speaker A: But so what happened is, once you had these 15 different programs in there, tit for Tat scored quite highly against everybody. So its average was very high, whereas the more complicated programs, they would implode in certain matches, which would bring down their average payoff. But it gets even crazier.
00:11:34.942 - 00:11:52.834, Speaker A: So Axelrod, after this tournament, he circulated its results. So he said, what happened? Said who won? All that stuff? And he solicited entries for a rematch for a second tournament with exactly the same rules. And so now more people had heard about this contest.
00:11:52.834 - 00:12:17.840, Speaker A: So instead of 15 entries, this time, there were 62. Rapapur, meanwhile, resubmitted his Tit for Tat program literally unchanged, and he won again. Even though some of these other 61 programs were explicitly tailored to exploit Tit for Tat and do well against Tit for Tat, those programs imploded when they were pitted against each other.
00:12:17.840 - 00:12:39.806, Speaker A: One thing that's kind of funny about the story is apparently no one submitted the program that would be guaranteed to beat Tit for Tat against every possible component, a program that would have won this tournament had someone submitted it. What is that program you play? Tit for Tat, except at stage 200. At the last stage, you always defect opponent by opponent.
00:12:39.806 - 00:12:56.886, Speaker A: You will do at least as well as Tit for Tat with that program. But again, apparently that was not one of these 62 contestants in the rematch tournament. So that's the most important history surrounding the Tit for Tat strategy in the last slide for this module.
00:12:56.886 - 00:13:06.200, Speaker A: Let's look at how the lessons learned from the repeated Prisoners dilemma. And the Tit for Tat strategy can be used to inform the design of a peer to peer file sharing system.
