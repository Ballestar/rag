00:00:00.570 - 00:00:14.030, Speaker A: So we concluded last lecture with a piece of good news. So we've moved on to this modular valuation case. Welfare maximization is NP hard, but we can get decent approximation algorithms and polynomial time if we ignore incentives completely.
00:00:14.030 - 00:00:46.394, Speaker A: So now, of course, what we want to do is we want to say, okay, well, we want just as good an incentive. We want just as good a performance guarantee and computational tractability guarantee, but now we want strong incentive guarantees, also ideally DSIC. So how to extend the two approximation for scenario number six to a DSIC mechanism? This turns out to be a lot harder than it might first appear, actually.
00:00:46.394 - 00:01:04.298, Speaker A: And I'm not going to give you any positive results for sort of this question today. We'll circle back to it next week after we've expanded our toolbox. So what I want to do next is I want to look at a couple of the scenarios where it's sort of a bit easier to get positive results.
00:01:04.298 - 00:01:27.574, Speaker A: And those other scenarios will also motivate new tools for designing mechanisms that have good approximation guarantees. And then finally we'll go back to at least a sub case of the sub modular case and apply those tools to get some positive results there. So first, let me just make sort of some high level comments just about kind of the nature of the challenges in doing this question.
00:01:27.574 - 00:01:50.234, Speaker A: So first, let's just say for those of you who took 364 A last quarter, we've been here before, actually, and it seemed fine at the time. So the case study that I used in 364 A was Napsack, and we had this notion, we had Myerson's Lemma and Myerson's Lemma. What it did is it told us exactly which allocation rules could be used in Dsyc mechanisms.
00:01:50.234 - 00:01:56.880, Speaker A: And it was very nice. It was exactly the monotone allocation rules. And so, you know, we had Napsack empty hard problem.
00:01:56.880 - 00:02:17.362, Speaker A: You can get a one minus epsilon approximation in polynomial time, so that was good. But then when we inspected the corresponding allocation rule, we observed it wasn't monotone, so it wasn't suitable for a DSIC mechanism. But you tweaked it a little bit because it was a homework problem and showed that it could be redesigned to be monotone and still be a one minus epsilon approximation.
00:02:17.362 - 00:02:33.458, Speaker A: And then we got a DSIC mechanism. So it was sort of a total happy ending, right? So it required a little bit of algorithmic work, but we got exactly the conclusion that we wanted. So the first thing you might think about is like, well, why don't we just go through exactly that same exercise here? We design the approximation algorithm, check if it's monotone.
00:02:33.458 - 00:02:39.280, Speaker A: If it's not monotone, we sort of tweak it. So it's monotone and we're off to the races. So idea number one.
00:02:39.280 - 00:02:50.322, Speaker A: So first of all, let me emphasize that Myerson's Lima, as stated last quarter, was only for single parameter problems. Actually, if you think about it. The statement only makes sense for single parameter problems.
00:02:50.322 - 00:03:17.446, Speaker A: What did it say? What does it mean for allocation? Will it be monotone? It says the more you bid, the higher you bid, the more stuff you get. And if you're bidding, if it's multi parameter, if there's all these different bundles you're biding on simultaneously, it's not even clear what to say the more you bid. What if you raise a bid on one bundle and decrease it on another one? What do you call that? So, Bob, we could hope to have an analog of Myerson's Lemma.
00:03:17.446 - 00:03:40.430, Speaker A: That works. So idea number one, identify a monotonicity condition that characterizes implementability, characterizes DSIC implementability. So just to remind you, what does it mean to be implementable? That means I hand you an allocation rule.
00:03:40.430 - 00:03:51.058, Speaker A: And the question is, is there or is there not a payment rule? When coupled with this allocation rule, gives you a DSIC mechanism. If there is, it's implementable. If there's no such payment rule, it's not implementable.
00:03:51.058 - 00:04:01.180, Speaker A: And what we proved last quarter is that monotonicity is exactly the same thing as implementable. So maybe there's an analog here. So actually there is.
00:04:01.180 - 00:04:20.890, Speaker A: There's something called cyclic monotonicity. It while there is a characterization of implementable allocation rules, it's just you got to take this on faith for now. It's just not that useful.
00:04:21.050 - 00:04:21.760, Speaker B: Okay.
00:04:27.010 - 00:04:38.854, Speaker A: So what do I mean it's not that? So that said, we will actually use it once in this class, I'm pretty sure in a couple of weeks. So what do I mean by not useful? First of all, it's just hard to check. Given an allocation rule, it's just hard to figure out whether or not it satisfies this property.
00:04:38.854 - 00:04:48.918, Speaker A: Whereas monotonicity often is not very hard to figure out whether or not it's satisfied or not. But two, it almost never holds. And we'll see more evidence of this as we go through the lecture today.
00:04:48.918 - 00:05:00.586, Speaker A: Okay, so if you come up with something and you check this condition, it's just always false. Is it a sufficient condition? It's necessary and sufficient, actually, yes. Hard to check.
00:05:00.586 - 00:05:19.842, Speaker A: Do you mean testing wise? So I just mean like, say, take your favorite approximation algorithm and just ask the question, does it satisfy this condition or not? As a math problem, it's annoyingly, time consuming, usually more so than in the single parameter case. Plus the other point is there tends to be just no payoff at the end. Usually the answer is no.
00:05:19.842 - 00:05:27.906, Speaker A: So usually you work hard to prove that actually your algorithm is not suitable. So I don't really advocate going this direction, is what I'm trying to say. Right.
00:05:27.906 - 00:05:45.100, Speaker A: So this kind of way of thinking about approximate mechanism design that was fruitful in the single parameter world, by and large has not been fruitful for researchers in the multipramter world. So we're going to think about a little bit differently. Okay, so idea number two.
00:05:45.100 - 00:05:59.886, Speaker A: So more the way we're going to think about it is we're going to just start from what we already know works and then just try to make it slightly more powerful one step at a time. Add bells and whistles. So kind of start bottom up.
00:05:59.886 - 00:06:15.218, Speaker A: So, for example, the VCG mechanism we know, we know works is DSIC. It may not be polynomial time in the cases we're now looking at, but at least it gets the incentives, right? So idea number two would be, okay, well, we've got the VCG mechanism. If it's NP hard, we can't implement polynomial time.
00:06:15.218 - 00:06:31.466, Speaker A: But if we have an approximation algorithm that does run in polynomial time, let's just stick that in instead. If you think about it, the VCG mechanism, you can define an analog with respect to any allocation rule, like our two approximation for welfare maximization. You get valuations from people.
00:06:31.466 - 00:07:02.770, Speaker A: You invoke your approximation algorithm to compute an approximately optimal allocation and then to compute the payments, you just invoke it n more times, okay? You delete a bidder, you use your approximation algorithm again, and then that defines the payments. Does that necessarily give you non negative payments? So, no, it does not, among other problems, rights. So that's going to be sort of the least of our problems at the moment.
00:07:02.770 - 00:07:20.902, Speaker A: Well, actually, frankly, in some applications, it's the most of your problems. But let me just say the following. So plug approximation algorithm into VCG, and let me just say the problem here and again.
00:07:20.902 - 00:07:37.630, Speaker A: So this is an attempt. So just as far as how we're approaching the problem, this is a different angle, right? So rather than kind of have a necessary and sufficient condition, which tells us what the whole design space looks like, we're just starting from something we know works and trying to extend it. The problem is this way of extending what we know works almost never succeeds.
00:07:37.630 - 00:07:48.130, Speaker A: And for now, the main thing I just want to say by never works is you will get a mechanism in general which is not Dsick.
00:07:50.470 - 00:07:51.220, Speaker B: Okay?
00:07:52.950 - 00:08:09.150, Speaker A: And this I can sort of tell you morally why this shouldn't work. What the problem is actually, there's some good intuition for why this is going to fail. So let's remember what the point of the VCG payments were, okay? So you're charged your externality.
00:08:09.150 - 00:08:35.410, Speaker A: So basically the surplus loss that others incur because of your presence. And the reason we're charging externalities is because if you then look at the utility of a bidder, its value minus its payment, its payment is then up to a constant the negative of other people's welfare in the outcome. So in other words, the payments are defined so that it aligns your own utility with the social welfare of everybody.
00:08:35.410 - 00:08:48.630, Speaker A: That's why the VCG mechanism works morally. So intuition by design, VCG aligns.
00:08:50.410 - 00:08:50.726, Speaker B: The.
00:08:50.748 - 00:09:17.822, Speaker A: Utility of a bidder with the social welfare up to some constant term which the bidder can't influence. So for incentives, it's is just this is just how the VCG payments are defined so that this is true. So in the happy case where you're maximizing welfare exactly, well, the bidder wants to make its utility as high as possible.
00:09:17.822 - 00:09:45.026, Speaker A: And so that means it just wants the social welfare to be as high as possible. So if the mechanism does this, then the bidder is going to be happy. Now, if the mechanism fails to maximize the social welfare, if it does something suboptimal, that corresponds to an opportunity potentially of a bidder to misreport in a way that coaxes the approximation algorithm to actually spit out a strictly better solution, resulting in a strictly bigger utility for that bidder.
00:09:45.218 - 00:09:46.006, Speaker B: Okay?
00:09:46.188 - 00:10:23.490, Speaker A: So suboptimality in the allocation rule kind of directly represent opportunities to misreport to have higher welfare allocations, therefore higher bidder utilities. So that's why fundamentally approximation algorithms just almost never work if you just plug them into the VCG mechanism with the BCG payments. So again, if right hand side suboptimal, there exists opportunity for some bidder to increase utility.
00:10:23.490 - 00:10:40.710, Speaker A: Now, this is sort of morally true. Technically. The reason this is a little not really the complete story is because it's not clear that a bidder has a unilateral way of coaxing the allocation rule into a better allocation.
00:10:40.710 - 00:10:52.350, Speaker A: But actually this can be dealt with. So there's a paper of Nissan and Ronan, I'll put the citation in the notes who prove that this really is true. Really? Basically, if you're doing something suboptimal, BCG payments just sort of basically never work.
00:10:52.350 - 00:10:54.480, Speaker A: There is a theorem that says exactly that.
00:10:55.810 - 00:10:56.462, Speaker B: Okay?
00:10:56.596 - 00:11:26.200, Speaker A: And so an important thing I want you to take away from this discussion, and this will become clear throughout the rest of today and next week, is that for multi parameter problems, so there's a big difference between single parameter mechanism design problems and multi parameter design problems. Really very big as far as both how well we understand it, but seemingly what is even possible versus impossible. So with the single parameter case being much, much easier, it seems.
00:11:26.200 - 00:11:40.750, Speaker A: So for multiprameter problems, like the commentary options we've been talking about, the bottom line is if you insist on dominant strategy and sending compatibility, it just seems there is very little you can do.
00:11:40.820 - 00:11:41.054, Speaker B: Okay?
00:11:41.092 - 00:12:10.470, Speaker A: The design space is just very meager. That said, we'll work hard today and next week to do the best we can in this very limited design space, but seems very limited indeed. And then in the entire second half of the class motivated by this sort of moral, we're going to relax the DSIC requirement so that we can actually get a bigger design space and more positive results.
00:12:10.470 - 00:12:25.322, Speaker A: Good. As a mathematical statement, this is more conjecture than proof at this point. There are theorems around this.
00:12:25.322 - 00:12:40.654, Speaker A: So you could imagine a theorem that actually said the only multi parameter DSIC mechanisms are x, where x is some small set. And there is something called Robert's theorem which basically says if you have a totally abstract problem. So literally just some abstract outcome space.
00:12:40.654 - 00:13:00.146, Speaker A: You don't have a notion of goods, nothing like that, then in fact, you can actually prove that the only deterministic DSIC mechanisms are minor variance on the VCG mechanism. So that's known as Robert's theorem. Basically, an open question is, does Robert's theorem hold for commentatorial auctions? Commutorial auctions have some extra structure.
00:13:00.146 - 00:13:08.390, Speaker A: You have these goods and I only care about what items I get. I don't care about what items you get. So there's, quote unquote, no externalities between bidders in that sense.
00:13:08.390 - 00:13:27.440, Speaker A: So that's extra structure in commercial auctions, which seems to on the one hand, make it really difficult to prove theorems like Robert's theorem, but on the other hand doesn't seem to be enough structure to enable non trivial d sick mechanisms. So that's kind of the state of the art at the moment. It's kind of hard to prove positive or negative results for commentary options.
00:13:27.440 - 00:13:32.030, Speaker A: So I'm going to tell you in these couple of weeks what we have been able to prove.
00:13:33.750 - 00:13:34.194, Speaker B: All right?
00:13:34.232 - 00:13:56.546, Speaker A: So any questions? All right, so here's the plan. So again, the plan is to just start from what we know works, which at the moment is pretty much just the VCG mechanism, and look at bells and whistles of it, look at variations, and look at some problems where that'll give us non trivial results.
00:13:56.658 - 00:13:57.320, Speaker B: Okay?
00:13:57.690 - 00:14:09.980, Speaker A: And so today I want to introduce a couple more scenarios. One will be simple and we'll solve completely. One is more complicated and we'll spill over into next week and the tools we develop will put to use in the submoduular case next week.
00:14:09.980 - 00:14:27.890, Speaker A: So beyond VCG, what else could you do? So here's idea number one. It's a very kind of minor idea, but it's useful in some cases. So let me tell you about maximal and range mechanisms.
00:14:27.890 - 00:14:46.806, Speaker A: So maximal and range mir, this is a property of an allocation rule. So mir allocation rule has the following structure. So what you do, okay, so say there's an outcome space.
00:14:46.806 - 00:14:56.010, Speaker A: I'm going to describe this abstractly, but you can go ahead and think about commentary options. So there's an outcome space Omega. So this would be like all allocations in the problem we've been discussing.
00:14:56.010 - 00:15:16.610, Speaker A: And this rule then pre commits before it ever sees valuations, before it ever sees bids by the players. It says up front, look, I'm only ever going to output an outcome in a subset, Omega Prime.
00:15:21.430 - 00:15:21.858, Speaker B: All right?
00:15:21.864 - 00:15:40.860, Speaker A: Now why would you ever do this? So here's what you want to have in mind. You want to think about Omega as being either too big or too unstructured to optimize over efficiently, okay? So searching over Omega is a hard problem. Omega prime is going to be chosen to be either small or structured enough so that searching over it's an easy problem.
00:15:40.860 - 00:15:50.170, Speaker A: So think of Omega Prime as a subset, which is tractable. So you're losing information. But hopefully gaining tractability and passing to Omega Prime.
00:15:50.170 - 00:16:09.700, Speaker A: And then once the bids or valuations come in, x just runs VCG on Omega Prime. So it's a very minor extension of VCG up front. I throw out some outcomes and I run VCG on what's left.
00:16:09.700 - 00:16:25.346, Speaker A: And the hope is that you can find a sweet spot, an Omega Prime that's rich enough that you can still get a good approximation. You've thrown out some stuff, but the hope is you still have kind of something near optimal for any valuations, but it's also small or structured enough that you can optimize efficiently.
00:16:25.538 - 00:16:26.280, Speaker B: Okay.
00:16:28.430 - 00:16:38.234, Speaker A: And this is clearly DSIC, just because VCG is DSIC, omega prime could well have been the original outcome space for all anybody cared, all anybody knew.
00:16:38.352 - 00:16:39.020, Speaker B: Okay?
00:16:40.430 - 00:16:57.714, Speaker A: So that's an Mir mechanism or allocation rule. So as far as what else could you do other than VCG? Well, this is something you could do. All right, so could it ever be useful for anything? Okay, well, it's not useful that often, but once in a while.
00:16:57.714 - 00:17:10.870, Speaker A: So let me show you an example how you can actually do this to get a somewhat interesting result. So let me give you a generalization. So we're going to go back to the world of identical items.
00:17:10.870 - 00:17:28.506, Speaker A: So identical items is before we were talking about downward sloping valuations, we had osevelt's, clinching, auction, blah, blah, blah, blah. So we're going to look at a harder version of that where we drop the downward sloping assumption. So remember, this is where all the items are the same, and as a bidder, you might want more than one.
00:17:28.506 - 00:17:41.070, Speaker A: You're not unit demand downward sloping, said each additional unit gave you only less marginal value. Now we're going to drop that assumption. So extra units may give you more or less marginal value than the previous one.
00:17:41.070 - 00:17:45.730, Speaker A: Non negative marginal value. You have free disposal as usual. Okay, but that's the only assumption.
00:17:47.430 - 00:17:47.922, Speaker B: All right?
00:17:47.976 - 00:18:15.206, Speaker A: So M, identical items, I has marginal values, mu I J, non negative for all J. And again, the key point here is need not be downward sloping. Downward sloping.
00:18:15.206 - 00:18:19.210, Speaker A: You'll recall we had a nice ascending auction and we basically got everything we wanted.
00:18:19.360 - 00:18:22.400, Speaker B: Okay? All right.
00:18:28.690 - 00:18:52.390, Speaker A: So let me tell you what we can do just with the regular VCG mechanism, and then I'll explain how we can get sort of an incomparable result using an Mir mechanism. Incomparable meaning it'll be faster, but it will be approximate instead of exact. So I'll leave it as an exercise to convince yourself that you can solve this exactly using dynamic programming.
00:18:52.390 - 00:19:16.958, Speaker A: It's not that different than say, Napsack or something like that. In fact, if you think about it, napsack is going to be a special case of this problem. So basically, if your marginal values are just and then at some point it kicks up to some number ten, and then the marginal values after that are like, say it was the 12th good that gave you this marginal value of ten.
00:19:16.958 - 00:19:52.090, Speaker A: That's like a knapsack item with size twelve and value ten, right? You give it twelve items, you get value ten. Your Napsack capacity is like M, so it's a little bit more general than Napsack, but dynamic programming again works fine. So exercise can maximize welfare in time, polynomial in n and m by dynamic programming.
00:19:52.090 - 00:20:18.378, Speaker A: And of course, if the valuations are represented explicitly, if you're just given a list of these mu IJs, then you'd be happy with this. On the other hand, dynamic programming for the Napsack problem, we usually think of that as pseudopolynomial, usually running time linear in the Nap. So M here corresponds to the Napsack capacity in a Napsack problem.
00:20:18.378 - 00:20:38.166, Speaker A: And if you run in time linear in the Napsack capacity, we usually think of that as only pseudo polynomial and not truly polynomial. And so you might want to think here, you might want to look for algorithms that actually are polynomial in n and log m, the number of bits needed to explain what the supply is. Now you have these marginal values, right? So again, you need some model for that, but we've already talked about that.
00:20:38.166 - 00:20:54.058, Speaker A: So let's think actually about a black box model for valuations that supports value queries. So for a bitter I, I'm just going to say, look, what if I gave you 17 items, what would you pay for it? And they'll answer us. And then other than that, we're not going to treat them as part of the input, okay? They just answer value queries.
00:20:54.058 - 00:21:21.042, Speaker A: Then it's conceivable we could get a running time that had sublinear dependence on that's what I'm going to show you next. So this is by Dobzinski and Nissan. So there exists a maximal in range algorithm or mechanism with two properties.
00:21:21.042 - 00:21:27.430, Speaker A: So first of all, it's not going to be exact, but we'll get at least 50% of the opt welfare.
00:21:30.830 - 00:21:31.194, Speaker B: And.
00:21:31.232 - 00:21:52.080, Speaker A: Two, the time plus the number of value queries is polynomial in n and log m. And I guess I should also write log of the biggest number probably.
00:21:52.930 - 00:21:53.342, Speaker B: Okay.
00:21:53.396 - 00:21:58.754, Speaker A: So again, the point here, so this is worse. It's only an approximation. This is better.
00:21:58.872 - 00:21:59.250, Speaker B: Okay.
00:21:59.320 - 00:22:08.040, Speaker A: The running time allow counting value queries as constant time is polynomial in the log of M, not an M. So if M is huge, this is a big win actually.
00:22:10.570 - 00:22:10.966, Speaker B: All right.
00:22:10.988 - 00:22:21.820, Speaker A: But again, the main reason I'm showing you this is just to convince you that mir as modest and advance as it sounds and is, can be useful in some contexts. That's the point of this example.
00:22:22.990 - 00:22:23.386, Speaker B: All right?
00:22:23.408 - 00:22:39.982, Speaker A: So any questions before the proof is not we'll be able to do the proof pretty quick, it's not hard. Any questions before that? All right, so if it's mir, I need to tell you what is this outcome space. So an allocation space.
00:22:39.982 - 00:22:50.994, Speaker A: So basically an mir algorithm is going to say, look, I will only ever output allocations with certain special properties. So I need to tell you what the special properties are. So here's what it is.
00:22:50.994 - 00:23:01.442, Speaker A: So what I'm going to do is just up front, I'm going to take these M items, conceptually at least, and I'm going to split them into blocks. Chunks. Okay, so I started with M items.
00:23:01.442 - 00:23:10.374, Speaker A: I only want there to be kind of n squared meta items. I'm okay, being polynomial on n. I don't want to be polynomial on m, I want to be logarithmic and m.
00:23:10.374 - 00:23:23.502, Speaker A: So I start with m. I want to squeeze it down to just n squared, which means each block has m over n squared items in it. And I'm only going to optimize over allocations where I dole out items in these blocks of m over n squared at a time.
00:23:23.502 - 00:24:14.762, Speaker A: Okay, so your allocation will be some integer multiple of m over n squared that's omega prime. So this is now just a multi unit auction in effect with n squared items, where each of these n squared items represents m over n squared in the original one. Okay, so now that there's so few items, right? So now that the number of items is just n squared, I can run the dynamic programming algorithm on these meta items and maximize welfare overall.
00:24:14.762 - 00:24:30.962, Speaker A: This entire restricted allocation space, omega prime. The only reason I have dependence on law on m at all is because I need to actually write down the quantity when I do a value query to one of these black box valuations. So I might have to ask it about a number as large as m.
00:24:30.962 - 00:24:52.330, Speaker A: So I need log m time to do that, so it can be done via DP in polyn login time plus value queries.
00:24:53.950 - 00:24:54.700, Speaker B: Okay.
00:24:56.910 - 00:25:12.110, Speaker A: So I did choose omega prime small enough that it enabled fast search. That's good. But now the question is, did I throw out the baby with the bathwater? Are there still enough allocations in there so I can always get a good approximation? That's what I have to prove.
00:25:12.110 - 00:25:31.078, Speaker A: So let me show that to you. So suppose the optimal allocation is s one star up to SN star. Now all the goods are identical, so I mean, really these are just non negative integers that sum to m.
00:25:31.078 - 00:25:53.870, Speaker A: Okay, so suppose that's the optimal allocation. What I need to show is that there exists an allocation in omega prime that is an allocation that only uses these blocks of m over n squared size that is almost as good as this one. Why is that enough? Well, because amongst all of those allocations, we're going to pick the best one.
00:25:53.870 - 00:26:24.870, Speaker A: So if I show you one good one, we're done. So I need to show there exists some allocation s one up to SN of blocks, so that the welfare that you get from it is at least one half of the optimal welfare. Agree? Okay, so this is easy enough two cases.
00:26:24.870 - 00:26:57.140, Speaker A: So first, in this optimal allocation, it turns out almost all of the welfare say at least half the welfare in here comes from a single bidder, no problem, because one of our feasible allocations is just to give everything to one bidder. So that's one of the things we optimize over. So if there's one bidder in here which contributes half of the welfare, no problem.
00:26:57.140 - 00:27:26.298, Speaker A: So then we just set si equals to be all M, nobody else gets anything, and then done. So I'm using monotonicity here. I'm using that.
00:27:26.298 - 00:27:27.526, Speaker A: The mus are non negative.
00:27:27.638 - 00:27:28.300, Speaker B: Okay?
00:27:28.830 - 00:27:41.406, Speaker A: So in this allocation, the key bidder I is as happy as before we lose everybody else, sorry, one half there. We lose perhaps everybody else, but they were only contributing at most half the welfare. So no big deal.
00:27:41.406 - 00:27:55.870, Speaker A: We're a factor two approximation. So what if that's not the case? This is slightly more interesting. So suppose no bidder contributes half of the welfare or more in the optimal allocation.
00:27:55.870 - 00:28:00.290, Speaker A: Basically what I'm going to do is I'm just going to sort of start from the optimal allocation.
00:28:00.370 - 00:28:00.678, Speaker B: All right?
00:28:00.684 - 00:28:09.574, Speaker A: So what's the issue? Right, so the issue is in the optimal allocation. So say M over N squared is like 100. So I'm only allocating in multiples of 100.
00:28:09.574 - 00:28:29.530, Speaker A: The issue is that in this optimal allocation, this guy might have like 101 items. And moreover, maybe his marginal value was like zero for the first hundred. And it was that mad magic 101 th item that gave them all of its value, right? So that means if I want to allocate it anything, if I want to get any value from that guy, I have to round up to the nearest multiple.
00:28:29.530 - 00:28:45.426, Speaker A: I can't give it 101 goods, I have to give it 200 because those are the multiples that I'm allocating it. So what I'm going to do? Well, so I basically want to top people off, okay? Because then I'll get their value. But obviously I can't round everybody up because I only have these M goods to work with.
00:28:45.426 - 00:29:08.282, Speaker A: So there'll just be some sacrificial lamb, some bidder, I'll take all its items away from them and I'll use that to round everybody else up. Okay, so why is there somebody that has so many items that I can actually round up everybody else? Well, this is the magic N squared number, right? So there's N squared blocks floating around. There's N bidders, so somebody's got N of them.
00:29:08.282 - 00:29:15.846, Speaker A: Okay, so that's my sacrificial lamb. I take his n blocks. That's a proof of concept.
00:29:15.846 - 00:29:26.820, Speaker A: I can round everybody else up and just round this one guy down. Why don't I lose all of the welfare by rounding this one guy down? Well, in case two, nobody has that much of the welfare. No single bidder contributes half the welfare or more.
00:29:26.820 - 00:29:57.210, Speaker A: All right, so I feel like I should write something. So case two, otherwise there exists I with at least n blocks. And so then how do I set my new allocation? So for K zero equal to I, so si equals S star, I rounded up to multiple of M over N squared.
00:29:57.210 - 00:30:24.050, Speaker A: So that is, I give this guy the fewest number of blocks so that it gets at least as much as it gets in the optimal allocation, and then I gets the rest or nothing, it doesn't really matter. And then what do we have? We have sum over the welfare in our allocation. Well, I was our sacrificial lamb, so we'll just lower bound that person by zero.
00:30:24.050 - 00:30:41.030, Speaker A: But for everybody else they get at least as many, at least as much quantity in our allocation than the optimal one. So by monotonicity we pick up all of their values by the assumption of case two. This is at least half of the full welfare in the optimal solution.
00:30:41.030 - 00:31:00.702, Speaker A: So that's that. So that's an example use of a maximal and range mechanism. Any questions about that? Do we know if the one half is tight? Good question, good question.
00:31:00.702 - 00:31:12.130, Speaker A: So for this mechanism, certainly that's not hard to show just with two bidders. So here's what's cool. There's actually a cool story about multi unit auctions, which is one of the reasons why I bothered to spend some time on it.
00:31:12.130 - 00:31:18.742, Speaker A: So for deterministic mechanisms, it is unknown whether you can beat two with DSIC or not.
00:31:18.876 - 00:31:19.318, Speaker B: Actually.
00:31:19.404 - 00:31:38.554, Speaker A: Quite nice open question. What is known is that if you restrict attention to DSIC mechanisms that always allocate all M items, then you cannot beat a factor two. What is unknown is whether there's a mechanism, deterministic DSIC mechanism, that may or may not allocate everything and always beats two.
00:31:38.554 - 00:31:46.366, Speaker A: Good open question. Interesting. So like definitely if you wanted to spend your project time thinking about an open question, that would be a good one to do.
00:31:46.366 - 00:32:13.462, Speaker A: Very appropriate randomized, and this is a project topic, looking about these papers, with randomized you actually can get one minus epsilon and it's going to be the same. So I'm about to pass to sort of a randomized generalization of maximum range, and I won't actually show you this proof, although it is a project, one of these randomized versions of maximum range. Very cleverly designed by a PhD student of mine here a few years ago.
00:32:13.462 - 00:32:21.450, Speaker A: And one co author shows you can get one minus epsilon. So that's very cool. And again in the same kind of polyn and login with value queries.
00:32:21.450 - 00:32:39.120, Speaker A: So the statement is you're randomizing, but it's still Dsick. It's DSIC assuming risk neutral bidders, assuming risk neutrality, and then you get an expected one minus epsilon fraction. That's a good question.
00:32:39.120 - 00:32:53.380, Speaker A: Yeah. Your expected welfare is one minus epsilon. There are some mechanisms out there with the approximations, with probability one, and the expectation is only over the incentives, but this is not one of them.
00:32:55.590 - 00:32:56.340, Speaker B: Yeah.
00:33:00.390 - 00:33:14.060, Speaker A: So scenario seven is actually a nice challenge problem. The downward sloping. Case is already very interesting on the tractable side, and this general case is a quite interesting example on the intractable side.
00:33:14.060 - 00:33:22.570, Speaker A: Okay, good. Any other questions? All right, then. As promised.
00:33:22.570 - 00:33:37.682, Speaker A: So again, we're trying to rack our brains and thinking about what could DSIC mechanisms look like for multiprameter problems. And we're just starting from what we know and taking baby steps. And so let me show you one of the baby step.
00:33:37.682 - 00:34:02.410, Speaker A: And actually this little baby step will get us basically to the state of the art, I'm sort of embarrassed to tell you. And so this is nothing more than a randomized variation of maximal in range. So maximal in distributional, kind of a painful name range.
00:34:02.410 - 00:34:19.354, Speaker A: So MIDR is now what we have, and I need to warn you. So first of all, this is going to be kind of abstract. And second of all, I won't have time today to give you an actual example of one of these mechanisms.
00:34:19.354 - 00:34:29.346, Speaker A: So I'm going to do the definition now anyways. I'll introduce you to the problem that we're going to solve using these mechanisms, but I won't have time today to give you that mechanism for that problem.
00:34:29.448 - 00:34:29.714, Speaker B: Okay?
00:34:29.752 - 00:35:00.460, Speaker A: So just forward pointer to what's going to be next week where we're going to pick back up next week. All right, but the idea is simple enough, it just says, okay, instead of pre committing to a subset of outcomes, we're going to allow lotteries over outcomes, randomizations over outcomes, distributions. So again, before you ever see any valuations, what the allocation rule or the mechanism has to do is pre commit to a set D.
00:35:00.460 - 00:35:29.842, Speaker A: It doesn't have to be countable, but I'll write this anyways, of distributions over omega. So one of these distributions might be as simple as with 50% probability, I do this first allocation, with 50% probability, I do this other allocation, or even just like with 1% probability, I cancel the allocation completely. Those would be examples of distributions over outcomes.
00:35:29.986 - 00:35:30.680, Speaker B: Okay?
00:35:32.490 - 00:35:43.974, Speaker A: Okay. So maximum range would just correspond to the case where each of these was a point mass on a single outcome. That would be that special case over Omega.
00:35:43.974 - 00:36:16.850, Speaker A: Good. And again, it's only going to remind you, so why do this? Okay, so over here, hopefully, it was sort of clear the role of mir over here, which is the search space for the original problem, was big, and we just compressed it so that it was small, so we could basically kind of search it more or less exhaustively. Now, here in general, the set of distributions need not be small relative to Omega, it might be infinite, but we know lots of examples where sort of enlarging the search space also makes stuff more tractable, right? Just think of integer and linear programs, right? Integer programs can be hard.
00:36:16.850 - 00:36:36.266, Speaker A: You go to linear programs. It's not that there's fewer solutions, but it's somehow very nicely structured and enables efficient optimization so that's a similar reason why distributions can sort of add tractability relative to the Omega that you started with. Okay, anyways, so those are some things you might want to think about.
00:36:36.266 - 00:36:44.474, Speaker A: Now, what does the allocation rule have to do? Well, in the same way that amongst all of the Omega primes, the allocation rule has to pick the best one.
00:36:44.512 - 00:36:44.714, Speaker B: Remember.
00:36:44.752 - 00:36:51.086, Speaker A: That's what VCG does. You tell it what it wants and it picks the best option. Here, it just said upfront omega prime are the set of all the options.
00:36:51.086 - 00:37:06.530, Speaker A: And again, best option means welfare maximizing with respect to the reported valuations. Same thing has to be true here. Amongst all the distributions, once you know what people actually want, once you know the alleged valuations, you have to pick the best, not outcome distribution.
00:37:06.530 - 00:37:20.658, Speaker A: So now the question is, okay, so how do you measure the quality of a distribution? Well, just by its expected welfare. So it's 50 50 over these two allocations, and you get these valuations, and the welfare would be ten in this case and 20 in this other case. You just say, okay, well, we'll treat it as 15.
00:37:20.658 - 00:37:27.754, Speaker A: And if there's this other distribution of our outcomes that randomizes between 1020 and 30 for expected welfare, 20, we treat that as better.
00:37:27.952 - 00:37:28.410, Speaker B: Okay?
00:37:28.480 - 00:37:39.914, Speaker A: So when we compare distributions, we do it before we sample from them. We just think, okay, just look at the expected welfare under this distribution, given the alleged valuations, and pick the one that's the highest.
00:37:40.042 - 00:37:40.430, Speaker B: Okay?
00:37:40.500 - 00:37:49.594, Speaker A: So that's by definition what an MIDR rule has to do. So, in other words, once you tell me the distributions, the rest of the rule is completely uniquely defined.
00:37:49.722 - 00:37:50.400, Speaker B: Okay.
00:37:52.850 - 00:38:05.010, Speaker A: So given it so it is, at the end of the day, going to be a randomized allocation rule.
