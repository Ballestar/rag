00:00:00.410 - 00:00:09.886, Speaker A: Hi everyone and welcome to this video that accompanies section 20.5 of the book algorithms Illuminated. Part four algorithms for NP hard problems.
00:00:09.886 - 00:00:37.622, Speaker A: So this section is about the principles of local search. So a local search algorithm is an algorithm that explores a space of feasible solutions via local moves, successively improving an objective function value. So the two hop heuristic for the Tsp that we saw in the last couple of videos, that's a totally canonical example of a local search algorithm where the local moves corresponded to the two changes discussed in that video.
00:00:37.622 - 00:01:11.134, Speaker A: So what I want to do now is zoom out and isolate the essential features of the local search algorithm design paradigm together with the key algorithmic and modeling decisions that you need to make in order to apply this technique effectively in your own work. So with an eye toward explaining to you local search in general, let's quickly revisit that two opt heuristic for the traveling salesman problem that we discussed in the last couple of videos. In particular, I want to think about the two opt heuristic as a walk through a really big graph.
00:01:11.134 - 00:01:31.810, Speaker A: I'm going to explain to you this really big graph which I'm going to call the metagraph in terms of the five vertex Tsp instance we had running through the last couple of videos. So let me just remind you about that five vertex instance, putting it in the upper right of this slide. So the vertices of the metagraph are going to correspond to the traveling salesman tours of this instance.
00:01:31.810 - 00:01:50.378, Speaker A: Now this is a five vertex instance and so if you remember the formula for the number of tours, it was one half times quantity n minus one factorial. So n minus one factorial is 24 half, that is twelve. So that means this metagraph is going to have twelve vertices in this case for this five vertex Tsp instance.
00:01:50.378 - 00:02:07.822, Speaker A: So let me arrange these twelve tours into four rows. At the top we're going to have that perimeter tour, the same one that was the output of the nearest neighbor heuristic. At the bottom we're going to have the complement tour that has none of those five edges and all of the other five, so it sort of looks like a star.
00:02:07.822 - 00:02:24.300, Speaker A: And then the other ten tours I'll put in the middle two rows and you'll see in a second why I'm arranging them in this way. So those are the twelve traveling salesmen tours of this instance. Let me now annotate each of those twelve with their cost.
00:02:24.300 - 00:02:44.570, Speaker A: So finally let me tell you about the edges of the metagraph. So the edges of the metagraph will correspond to two changes. So in other words, two tours of the metagraph, they will be connected by an edge of the metagraph if and only if you can get from one to the other using a two change equivalently.
00:02:44.570 - 00:02:57.486, Speaker A: Two tours are connected if they share three out of their five edges. So for example, consider the tour on top, sort of the cycle around the perimeter. Remember this was the output of the nearest neighbor heuristic on this particular instance.
00:02:57.486 - 00:03:27.690, Speaker A: And this is also where we started our example, tracing through the two opt heuristic to see what it would do on this example. So if the patterns in the second row, that first list of five tours, if that looks familiar, that's because those are exactly the five tours that we examined in the first iteration of the two opeuristic when we ran through that example in the previous video. So in other words, the five neighboring tours of this top tour are exactly the five tours in the second row.
00:03:27.690 - 00:03:45.890, Speaker A: So the bottom half, the bottom six tours are in some sense a reflection of the top six where we just toggle which edges are in and which are out. So the tour on the bottom, that's all the edges missing from the top tour. And correspondingly, it's connected by a two change to each of the five tours in the third row.
00:03:45.890 - 00:04:00.646, Speaker A: So how about the rest of the edges? Well, you might remember that there was always five two changes you could take from a tour in a five vertex instance. So we should expect to have five incident edges around each of these tours. So we're all set for the top, all set for the bottom.
00:04:00.646 - 00:04:18.234, Speaker A: But we expect each of the tours in the second and third rows to have four more edges incident to them. And I've drawn the tours in such a way that those four incident tours, they're going to be tours in the other row. So if you're in the third row, you'll be adjacent to ones in the second row and vice versa.
00:04:18.234 - 00:04:41.266, Speaker A: And moreover, the four out of the five that you're adjacent to are all of those that are not in your same column. So, for example, the third tour on the second row, it's going to be adjacent to all of the tours on the third row, except for the one immediately below it. And now we see that indeed that cost 32 tour, the middle one in the second row.
00:04:41.266 - 00:04:48.546, Speaker A: Now it has five edges around it. So it's exactly the same for all the other tours in the second and third rows. I'll fill in some of those edges.
00:04:48.546 - 00:05:08.110, Speaker A: I'll also leave some of those edges out because it would just clutter the picture too much to have them all in there. So that's the definition of the metagraph associated with an instance of the traveling salesman problem. The vertices of the metagraph correspond to tours of the Tsp instance, and two tours are adjacent in the metagraph if and only if they differ in only two edges.
00:05:08.110 - 00:05:28.082, Speaker A: Why am I torturing you with this metagraph? Well, we can actually visualize the two Op heuristic really, really nicely in terms of this metagraph. So remember, in our running example, we started with the output of the nearest neighbor heuristic, and that was this tour on the top. And then the way the two operistic worked is we were going to take a two change.
00:05:28.082 - 00:05:46.074, Speaker A: So in other words, the next thing the algorithm is going to do is it's going to follow a one hop path in this metagraph to one of the neighboring tours. Like in the example, there are five options, five different tours you can reach by a two change. And as you saw in that example, three of those five tours have strictly smaller total cost.
00:05:46.074 - 00:05:58.570, Speaker A: So three of these two changes are improving the ones corresponding to the Cost 27, cost 24, and Cost 25 tours. So the two opt, heuristic could have picked any of those three. That would have been a valid execution.
00:05:58.570 - 00:06:14.286, Speaker A: We dealt with the variant where it takes the first improving two change that it finds. So that led it to follow the second incident edge out of that top tour, winding up at the Cost 27 tour, the second one in the second row. So we've taken one hop in the graph, we've gotten to a new tour.
00:06:14.286 - 00:06:23.474, Speaker A: That was exactly the second tour adopted by the two opturistic in our example. Now we just do it again. We're going to take a walk of one more hop in this graph.
00:06:23.474 - 00:06:36.774, Speaker A: There's again, five options, five neighboring tours. We check if any of them are improving and indeed there are. As we saw, there were two improving two changes corresponding to the first and third tours in the third row.
00:06:36.774 - 00:06:53.934, Speaker A: So again, if we just take the first one that we find, then we're going to wind up walking in the metagraph from the Cost 27 tour to the Cost 24 tour. So after making these two changes, that is, after taking two steps in this metagraph, we wind up at this Cost 24 tour. And now we do it again.
00:06:53.934 - 00:07:04.270, Speaker A: We say, okay, there's five places we could go to from here. Are any of them improving? And here the answer is no. In fact, there's only one better tour of them all, the Cost 23 tour.
00:07:04.270 - 00:07:15.618, Speaker A: But that's in the same row as the tour we're at. And remember, no two tours in the same row turn out to be adjacent, the way I've drawn the picture. So the Cost 24 tour is not adjacent to the Cost 23 tour.
00:07:15.618 - 00:07:33.282, Speaker A: All of the adjacent tours have cost 24 or more, which means this is exactly where the two opportunistic is going to stop. So more generally, any execution of the two opturistic for any Tsp instance can be viewed as a walk just like this. In a suitable metagraph, vertices correspond to ToRs.
00:07:33.282 - 00:07:49.054, Speaker A: Tours are adjacent. If they're connected by a two edge, what is twoopt really doing? It's following a path through this metagraph, visiting tour after tour after tour with the property that each one has strictly smaller cost than the previous one until it can't continue the walk. Any further.
00:07:49.054 - 00:08:28.496, Speaker A: So this metagraph is going to be very important in this pair of videos. So let's have a quiz to just make sure that the definition is crystal clear. So the question then is, suppose I give you a Tsp instance with some number N of vertices, where N is at least four, say, how many vertices and edges does that metagraph actually have? All right, so the correct answer is the first one answer A.
00:08:28.496 - 00:08:43.840, Speaker A: I guess one way you could figure out the answer is just by counting up the number of vertices and edges in our N equals five example and seeing which of these is consistent with that. But let's have a more general argument about why this is true. So the easier question is the number of vertices.
00:08:43.840 - 00:09:00.180, Speaker A: Remember, vertices of the metagraph correspond to tours in the TSB instance. And actually, you might recall that we had a quiz back when we were first talking about TSB, where we counted up the number of different traveling salesmen tours and that number was one half times quantity n minus one factorial. That's the number of tours.
00:09:00.180 - 00:09:07.980, Speaker A: Tours correspond to vertices in the metagraph. So that's the number of vertices in the metagraph. So that narrows it down to either answer A or answer B.
00:09:07.980 - 00:09:27.560, Speaker A: So how about the number of edges? And this is what's a little more interesting. So one way to count up the number of edges in a graph is to go through the vertices one by one, see how many edges are incident to that vertex, and add up the results. And then you also have to remember to divide by two at the end because that process counts each edge twice, once from either endpoint.
00:09:27.560 - 00:09:36.740, Speaker A: So let's do that here. So how many vertices do we have? Well, we already solved that. We know the number of vertices is one half N minus one factorial.
00:09:36.740 - 00:10:10.124, Speaker A: How many edges are incidents to a given vertex, that is, for a given tour? How many incident tours are there? How many different tours can you get to via a two change? Well, we already saw that in the case where n equals five, the number is five adjacent tours. And in general, if you do the counting, you will see that there is N times n minus three over two adjacent tours in an n vertex Tsp instance. So we multiply those two numbers together, the number of vertices times the number of edges incident to each vertex.
00:10:10.124 - 00:10:24.630, Speaker A: Remember that we're double counting because each edge gets counted once from each of its two endpoints. So we divide back by two and we get the final answer. And if you sort of look at that expression, it's going to be equal to n factorial times n minus three over eight.
00:10:24.630 - 00:10:44.376, Speaker A: So now I want to move on from the specific case study of the traveling salesman problem in the two opturistic and discuss local search algorithms much more generally. What's cool is that most local search algorithms can be viewed just like what we just saw. It's literally just a walk through a metagraph of the feasible solutions.
00:10:44.376 - 00:11:06.396, Speaker A: If you want, you can even add a third dimension to the visualization where sort of the height or the altitude at a given point at a given feasible solution corresponds to that solution's objective function value. So in a minimization problem like the Tsp that we were just looking at, this walk is always going down. It's going to feasible solutions that are lower altitude.
00:11:06.396 - 00:11:32.708, Speaker A: If it was a maximization problem, you'd be climbing up. And indeed, it's very common to hear local search known as hill climbing, and it's because of this visualization for a maximization problem, you're taking steps through this metagraph always going higher and higher. So most local search algorithms can be visualized exactly like this as a walk in a metagraph of feasible solutions, the different local search algorithms differ primarily in their choice of the metagraph.
00:11:32.708 - 00:11:49.196, Speaker A: So obviously for different problems, you're going to have different feasible solutions or different vertex sets. But even for a fixed problem, you can have different local search algorithms define the edges of the metagraph differently. That is, they can have different definitions of which feasible solutions get to be adjacent in the metagraph.
00:11:49.196 - 00:12:07.156, Speaker A: And then the second main way that different local search algorithms differ is the way in which they explore the graph. And we'll have a lot more to say about that in the next video. You're also likely to come across local search algorithms in the context of continuous optimization as opposed to the discrete optimization problems that we're talking about here.
00:12:07.156 - 00:12:43.164, Speaker A: And the most famous of those is an ancient algorithm known as gradient descent, which is really just hill climbing, but where you're doing hill climbing over all points in Euclidean space rather than over this finite set of discrete solutions. One reason you're likely to be hearing about gradient descent these days, or perhaps it's stochastic gradient descent variant, is that that algorithm is really the workhorse behind how modern machine learning works. So specifically supervised machine learning like, say, training a neural network to make good predictions, that neural network training is done using variants of gradient descent.
00:12:43.164 - 00:12:53.696, Speaker A: So it's another famous local search algorithm. Doesn't quite fit into our paradigm, but it's very much in the same spirit. So let's now really spell out what are the details of the local search algorithm design paradigm.
00:12:53.696 - 00:13:07.700, Speaker A: How would you apply this to a problem coming up in your own work? Let me break it down into six steps. So the first three steps all involve defining the appropriate metagraph for your application. So we start with the vertices.
00:13:07.700 - 00:13:20.648, Speaker A: Remember, vertices are supposed to correspond to feasible solutions. So step one is just figure out what feasible solution means in the problem that you care about. For the kind of cut and dried problems we're talking about in these videos, this answer is usually straightforward.
00:13:20.648 - 00:13:31.296, Speaker A: If you're working on the Tsp, the feasible solutions are going to be the ToRs. If you're looking at make span, minimization the feasible solutions are going to be the possible schedules. Step number two.
00:13:31.296 - 00:13:41.456, Speaker A: Remember, in our metagraph for the Tsp, we didn't just have vertices and edges. Also, each vertex was labeled with its total costs. That is, we had an objective function that we wanted to minimize.
00:13:41.456 - 00:14:05.896, Speaker A: And in general, to apply local search, you need to articulate what it is you want to either maximize or minimize. That is, what is your objective function or what are the heights? If you're thinking about that 3D visualization of the various vertices in your metagraph, again, for the kinds of problems we're going to be looking at, the answer will usually be obvious. So traveling salesman problem, it's part of the problem definition you care about the total cost makespan.
00:14:05.896 - 00:14:18.400, Speaker A: Minimization it's. Again, part of the problem. Definition you care about minimizing the makespan in applications, this can sometimes be a tricky step, and you may need to experiment with different objectives to see what gives you the best results.
00:14:18.400 - 00:14:44.676, Speaker A: And finally, to complete the description of the metagraph, you of course have to say what the edges are. That is, which feasible solutions are you going to deem as adjacent? That is, what are your local moves? Remember, edges of the metagraph correspond exactly to the allowable local moves. So these three steps are really modeling decisions, and you have to make them before you even sort of start thinking about implementing your local search algorithm.
00:14:44.676 - 00:15:27.344, Speaker A: Right? Your first two steps are basically defining the problem precisely what's allowable so what are the feasible solutions and what is it you want? What are you trying to maximize or minimize? And then of course, before running local search, you have to say what local search is allowed to do. That is, what are the allowable local moves? Now, even after you've fully defined your metagraph, you have a couple decisions you need to make that are more algorithmic in nature. So step four is just you need to answer the question of how are you going to initialize the local search algorithm? That is, from which feasible solution are you going to start this walkthrough, this metagraph? For example, in our Tsp case study, we normally thought of starting from the output of the nearest neighbor heuristic.
00:15:27.344 - 00:15:50.204, Speaker A: Of course, we could have made other decisions, but that was the particular initialization step that we made in the last couple of videos. So step five is, again, an algorithmic question. It concerns sort of the details of how you implement your local search algorithm, which is, as we saw in our Tsp examples, you might have multiple improving local moves available from a feasible solution, and you then need to make some decision about which of those you're going to actually perform.
00:15:50.204 - 00:16:03.520, Speaker A: For example, in our Tsp running example, we always just picked the first improving local move that we found. Once you've answered all five of these questions, you're good to go. Now just your local search algorithm writes itself.
00:16:03.520 - 00:16:09.328, Speaker A: You've got your metagraph. That's what you defined in steps one through three. You know where to start, that's the answer to step four.
00:16:09.328 - 00:16:24.788, Speaker A: And you know how to take each step among all of the steps that you could take. Among all of the improve proving local moves, your answer to step five tells you exactly which one to take. So just to make sure this is crystal clear, let me give you some pseudocode for the generic local search algorithm.
00:16:24.788 - 00:16:47.260, Speaker A: So the algorithm which you can just run after you've made your decisions in steps one through five of the paradigm, the pseudocode is going to look exactly like the two operistic for the Tsp, just for sort of a generic problem and a generic notion of improving local move. So first you just start from some arbitrary feasible solution. And the whole point with step four is to figure out exactly how you're going to do this initialization.
00:16:47.260 - 00:17:03.684, Speaker A: Then you just again have a main while loop where as long as there's an improving local move, a local move you can take from the current solution that gives you a strictly better objective function value, bigger for a maximization problem, smaller for a minimization problem. As long as you can do that, you continue to do it. You take an improving local move as long as you can.
00:17:03.684 - 00:17:29.180, Speaker A: There may be many from a given feasible solution, but the whole point of step five is to resolve the ambiguity when there's multiple moves, which one should you pick? So in the main while loop, you just invoke whatever decision you made in step five. Eventually local search will terminate because the objective function value keeps improving with every iteration. And at the end you will have a solution from which there is no improving local move.
00:17:29.180 - 00:17:43.010, Speaker A: Every local move either keeps the objective function the same or makes it worse. That type of solution is something known as a local optimum. A local optimum is one that cannot be improved by any local move.
00:17:43.010 - 00:17:57.684, Speaker A: So at an abstract level, that is exactly local search. So you have to make these three modeling decisions in steps one through three, the two algorithmic decisions in steps four and five. And then boom, you've got your generic local search algorithm which you can simply apply.
00:17:57.684 - 00:18:15.608, Speaker A: So this discussion may all feel a little abstract. We do have the one case study with the two opturistic for the TSB, but still I want to spend the next few minutes giving you a bunch of concrete examples of how steps one through five might work out. Let's start with the first three steps where you are defining your metagraph of feasible solutions.
00:18:15.608 - 00:18:38.768, Speaker A: And let's look not only at our running Tsp example, but also at two other problems that we designed fast heuristics for the makespan minimization problem and the maximum coverage problem. So how about step one, defining your feasible solutions? Well, for the Tsp, of course, this would just be the tours, so there'd be one half times quantity n minus one factorial. Feasible solutions for an N vertex instance makespan minimization.
00:18:38.768 - 00:18:52.884, Speaker A: Well, they're the feasible solutions are going to be schedules. So if you have N jobs and M machines, then there's M different places you can put each of the N jobs. So that's going to give you a total of M raised to the N different schedules.
00:18:52.884 - 00:19:14.450, Speaker A: So those are going to be the vertices of the metagraph. If you were applying local search to make span minimization in maximum coverage, where you're given a collection of m subsets of some ground set and you have to pick k of them to maximize the coverage, their feasible solutions would just correspond to subsets of cardinality k of size k from those M subsets you're given. So that would be m choose k.
00:19:14.450 - 00:19:27.832, Speaker A: Different feasible solutions for maximum coverage. Step two defining your objective function. Not much to say in our running examples tsp, by definition it's the total cost makespan minimization, it's the makespan objective and maximum coverage.
00:19:27.832 - 00:20:04.488, Speaker A: It's the coverage objective that you want to maximize. Now notice once you've made these first two decisions, what are the vertices of your metagraph and what's the objective function value? At this point, you already know what the Holy Grail solution is, that is, you already know the global optimum of an instance that is just the feasible solution with the best possible objective function value. Like in our five vertex Tsp example, the Tor with cost 23, we're only going to be able to speak about local optima after we answer the question to step three, after we define what are the allowable local moves.
00:20:04.488 - 00:20:33.080, Speaker A: So we've seen one example of a choice of allowable local moves, that was the two opturistic for the Tsp, where local moves corresponded to two changes. When we talked about makespan minimization or maximum coverage, we weren't actually using local search, so there was no need to define allowable local moves. But we could now step back and say, well, suppose we did want to approach those problems by local search, how would we do it? So for makespan minimization or feasible solutions or schedules, probably the simplest local move you could imagine is just reassigning one job.
00:20:33.080 - 00:20:53.630, Speaker A: So you take a job that's on some machine and you just reassign it to one of the other M minus one machines. That would mean from each schedule there would be N the number of jobs times quantity m minus one, where m is the number of machines n times quantity m minus one. Different neighboring schedules, different schedules you could go to via a local move.
00:20:53.630 - 00:21:12.544, Speaker A: For the maximum coverage problem, where feasible solutions correspond to collections of k of the given subsets, probably the simplest local move would just be a swap. So if you have a current collection of k subsets, you would take one of them out and replace it with some different one. And now you'd have a new collection of k subsets, hopefully with more coverage.
00:21:12.544 - 00:21:33.096, Speaker A: So there you have k different choices of which subset to take out, and you have M minus k choices for which one to put in. So there you'd have k times m minus k neighboring solutions from each feasible solution. And so once you've answered step three, you've now fully specified what are the local optima of the instance of the problem that you care about.
00:21:33.096 - 00:21:58.720, Speaker A: So, like in our running five vertex Tsp example, we had two local optima, the first and third tours from the third row. The first of those was not a global optimum, not a global minimum, but the third one in the third row was a global minimum. In the context of make span minimization, if local moves are just reassigning one job, then a locally optimal solution is one where any single job reassignment fails to make the makespan smaller.
00:21:58.720 - 00:22:27.400, Speaker A: So every job reassignment makes the makespan either stay the same or get bigger. Similarly, a locally optimal solution in maximum coverage, if we're using swaps for local moves, that's going to be a collection of k subsets, where swapping in any new subset for one of your own fails to increase the coverage, leaves the coverage the same, or makes it even smaller. So we saw a number of examples through quizzes of mixpan minimization and maximum coverage feasible solutions.
00:22:27.400 - 00:22:53.760, Speaker A: I encourage you to go back and revisit the examples that we saw and examine which ones are in fact locally optimal and which ones could be improved by doing further local search. On top of it, you will find examples of both types. And actually, this is touching on one of the sort of really no brainer uses of local search, which is as a post processing step to further improve the output of some heuristic algorithm, like for example, a greedy algorithm.
00:22:53.760 - 00:23:11.290, Speaker A: So back when we were doing Graham's algorithm or LPT or the maximum coverage algorithm, we didn't do it, but we could have tacked on at the end a post processing step that then did further local search to give us a still better solution. That's something you might want to consider when you're implementing those algorithms in practice and.
