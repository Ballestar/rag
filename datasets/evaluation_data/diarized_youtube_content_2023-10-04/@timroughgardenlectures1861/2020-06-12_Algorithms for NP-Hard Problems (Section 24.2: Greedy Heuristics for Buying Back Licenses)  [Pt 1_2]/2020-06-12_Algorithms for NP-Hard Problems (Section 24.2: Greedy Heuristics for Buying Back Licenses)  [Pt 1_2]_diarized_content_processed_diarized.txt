00:00:00.490 - 00:00:12.282, Speaker A: Hi everyone, and welcome to this video that accompanies section 24.2 of the book Algorithms Illuminated, part four. It's a section about greedy heuristics for buying back licenses in the FCC incentive auction.
00:00:12.282 - 00:00:35.800, Speaker A: Now, the FCC incentive auction, it actually had two parts. It had, on the one hand, a reverse auction which was responsible for deciding which station should switch channels, which station should go off the air, and also what was the appropriate compensation for those stations. And it also had a forward auction responsible for deciding who would receive blocks of the newly freed spectrum and what they would pay for it.
00:00:35.800 - 00:00:49.706, Speaker A: Now. The US. Government, actually governments of lots of different countries, had been running these forward auctions to, in effect, sell spectrum licenses to the highest bidder for quite a while, for something like 25 years, making small tweaks to them along the way.
00:00:49.706 - 00:01:11.918, Speaker A: So in this case study, we're going to focus on the most innovative part of the FCC incentive auction, namely its unprecedented reverse auction for buying licenses back from television stations. So let's dive right in. Let's first just be clear on exactly what it is that the government is buying back in this reverse auction from television stations.
00:01:11.918 - 00:01:35.114, Speaker A: So if you're a television broadcaster, property rights are conferred to you by the FCC through a broadcasting license. And that license will authorize broadcasting over some channel in a specified geographic area. And the FCC assumes responsibility for ensuring that a station receives little to no interference across its broadcast area.
00:01:35.114 - 00:01:58.770, Speaker A: Now, interestingly, for the purposes of the FCC incentive auction, the specific channel assignment of a station like channel 41 was not considered part of the license owner's property rights. So an active Congress was actually required to authorize this interpretation and allow the auction to reassign stations channels as needed. 2012 was not a great year for US.
00:01:58.770 - 00:02:16.760, Speaker A: Congress. It passed only eight bills that year, but this was one of them. Maybe the reason that this bill authorizing the FCC incentive auction passed is because it had the not exactly descriptive, but possibly pretty veto proof title, the Middle Class Tax Relief and Job Creation Act.
00:02:16.760 - 00:02:47.940, Speaker A: The goal of the reverse auction in the FCC incentive auction was to reclaim enough of these licenses from television stations to free up a target amount of spectrum, like, say, the 84 MHz tied up by channels 38 to 51. So to get an initial feel for this problem of reclaiming enough licenses to free up a target amount of spectrum, let's begin with four simplifying assumptions. These are not that reasonable, but they'll help us understand the problem and we'll remove all of these as we go along.
00:02:47.940 - 00:03:03.510, Speaker A: So first of all, a pretty ridiculous assumption and one will relax pretty soon. But for now, let's just assume that all the stations that remain on the air all broadcast on a single channel. So suppose every station on the air is forced to broadcast on, say, channel 14.
00:03:03.510 - 00:03:38.282, Speaker A: The second assumption which is approximately accurate, but we'll tweak it a little bit in the next video is we're going to assume that two stations can be on the air simultaneously on the same channel if and only if there's no overlap among their broadcasting regions. Third, we're going to assume that we know what the value of each station is in US. Dollars.
00:03:38.282 - 00:03:53.182, Speaker A: So maybe we know this station is worth $10 million, this other one's worth $17 million and so on. Finally, let's assume for the moment an authoritarian government that can just unilaterally sort of take stations off the air whenever it wants. Now that's not what happened.
00:03:53.182 - 00:04:04.098, Speaker A: The government did not use eminent domain to reclaim these licenses. Rather, the stations going off the air relinquish their licenses voluntarily in exchange for compensation. So we'll have to talk about that in a couple of videos from now.
00:04:04.098 - 00:04:32.550, Speaker A: But for now, let's just imagine the government could unilaterally take stations off the air whenever it wants under these four simplifying assumptions, which again we'll remove later. But for now, making these simplifying assumptions, let's try to formulate the computational problem that we're dealing with. So what are the decisions that we're making? Fundamentally, we're deciding which stations stay on the air and which stations have to go off the air.
00:04:32.550 - 00:04:56.792, Speaker A: What's the objective function we care about? Well, stations have values so it makes sense to have the most valuable stations stay on the air and the least valuable stations be the ones that go off of the air. So a natural objective function would be to maximize the total value of the stations that remain on air. So what about the constraints? Well, those are specified by these first two of the simplifying assumptions.
00:04:56.792 - 00:05:15.460, Speaker A: So the second assumption, what that does is it forbids any pair of overlapping stations from broadcasting on the same channel. Now by our first assumption, there's only one channel available. So that means we're only going to be able to allow stations to both remain on the air if they have disjoint broadcast areas.
00:05:15.460 - 00:05:48.716, Speaker A: Summarizing then the optimization problem that we're really interested in under these four simplifying assumptions is to maximize the total value of the stations that remain on air subject to no interference, subject to the stations remaining on the air having disjoint broadcast regions. As always, when you first see a computational problem, you want to recognize it if it's something you've already seen or a special case of something you've already seen. So do you recognize this optimization problem? Well, I'm guessing some of you do.
00:05:48.716 - 00:06:00.640, Speaker A: This is something we talked about quite recently. This is actually exactly the weighted independent set problem. The vertices of the graph correspond to the television stations that we might want to put on the air.
00:06:00.640 - 00:06:22.910, Speaker A: Remember, an independent set edges represent conflicts. And so here two stations or two vertices, they're going to conflict if they have overlapping broadcast regions. So for example, if you imagine the following five stations with each circle representing the broadcast area of that station.
00:06:22.910 - 00:06:47.750, Speaker A: The little gray triangles are meant to indicate the transmitters. So I'm showing off kind of the limits of my artistic abilities here. So this picture is going to correspond to a graph with five vertices, one for each of the five stations and an edge for each pair of circles that overlap.
00:06:47.750 - 00:07:27.966, Speaker A: The values of these stations would translate over into weights for the vertices. Now, recognizing this problem as really just being weighted independent set in disguise, that's not necessarily good news for us, right? So back in the videos corresponding to Chapter 22, we proved that the independent set problem is NP hard even when all the vertices just have a common weight, a weight equal to one. Now, we did see back in part three in our dynamic programming bootcamp that you can solve the weighted independent set problem on path graphs or more generally, on tree graphs.
00:07:27.966 - 00:07:41.974, Speaker A: But if you think about it, the interference patterns of television stations are not at all tree like. So for example, literally every station in New York City interferes with every other station in New York City. So that's going to be this big clique in the graph.
00:07:41.974 - 00:07:59.694, Speaker A: So a bunch of vertices that are all mutually adjacent, very, very different than a tree. So we've now recognized our problem as basically being weighted independent set and it does not appear to be a polynomial time solvable special case of the independent set problem. But no reason to give up.
00:07:59.694 - 00:08:25.030, Speaker A: Remember, the whole point of this video playlist is that NP hardness is not a death sentence. So we now have this rich toolbox, lots of different things we can throw at this version of weighted independence set to try to solve it in practice. So we could start with the most ambitious goal of trying to solve this problem exactly like really finding the subset of stations with disjoint regions that maximizes the total value.
00:08:25.030 - 00:08:53.498, Speaker A: So are we going to be able to do that in a tolerable amount of time? So let's say maybe like a week or less of computation? Well, the answer to that, as always, is going to depend on how big a problem size you're dealing with. So if we only had like 30 stations, we could even just use exhaustive search to find the maximum value subset of stations with no interference. But unfortunately, in the United States, there's more like thousands of stations to deal with and tens of thousands of interference constraints.
00:08:53.498 - 00:09:19.106, Speaker A: So that's way above the pay grade of exhaustive search or even the dynamic programming techniques that we talked about in the videos corresponding to Chapter 21. This means that if we really want an exact algorithm, there's sort of one tool we have left at the bottom of our toolbox that we can try, which would be the semirelible magic boxes that we discussed. So we're dealing with an optimization problem, right, maximizing the total social value station value subject to no interference.
00:09:19.106 - 00:09:33.230, Speaker A: And so for optimization problems, the first magic box you should think about would be a mixed integer programming solver. And indeed, the weighted independent set problem is very easy to encode. As a mixed integer program, I encourage you to think through what that formulation would look like.
00:09:33.230 - 00:10:01.350, Speaker A: It's really quite straightforward and indeed, using a mixed integer programming solver is exactly the first thing the FCC tried. Unfortunately, the problem faced by the FCC, these thousands of stations and tens of thousands of interference constraints that proved too big and even the latest and greatest mix integer programming solvers choked on it. Or to be fair, the latest and greatest solvers choked on the harder multichannel version of the problem that we'll discuss in a couple of slides.
00:10:01.350 - 00:10:27.994, Speaker A: With all the options exhausted. For a 100% correct algorithm, at that point, the FCC had no choice but to compromise on correctness and instead use a fast heuristic algorithm for the weighted independent set problem. As with so many other Nphard problems, the greedy algorithm design paradigm is the perfect place to start brainstorming about fast heuristic algorithms.
00:10:27.994 - 00:10:48.974, Speaker A: And like with many problems, it's easy to come up with multiple greedy algorithms that you could use, maybe the first one you'd think of if you wanted to tackle the weighted independence head problem. Using a greedy algorithm would be to mimic the idea behind Kruskal's algorithm. So Kruskal makes a single pass over the edges from most attractive to least attractive, always including it in the solution as long as it preserves feasibility.
00:10:48.974 - 00:10:58.242, Speaker A: We could do the same thing here. Now we're picking vertices, so we'll do a single pass over the vertices of the graph. Most attractive means highest weight, least attractive means lowest weight.
00:10:58.242 - 00:11:23.658, Speaker A: So we'll go in descending order of vertex weight and then we'll just include the current vertex in our solution as long as it doesn't mess up feasibility, as long as that vertex is not adjacent to some vertex that we committed to in a previous iteration. Let's call that algorithm the basic greedy algorithm. And again, it takes as input instance of weighted independent sets that's going to be an undirected graph along with a non negative vertex weight for each vertex.
00:11:23.658 - 00:11:37.940, Speaker A: And its responsibility is to output an independent set that's a subset of vertices that are all non adjacent. So you're not allowed to pick both endpoints of the same edge. And then subject to being an independent set, you're supposed to do as well as you can maximizing the total weight of the independent set.
00:11:37.940 - 00:12:00.166, Speaker A: This basic greedy algorithm, it's probably the most natural starting point. We're not necessarily expecting it to be the most amazing fast heuristic algorithm. We might expect to do better.
00:12:00.166 - 00:12:21.262, Speaker A: This is really just the start of our brainstorming, but it's going to help us understand the intricacies of the problem a bit better by exploring what it does on some examples. So let's start with a five vertex example and see what this algorithm does. This is the exact same graph we used in our example showing the correspondence between the station selection problem and the independent set problem.
00:12:21.262 - 00:12:41.666, Speaker A: I've labeled each of the five vertices in magenta with their weight. So what is the basic greedy algorithm going to do if it's given this graph as input? Well, it's going to do a single pass through the vertices, starting with the one with highest weight and concluding with the one with the lowest weight. So here the highest weight vertex is that one in the lower left it has weight four.
00:12:41.666 - 00:12:57.450, Speaker A: Now of course the greedy algorithm starts with the empty set so there's no conflicts between the first vertex and what it's already chosen so far because it hasn't chosen anything so far. So the greedy algorithm will always select the vertex from that first iteration. So in this example, it'll definitely select that weight four vertex.
00:12:57.450 - 00:13:24.882, Speaker A: Now in the second, third and fourth iterations, the algorithm is going to consider the three weight three vertices in some arbitrary order. But the order actually doesn't matter because now that we've already committed to the weight four vertex, that's adjacent to all three of the weight three vertices. So second iteration, third iteration, fourth iteration, when we ask, when we ask the test, could we include this new vertex into our current solution without destroying feasibility? The answer is no.
00:13:24.882 - 00:13:46.758, Speaker A: If we tried to include one of these weight three vertices it would destroy feasibility because each of those vertices has an edge connecting it to the weight four vertex that we already chose. So in the fifth iteration, the last one, the greedy algorithm considers the lowest weight vertex, the weight two vertex. And you'll notice that vertex actually is not adjacent, is not a neighbor of the weight four vertex.
00:13:46.758 - 00:14:00.382, Speaker A: So it's safe to include the weight two vertex and that will conclude the greedy algorithm. So it'll pick the lower left and the upper right vertices in its solution. The output therefore, of the basic greedy algorithm is an independent set that has total weight six.
00:14:00.382 - 00:14:15.780, Speaker A: Pretty easy to see. That's not an optimal solution. That's not the maximum weight independent set because if we pick all three of the vertices on top, that's also an independent set and that one's going to give us a total weight of eight and that turns out to be the optimal, the maximum weight independent set.
00:14:15.780 - 00:14:30.866, Speaker A: So how should we feel about this example? Well, it's not really clear, right? I mean, the weighted independent set problem as we know, is an NP hard problem. This basic greedy algorithm quite obviously runs in polynomial time. So we were fully expecting examples of this type where its output is not optimal.
00:14:30.866 - 00:14:48.410, Speaker A: If there were no inputs of that type, we would have refuted the P not equal to NP conjecture and that's not something we're expecting to happen. But here's a more troubling example which suggests we might actually want to revisit the greedy algorithm and use a different one. So in this example, we have a star graph.
00:14:48.410 - 00:15:08.786, Speaker A: So there's a center vertex which has weight two, and then there's a bunch of spokes. So there could be any number of spokes on the slide here, there's eleven spokes, and each of the vertices on the perimeter has a weight of one. So what is the basic greedy algorithm going to do here? Well, it's going to start with the highest weight vertex, which is the center vertex with weight two.
00:15:08.786 - 00:15:23.174, Speaker A: It's going to pick it, it's going to commit to it, thereby precluding it from picking any of the spoke vertices. And that's a pretty terrible outcome for this greedy algorithm, right? It just outputs this independent set. That's a single vertex, it has weight two.
00:15:23.174 - 00:15:46.618, Speaker A: What do we wish it had done? We wish it had instead chosen all of the spokes. So in this case, it would have had a total weight of eleven to choose the independent set consisting of all of the spoke vertices. What went wrong with this example? The reason the basic greedy algorithm did so poorly is its single minded focus just on the weight of a vertex without thinking about other ramifications of committing to a vertex in your solution.
00:15:46.618 - 00:16:26.266, Speaker A: So in particular, the basic greedy algorithm did not take into account that choosing the center vertex would block from future consideration all of the spoke vertices. So how can we tweak this algorithm so that we do have the option of taking into account the degree of a vertex, the number of other vertices that it would block if it were chosen to avoid the errors of the basic greedy algorithm? We can discriminate against vertices that have high degree, that have many neighbors who would knock a bunch of other vertices out of consideration if we chose them. So for example, we could do a cost benefit analysis, we could take a vertex, we could say, okay, if we pick this vertex, we get its weight, whatever it is, ten.
00:16:26.266 - 00:16:41.230, Speaker A: On the other hand, if we pick this vertex, it knocks out from consideration a bunch of vertices. So V in particular won't ever be considered again, but also all the neighbors of V will be knocked out of contention from being chosen in the future. So we use up the degree of V plus one vertices.
00:16:41.230 - 00:17:08.278, Speaker A: The plus one is for V itself, we use up the degree of v plus one vertices, getting a benefit of w sub V that vertex's weight. So rather than just doing a single passive of the vertices from high weight to low weight, we could look at the bang per buck. So the weight that you get for the vertex per vertex that gets knocked out of future consideration, that would be an alternative greedy algorithm that would discriminate against high degree vertices more generally.
00:17:08.278 - 00:17:43.974, Speaker A: The greedy algorithm can compute vertex specific multipliers however it wants in a preprocessing step, then scaling the vertex weights by those multipliers and proceeding to visit the weights in nondecreasing order of their scaled weights. That's what we're going to call the general greedy algorithm. I've been calling this a greedy algorithm, right? But really this is a whole family of greedy algorithms.
00:17:43.974 - 00:18:04.254, Speaker A: For each, each formula for how you might compute the betas of v's, you get a different greedy algorithm. So the basic greedy algorithm that we discussed that corresponds to setting beta sub v equal to one for every vertex v. We also discussed the possibility of discriminating against high degree vertices by setting beta sub v equal to one plus the degree of the vertex v.
00:18:04.254 - 00:18:35.754, Speaker A: But you could play around with other formulas as well. So the question then is, okay, of all these greedy algorithms, which one should you use? What's the best choice of these vertex specific multipliers? Now keep in mind that no matter how smart a formula you use for computing the betas of v's, there's going to be examples where the greedy algorithm does not return a maximum weight independence, yet where it returns something suboptimal. I say this assuming that the betas of v's can be computed in polynomial time so that the entire algorithm runs in polynomial time.
00:18:35.754 - 00:19:06.830, Speaker A: And as usual, assuming that the P not equal to NP conjecture is true, but for any reasonable beta v's, you might possibly think about you're not expecting the greedy algorithm to be correct in all cases. So how should you choose among the different competing ways to define the betas of v's? Well, the best choice is going to depend on the problem instances that tend to show up in the application that you're interested in. Which means that the best way to figure out which betas of these to use is empirically really just by trying a whole bunch of different possibilities on representative instances.
00:19:06.830 - 00:19:30.966, Speaker A: And this really kind of ties into some general advice when you're tackling NP hard problems in a real application, which is exploit as much domain specific knowledge as you can. So hopefully you have some representative instances for your application, those can be used to tune these vertex specific multipliers in the best possible way. Now, in the FCC Incentive auction, one thing that the designers had going for them is that they really did have representative instances.
00:19:30.966 - 00:19:52.926, Speaker A: So they really did have domain knowledge about what instances of weighted independent set they cared about, including for the multi channel generalization that we'll start talking about on the next slide. And you can already see part of why that's true, right? So like, what is the graph in these independent set problems? The vertices correspond to stations. So they knew about all the stations in advance that were going to be participating in the FCC Incentive Auction.
00:19:52.926 - 00:20:04.626, Speaker A: And then the edges of the graph are derived from interference constraints, overlapping broadcast regions, and those were also fully known in advance. Those were specified by all the stations existing licenses. Now, there are these vertex weights.
00:20:04.626 - 00:20:41.986, Speaker A: It wasn't totally clear what those are. Those are sort of known to the owners of the license, not necessarily to the FCC in advance, but you can make educated guesses and try a range of possibilities about reasonable station values informed by historical data like what licenses had sold for in the past. They then used these representative instances to tune the parameters to choose how to compute betas of V and what they discovered is that it was possible to carefully tune those parameters so that on their representative instances this greedy algorithm was routinely returning solutions with total weight quite close to the maximum possible.
00:20:41.986 - 00:21:17.390, Speaker A: Quite close to optimal, like well over 90% in most cases. You might be well wondering how were these parameters betas of V actually set in the real FCC incentive auction? Well, I've put the formula for the real betas of V's down here at the bottom of the slide. So in the FCC incentive auction betas of V for a station, v was defined as the square root of the degree of that station, meaning the number of stations with which it overlaps, the number of stations which it would block from being assigned to the same channel times the square root of the population served by that station.
00:21:17.390 - 00:21:37.726, Speaker A: We've already seen the point of allowing the beta to depend on the degree of a vertex or of a station that's used to discriminate against vertices with high degree or equivalently here. Stations that overlap with many other stations would block many other stations from being on the air. We're penalizing high degree vertices less severely here by taking the square root than we were in the original formula.
00:21:37.726 - 00:21:58.550, Speaker A: But still, that's what this does discriminates against stations with many overlapping stations. The point of the second term, the square root of pop term, that was more subtle and frankly more controversial as well. Its effect was actually to decrease the compensation paid by the government to small television stations that were likely to go off the air in any case.
00:21:58.550 - 00:22:01.020, Speaker A: And it did indeed have that intended effect. It.
