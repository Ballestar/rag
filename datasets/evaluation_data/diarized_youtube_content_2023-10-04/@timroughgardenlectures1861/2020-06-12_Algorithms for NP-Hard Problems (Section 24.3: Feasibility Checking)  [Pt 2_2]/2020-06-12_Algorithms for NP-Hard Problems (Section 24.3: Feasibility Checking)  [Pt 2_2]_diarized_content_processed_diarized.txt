00:00:00.970 - 00:00:24.754, Speaker A: Let me now tell you about three different techniques the designers of the FCC incentive auction used to reliably solve repacking instances in a minute or less. The first of the three is going to be pre solvers. And so these are kind of quick and dirty checks for feasibility or infeasibility to quickly ferret out easy instances, obviously packable or obviously unpackable instances.
00:00:24.754 - 00:01:00.640, Speaker A: These presolvers are going to exploit the nested structure of the feasibility checking instances that arise over the course of the FCC greedy algorithm. So we had a quiz on that nested structure in the previous section, but let me just briefly remind you how each repacking instance relates to what has already been solved in previous iterations. The FCC greedy algorithm maintains a solution so far a subset of stations, capital S.
00:01:00.640 - 00:01:24.464, Speaker A: And each iteration of the main loop asks whether the next station, some station v, can be added to S and stay feasible. So at all times throughout the course of that algorithm, the solution so far, capital S, that corresponds to a packable set of stations. And we're asking is it possible to pack not just capital S but also this one new station V as well? Presolver.
00:01:24.464 - 00:01:40.188, Speaker A: Number one is going to be a quick and dirty check for infeasibility, where we're going to ask the question. Suppose we look at an easier problem and suppose forget about all of capital S. Let's just worry about the stations in capital S that might conceivably interfere with the station V.
00:01:40.188 - 00:02:08.688, Speaker A: So it's going to be Subset capital T. Of S? And let's ask, is it at least possible to pack the new station V together with its neighbors in capital S? Together with the stations in capital T? And if not, if even that subset is unpackable, then certainly the bigger set of stations can't be packed either. If we had a pure graph coloring instance, what this would correspond to is we have a graph, we know it's k colorable, we add in one new vertex and we want to see if it remains k colorable.
00:02:08.688 - 00:02:26.540, Speaker A: What we do is we just look in the neighborhood of that new vertex v, so we just look at v and we look at its neighbors and we say, well at least is this subgraph k colorable? Because of course, if it's not k colorable, then neither is the bigger graph. If indeed t union v is unpackable, we're done. We can correctly conclude that s union v is unpackable.
00:02:26.540 - 00:02:44.764, Speaker A: In the other case, if T union V is Packable, ambiguity remains S Union V, it might also be packable or it might not. Maybe there's enough channels to accommodate T Union V, but once you throw the rest of S in there, you don't have enough channels anymore and it's unpackable. So we don't know if this winds up being Packable.
00:02:44.764 - 00:02:53.936, Speaker A: Could go either way. In the second presolver, we're going to explicitly use the fact that the set capital S is a packable set of stations. And in fact, we're going to use that.
00:02:53.936 - 00:03:17.064, Speaker A: The last time we ran the feasibility checker, it actually handed us a bunch of channel assignments for the stations in capital S so that all of the constraints were satisfied. What we want to then do is extend the feasible channel assignments for the stations in capital S that we inherited from a previous iteration to extend those so that also V has a channel assignment and so that everything is still feasible. But we're going to try to do that in kind of a lazy way.
00:03:17.064 - 00:03:33.600, Speaker A: We're only going to allow ourselves a limited number of degrees of freedom. We're going to say for any stations that don't even neighbor this new station V, let's just hold their channel assignments fixed. So we'll just require that they stay exactly the same as they were in the channel assignments that we inherited.
00:03:33.600 - 00:04:20.664, Speaker A: But meanwhile, we will allow ourselves to assign and reassign channels locally in the neighborhood of V in an attempt to find feasible channel assignments, an attempt to pack all of the stations. So again, we let capital T be the stations in capital S that might potentially interfere with station V. And then we ask the question holding channel assignments in S minus T fixed, can we find channel assignments to T Union V so that the combined channel assignments are feasible, meet all of the constraints? Now, if we succeed, if we actually do manage to find assignments of channels to the stations in T plus the new station V that are compatible with each other and also compatible with the fixed channel assignments in S minus T that we inherited, then we're done.
00:04:20.664 - 00:04:34.820, Speaker A: Then we know this is a repackable instance because we've proved it ourselves. We've actually exhibited a channel assignment for all of the stations in S Union V so that all of the constraints are satisfied. So that's a great way to quickly ferret out a packable instance.
00:04:34.820 - 00:04:56.664, Speaker A: Now, if this second presolver fails, meaning if it says actually, there's no way to assign channels to T union V while holding the stations in S minus T fixed to satisfy all the constraints it may or may not be the case that s Union v. Is packable. Because it's totally possible that under this extra constraint that you have to hold the stations in S minus T.
00:04:56.664 - 00:05:10.240, Speaker A: Fixed. Totally possible that that version of it is unpackable. But then once I take away that constraint and you're allowed to reassign channels to the stations in capital S, also perhaps with that additional freedom, all of a sudden it becomes a packable instance.
00:05:10.240 - 00:05:34.416, Speaker A: Let's look at an example in the pure graph coloring context. So in this picture on the right, we have a magenta path, so nine vertices, eight edges, that corresponds to our set capital S and the interference constraints between those stations. And then the orange vertex V, that's the new station we're trying to accommodate in addition, I'm going to assume here that k equals three.
00:05:34.416 - 00:05:58.984, Speaker A: So there's three channels or three colors that we're working with. So the set S, it has to be feasible, so it has to be three colorable and it comes when we inherit a three coloring of that graph from a previous iteration. So I've shown you that three coloring here, right? Each of the vertices and the path is circle, either is colored red or blue or green and each of the edges has endpoints with distinct colors.
00:05:58.984 - 00:06:25.584, Speaker A: So now we add V into the picture and we want to know is the graph still three colorable after we've added in V? And again we want to be lazy about it, we want to just sort of extend the previous coloring so that it includes V in the easiest way possible. The first thing you'd try is you'd say well maybe we can just color V something and it won't conflict with anybody else and we'll be done. But that's not going to work, right? So if you colored V red, it would conflict with the 8th vertex on the path.
00:06:25.584 - 00:06:40.812, Speaker A: If you colored it green, it would conflict with the middle vertex, the fifth vertex of the path. And if you colored it blue, it would conflict with the second vertex of the path. So you can't just hold all of S the same and find a color for V that's compatible with it.
00:06:40.812 - 00:06:49.840, Speaker A: However, that's not what the presolver is. We have a little more flexibility in the presolver. We can also recolor the neighbors of the new vertex V if we want.
00:06:49.840 - 00:07:09.456, Speaker A: And with that additional freedom, actually we can extend this three coloring that we inherited into a three coloring of the whole set. To do that, for example, we could just take that second vertex, the blue vertex, we could toggle its color to green, both of its neighbors are red. So that's fine, it can be green, doesn't violate any edges.
00:07:09.456 - 00:07:22.104, Speaker A: And now from vertex v's perspective, two of its three neighbors have a colored green and one is red. So that frees up the color blue to color V. So that gives us a bona fide three coloring including V.
00:07:22.104 - 00:07:37.640, Speaker A: So in this case the second presolver would succeed. It would extend the inherited three coloring into a three coloring for the entire graph including the new vertex V. Now let's look at the exact same example, an example which we now know is three colorable.
00:07:37.640 - 00:07:54.372, Speaker A: So the exact same example. But let's look at a different possibility for the three coloring of the Magenta path that we might wind up inheriting. You'll notice that literally the only change I made is for the third vertex in the path, I changed its inherited color from red to green.
00:07:54.372 - 00:08:12.820, Speaker A: That's totally allowed. This is another three coloring of the path, so that's something we might inherit from the previous feasible subroutine. But now actually all of a sudden this presolver is going to fail, there's not any way to locally recolor to extend this to a three coloring of the whole graph, even though we know the graph is indeed three colorable.
00:08:12.820 - 00:08:28.812, Speaker A: So why not? Well, look at the three neighbors of V, right? Its first neighbor, the second vertex, it's blue and its two neighbors are red and green. So it's forced to be blue given its two neighbors. Same thing with the fifth vertex, v's second neighbor, right, its neighbors are blue and red, so it's forced to be green.
00:08:28.812 - 00:08:46.208, Speaker A: And then the last of V's neighbors, the 8th vertex, is colored red and it has to be so because its neighbors are green and blue. So there's no flexibility in how to recolor V's neighbors. And as we discussed, v itself can't take on any of the three colors without recoloring one of its neighbors.
00:08:46.208 - 00:09:09.260, Speaker A: So that's an example of the second presolver failing. So there actually was a packable set of stations, but the presolver was unable to prove its packability because it restricted itself just to assigning and reassigning channels locally in the neighborhood of the new station, just in case it wasn't clear. So the motivation for focusing on the neighboring stations of the new station V.
00:09:09.260 - 00:09:44.424, Speaker A: So focusing on capital T rather than all of capital S that showed that we only had to solve a repacking instance with size equal to the number of stations in T along with V as opposed to all of the stations in capital S along with V, capital S might well have thousands of stations. That's why this is a potentially hard repacking instance, whereas typically the neighbors of V capital T, that would be in the single digits or maybe in the double digits. So just determining the packability status of T union V and either of the two presolvers, that could be done quickly using an off the shelf sat solver because those instances were so small.
00:09:44.424 - 00:10:10.652, Speaker A: So that's why these presolvers you could more or less do for free to ferret out the obviously packable and obviously unpackable instances. Speaking of for free, this second batch of ideas is very much in the spirit of the for free primitives that I've been trying to impress upon you throughout this book series, throughout these video playlists. So remember, what is a for free primitive? It's a subroutine which is blazingly fast.
00:10:10.652 - 00:10:31.492, Speaker A: So linear time, or very close to linear time, so the time needed to execute it is barely exceeds the time you're spending anyways to read the input. And the point is that once you have a subroutine that's so blazingly fast, at that point you may as well just sort of apply it even if you don't quite understand how it's going to be helpful. So maybe sort the data that's a four free primitive, maybe it'll help.
00:10:31.492 - 00:10:57.896, Speaker A: Or if you have a graph problem, maybe compute the connected components. And both of the steps I'm going to tell you about on this slide, they're both preprocessing steps and they're designed to take a hard instance of the repacking problem, one that already passed through both of the presolvers and simplify it and or reduce its size. So the first idea is to prune away from the input any stations that are sort of so unconstrained as to be irrelevant.
00:10:57.896 - 00:11:09.040, Speaker A: This idea is probably simplest to understand initially with an example. So let's just look at a pure graph coloring instance. Let's suppose we're trying to come up with a three coloring for the following graph.
00:11:09.040 - 00:11:37.770, Speaker A: So in this graph, notice that every vertex has degree three or more except for one of them, except for that vertex in the lower right corner. And this is a vertex that is so unconstrained as to be irrelevant for the purposes of computing a three coloring, right, because it only has two neighbors. Doesn't matter what you color those two neighbors red and green, whatever, there's going to be a third color left over that we can always assign to this bottom right vertex like green.
00:11:37.770 - 00:11:53.424, Speaker A: So what are we going to do? We're just going to throw out that easy vertex? We can just worry about that at the end. We know there's going to be some color left over that we can always assign to it. You in the original graph, that bottom right vertex was the only one that had degree two or less.
00:11:53.424 - 00:12:14.500, Speaker A: But now something interesting has happened, right? So now that we've sort of peeled away that bottom right vertex, now there's a new vertex that has degree only two, the one in the upper right. So again, this is now a vertex that we can prune. Doesn't matter how you color the other five vertices, there's always going to be some third color left over that we can use for this upper right vertex.
00:12:14.500 - 00:12:31.954, Speaker A: Now, once we remove that upper right vertex, we're left with five vertices and now in fact, all of them have degree three or more. So there's no longer a vertex which is sort of obviously irrelevant that we can just prune. So this is where we get stuck.
00:12:31.954 - 00:12:51.542, Speaker A: And so now we really are going to be responsible for checking whether or not this graph is three colorable, but two pieces of good news. So first of all, this graph is going to be three colorable if and only if the graph we started with was three colorable. So obviously if the smaller graph is not three colorable, then you certainly can't three color the bigger graph.
00:12:51.542 - 00:13:19.220, Speaker A: But as we'll trace through in a second, if we do successfully three color this smaller graph, we'll be able to extend that coloring to the original graph just by putting the easy vertices back in of the reverse order in which we pruned them. And the second piece of good news is that this graph is smaller than the one that we started with, right? It has fewer vertices. And so hopefully whatever algorithm we use to compute the three coloring, that's going to run considerably faster on the Pruned graph than it would have on the graph that we started with.
00:13:19.220 - 00:13:38.470, Speaker A: So for example, suppose we invoke some three coloring subroutine and it comes back with the three coloring of these five vertices, alternating blue and green around the perimeter and then saving the color red for the middle. So now we're going to reintroduce the vertices that we pruned in reverse order. So next comes the upper right vertex.
00:13:38.470 - 00:13:45.702, Speaker A: We put that back in, we need to give it a color. But again, this was an easy vertex. Its two neighbors have the colors red and blue.
00:13:45.702 - 00:14:01.074, Speaker A: So this upper right vertex, when we reintroduce it, we're just going to give it the color red and avoid all the conflicts with its neighbors. Now we can go ahead and reintroduce that first vertex that we pruned. The bottom right vertex, its neighbors have been colored blue and red, but again, it had degree two.
00:14:01.074 - 00:14:11.350, Speaker A: So we know there's color left over, it happens to be green. So we're just going to give that bottom right vertex the color green and boom. We extended the three coloring of the small graph to one for the entire graph.
00:14:11.350 - 00:14:36.822, Speaker A: This will be our third step in the feasibility checker. So for any repacking instance that passes the first two presolvers and makes through them, then we're going to do this pruning. So we're going to look for stations that are easy in the sense that no matter how you assign channels to the stations that might interfere with it as neighbors, no matter how they're assigned channels, there's always going to be some channel left over that you can assign to this easy station.
00:14:36.822 - 00:14:54.386, Speaker A: And if you have an easy station, you prune it and then you repeat the process all over again because now a new station might have been made easy by the removal of this previous one. So you keep going, you keep pruning easy stations until none remain. Then that repacking instance you're actually responsible for solving, so you solve it.
00:14:54.386 - 00:15:25.130, Speaker A: But the good news is the packability status of that smaller instance is the same as the one that you started with. So if the smaller instance is unpackable, then there's no question that the bigger instance, which is only harder, that's also unpackable. And meanwhile, if it is packable and you're given back some feasible channel assignment for the subset of stations that are not easy, then just like in this example, you can reintroduce the easy stations one by one, always giving them the assured channel that will prevent interference with all of their neighbors.
00:15:25.130 - 00:15:47.310, Speaker A: To motivate step four, let's again think about the case of a pure graph coloring problem, like checking three colorability. So suppose I asked you if I gave you a graph and I wanted to know if it's three colorable and you noticed it was actually a disconnected graph, it had multiple connected components. Well, for coloring those connected components cannot interfere with each other because there's no edges between distinct connected components.
00:15:47.310 - 00:15:58.070, Speaker A: So you may as well just solve the three coloring problems separately on each connected component. If everyone turns out to be three colorable, then the original graph was three colorable. Just by taking the union of the color assignments.
00:15:58.070 - 00:16:23.194, Speaker A: If at least one of the connected components is not three colorable, then of course the whole graph, which is only harder is also not three colorable. And you can do exactly the same thing for the repacking problem. So what do condensed components mean in the context of a bunch of stations? Well, you just think of the stations as a graph with one vertex per station and an edge between two stations if they have the possibility of interfering.
00:16:23.194 - 00:16:39.314, Speaker A: So if there is some joint channel assignment to them which is forbidden. So that gives you a graph, you can connect its connected components. Different connected components have no edges between them, which means stations and different connected components have no possibility of interfering with each other.
00:16:39.314 - 00:16:56.422, Speaker A: So again the repacking problem just completely separates into these independent subproblems corresponding to the connected components. And then what you do is you're just going to solve each of those connected components separately. If you manage to repack all those subsets of stations you can just return the union of those channel assignments.
00:16:56.422 - 00:17:14.158, Speaker A: If you fail to repack even one of the connected components then you can correctly deduce that it's not a packable set of stations because if the small set is unpackable then so is the big set of all the stations. So that is the second of the preprocessing steps. So you take the output from step three.
00:17:14.158 - 00:17:25.246, Speaker A: So step three is pruned away all the easy stations. You're left with just a bunch of not so easy stations. You compute these connected components and then you solve the repacking instances separately for each of the kinetic components.
00:17:25.246 - 00:17:51.578, Speaker A: Now why did this decomposition step help? After all, the algorithm is still on the hook for solving all of these subproblems corresponding to these connected components. And the combined size of these subproblems is exactly the same as the repacking instance that you started with. But don't forget that when you have an algorithm that runs in super linear time and you'd certainly expect a sat solver to run in super linear time most of the time, it's always going to be faster to solve an instance in pieces than all at once.
00:17:51.578 - 00:18:15.854, Speaker A: So for example, imagine you had a quadratic time algorithm, some algorithm that ran in time n squared on size n instances. Now imagine that you had a size n instance which was actually two independent size n over two instances and then you could just invoke this quadratic time algorithm separately on each of the two sub instances. Well then the running time on each of those two instances would be n over two squared.
00:18:15.854 - 00:18:21.042, Speaker A: So the input size n over two squared. That gives you the running time. That would be N squared over four.
00:18:21.042 - 00:18:42.694, Speaker A: You have to do that twice, once for each of the subproblems, but that still gives you a factor two speed up. You would be solving the two independent subproblems in N squared over two time rather than the N squared time you would need if you solved the original instance in one shot. Now, the toughest of all the repacking instances, they actually survived all four of these steps.
00:18:42.694 - 00:19:03.598, Speaker A: They survived the gauntlet of the presolvers and the preprocessing steps and awaited more sophisticated tools. So what about using a Satsolver once you've boiled it down to one of these sort of really tough instances? Well, the state of the art SATS solvers used off the shelf. All of them had success on like a decent fraction of representative instances.
00:19:03.598 - 00:19:18.870, Speaker A: But none of them met the mandate set forth by the FCC of reliably solving repacking instances in a minute or less. So we need a couple more ideas. The designers of the FCC incentive auction next took advantage of two things.
00:19:18.870 - 00:19:52.446, Speaker A: First thing, probably something you're already well aware of, which is the awesomeness of modern computer processors and in particular multi core processors. So they used eight core workstation and so the eight cores allowed them to run eight algorithms in parallel. So how is this helpful? What were the eight programs that you're going to run in parallel in the FCC incentive auction? Well, this brings us to the second and kind of more interesting empirical observation, which is that if you look at the latest and greatest Satisfiability solvers, there's tremendous heterogeneity in running time performance.
00:19:52.446 - 00:20:20.582, Speaker A: And I mean that in two senses. So first of all, if you look at a fixed Sat solver and you look at different repacking instances, you will see orders of magnitude difference in the running time that solver needs to solve that particular instance of Satisfiability. Also, if you fix the instance, the repacking instance and vary across Sat solvers, you will again discover orders of magnitude difference in running time across the solvers, even just for this one fixed instance.
00:20:20.582 - 00:20:32.430, Speaker A: So the point being is that different solvers are kind of incomparable. Some do really well on certain kinds of instances and struggle on some others. And then some other set solver, it'll be a different set where it does well on a different set where it does poorly.
00:20:32.430 - 00:20:53.074, Speaker A: And this solver heterogeneity dovetails very nicely with the fact that it's pretty much for free to run eight of these things in parallel. So why put all your eggs in one basket and just commit to one Satsolver? No. Instead they used a portfolio of eight Sat solvers to be run in parallel whenever they had a repacking instance.
00:20:53.074 - 00:21:02.118, Speaker A: So as soon as one of those eight solvers successfully solved the repacking instance, boom, you're done. You can return that answer. So that is a pretty neat idea.
00:21:02.118 - 00:21:38.450, Speaker A: Use the fact that different solvers have their own kind of regions of expertise among the landscape of repacking instances and get the best of both worlds, or actually really the best of eight worlds by running eight of them in parallel. In case you're wondering, how did they actually settle on what's in this portfolio? How did they settle on which eight Sat solvers to use in parallel? Well, kind of. Amazingly, they were chosen using a greedy heuristic, which is more or less exactly the same as the greedy heuristic that we studied in chapter 20, both for the maximum coverage problem, where we kept adding a new subset to cover as many new elements as possible.
00:21:38.450 - 00:22:06.990, Speaker A: And the generalization in the influence maximization problem where we kept adding vertices to boost the influence as much as possible. So these eight Sat solvers, they were chosen sequentially and each Sat solver was chosen to maximize the marginal running time improvement on representative instances relative to the solvers that had already been put in the portfolio. So really just the exact same type of greedy heuristic that we studied for maximum coverage and influence maximization.
00:22:06.990 - 00:22:32.450, Speaker A: I should also mention that if there's any big fans of local search out there who are kind of distraught over its apparent absence from this case study, don't worry. It turns out that of the eight Sat solvers in this portfolio, several of them were in fact local search algorithms. Algorithms that maintained a truth assignment and made small changes to the truth assignment in each step to satisfy more and more of the constraints.
00:22:32.450 - 00:23:06.538, Speaker A: So local search also played a fundamental role in the FCC incentive auction. And now putting together all of the ideas that we've discussed, the presolvers, the preprocessing, this portfolio of Sat solvers that wound up being sufficient algorithmic firepower to solve over 99% of the repacking instances faced by the FCC incentive auction within the target of 1 minute each. And don't forget, we're talking about instances of Satisfiability with tens of thousands of variables and over a million constraints.
00:23:06.538 - 00:23:38.630, Speaker A: So this is pretty amazing. Now, solving over 99% of the repacking instances in this very ambitious goal of 1 minute, I mean, that sounds impressive at all. But you might be wondering like what about the other 1%? I mean, did the FCC auction just sort of spin its wheels helplessly while eight Sat solvers fumbled around desperate for a satisfying assignment? Well, another remarkable feature of this FCC greedy algorithm that we're working with is it's highly tolerant of failures by its feasibility checking subroutine.
00:23:38.630 - 00:23:53.982, Speaker A: So imagine the context of the, when the feasibility checking subroutine fails. What does that mean? So in the FCC greedy algorithm, it's doing this single pass over the stations, it's maintaining its solution. So far, capital S, that's a bunch of stations it's committed to putting on the air.
00:23:53.982 - 00:24:06.686, Speaker A: And so that's going to maintains the invariant that, that's a packable set of stations. They really do fit on the air in the given K channels. And so in a current iteration of the greedy algorithm, basically the algorithm is going to ask its feasibility checker.
00:24:06.686 - 00:24:35.930, Speaker A: It says, hey look, I've got these stations capital S, I know they're packable. What if I also tried to fit this additional station v onto the K channels? Would S union v again be a packable set of stations? So the subroutine is going to think about it and in the failure mode a minute's going to expire and the subroutine is going to time out and in effect the subroutine will tell the greedy algorithm. I do not know whether the set of stations S plus v is packable or unpackable.
00:24:35.930 - 00:25:00.514, Speaker A: So how should the greedy algorithm respond and proceed when its feasibility checking subroutine times out? Well, an ironclad constraint of this application is that if you've designated a set of stations capital S to stay on the air, it better be feasible that they stay on the air. It better be a packable set of stations. You cannot afford to return an unpackable set of stations as your final output.
00:25:00.514 - 00:25:24.878, Speaker A: So that means that in the absence of an assurance of feasibility from the feasibility checker, the greedy algorithm has to say, well I've got to play it safe, I can't risk possibly creating an infeasible set. So I'm just going to assume that you cannot pack V in addition to the station's capital S that I've already committed to. And that's potentially a bummer because maybe actually you could pack V in addition to all of capital S.
00:25:24.878 - 00:25:40.742, Speaker A: And in that case this algorithm is potentially foregoing some of the value that it could have otherwise obtained. But the good news is this greedy algorithm, it's going to finish in a predictable amount of time, but it's going to run for 2000 3000 iterations. Each iteration will take at most a minute.
00:25:40.742 - 00:25:56.850, Speaker A: So you know when it's going to finish. You have an ironclad guarantee that it's going to finish with a feasible solution, a bunch of stations that really do fit on the air and K channels. And moreover, as long as these timeouts are infrequent as they were in the actual FCC incentive auction, you're probably losing a little bit of value.
00:25:56.850 - 00:26:20.876, Speaker A: But with infrequent timeouts that should be quite modest. So that concludes the part of this video sequence detailing all of the really nice algorithmic ideas that are built in under the hood in the FCC incentive auction. I still have to tell you about how you put the auction into the FCC incentive auction.
00:26:20.876 - 00:26:22.670, Speaker A: That's coming up next. I'll see you there.
