00:00:00.570 - 00:00:12.042, Speaker A: All right, welcome back, everyone. Let's start talking about how to take longest chain consensus, which we studied at length in lecture number eight. In the permission setting, we proved a lot of nice properties about longest chain consensus.
00:00:12.042 - 00:00:18.606, Speaker A: Let's see how to use proof of work civil resistance to extend longest chain consensus and those nice guarantees to the.
00:00:18.628 - 00:00:23.854, Speaker B: More demanding, more general permissionless setting. I'm going to start this video just.
00:00:23.892 - 00:00:41.702, Speaker A: By sort of briefly review viewing what longest chain consensus looks like, kind of paging it back into memory. I also want to review, if you recall, at the very end of lecture number eight, I highlighted what were the sort of essential points of our consistency and liveness analysis of longest chain consensus. I sort of isolated what was really.
00:00:41.756 - 00:00:43.658, Speaker C: Needed for those proofs to go through.
00:00:43.744 - 00:00:57.342, Speaker A: And I did that in a way to sort of ease the transition to the permissionless setting that we're studying in this lecture. So I want to review that as well. Then in the rest of this video, I'll go on and explain what proof of work civil resistance actually is.
00:00:57.342 - 00:01:02.778, Speaker A: And then in the next video, in the third video, we'll talk about the nice mathematical properties that proof of work.
00:01:02.804 - 00:01:04.660, Speaker C: Civil resistance gives you.
00:01:07.190 - 00:01:21.794, Speaker A: So here's the last slide from lecture number eight. On the left hand side, it's just a recap of the description of longest chain consensus. On the right hand side of the slide just sort of summarizes the key points of our analysis of consistency and liveness of longest chain consensus.
00:01:21.794 - 00:01:27.106, Speaker A: So for the description, remember we have this initialization step. So we're going to be growing sort of a blockchain.
00:01:27.138 - 00:01:28.466, Speaker C: More generally, we're going to be growing.
00:01:28.498 - 00:01:38.470, Speaker A: Kind of an entry directed into a root. And so we need to sort of commence the protocol with that route. And that route is called a genesis block that's hard coded into the protocol.
00:01:38.470 - 00:01:55.760, Speaker A: And you might recall we have this trusted setup assumption, we were calling this a one back in lecture number eight that nobody knows the genesis block up until the point that the protocol is actually deployed. So we're going to assume that Byzantine nodes do not have advanced knowledge of the genesis block B zero.
00:01:56.370 - 00:01:57.774, Speaker B: So the way I described the rest.
00:01:57.812 - 00:02:10.550, Speaker A: Of longest chain consensus in lecture number eight, when we were thinking about the permission setting, we thought about it operating sort of in rounds round number one, round number two, round number three, et cetera. With each round there's a leader. So that's what gets selected in two A.
00:02:10.550 - 00:02:28.214, Speaker A: So somehow this magenta box takes as input a round number round number 23, and gives you back as output a sort of ID for a leader like node number 17. And whichever node happens to be the leader of this round can then propose blocks. And along with the blocks, it can also propose sort of predecessors.
00:02:28.214 - 00:02:52.210, Speaker A: So for each block it proposes, it specifies sort of which previously created block, it's extending, so it's claiming one of the previous blocks as its immediate ancestor as far as the magenta box, the leader selection box. So last lecture in lecture number eight, we had in mind the permission setting. So we had in mind a magenta box that was well aware of all of the nodes running the protocol in lecture number nine.
00:02:52.210 - 00:02:58.946, Speaker A: Now we're going to be interested in magenta boxes that somehow make the selection of a node without being aware of.
00:02:58.968 - 00:03:00.710, Speaker C: The nodes that are running a protocol.
00:03:01.770 - 00:03:05.186, Speaker A: Now, I need to warn you that the version of longest chain consensus that's.
00:03:05.218 - 00:03:07.250, Speaker C: Coupled with proof of work civil resistance.
00:03:07.410 - 00:03:34.334, Speaker A: As practiced in, for example, Bitcoin, there's going to be probably three different things about that description that surprise you a little bit relative to this pseudocode description, especially if you're kind of still thinking solidly in the sort of permissioned model. So the first sort of idiosyncrasy, the proof of work implementation is that what I've described here is logically separate steps. Sort of two A select the leader of around and then two B, once selected, the leader gets to make whatever proposals it wants.
00:03:34.334 - 00:03:35.658, Speaker A: Two A and two B are actually.
00:03:35.684 - 00:03:37.122, Speaker C: Going to wind up being smooshed into.
00:03:37.176 - 00:03:57.746, Speaker A: Kind of the same step of the version of longest chain consensus we talk about in this lecture. Also, not only are two A and two B going to be smushed together, but the way that they will be smushed together will actually prevent the leader from proposing more than one block. It's only going to be able to propose one block in a given round.
00:03:57.778 - 00:03:59.030, Speaker B: That it's the leader.
00:03:59.930 - 00:04:01.926, Speaker C: That property will not be true, for.
00:04:01.948 - 00:04:29.358, Speaker A: Example, of the proof of stake implementations of longest chain consensus that we'll talk about in lecture number twelve, but we'll see that it actually is true in lecture number nine. So two A and two B happen at the same time and actually involves a proposal of at most one block with a corresponding predecessor. The third possible surprise to look out for, if you're thinking in the permission setting, you might be thinking that these rounds probably have some fixed duration, like every 10 seconds you have sort of another round.
00:04:29.358 - 00:04:54.010, Speaker A: And in the permissionless version of longest chain consensus we'll talk about today in lecture number nine, that's not going to be the case. Rounds will actually have potentially different lengths, they'll have a random length and it'll be just a purely event driven version of longest chain consensus. So every time a certain event happens, which as we'll see, will be a node sort of solving a difficult puzzle, every time an event happens that will correspond to a new round.
00:04:54.750 - 00:04:56.250, Speaker B: All right, so that's the review of.
00:04:56.320 - 00:05:01.574, Speaker A: The left part of the slide of sort of just the description of the protocol. How about a recap of the analysis.
00:05:01.622 - 00:05:03.038, Speaker C: We did of this protocol in the.
00:05:03.044 - 00:05:17.806, Speaker A: Permission setting back in lecture number eight. So you might recall that the analysis in that lecture really hinged on a property around leader sequences. So in longest chain consensus, each round some node is the leader.
00:05:17.806 - 00:05:35.746, Speaker A: That's what the magenta box tells us. So if you let 1000 rounds go by, the magenta box gets invoked a thousand times, you're going to see a sequence of 1000 nodes, the leaders of those thousand rounds. Now, for our purposes, for consistency, liveness, et cetera, we don't need to distinguish between different honest nodes.
00:05:35.746 - 00:06:04.154, Speaker A: They're all doing the same thing, they're all just following the protocol, honestly acting in the same way. Similarly, we don't need to distinguish between different Byzantine or adversarial nodes always we're assuming that Byzantine nodes are basically in cahoots, so they're all collaborating anyways, so it doesn't matter which one gets chosen. So we can think of this leader sequence, these sort of thousand leaders really all we care about is the pattern of H's and A's where by an H I mean the rounds in which an honest node was selected as a leader.
00:06:04.154 - 00:06:31.554, Speaker A: And by A, I mean the rounds in which a Byzantine I e adversarial node was chosen as a leader. And so what we introduced in that analysis a crucial definition, that of a leader sequence being W balanced. So what does it mean for a sequence of A's and H's to be W balanced? It means that in any window of length W or more a strict majority of the letters in that window should be H's.
00:06:31.554 - 00:07:00.386, Speaker A: So in any window of length W or more you should have a strict the number of honest leaders should outnumber the number of Byzantine notes. So the analysis then factored into two distinct parts. So in one part, what we proved is that if the leader sequence happens to be W balanced, doesn't matter why, doesn't matter how you generated that balanced leader sequence, as long as you wound up with a balanced leader sequence, you're guaranteed to be good.
00:07:00.386 - 00:07:15.154, Speaker A: You have everything you want liveness, even chain quality and you have finality. Now caveat for that to be true, it's important that the security parameter k. So remember k is how deep on a longest chain a block needs to be before it's considered finalized.
00:07:15.154 - 00:07:31.680, Speaker A: The parameter K should be chosen as a suitable function of W, where W is the parameter in the W balanceness assumption. Specifically k should be set equal to W over two. But for that value of K, if you have a W balanced leader sequence, you have all of the properties that you want.
00:07:31.680 - 00:07:50.820, Speaker A: And crucially, nothing in that part of the analysis depended whatsoever on the assumption of the permissioned setting. It did not matter if you had a sequence of H's and A's such that every window of length at least W had more honest leaders than Byzantine leaders, then you were good.
00:07:51.750 - 00:07:53.410, Speaker B: So that was the content of videos.
00:07:53.480 - 00:08:02.550, Speaker A: Five, six and seven from lecture number eight. The other part of the analysis was in video number four of lecture eight. And there we asked, okay, that's fine.
00:08:02.550 - 00:08:28.174, Speaker A: If you happen to have a balanced leader sequence, you're done, but why should you have a balanced leader sequence? And so in that fourth video, we in particular studied to what extent you get balanced leader sequences if you pick one node uniformly at random. Remember in lecture eight we were talking about the permission setting, so it made sense to speak about the protocol selecting a node as a leader uniformly at random. Okay, that's a permissioned version of the magenta box.
00:08:28.174 - 00:08:30.714, Speaker A: But in lecture number eight, we were in the permissioned setting.
00:08:30.842 - 00:08:34.186, Speaker B: So that was okay. And the main result in that fourth.
00:08:34.218 - 00:09:19.038, Speaker A: Video is that as long as a strict majority of the nodes are honest, so a strict minority of the nodes are Byzantine, then in fact for sufficiently large W, if you take W large enough, in fact, you will generate a W balance leader sequence except with very small failure probability. And the sort of more general principle behind this, which you might recall we took advantage of when we studied the chain quality of longest chain consensus in lecture number eight is just that in sufficiently long windows you're going to get basically proportional representation of honest nodes and Byzantine nodes. So if out there in the world more than half of the nodes are honest, then in sufficiently large window sizes you also are going to be seeing more than half of the nodes being honest.
00:09:19.038 - 00:09:36.522, Speaker A: Now, how big you have to take the window size is going to depend on your margin of error. So it's going to depend on how close alpha is to one half. The closer the fraction alpha of Byzantine nodes is to a half, the longer you're going to have to take those window sizes to guarantee a strict majority of honest leaders within every window.
00:09:36.522 - 00:10:05.790, Speaker A: But nonetheless, for any sort of fraction alpha less than 50% of Byzantine nodes, there exists a sufficiently large window size such that the W balancedness condition holds with high probability. So, guilty as charged in lecture number eight, we definitely did use the permissioned assumption specifically just in sort of our construction of our magenta box. So right there in our protocol description, select the node uniformly at random, that's using the assumption that we're in the permissions setting.
00:10:05.790 - 00:10:34.482, Speaker A: However, if you look at the analysis we did of that protocol, if you look at the math which says that you will have the W balancedness condition satisfied with high probability as long as you choose W to be sufficiently large. If you look at that analysis, it doesn't care at all whether you're in the permissioned setting or not, right? Remember what that math says. That math just says you get proportional representation in sufficiently large window sizes.
00:10:34.482 - 00:10:56.138, Speaker A: So all that you needed was that this magenta box, however it works inside the magenta box as long as every round it's going to give you an honest node with strictly bigger than 50% probability. So a Byzantine node with strictly less than 50% probability, then the exact same argument works. You will still have proportional representation and sufficiently large window sizes.
00:10:56.138 - 00:11:28.726, Speaker A: You're expecting at least 51% honest nodes. If the window is big enough, you really will have more or less 51% honest nodes. Putting all of this together, it means we are missing one and only one ingredient from being able to extend longest chain consensus to the permissionless setting with exactly the same guarantees we got in the permissioned setting, the only thing we are missing is a permissionless version of the magenta box with the correct property.
00:11:28.726 - 00:11:53.966, Speaker A: Meaning with a property that in each round, it's more likely to output an honest node than it is to output a Byzantine node. If we can have a magenta box with that property, however it works, doesn't matter, just a magenta box that is well defined in the permissionless setting that is guaranteed to output honest nodes more frequently than Byzantine nodes, then everything in lecture eight holds exactly as is. We get our theorem one, we get.
00:11:53.988 - 00:11:55.466, Speaker C: Our theorem two, we get our theorem.
00:11:55.498 - 00:12:11.846, Speaker A: Three, we get our theorem three, prime, finality, liveness chain quality, all of it. We're going to get it in the permissionless setting as long as we can implement a permissionless version of the magenta box. So to summarize that discussion, we want a random sampling procedure, or in other.
00:12:11.868 - 00:12:15.462, Speaker B: Words, we want a magenta box so.
00:12:15.516 - 00:12:24.540, Speaker A: That at least under suitable assumptions produces a Byzantine leader with probability at most alpha, where alpha should be strictly less than one half.
00:12:25.550 - 00:12:27.258, Speaker B: And if we succeed, we'll inherit all.
00:12:27.264 - 00:12:29.178, Speaker A: Of those finality and liveness properties that.
00:12:29.184 - 00:12:31.100, Speaker C: We discussed in lecture number eight.
00:12:32.350 - 00:12:33.382, Speaker B: So one caveat.
00:12:33.446 - 00:12:57.282, Speaker A: I mean, you may remember that in lecture number eight, we had these assumptions, a one through a five that we used in our analysis to prove all of these guarantees. And some of those assumptions were very easy to make sure they were satisfied in the permissioned plus PKI setting we were thinking about last lecture. Now that we're in the permissionless setting, we need to go back and make sure that those same assumptions are actually satisfied with our sort of proof of work, civil resistant implementation.
00:12:57.346 - 00:12:58.566, Speaker C: So we will do that after I.
00:12:58.588 - 00:13:16.330, Speaker A: Describe to you how proof of work actually works. So, proof of work, what is it? Well, the main idea is to declare the next leader to be the first node that manages to come up with a solution to a hard puzzle.
00:13:16.910 - 00:13:19.402, Speaker B: So looking ahead to civil resistance, remember.
00:13:19.456 - 00:13:28.798, Speaker A: We want sort of the nodes to be unable to manipulate the probability that they're selected by generating multiple IDs. So the hope is that these will be puzzles where having multiple IDs just.
00:13:28.804 - 00:13:29.854, Speaker C: Like doesn't help you at all.
00:13:29.892 - 00:13:44.670, Speaker A: All that matters is kind of how smart you are how much computational power you have, it doesn't really matter how many public private key pairs you've generated. Now, I think already at this point you can see what I mean. That for us in this lecture, longest Chain Consensus will be event driven.
00:13:44.670 - 00:13:57.506, Speaker A: So you're not going to have necessarily one round every 10 seconds. It's just whenever some node manages to solve some new puzzle, that's going to be the next round. If it takes an unusually long amount of time for some node to solve.
00:13:57.538 - 00:13:58.566, Speaker C: A puzzle, then there's going to be.
00:13:58.588 - 00:14:22.330, Speaker A: An unusually sort of long period of time between successive rounds, between successive blocks. If a puzzle is solved very quickly, it's going to be a relatively short period of time between successive rounds or successive blocks. So one neat plot twist here, which I think is really emblematic of sort of the shift of thinking in the permissionless setting, is that the next leader is not actually being explicitly computed by the protocol.
00:14:22.330 - 00:14:29.426, Speaker A: And that's different than when we're talking about, say, round robin rotating leaders or randomly sampled leaders. So they are really the protocol as.
00:14:29.448 - 00:14:30.786, Speaker C: Part of its code with sort of.
00:14:30.808 - 00:14:55.082, Speaker A: Dictating sort of top down who the next leader was. And here in Proof of Work, it's really sort of bottom up, right? Actually, we're putting the burden of proof onto the nodes to convince the protocol and all the other nodes that actually they are the leader, convincing everybody else through exhibiting the solution to this hard puzzle. So that's the primary idea behind Proof of Work.
00:14:55.082 - 00:15:17.630, Speaker A: It was not invented by Nakamoto for the Bitcoin protocol, unlike Longest Chain Consensus, which as far as I know, was invented by Nakamoto. Rather, there's a very prescient paper from 1992 by Cynthia Dwark and Moni Noir who were thinking about fighting spam emails. And so Proof of Work was proposed as a measure to make it sort of more difficult for an attacker to send a lot of spam emails.
00:15:17.630 - 00:15:37.670, Speaker A: It was prescient both because of its later application in blockchains, but actually in 1992, believe it or not, spam email basically didn't exist at that point. So even for the intended application, they were ahead of the curve. And certainly now, 15 years later, proof of Work really got its true killer application in the form of Bitcoin and permissionless consensus.
00:15:37.670 - 00:15:54.878, Speaker A: So this all probably seems a little vague, like, what do I mean by a hard puzzle? Do I mean the Saturday New York Times crossword or what? And there's various approaches you could use, but there's really one approach that works really, really well. And Nakamoto already nailed it in the.
00:15:54.884 - 00:15:57.118, Speaker C: Bitcoin protocol, and all other versions of.
00:15:57.124 - 00:16:21.350, Speaker A: Proof of Work use a similar idea, where basically the hard puzzle is going to be to approximately invert a cryptographic hash function. So Proof of Work is going to lead us to adopt our second cryptographic assumption. The first one, you might recall, we introduced all the way back in lecture number one, which was we've been assuming that secure digital signature schemes exist.
00:16:21.350 - 00:16:47.934, Speaker A: So we've been using that assumption all over the place in our consensus protocols, right? Typically nodes are kind of signing their messages with their private key and we certainly need it to be true that other nodes like Byzantine nodes are unable to forge messages from other honest nodes. And that rests on our cryptographic assumption that really these signature schemes are unbreakable. So that was cryptographic assumption number one that we've had sort of all along.
00:16:47.934 - 00:16:58.814, Speaker A: That's a very nonexotic assumption. It's very kind of well accepted that these signature schemes do exist in the real world. And happily this second cryptographic assumption is also not very exotic.
00:16:58.814 - 00:17:05.650, Speaker A: It's also not very controversial to make this assumption, namely that there exist cryptographic hash functions.
00:17:06.870 - 00:17:08.434, Speaker B: So what do I mean by this.
00:17:08.472 - 00:17:19.954, Speaker A: By a cryptographic hash function? Well, a hash function, frankly, it's just a function. It just takes some input from some domain and then it outputs some output from some range. Hash functions show up in lots of different contexts.
00:17:19.954 - 00:17:48.210, Speaker A: Like if you study algorithms and data structures you might study hash functions where the main point is to kind of like balance load over many buckets in a hash table, something like that. So here we're talking about hash functions with a very different purpose, right? Cryptographic hash functions where here the point is that basically the goal is to be completely inscrutable. Basically, whatever you throw into the hash function, it's going to give you back as output some unintelligible gibberish that moreover, you've never seen before in your life.
00:17:48.210 - 00:18:01.320, Speaker A: So we'll formalize that in terms of a random oral assumption shortly. But basically cryptographic hash function just means a hash function that is totally inscrutable, that is completely resistant to any kind of understanding about what it's actually doing.
00:18:02.090 - 00:18:03.414, Speaker B: And if you want to know just.
00:18:03.452 - 00:18:11.080, Speaker A: One example of a hash function that appears to be cryptographic in this sense, a canonical example would be Sha 256.
00:18:12.010 - 00:18:13.314, Speaker B: If memory serves.
00:18:13.362 - 00:18:26.862, Speaker A: I think Sha stands for secure hash algorithm. The 256 refers to the number of bits in the output. So Shaw 256, you should think of it as this inscrutable box where you can put in inputs of any length that you want.
00:18:26.862 - 00:18:42.818, Speaker A: It's going to give you back 256 bits which as far as you can tell are like totally random. They resemble nothing like you've seen anything previously in your life. So I encourage you to sort of look up on the web a reference implementation of shot 256.
00:18:42.818 - 00:18:52.566, Speaker A: It's not that long. It should be maybe like 100 lines of C code, something like that. It's deterministic, right? It's sort of public, everybody knows the source code.
00:18:52.566 - 00:19:04.300, Speaker A: And yet despite all that, it's completely inscrutable. For all practical purposes. It's completely unpredictable what the output of Sha 256 is going to be on any input that you haven't already evaluated it on.
00:19:04.300 - 00:19:17.440, Speaker A: So to formalize this idea of sort of an inscrutable, unpredictable cryptographic hash function. Let me introduce the random Oracle assumption, which is something we're going to be making about functions like Sha 256.
00:19:18.370 - 00:19:18.718, Speaker B: All right?
00:19:18.724 - 00:19:31.810, Speaker A: So the random Oracle assumption, it's going to be something we adopt for the purposes of our mathematical analysis. It's going to be in some ways patently false. But also, on the other hand, it's sort of an extremely close approximation of reality.
00:19:32.550 - 00:19:33.986, Speaker B: And it's going to state that a.
00:19:34.008 - 00:20:00.218, Speaker A: Cryptographic hash function like, say, Sha 256, it may as well be a random function. And by a random function, I mean literally, for each possible input, the corresponding output is independent and uniformly random draw from the range of the hash function. So how should you think about the random Oracle assumption? How should you think about h being like a random function? Well, think of it this way.
00:20:00.218 - 00:20:13.162, Speaker A: So just think of a hash function as like a block, a box, an opaque box. Let's make it an orange box on the slide, takes as input whatever, and spits out as output something from the range. Let's say it's sort of 256 bits.
00:20:13.162 - 00:20:14.906, Speaker A: So it's basically zero comma one raised.
00:20:14.938 - 00:20:17.126, Speaker C: To the 256 just like it is in shot 256.
00:20:17.128 - 00:20:20.146, Speaker B: And I encourage you to think about.
00:20:20.168 - 00:20:45.340, Speaker A: This random function as being defined kind of by lazy evaluation, so sort of only as needed. So, like, imagine this orange box has a little gnome in it, right? And imagine like, you query the box for the first time, you sort of evaluate little h on some input for the first time. The gnome is going to then sort of flip a coin 256 times and it's going to output whatever that 256 bit string of zeros and ones is.
00:20:45.340 - 00:21:10.820, Speaker A: So now, if you query the orange box again on exactly the same input, it's a deterministic function, so you should be getting back exactly the same output. So if you ever ask the same thing, you're going to get the same answer. But if you feed in any different input into the orange box, that little gnome in the box is going to flip another 256 coins and output the corresponding 256 bit string of zeros and ones.
00:21:10.820 - 00:21:31.538, Speaker A: And so now you see the sense in which I meant that the function under the random Oracle assumption is utterly unpredictable. So you cannot learn anything about how h works other than through evaluating it at various points. But whatever you evaluate at a new point, you just get back in return a new 256 bits of randomness.
00:21:31.538 - 00:21:45.790, Speaker A: So evaluating at sort of 17,000 different points tells you literally nothing about the next point you evaluated at that is again going to be just a completely freshly sampled sequence of 256 random bits.
00:21:46.530 - 00:21:48.554, Speaker B: And so what the random Oracle assumption.
00:21:48.602 - 00:22:16.162, Speaker A: Asserts is that like any program you might ever conceivably write, any computations that computers might conceivably do, interacting with a function like shot 256, it will be indistinguishable from interacting with this little gnome inside the orange box. Now, strictly speaking, that is of course, utterly false. Shot 256 is just some concrete deterministic function that takes about 100 lines of code to describe.
00:22:16.162 - 00:22:30.982, Speaker A: It is most certainly not sort of a lazily evaluated random function in this sense. But here's the thing. So things that are deterministic can appear random if you don't have enough computational power to analyze them deeply.
00:22:30.982 - 00:23:01.334, Speaker A: So for a real world analog, like, imagine someone sort of flips a coin, right? So you're watching and there's this sort of coin tumbling in midair. From your perspective, you probably have a 50 50% chance of getting it right, whether it's going to be heads or tails, you're going to be unable to predict which side it's going to land on. But you can imagine if you had a much, much more computationally powerful system, like you had all kinds of crazy cameras sort of tracking the coin flip and you had a sort of very detailed sort of physics simulation of exactly what's going to happen next.
00:23:01.334 - 00:23:16.714, Speaker A: You could imagine that with all of that sort of extra power, maybe that coin flip midair, it wouldn't really be random anymore. Maybe you could predict it actually extremely accurately with all of that additional information. So exact same principle here, right? Shot 256, it is a concrete function.
00:23:16.714 - 00:23:41.540, Speaker A: It's 100 lines of code. In principle, you should be able to predict its output on inputs you haven't yet seen. But from the perspective of any kind of given the bounded computational power that we have in the universe, as far as anyone can tell empirically, we are unable to predict shot 256 any better than we could a random function, which is to say, not at all.
00:23:42.150 - 00:23:44.930, Speaker B: Now, it is certainly possible in principle.
00:23:45.750 - 00:24:18.414, Speaker A: That a function that was thought to be a cryptographic hash function like shot 256, maybe eventually someone figures out some clever way to actually predict its outputs on not yet seen inputs. If someone broke it in that way, it would definitely have detrimental consequences for blockchains, including bitcoin. On the other hand, we also have this other standing assumption, right, sort of the secure digital signature schemes, which for the signature schemes used in most blockchain protocols rests on the computational hardness of the discrete logarithm problem in sort of an appropriate group.
00:24:18.414 - 00:24:45.670, Speaker A: So it's equally possible that in principle, someone could come up with a fast algorithm for that discrete logarithm problem and break the signature schemes that were previously thought to be secure. So it's kind of the same thing, right? So as far as we can tell, and people have been trying for years to kind of, sort of either kind of solve discrete log efficiently or find sort of shortcuts in figuring out shot 256, no one's been able to do it. And so that's kind of as good as cryptographic assumptions get battle tested over the decades.
00:24:45.670 - 00:24:48.360, Speaker A: That's about the best you can hope for.
00:24:48.730 - 00:24:49.926, Speaker B: So now that we sort of have.
00:24:49.948 - 00:25:22.770, Speaker A: Talked about cryptographic hash functions like shot 256, I can tell you what the hard puzzle looks like. The hard puzzle is finding an input which when fed into the cryptographic hash function, gives you a sort of very small number as output, a number relatively close to zero. So precisely given threshold tau, which you can think of as an integer, find an input x such that x hashes to an output which when viewed as an integer is no larger than tau.
00:25:22.770 - 00:25:36.706, Speaker A: One immediate question is, okay, what is tau exactly? So tau is going to be a tunable difficulty parameter. The smaller tau is, the harder the puzzle. The bigger tau is, the easier the puzzle.
00:25:36.898 - 00:25:38.518, Speaker B: In the most extreme case, you could.
00:25:38.524 - 00:25:55.150, Speaker A: Set tau to be zero. Then the puzzle is literally inverting the cryptographic hash function, little h at zero. If that's too hard a puzzle, then you may want to take tau to be larger so that there's more and more x's which actually satisfy which actually qualify as solutions.
00:25:55.150 - 00:26:07.710, Speaker A: If it would be helpful to think about some concrete parameter values. Take little h to be shot 256. So the output of the hash function is a 256 bit string which we can interpret as an integer.
00:26:07.710 - 00:26:36.934, Speaker A: And imagine taking tau to be, I don't know, two raised to the 176th. So viewed as a binary expanded in binary, two to the 176th is 80 zeros, followed by a one, followed by the remaining being zeros. So to say that we're looking for an x that hashes to a number that's at most tau, that's the same as saying we're looking for an x that hashes undershot 256 to a 256 bit string, the first 80 of which are zeros.
00:26:36.934 - 00:27:03.730, Speaker A: So that's the puzzle. Find an x so that you get an output that begins with at least 80 zeros in a row. So the fact that these puzzles have such sort of easy to tune difficulty through the threshold tau, right? Again, with smaller tau's being harder puzzles, with bigger taus being easier puzzles, I mean, that's what makes this kind of partial inversion of a cryptographic hash function so attractive to use in a proof of work context.
00:27:03.730 - 00:27:21.740, Speaker A: If you tried to use an NP hard problem like Satisfiability or traveling salesman problem or something, this wouldn't work at all. It's really not obvious how you sort of take satisfiability instances and make them twice as hard, where it's quite clear, at least intuitively, how you make these puzzles twice as hard. Namely, you would cut tau in half.
00:27:21.740 - 00:27:36.746, Speaker A: So again, in the fourth video, we'll sort of talk in more detail about how tau should be tuned. But sort of the one sentence kind of foreshadowing, I'll tell you now, is that basically tau is going to be set to target a particular rate of block production. Like bitcoin.
00:27:36.746 - 00:27:44.690, Speaker A: Famously, there's a target rate of block production of. One block per ten minutes on average, that's going to dictate how this threshold tau is going to be chosen.
00:27:46.790 - 00:27:48.754, Speaker B: So let's now focus on a hard.
00:27:48.792 - 00:28:14.680, Speaker C: Puzzle for some fixed threshold tau. And again, for concreteness, you might want to think about h being shot 256. So 256 bit output, you might think of tau as two raised to the 176, in which case we're looking for an X that hashes to a string that begins with at least 80 zeros.
00:28:15.420 - 00:28:16.924, Speaker B: Now let me connect this to our.
00:28:16.962 - 00:28:39.428, Speaker C: Random Oracle assumption, right? Remember that says that our cryptographic hash function, like, for example, shot 256, basically to us it's indistinguishable between that orange box with a gnome inside flipping 256 coins every time it's queried on some new input. So under this assumption, our cryptographic hash function behaves like a perfectly random function. And so what that means is information.
00:28:39.428 - 00:28:55.540, Speaker C: Theoretically, we literally know nothing about little h other than its outputs for the inputs on which we've already evaluated it. So maybe we've evaluated shot 250, 617 thousand times. So we have 17,000 corresponding 256 bit outputs.
00:28:55.540 - 00:29:21.596, Speaker C: But under the random Oracle assumption, we know literally nothing about h's output. It's completely unpredictable to us outside of the 17,000 points where we've already evaluated it. And so what that means is that when you're searching for a solution, when you're searching for an X that hashes to a number that's at most tau, literally, you have no options available to you other than just repeatedly evaluating the hash function on various inputs.
00:29:21.596 - 00:29:29.312, Speaker C: So you try x sub one, see if it works. You try some other x, sub two, see if it works. You try some other x, sub three, see if it works.
00:29:29.366 - 00:29:31.216, Speaker A: And the point is, the outputs of.
00:29:31.238 - 00:30:04.780, Speaker C: Little h on the ones you've tried so far gives you literally no clues about which other inputs might, might be a solution, which other inputs might hash to something at most tau. You know literally nothing about h's outputs on any of the other inputs that you haven't yet evaluated it on. And furthermore, because H's outputs on different inputs is assumed not just to be independent, but because its output on any given input is assumed to be uniformly at random, that means any particular guess, any particular input, x you feed into the hash function, they're each equally likely to actually be a puzzle solution.
00:30:04.780 - 00:30:42.996, Speaker C: And under our assumption that the output is uniformly at random, we also know exactly what this probability is, right? It's really just going to be sort of the ratio between tau, which kind of tells you the number of acceptable outputs divided by the total number of possible outputs, the size of the range of the hash function. So if it's 256 bit hash function like shot 256, right, that denominator is two raised to the 256. If we take Tau to be two raised to the 176th then the probability that any given guess will be a solution is going to be that ratio which is two raised to the -80 which makes sense right we're trying to find something where we get a hash that's sort of 80 zeros in a row.
00:30:42.996 - 00:30:48.264, Speaker C: And so we need that gnome to flip heads on its 1st 80 coin flips. And so that's going to be probability.
00:30:48.392 - 00:30:51.756, Speaker B: Two to the -80 now for these.
00:30:51.858 - 00:31:12.768, Speaker C: Particular parameter choices this probability of success is really really small it's sort of just very unlikely that any given guess x is going to wind up hashing to a puzzle solution two to the -80 is quite small. So you're basically like throwing darts at a dartboard repeatedly. And the dartboard has a really tiny bullseye with these particular parameter choices.
00:31:12.768 - 00:31:35.016, Speaker C: And you're hoping you just get super lucky and sort of pierce it right in the middle. And if the probability that any given guess succeeds, is two to the -80, that means that on average, you're going to be expecting to make two to the 80 distinct guesses before you actually find a solution, before you actually throw a dart that hits the bullseye. Obviously, with other parameter values, it would.
00:31:35.038 - 00:31:36.136, Speaker A: Be easier or harder. Right?
00:31:36.158 - 00:31:56.956, Speaker C: So like for a much bigger value of Tau, like tau two raised to the 226, then the probability of success of any one dart would be roughly one over a billion. And so you'd expect to need a billion guesses before you actually sort of hit the bullseye. But a billion operations is something you can definitely think about doing on sort of just your commodity laptop or desktop obviously if the puzzles are much harder.
00:31:56.956 - 00:32:09.430, Speaker C: If Tau really is two to the 176th, you're basically in reality never going to find a puzzle solution just using sort of normal computers. The only hope would be to use specialized hardware if the puzzles were sort of quite difficult.
00:32:10.440 - 00:32:11.536, Speaker B: So I don't know if this assumption.
00:32:11.568 - 00:32:26.164, Speaker C: Maybe it strikes you as a little strong, right you're kind of saying look, we're going to assume that the nodes just sort of haven't come up with some clever solution, some clever shortcut that allows them to find puzzle solutions faster than just this kind of mindless sort of repeated guessing.
00:32:26.292 - 00:32:28.812, Speaker A: But I will say that is just like empirically true.
00:32:28.866 - 00:32:50.020, Speaker C: So if you actually look at sort of proof of work blockchains out there in the wild bitcoin et cetera, and you look at the nodes running the protocol that are trying to find sort of puzzle solutions, they literally are just doing sort of repeated guesses. So this assumption even if it seems strong it's basically 100% accurate description of how things actually work in practice.
00:32:50.760 - 00:32:51.828, Speaker B: All right, so the last thing I.
00:32:51.834 - 00:32:58.950, Speaker C: Want to talk about in this video is the format we're going to require for a possible puzzle solution X.
00:33:02.890 - 00:33:04.566, Speaker B: So from the discussion so far, it.
00:33:04.588 - 00:33:12.390, Speaker C: Probably sounds like X is just allowed to be arbitrary, it can have any length, any contents as long as it hashes to something at most tau, it constitutes a puzzle solution.
00:33:12.550 - 00:33:14.850, Speaker A: It's actually going to be really convenient.
00:33:15.030 - 00:33:49.270, Speaker C: To require little x not only to hash to something at most tau, but in fact also have a prescribed format. So we're going to require that little x actually encodes some additional data, specifically the node which is making random guesses, sort of looking for different various guesses x. We're going to actually require that it announce in advance through its puzzle solution what block it would be adding to the blockchain and what predecessor it would be extending.
00:33:50.330 - 00:33:51.666, Speaker B: So to make this sort of crystal.
00:33:51.698 - 00:33:55.850, Speaker C: Clear, let's just go back and look at the description of longest chain consensus.
00:33:57.390 - 00:33:59.126, Speaker B: So this again is the last slide.
00:33:59.158 - 00:34:18.154, Speaker C: From lecture number eight for review. We're looking at the left hand side, we're looking at the pseudocode. And let me remind you of something I said earlier, which is that there's going to be maybe three differences between longest chain consensus implemented with proof of work, civil resistance, compared to probably how you were thinking about the protocol based on how I described it in lecture number eight in the permission setting.
00:34:18.154 - 00:34:22.322, Speaker C: So difference number one, and we sort of already see now very concretely why this is true.
00:34:22.456 - 00:34:24.306, Speaker A: In lecture number eight, you might have.
00:34:24.328 - 00:34:28.318, Speaker C: Thought about rounds as like having a prescribed duration, like one round every 10 seconds.
00:34:28.414 - 00:34:29.666, Speaker A: And what we see with proof of.
00:34:29.688 - 00:34:38.962, Speaker C: Work is that that's not going to be true. There's going to be a variable sort of length between sort of successive rounds. It's really just going to depend on whenever the next node winds up finding a new puzzle solution.
00:34:38.962 - 00:34:47.210, Speaker C: So it's going to be purely event driven with a new round sort of commencing whenever the event that some node comes up with a new puzzle solution.
00:34:48.030 - 00:34:50.246, Speaker A: So the second difference is that steps.
00:34:50.278 - 00:34:54.966, Speaker C: Two A and two B are going to be smushed together and happen at the same time rather than in sequence.
00:34:55.078 - 00:34:56.566, Speaker A: So in the permission setting in lecture.
00:34:56.598 - 00:35:14.018, Speaker C: Number eight we were sort of thinking about first Step Two A happens. Somehow the magenta box kind of declares which node winds up being the leader of this round? And then subsequently, now that node, now knowing that it's the leader is free to make whatever block proposals that it wants and specify whatever predecessors that it wants.
00:35:14.184 - 00:35:16.578, Speaker A: And so with the proof of work.
00:35:16.664 - 00:35:32.390, Speaker C: So this is what ties back into kind of like, what's the format of little x, right? So what constraints do we want to impose on little x in addition to hashing to something small? What constraints do we want to sort of impose on x for it to be eligible as a puzzle solution? And so a really nice idea here.
00:35:32.460 - 00:35:34.406, Speaker A: Is we're going to actually force a.
00:35:34.428 - 00:35:48.358, Speaker C: Node to encode in its guess little x the actions that it would take in step two B. So before the node even knows whether it's going to be the leader or not. Before it knows whether X is a puzzle solution or not, we force it.
00:35:48.384 - 00:35:50.606, Speaker A: To pre commit to the blocks it.
00:35:50.628 - 00:36:09.074, Speaker C: Would propose and what those predecessors would be. So in that sense, two A and two B are going to be smushed together because little X, in order to qualify as a puzzle solution, it must be formatted in a way that it specifies. It sort of commits to the block proposal and predecessor that that node would make.
00:36:09.074 - 00:36:19.126, Speaker C: The third difference concerns step two B. Now remember, honest nodes in longest chain consensus, those that are following the protocol correctly, when they get, if they wind.
00:36:19.148 - 00:36:20.534, Speaker A: Up being elected the leader in step.
00:36:20.572 - 00:36:27.386, Speaker C: Two B, they're going to propose only one block. They're going to propose a block that extends the longest chain that they're aware of. That's what honest nodes are supposed to do.
00:36:27.386 - 00:37:05.474, Speaker C: Now, in the description in lecture number eight, we allowed Byzantine nodes the option of proposing multiple blocks when elected as a leader, right? So for example, we could imagine a Byzantine node that's elected as a leader sort of coming up with two different block proposals and telling some of the honest nodes about one of them and then the other honest nodes about sort of a conflicting block proposal, right? That's the usual kinds of things that the Byzantine nodes do. But somewhat miraculously, when we couple longest chain consensus with proof of work civil resistance, we can actually set things up so that Byzantine nodes are unable to actually make these sort of conflicting block proposals to different nodes.
00:37:05.602 - 00:37:07.558, Speaker A: So the idea is, okay, well if.
00:37:07.564 - 00:37:09.574, Speaker C: We'Re already imposing constraints on little X.
00:37:09.612 - 00:37:11.014, Speaker A: Again, on top of hashing to something.
00:37:11.052 - 00:37:20.074, Speaker C: Small, additional constraints on the format of little X so that it qualifies as a puzzle solution, we're already forcing the node to encode its choices in step two B.
00:37:20.192 - 00:37:22.010, Speaker A: Why don't we just declare little X.
00:37:22.080 - 00:37:32.606, Speaker C: As ineligible for a puzzle solution if it tries to specify multiple blocks? Okay, so to qualify as a puzzle solution, little X, not only do you have to hash to something that's at.
00:37:32.628 - 00:37:34.398, Speaker A: Most tau, not only do you have.
00:37:34.404 - 00:37:43.294, Speaker C: To specify in advance, encoded in little X your step two B choices, but moreover, there should be exactly one block and there should be exactly one predecessor.
00:37:43.422 - 00:37:45.698, Speaker A: Any other little X, it cannot be.
00:37:45.784 - 00:38:14.032, Speaker C: By definition a puzzle solution. So that's the second really nice design choice that Nakamoto made when coupling proof of work civil resistance with longest chain consensus. Again, the first idea was just to force nodes to basically elect themselves as leaders through the search for solutions to a puzzle.
00:38:14.032 - 00:38:26.840, Speaker C: And then the second idea is like, okay, in addition to the puzzle solutions needing to hash to something small, let's also force the node to commit in advance to a single block and a single predecessor for that block.
00:38:27.740 - 00:38:29.464, Speaker B: So in other words, to have any.
00:38:29.502 - 00:38:40.524, Speaker C: Chance of being a puzzle solution. Little X, it must have a form where we can think of it as kind of having a number of fields. We can think of it sort of as a tuple, which in particular specifies the two B choices.
00:38:40.524 - 00:38:44.496, Speaker C: So it should encode a block, capital B, and then a predecessor block, which.
00:38:44.518 - 00:38:45.920, Speaker B: I'm just going to call pred.
00:38:48.800 - 00:39:08.752, Speaker C: Here I'm using the two parallel lines as a separator. You can think of it as concatenation if you want, I'm not going to discuss here kind of representation issues. So you might ask the question, how exactly is the block encoded? Actually in practice? Usually you don't actually encode the whole block, you just encode kind of a commitment to a block, something known as a root of a merkel tree.
00:39:08.816 - 00:39:09.956, Speaker A: We'll get into the details of that.
00:39:09.978 - 00:39:26.660, Speaker C: Later when we do deep dives on bitcoin and ethereum. Similarly, you can ask exactly in what way do you specify a predecessor block get in practice? That's going to be something like the hash of the block header of the corresponding block. Again, those are all details we'll get into later when we talk about specific protocols.
00:39:26.660 - 00:39:37.420, Speaker C: But conceptually you just want to think about little X as encoding those step two B choices. So a block capital B, that's really part of the proposal and the predecessor for that block.
00:39:38.320 - 00:39:40.648, Speaker A: Let's also think of a possible puzzle.
00:39:40.664 - 00:39:43.470, Speaker C: Solution, little X as encoding a public key.
00:39:44.320 - 00:39:45.756, Speaker B: So if you're a node and you're.
00:39:45.788 - 00:39:50.736, Speaker C: Sort of trying different little X's, you're searching for a puzzle solution. You have maybe multiple public keys just.
00:39:50.758 - 00:39:52.624, Speaker A: In any of your, in a given guess.
00:39:52.662 - 00:39:56.130, Speaker C: You just put in one of the public keys that you own. It doesn't matter which one.
00:39:56.660 - 00:39:57.956, Speaker B: The way this sort of shows up.
00:39:57.978 - 00:40:15.620, Speaker C: In practice, it's pretty indirect to be honest. What we're going to see is that nodes that are searching for puzzle solutions are going to want to get credit for any puzzle solutions that they find. That's because as we'll talk about starting in lecture number ten proof of work, blockchains generally use block rewards to motivate nodes to search for puzzle solutions.
00:40:15.620 - 00:40:29.772, Speaker C: So given that there's a reward, you want to make sure that you get credit for it. So that's why you're going to be including your public key as part of your guess little X. So those are some key ingredients in what a guest little X has to look like.
00:40:29.826 - 00:40:32.076, Speaker A: So remember, in addition to satisfying these.
00:40:32.098 - 00:40:47.344, Speaker C: Formatting constraints, little X has to hash to something small. Remember, we're throwing sort of darts at this dartboard with a very small bullseye, which means nodes in their quest for a puzzle solution would presumably be trying lots of different choices for capital B and for pred and or for the public key.
00:40:47.462 - 00:40:49.332, Speaker A: And it's convenient to just say, okay.
00:40:49.466 - 00:40:54.596, Speaker C: Given that a node is going to wind up grinding through like multiple sort of guesses for little x.
00:40:54.698 - 00:40:58.448, Speaker A: Why don't we just also include a field which is just kind of bits.
00:40:58.464 - 00:41:07.880, Speaker C: That have no meaning, they're really just the degrees of freedom for the node to experiment with when trying to get sort of its guess, little X to hash to something that's at most tau.
00:41:08.220 - 00:41:09.988, Speaker B: So those sort of additional bits, the.
00:41:10.014 - 00:41:15.870, Speaker C: Additional degrees of freedom, those are referred to as a nonce here, nonce stands for number used once.
00:41:22.230 - 00:41:23.458, Speaker B: So the way to think about, you.
00:41:23.464 - 00:41:29.714, Speaker C: Know, what nodes are actually doing, nodes that are running a protocol that uses proof of work, civil resistance, is they.
00:41:29.752 - 00:41:31.046, Speaker A: Sort of decide once and for all.
00:41:31.068 - 00:41:41.866, Speaker C: On the block of transactions that they're trying to add. They decide once and for all for the predecessor block of the block it's proposing. They decide once and for all, sort of which of its public keys it wants to use.
00:41:42.048 - 00:41:44.134, Speaker A: And then with those three fields fixed.
00:41:44.182 - 00:41:59.062, Speaker C: It just kind of grinds through possible options for the nonce. So every sort of different nonce right, is a sort of fresh 256 bits out of shot, 256 at least under our random oracle assumption. Every sort of choice of knots is sort of a new throw of a dart to this dartboard.
00:41:59.062 - 00:42:07.650, Speaker C: And with B pred and PK fixed, you're trying to find the nonce that leads you to hit the bullseye, that leads the whole thing to hash to something that's at most tau.
00:42:08.310 - 00:42:10.658, Speaker B: And so one really nice property we.
00:42:10.664 - 00:42:23.590, Speaker C: Get, at least under the random Oracle assumption, is that just because you solve a puzzle once, that doesn't really mean anything about other puzzles you might want to solve. So having one puzzle solution is no help in finding another. You really have to sort of start over from scratch.
00:42:24.330 - 00:42:26.118, Speaker B: And so this is what justifies what.
00:42:26.124 - 00:42:50.702, Speaker C: We said was that sort of third difference about longest chain consensus with proof of work civil resistance, the fact that we can actually force Byzantine nodes to not send conflicting block proposals in a given round, we can force them to only make a single block proposal. And that's exactly because just because you sort of make one block proposal, meaning you found sort of an X that has a particular block B one in the first field that hashes to something at most tau. That doesn't help you at all.
00:42:50.756 - 00:42:52.478, Speaker A: Finding another X with B two in.
00:42:52.484 - 00:42:57.258, Speaker C: The first field that hashes to something that is at most tau. You really have to start over from scratch.
00:42:57.354 - 00:42:58.258, Speaker A: And so that's going to be a.
00:42:58.264 - 00:43:06.674, Speaker C: New puzzle solution and by definition, that's going to be a new round. So really just by virtue of requiring puzzle solutions to have this form, so.
00:43:06.712 - 00:43:11.862, Speaker A: That means that any leader of a round, it had to exhibit a legitimate little X.
00:43:11.916 - 00:43:20.950, Speaker C: So it has to propose just one block. It can try to propose another one later, but that's going to be another puzzle solution and that's going to happen in a different subsequent round.
00:43:21.450 - 00:43:22.842, Speaker B: So you now have a very strong.
00:43:22.896 - 00:43:34.746, Speaker C: Conceptual understanding of exactly how proof of work actually works. In the next video, in the third video of lecture number nine, we're going to talk about the properties of proof of work. So we're going to prove its civil resistance property, and then we're also going.
00:43:34.768 - 00:43:36.666, Speaker A: To connect that property back to the.
00:43:36.688 - 00:43:43.458, Speaker C: Discussion of a permissionless magenta box that we need to get the finality and liveness guarantees that we proved in lecture number for eight.
00:43:43.544 - 00:43:45.150, Speaker B: So I'll see you there. Bye.
