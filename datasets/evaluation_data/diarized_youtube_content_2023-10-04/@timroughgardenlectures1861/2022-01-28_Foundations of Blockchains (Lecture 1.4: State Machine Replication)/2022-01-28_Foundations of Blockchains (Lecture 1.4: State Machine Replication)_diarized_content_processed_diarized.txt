00:00:00.570 - 00:00:59.790, Speaker A: Okay, so in this final video belonging to lecture one, I want to start introducing some of the vocabulary we'll need to start to start discussing the correctness of consensus protocols, which we'll study in earnest beginning next lecture and lecture two. So in this lecture series, we'll see a few different notions of consensus, probably at least three different problems of consensus here. I want to start with the one that's most immediately relevant in a blockchain context text, which is known as the SMR or state machine replication problem. Now, if you're thinking that state machine replication sounds like a kind of old school name, you'd be right. It was definitely studied as early as the 1980s. And in fact, as we'll see, computer scientists in the 1980s had a very different motivation for defining this problem than we're going to have in a blockchain context. And it kind of actually blows me away that this problem definition, which preceded blockchains by 25 plus years is so immediately relevant.
00:00:59.790 - 00:01:47.120, Speaker A: Honestly, I think it sort of speaks to the power of abstraction and the power of sort of theoretical work, where if you really tease out the essence of what makes a problem hard, good chance that many decades later there's going to be a new technology where the essential difficulty of it will again be the same as the one you identified many decades before. All right, so what does state machine replication refer to? Well, let's take it in two steps. Let's talk about state machines and talk about replication. So state machine, you should think here just about like if you've ever studied finite automata, that's the kind of thing you should be thinking about. You should be thinking of there's a bunch of different states that a machine could be in. Whenever it kind of processes a message or whenever it executes an instruction, there's potentially a straight state transition. So it goes from one state to another state.
00:01:47.120 - 00:02:32.010, Speaker A: A canonical example of the 1980s would be you're working with a database. You can think of a database as sort of a state machine where the possible states are the possible contents of the database. And whenever, for example, someone does a write or an insert to the database, that's going to be a state transition because it changes the state of the database. So in a blockchain context, for concreteness, you could think about the state encoding the current balance in the native cryptocurrency of all of the users of that blockchain. As we'll see for a lot of blockchains, state will be something more general than that, but that'd be a concrete example of what state would mean for us just account balances. And then obviously, whenever anyone makes a payment transfer some currency, that's going to change the state. So that's going to be a state transition.
00:02:32.010 - 00:03:27.278, Speaker A: And so the little cartoons that you often study when you study finite automata is you write down a bunch of circles, so vertices of a graph which correspond to states, then you have a directed edges which correspond to state transitions. And maybe you label those edges with the sort of conditions under which you make that state transition, like receiving a particular message or some other kind of event. So that's the state machine part of SMR. So what about the replication part? Well, let me again sort of tell you the kinds of things they had in mind in the 1980s when they coined this term. And let's again use the database example. So imagine maybe you're a big company, you're IBM or something like this, and you have some database that some customers of yours, you'd like them to be able to use it so they can issue queries to the database, maybe they can even insert stuff into the database, whatever. And imagine you actually want to provide them with super high uptime, very close to 100%, 99.99%
00:03:27.278 - 00:04:16.178, Speaker A: uptime. You're not going to be able to achieve that uptime with just sort of a single machine running the database because machines fail with some probability that's bigger than zero 1%. So a natural way to boost the uptime would be to have replicas of the database multiple copies. They're all the same. The point is just that when one of the copies crashes, maybe there's sort of a hurricane, you have a different server in a different part of the world, which you can route clients requests to instead. So replicating something with the goal of higher uptime, that's a very natural idea. Of course, as soon as you have multiple copies that are supposed to be in sync, you've got a consensus problem, right? You really want from the customer perspective, from the client perspective, you want it to be logically as if there was just one copy of the database.
00:04:16.178 - 00:05:02.886, Speaker A: So it better not be the case that if you ask copy number one you get one answer and you ask copy number two you get a different answer, right? That would be a total disaster. That means you're really not simulating a single database if the answer depends on who you ask. So that was their state machines databases. That was one example of what they had in mind with a state machine and what they had in mind for replication. Now, in a blockchain context, replication does help with uptime. But there's another completely different goal of replication in permissionless blockchains, which is sort of decentralization, something I'll leave safely undefined. But remember I said the functionality we're looking for is a big programmable computer in the sky which is not operated by any one entity, it's really operated by thousands or tens of thousands of nodes.
00:05:02.886 - 00:05:40.498, Speaker A: And you can be one of those nodes if you want. So that's replication. So all of these nodes running the protocol, they will all be replicating the same sequence of instructions and it's so that none of them is a sole owner of the state and of the computation that's being done on that state. So again, I think it's kind of amazing that basically the same formalism is equally relevant both to sort of an old school problem like replicating a database and a new school problem like running a permissionless blockchain. Very cool. All right, so let me tell you what the SMR problem actually is. So I want to distinguish between two types of parties.
00:05:40.498 - 00:06:42.630, Speaker A: So first of all, we're going to have nodes who are actually sort of running a protocol that actually want to stay in sync with each other, but then there's also going to be clients or customers or users. So these are entities that aren't necessarily running the protocol, they're not necessarily running the node, but they'd like to either sort of read the state or change the state in some way. And so again, in the database context this would just be a database customer who's sort of issuing a reader right to the database. In a blockchain context, this would be just a user of a blockchain like Bitcoin or Ethereum issuing a transaction, for example, a payment from themselves to somebody else. So in a blockchain context, the messages that clients send to the nodes running the protocol, I'm going to refer to them as transactions. For concreteness, you can think of a transaction as a currency transfer from one party to another party. In more general smart contract platforms, potentially a transaction represents something much more complicated, like for example, a function call to a smart contract, which then might in turn launch a bunch of different function calls to other smart contracts, et cetera.
00:06:42.630 - 00:07:25.702, Speaker A: So we're going to refer that to as a transaction. That is a message being sent from the client to one or more of the nodes running the protocol. So what are the nodes responsible for doing? Well, each of them is going to maintain locally an appendonly data structure. So a data structure that you can stick stuff up at the end but you can never take, stuff you can never delete from. And what gets stored in this data structure are transactions that have been submitted previously by clients. So in effect, each node is maintaining locally an ordered sequence of transactions. Notice that I will sometimes abbreviate transaction by TX and transactions by TXS append only data structure is kind of a mouthful.
00:07:25.702 - 00:07:51.778, Speaker A: So I will just call each of these things a history for short. So each node is going to have its own local history which represents an ordered sequence of transactions. It's very common that you'll hear people call what I'm calling a history. People will call it a ledger. I'm going to stay away from the word ledger because to me it too strongly connotes payments. And as I said earlier, for us, blockchains are not really about payments per se. That's kind of a very narrow use case.
00:07:51.778 - 00:08:28.458, Speaker A: We're going to be interested in much more general functionality. So I'll use this much more generic term of just a history to mean an ordered sequence of transactions. And so now what would we like to see happen? We would like to see all of these nodes have identical local histories. That's what we mean by keeping them in sync. And remember, fundamentally consensus means keeping a bunch of different nodes in sync despite potentially failures, delays and attacks. One thing to notice is I keep talking about the ordered sequence of transactions. I talk about histories as ordered lists.
00:08:28.458 - 00:09:20.906, Speaker A: And notice if you think about the applications I just told you about, the order is really important, right? That was already true in the database example, right? If you have like two different clients submit conflicting writes rights to the same variable, it really matters which of them gets executed first and which of them gets executed second. And it's even starker in the blockchain context, right? Because maybe you have sort of two different know, one spends a coin and gives it to Alice, the other one sends that exact same coin to Bob. Then obviously the order in which those transactions are executed matters a lot. Whichever one comes first will actually get the transfer of the coin. Whichever one comes second will fail because that coin will have already been spent. So very important that all of the nodes, all of the histories, they're an ordered sequence of transactions. All right? So that's informally the problem, right? So clients are sort of sending transactions to these nodes.
00:09:20.906 - 00:10:23.102, Speaker A: We want to keep the nodes in sync, meaning they should have identical local histories, local orders of transactions. Now what would a solution to the SMR protocol? What form would it take? Well, it's going to take the form of a protocol. I'm not going to burden you with an overly formal definition of a protocol, especially because we're about to see zillions of examples in the next four lectures or so. So it'll be very clear over time what I mean by a protocol. But let me just give you kind of a very just to sort of orient you give you a sort of very high level description of what I mean by a protocol. So a protocol, it's really just going to be a piece of code that each of the nodes runs locally and you should think of it as sort of event driven code, right? So there's going to be basically a bunch of functions and it's sort of like when one event happens that will trigger one of those functions which will then do some stuff. So what kind of stuff might a node do in response to some event? An event here being like maybe you sort of receive a message from a different node, maybe you receive a new transaction from client.
00:10:23.102 - 00:11:05.614, Speaker A: Well in response to an event like that receiving a message, you might want to sort of do something with your local state. Maybe you add a new transaction to the end of your history. Or you may want to send some messages yourself, like you may want to compare notes with your fellow full nodes. So that's the way you should think about life in the day of a node who's running a protocol, right? I mean, you're receiving messages both from other nodes and from clients. You're potentially sending messages out to other full nodes in response. You're generally not sending messages to clients, but you're going to be sending messages to other nodes and you might be doing local computation sort of on top of that. So that's what a potential solution to the SMR problem looks like.
00:11:05.614 - 00:11:41.546, Speaker A: It looks like a piece of code. It looks like a protocol. So instructions for what each node is supposed to do as it receives messages and as the results of its local computations. All right, so next. Now given such a protocol, when should we say that it solves the SMR problem? Like, what does it mean? This question is a lot harder to answer for sort of a distributed protocol that runs forever than it is to say, Dijkstra's shortest path algorithm. If you have an algorithm that's just going to be run once on one input, it's kind of like, well, the algorithm either returns the shortest path or it doesn't. So it's either correct or it's not.
00:11:41.546 - 00:12:23.226, Speaker A: Whereas these protocols, they're sort of running forever and it's not like there's some single output at the end. So we need to think a little harder about what it means to correctly solve a consensus problem like SMR. All right, so let's be a little more formal about what we want, what's required to be deemed a solution to the SMR problem. So generally distributed protocols like this one talks about liveness properties and safety properties. And liveness properties have the form something good eventually happens. And so for different things you might want to have happen, you get different liveness properties. Safety says that bad things never happen.
00:12:23.226 - 00:13:08.992, Speaker A: And again, you can have different types of safety properties depending on which bad events you're looking at. And so here we're going to have one liveness property and one safety property. Let's start with a safety property, which we're going to call consistency. And consistency is really just what we've been talking about all along, keeping the nodes in sync, meaning that their local histories should match up. In fact, we're going to be satisfied with something a little weaker than that. We're not going to insist that all of the machines sort of add transactions to their histories 100% in lockstep because remember, I mean, these nodes are potentially scattered all over the globe. There might be a node like in Siberia that just gets messages much later than anybody else.
00:13:08.992 - 00:13:56.560, Speaker A: So we want to allow that some machine might lag behind, okay? And if we wait a while it's going to catch up. But in any given snapshot in time, it might be a little bit behind the others. So we're going to be fine with that as long as the laggard's history is a prefix of the history of everybody else. Okay? So more formally, for any pair of nodes it should be the case that either they have identical histories or one of them should have a history that's a prefix of the other one. So the thing which is really never, okay, the stuff that we never want to have happen is that two different nodes order a pair of transactions in opposite ways. Okay, that's the bad event we want to make sure never happens. Okay? So that's why this is a safety property and we're calling it consistency.
00:13:56.560 - 00:14:31.070, Speaker A: Now if the only thing we cared about was consistency in this sense, consensus or SMR would not be a hard problem. Want to know a really easy way to make sure that all of the nodes always have the same history? Never add anything to anybody's history. Literally do nothing. All the nodes will always have the empty sequence and will always be in sync. Obviously that's not what we have in mind. So we need to impose another constraint on the protocol to qualify as a solution. And this is going to be the Liveness property.
00:14:31.070 - 00:15:05.636, Speaker A: So we're going to just want to say that transactions that are submitted by clients eligible to be added should eventually be added. So when there's work to be done, the nodes actually should do it. So the word valid here in the Liveness definition, I mean that depends a little bit on the details of the blockchain that you're talking about. But you can think of things like it should be digitally signed by the sender. If it's a currency transfer, there should be sufficient currency in that user's account, et cetera. Okay? So that's what I mean by any transaction which is sort of eligible for inclusion. Like it is a sensible thing.
00:15:05.636 - 00:15:39.820, Speaker A: You could add anything that's valid in that sense should eventually get added by some node which then by consistency means it's going to get added by all of the nodes. Of course one might like an even stronger version of liveness. You might like concrete bounds on how long it takes a message to be added and we will probably see some examples of that later in the lecture series. All right, so this is a nice milestone. We've specified what it is we want, at least for now, what it is we want. We want to solve the state machine replication problem. And by solve we mean we want a protocol that satisfies both the consistency condition.
00:15:39.820 - 00:16:33.788, Speaker A: So all of the nodes in sync, maybe some are lagging behind, but there's never any disagreements over the orders of transactions and that's also live. So that also does work whenever there's work to be done. So the question now is anyone can make a definition, but it's not a foregone conclusion that there's anything that satisfies the definitions. So you should be asking the question like is there or is there not a protocol that solves SMR in this sense that is live and is consistent? What we're going to see over the next four or so lectures is the answer to that question. The possibility or impossibility of SMR protocols will depend on the assumptions that we make. There are two main types of assumptions that govern whether or not there exist consensus protocols with these two properties. One genre of assumptions is about the underlying communication network, to what extent there are delays or outages or denial of service attacks.
00:16:33.788 - 00:17:34.070, Speaker A: So we'll need different models of sort of how reliable the communication network is. And then the other genre of assumptions, which is super important to know if things are feasible or infeasible, is how many of the nodes we can count on operating correctly. Okay, so staying up executing the updated and correct version of the protocol and not being controlled by some adversary that wants to mess up the protocol. So we're going to see that under sufficiently strong assumptions about the communication network and under sufficient bounds on the adversary's power, we will in fact be able to solve the SMR problem in this sense with a protocol that is both live and consistent. So we'll look at our first result of that type in the next lecture, in lecture two, a famous protocol from the early 1980s by Dolev and Strong, which solves this problem in the context of a synchronous network model where you do not have kind of unbounded unexpected delays. So that's coming up in lecture two. I look forward to seeing you there.
