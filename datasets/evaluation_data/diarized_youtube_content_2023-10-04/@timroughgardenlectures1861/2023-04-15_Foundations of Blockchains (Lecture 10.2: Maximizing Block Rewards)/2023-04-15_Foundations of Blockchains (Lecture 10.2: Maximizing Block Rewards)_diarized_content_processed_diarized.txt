00:00:00.490 - 00:00:41.994, Speaker A: All right, so let's go ahead and focus on the setting of Nakamoto Consensus. So longest chain consensus, along with proof of work sybil resistance. Let's go ahead and assume that there's a fixed block reward analogous to the six and a quarter bitcoins per block that you have today in the bitcoin protocol. So for each block that winds up sufficiently deep in the longest chain, I. E. Each finalized block the creator of that block is going to be and some fixed block reward. In a perfect world, we'd be able to say that nodes are incentivized to just honestly follow longest chain consensus, so to just sort of create blocks that extend the current end of the longest chain and announce those blocks immediately to everyone else.
00:00:41.994 - 00:01:40.100, Speaker A: And at first, if you think about it, it's kind of like, what's the problem? I mean, didn't our sort of civil resistance, property of proof of work kind of say there's nothing you can do, right? If you have an alpha fraction of the overall hash rate, you simply have an alpha probability of being the person to create the next block. And here's the key point. While it's true that in Nakamoto Consensus, if you have 10% of the overall hash rate and as usual making a random oracle assumptions and so on, you will be creating ballpark 10% of the blocks that get created. But here's the thing. Rewards are only doled out for blocks that get finalized. Blocks that wind up on the longest chain, sufficiently deep in the longest chain. Blocks that get orphaned do not get a block reward.
00:01:40.100 - 00:02:25.434, Speaker A: So the worry then would be that some nodes might get their blocks orphaned at a higher rate than others. If so, then we've got an issue, because a node whose blocks are getting orphaned at a higher than average rate is going to be earning a less than expected fraction of the overall rewards. To make this a little more concrete, let's just sort of page back in how difficulty adjustment works. In Nakamoto Consensus. We have proof of work, civil resistance. So in proof of work, you have these difficulty parameters. It's what we were calling tau in lecture number nine.
00:02:25.434 - 00:03:32.222, Speaker A: And the question is, how should you set tau? And what I've been saying is that generally you set tau to target a given rate of block production. Like, for example, in the bitcoin protocol, famously, tau is tuned, so the average rate of block production is one block every ten minutes. Except I'm being a little imprecise there, right? And we talked about this a little bit in lecture nine, actually. You're tuning it to target a particular rate of growth of the longest chain. For example, in the blockchain protocol, the difficulty parameter is adjusted periodically, meant to be roughly every two weeks or so. Now, if one block is being added to the longest chain every ten minutes, then over a two week period, you expect there to be 2016 blocks added to the longest chain. So every time sort of the height of the longest chain grows by 2016, the bitcoin protocol says, oh, well, how long did it take to produce these 2016 blocks? By looking at the timestamps in the blocks? And if it took a long time, if it took more than two weeks to produce those 2016 blocks on the longest chain, well, that means that the puzzles are too difficult.
00:03:32.222 - 00:04:05.158, Speaker A: So you make them easier. You increase the difficulty parameter tau. If you created 2016 blocks faster than expected, meaning in less than two weeks, then the puzzles will too easy. So you decrease the difficulty threshold tau to make them harder. But the point is that the difficulty parameter is being sort of adjusted, constantly tuned, so that 2016 blocks get added to the longest chain every two weeks. That does not speak about the number of blocks produced. That might not be on the longest chain.
00:04:05.158 - 00:04:43.750, Speaker A: Maybe nothing was orphaned. There were only 2016 blocks total during those two weeks, and they all wound up in the longest chain. Or maybe 3016 blocks were produced during those two weeks, 1000 of them were orphaned, and then 2016 wound up on the longest chain. From the perspective of difficulty adjustment, it does not matter. All that matters is the growth of the longest chain over a two week period. Block rewards, remember, are also doled out only to the blocks on the longest chain and not to the blocks that get orphaned. All right? Sometimes you see sort of variations on that, like the pre merge version of Ethereum did something more complicated, but whatever.
00:04:43.750 - 00:05:36.038, Speaker A: Pretty much all the Nakamoto Consensus protocols that are around now, they reward the blocks on the longest chain. They do not reward the blocks that are not on the longest chain. So if the longest chain is growing at a predictable rate, given that that's what the difficulty adjustment algorithm is meant to do, so like 2016 blocks every two weeks, then the total amount of rewards being doled out is also growing at a steady rate. So again, for example, in bitcoin, every two weeks, you would expect 2016 times six and a quarter bitcoins, so 12,000, and change bitcoins to be doled out in each two week period. Another way to think about this is there is just some fixed size pie. Again, for example, every two weeks there's a pie that has ballpark 12,000 bitcoins in it. So if you want to be maximizing your rewards, that is the same thing as maximizing your slice of the pie.
00:05:36.038 - 00:06:46.842, Speaker A: Again, the pie is fixed by difficulty adjustment. There's nothing you can do about it. All you can do is try to give yourself as big a slice of the pie as possible. Now, you might hope that this pie is just being split proportionally amongst the nodes according to the hash rate, right? So if you're a node, you have 10% of the hash rate just by the nature of sort of proof of work. Under the random oracle assumption you're producing 10% of the blocks and hopefully that means you have 10% of the share of the longest chain. But again is that really true? We're going to have to think a little harder about that, right? Could it be that some very sort of devious node could somehow get even though they have 10% of the hash rate is there some way they could guarantee themselves like 12% of the blocks on the longest chain? And the key takeaway of this lecture is that in fact, and this is not necessarily intuitive or easy to see, in fact the answer is yes. So if you assume that all of the other nodes are just sort of honestly following the longest chain protocol, there exists a deviation that you can make that boosts your share of the rewards beyond just your fraction of the hash rate.
00:06:46.842 - 00:07:37.410, Speaker A: So you might have 10% of the hash rate but there is a sort of deviating strategy that will get you for example, like 12% say, of the blocks on the longest chain. So the types of deviations we're going to be talking about in this lecture they often go by the name selfish mining. The word selfish here hopefully self explanatory. Right now that we have block rewards of meaningful economic value we're not going to treat nodes as just sort of obediently following the protocol. Rather we're going to treat them as profit maximizing nodes so that's the sense in which they're selfish mining is kind of just a word used for block production that's often used in the context of Nakamoto Consensus, in the context of proof of work because nodes are sort of working hard to be able to produce a block. It's kind of like sort of digging for gold or mining for gold in some sense. So mining here just refers to block production in a proof of work system.
00:07:37.410 - 00:08:25.836, Speaker A: Another way to phrase the key takeaway of this lecture which for those of you who like game theory is we're basically going to show that Obediently following Nakamoto Consensus does not in general constitute a Nash equilibrium. Nash equilibrium. Remember that's kind of an outcome where all of the participants in the outcome, none of them have an incentive to deviate unilaterally. So something is not a Nash equilibrium then if one of the participants does have an incentive to deviate unilaterally and that's exactly what we're going to show. We're going to show that if we consider the outcome in which all of the nodes are just obediently following the protocol in general there will be a node that has an incentive to deviate unilaterally. It can get higher rewards by not following the protocol Obediently. So this result you're not supposed to find this obvious or intuitive or easy to see.
00:08:25.836 - 00:09:11.436, Speaker A: It may well in fact run counter to your intuition. That's normal. Certainly when this was first discovered it surprised a lot of research in the area. It also seems Nakamoto did not anticipate this. Nakamoto doesn't state this explicitly in the Bitcoin white paper, but the writing suggests that Nakamoto probably believed that following the protocol would constitute a Nash equilibrium because of the incentives provided by the block rewards. Now, I don't think anyone would call this a fatal flaw of, for example, the Bitcoin protocol, which has been happily humming along for over 13 years at this point. And we'll discuss that in the final video of lecture Ten a little bit about how you should interpret these results and the practical implications of them.
00:09:11.436 - 00:10:11.068, Speaker A: But primarily this result will serve for us as kind of a proof of concept or, if you like, sort of a cautionary tale, showing that even when you may have strong intuition that the incentives in your system motivate the participants to behave as you intend them especially if you have a very rich strategy space of possible deviations, as we do here. If you have a rich space of deviations, it's often not the case. There's often something even more clever that participants could do, which is not what you intended and perhaps also not what you want. So just to sort of orient you about sort of where we're going for the rest of this lecture, we're basically going to keep establishing this takeaway in kind of more and more robust and satisfactory ways. So we're going to start on the next slide with just sort of a warm up. It's going to be kind of unsatisfying. It's going to be a very extreme case where we think of a scenario where there's one huge node, so a node that has more than half of the hash rate and we're going to show that it can definitely do things that are better for itself than just obediently following the protocol.
00:10:11.068 - 00:10:59.580, Speaker A: That's not super satisfying, but it'll help us develop correct intuition about what's going on. Then we'll move on to a case where we do not assume that any of the nodes are big. They don't have to have big hash rate, but we will sort of assume that honest nodes break ties between longest chains in an adversarial manner, which will also be like a little unsatisfying. And then the hardest result that we'll look at will be we'll say that even actually, if tiebreaking is done in the best possible way by honest nodes, there are regimes in which it's still the case that you have this takeaway. It's still the case that nodes, nodes that are left less than 50% of the hash rate actually are incentivized to do something other than obediently following the protocol. Okay, so that's the plan. We're going to just sort of step up to more and more robust and satisfying versions of this key takeaway.
00:10:59.580 - 00:12:03.240, Speaker A: So before we get to the first of those variants where we have a 51% node, let me just sort of pause and make sure we're all clear on the model and some of the key assumptions. Basically the model is exactly the same as the model that we've been using the last couple of lectures in particular, think about lecture eight where we first started talking about longest chain consensus and we proved sort of security, we proved consistency and liveness properties for it. Basically it's going to be the same set of assumptions funnily enough, because here we're proving negative results rather than positive results. The pros and cons of the various assumptions will sort of be flipped but the model is going to be quite familiar from lecture eight. So the first assumption is going to concern the communication network and we are going to be working in what, in lecture eight and nine we were calling either the supersynchronous model or the instant communication model. So we worked with this assumption for almost all of lectures eight and nine. We did have that one video sort of late in lecture nine that relaxed the results to the more general synchronous model with a finite but nonzero maximum message delay delta.
00:12:03.240 - 00:12:42.412, Speaker A: And in lectures eight and nine this assumption kind of really bothered us. It was sort of for convenience, for pedagogical reasons so we could focus on the key ideas. But we knew communication networks are not perfect, we know there's nonzero message delays and so we certainly weren't content to have proofs of consistency and liveness in this model. And that's why it was very important that we worked hard to relax it to the more general synchronous model. Now here we're not proving possibility results, we're not proving good things about longest chain consensus. We're proving a bad thing about longest chain consensus that honest behavior doesn't constitute a Nash equilibrium. So this actually only makes the results of this lecture stronger.
00:12:42.412 - 00:13:51.680, Speaker A: So we're going to be arguing that even with a perfect communication network, even where the honest nodes sort of all can sort of communicate by telepathy, even then nodes have an incentive to not be honest and instead deviate from intended behavior. The second assumption, also familiar from lecture number eight, concerns the behavior of honest nodes when there's ambiguity about what block they should be extending, right? So they're supposed to extend the end of a longest chain with their block. If there's more than one longest chains we're going to allow them to choose arbitrarily. So there will be arbitrary tiebreaking amongst longest chains by honest nodes. And for the analysis that in effect means that the tiebreaking can be carried out by an adversary because we're making absolutely no assumptions about how it's done. Now back in lectures eight and nine we took a lot of pride in this assumption, right, because we were proving good things about longest chain consensus like consistency and liveness. And we were very proud of ourselves for proving those guarantees, making no assumptions whatsoever about how honest nodes might break ties among competing longest chains.
00:13:51.680 - 00:14:18.396, Speaker A: We basically said we are uninterested in any proof of consistency or liveness such important properties. We don't want any proof that somehow relies on delicate properties of the tiebreaking rule. That somehow an artifact of the tiebreaking rule that was not good enough for our purposes. So we never tried to relax this assumption in lectures eight and nine because we were very happy to have it. Now here in lecture ten, once again the tables are turned. We're proving something bad about longest chain consensus. Not good.
00:14:18.396 - 00:15:03.960, Speaker A: We're proving that honest behavior is not in general an ash equilibrium that a node. If all the other nodes are being honest, a node generally has an incentive to deviate from the intended behavior. And as you'll see, we're going to have three versions of this key takeaway. In the first two of those three versions we are going to be exploiting the fact that the node that's deviating from honest behavior also in effect can sort of control how the other nodes break ties amongst longest chains. And that's going to be a little unsatisfying in the first two versions of this key takeaway. It's going to maybe feel like the lesson of the lecture is kind of an artifact of this kind of adversarial tiebreaking, which seems like not that realistic. But in the third and hardest version of this key takeaway, we will actually relax.
00:15:03.960 - 00:15:53.670, Speaker A: Assumption two, we'll relax it actually as much as you could possibly imagine where honest nodes basically break ties in the way that's best for themselves and worst for the node that's pondering a deviation. All right, so hopefully clarifies the model that we're working in and also sort of where we're going for the rest of this lecture. So now let's move on to the first of the three versions of this key takeaway that we're going to talk about, and again for a warm up, we're going to talk about sort of an extreme case where you have one really big node, a node that has more than 50% of the overall hash rate. And we'll see that at least in that extreme case, for starters, definitely that node is not incentivized to just obediently follow low longest chain consensus. So you'll see why in the next video. I'll see you there. Bye.
