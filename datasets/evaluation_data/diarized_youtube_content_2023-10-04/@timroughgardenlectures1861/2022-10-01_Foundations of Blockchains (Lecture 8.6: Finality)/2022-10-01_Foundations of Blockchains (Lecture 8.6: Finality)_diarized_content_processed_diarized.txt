00:00:00.330 - 00:00:45.256, Speaker A: Let's move on to the second consequence of the W balance condition, which is finality of longest chain consensus. And I'm sure after the last video you'll be pleased to hear that this proof will be really pretty short. This will be just a sort of short and sweet reduction back to what we already did in theorem one. All right, so let me remind you of the statement of theorem two. The finality property hypothesis, exactly the same as in theorem one is for the common prefix property. We're going to assume that we have a two k balanced leader sequence, just like in the in the last result, if you are paying careful attention, you'll notice we only need to assume quantity two k plus two balanced. But whatever, let's work with two k balanced among friends.
00:00:45.256 - 00:01:26.428, Speaker A: Don't forget what this means. A leader sequence is W balanced if in any window of at least W consecutive leaders, a strict majority of them are honest. So strictly less than 50% of the leaders in any length W or bigger window, strictly less than 50% can be Byzantine. Now for finality, we really want to track the entire evolution of longest chain consensus. So initially all there is is the genesis block and then new blocks keep getting added one by one. Multiple blocks might get added in the same round by a Byzantine node. But just think of those blocks as being added one at a time.
00:01:26.428 - 00:02:09.620, Speaker A: And then we get a sequence of entries, each with exactly one more block than the previous one. So when we say for any possible outcome sequence, we mean the same thing that we meant in theorem one. So if we fixed the leader sequence, what are the indeterminates? Well, we don't know what Byzantine nodes are going to do. They might do deliberate forking attacks, they might delay the announcements of the blocks they created, whatever. So we want to say no matter what the Byzantine nodes do and then also no matter how the honest nodes break ties among competing longest chains, remember, we don't want to assume anything about the behavior of honest nodes tie breaking. So that's what we're quantifying over when we say for any possible outcome sequence. And the conclusion is going to promise us finality.
00:02:09.620 - 00:03:03.290, Speaker A: So specifically, once a block is not only on the longest chain, but has also been extended at least k times on the longest chain, at that point we can safely regard that block as finalized with no possibility of ever being rolled back in the future. Again, this is assuming that the leader sequence is two k balanced. So mathematically, if we look at the sequence b sub k of g sub I, so the longest chain of the current graph with the last k blocks lopped off that set of blocks is only increasing over time. Blocks only ever get added to that set, they never get removed. So in that sense, if each honest node takes b sub k of the current g as its local history. Then again, under this balanced assumption, it is indeed an append only data structure. Things only ever get added, they never get ruled back.
00:03:03.290 - 00:03:37.184, Speaker A: Now keep in mind we are continuing to, for convenience, operate in the instant communication model or the supersynchronous model, where all honest nodes are assumed to always know the same thing. So that's why we can write g sub i. It's not g sub I from the perspective of a given honest node j, because we're assuming that all of the honest nodes see exactly the same entry. They all have exactly the same view of what the current entry capital g is. So remember, there's really two types of consistency. One type is consistency between different honest nodes. That part turns out that's not the hard part really, of analyzing longest chain consensus.
00:03:37.184 - 00:04:12.380, Speaker A: And so we've sort of assumed it away. And the hard part is actually self consistency, consistency with your future self. That's what's really kind of at risk in longest chain consensus. And that self consistency is exactly the promise of this theorem two. As we've discussed in previous videos, you can relax the sort of instant communication model. You can prove an analog of theorem two. That's basically the same for the general synchronous model with a known bound capital delta on message delay, at least assuming that the length of rounds are typically substantially bigger than capital delta.
00:04:12.380 - 00:04:32.816, Speaker A: So let's go on to the proof, which actually is quite short. We're just going to show that if theorem two is false, theorem one is also false. But we just proved that theorem one is true. So I guess then theorem two has to be true as well. And this proof is not too long. This slide will be much less crowded than the previous one. So like the proof of theorem one, let's proceed by contradiction.
00:04:32.816 - 00:05:37.424, Speaker A: Let's assume that it actually is possible that some block gets rolled back, meaning it is sort of confirmed I e belongs to b sub k of GI, for some graph GI, and then for some later graph g sub j. All of a sudden it's not part of b sub k of g sub j. All right, so what does this imply? Well, by virtue of being a member of b sub k of GI, it must be the case that little B actually belongs to every single longest chain, right? I mean, by definition this says it belongs to the common prefix of every longest chain. So in particular it belongs to every longest chain in g sub i. Meanwhile, by virtue of not belonging to b sub k of the later graph of the later entry g sub j, if you think about it, this block B must not be in any longest chains of g sub j, right? I mean, after all g sub j, it's later in the sequence. It has only more blocks than g sub i. So its longest chains are only longer than those in G sub I.
00:05:37.424 - 00:06:27.660, Speaker A: And so that means if the block little B belonged to any longest chain of the graph G sub J, it definitely would be more than K deep because it was more than K deep even in the shorter chains in G sub i. And if it was more than K deep on some longest chain, then little B would belong to the set B sub k of G sub J. So by virtue of not being in that set, it can't be in any of the longest chains in this later entry G sub J. Now I want you to think about the sequence of entries beginning with G sub I and concluding with G sub J. So for each entry in the sequence, it has one additional block relative to the previous one. I know that Byzantine nodes are allowed to create multiple blocks in the same round, but in our minds, we can sort of imagine sort of arbitrarily ordering those blocks and adding them one by one. So we get the sequence of entries.
00:06:27.660 - 00:07:15.340, Speaker A: G sub I is where it starts, g sub J is where it ends. One new block each time. Initially, Little B belongs to all the longest chains. At the end, Little B belongs to none of the longest chains. So there must be some transition point, call it G sub H, where for the first time there exists a longest chain in the graph which excludes this block Little B. So this is like the first point at which little B is about to get dislodged from a longest chain. All right, so what does this graph G sub H look like? Well, the block B is in there somewhere and we know that already in the entry G sub i.
00:07:15.340 - 00:08:10.990, Speaker A: At that point, Little B had been extended K or more times because it's a member of B sub K of G sub I. So in addition to this incumbent longest chain, this longest chain that includes the block Little B because it was already a longest chain in the graph G sub i, at this point in G sub H, by definition of H, there now is a new challenger, a new longest chain that excludes the block B. So this new longest chain is of course equally long to the old incumbent longest chain. And we can imagine tracing it back. Now, if you think about it, as we trace this new longest chain back, it's not going to ever hit the block Little B, right. Remember, this new longest chain excludes the block Little B. So that means when we trace past it from right, we trace it out from right to left, it's actually going to shoot past the block Little B.
00:08:10.990 - 00:08:57.810, Speaker A: If we keep tracing back from here and also in parallel trace back from Little B, at some point, they'll have a common ancestor, if nothing else, at the Genesis block. But that common ancestor is going to be before this fork, only one prong of which includes the block little B. This orange structure probably seems hauntingly familiar. This is the exact same orange structure that we talked about at great length in the last video, improving the common prefix property. And indeed the content of theorem one was that these orange structures cannot arise if you have a two k balanced leader sequence. And look at this orange structure. We have this black little b.
00:08:57.810 - 00:09:53.810, Speaker A: We knew it was extended at least k times on its own longest chain. So B, together with everything that extended it, that's a chain of length k plus one, this new challenging longest chain, right, it has to be just as long by virtue of not including B. The only way that's possible is if it disagrees with the old longest chain on at least the last k plus one blocks. It has a parallel block at the same height as B, and then it has parallel blocks also at all of the heights subsequent to B's height. So that gives us two longest chains disagreeing in their final k plus one blocks. That means B sub k of G sub H is not well defined, but we already proved in theorem one that it is well defined, at least assuming that the leader sequence is two k balanced, which is also what we're assuming here. So that's the proof of theorem two of the finality guarantee of longest chain consensus.
00:09:53.810 - 00:11:00.120, Speaker A: And, you know, short as the proof may be, I still think this is a pretty satisfying guarantee to prove about longest chain consensus. Because really, right when we first started talking about it, this idea of sort of embracing forks and kind of resolving forks and protocol, it was kind of obvious right away that finality might be an issue. Right. And certainly in particular like the blocks at the end of the longest chain, you certainly cannot consider finalized. They're very much still under negotiation that can be disrupted by a small number of Byzantine nodes. So what this finality guarantee assures us is that, well, at least if a block has been extended enough time so you're not just on the longest chain, but you've been extended K times, where K should match up with sort of the extent to which your leader sequence is balanced, then you actually can consider that block totally finalized. This is a promise that it's never going to get rolled back as long as your leader sequence is balanced to give you sort of a little bit of a forward pointer, kind of when we start talking about permissionless, consensus, both sort of the proof of work genre in lecture nine and the proof of stake genre in lecture twelve.
00:11:00.120 - 00:12:02.710, Speaker A: There we're going to be choosing leaders randomly. So there's always some probability that you're going to have a very unbalanced leader sequence, but sort of akin to what we saw in the fourth video of this lecture. With high probability, you're going to have a balanced leader sequence, and in that high probability event, you will have finality, right? So this theorem two will apply whenever the leader sequence meets the balance guarantee, which will happen 99% of the time. So in that sense, theorem two, with randomly chosen leaders gives you probabilistic finality. There's still the order of business of liveness. We really want to know that transactions that get submitted will eventually be confirmed, will eventually not only appear in a longest chain, but also will be extended by K blocks on a longest chain. So that's coming up next.
00:12:02.710 - 00:12:03.300, Speaker A: I'll see you there.
