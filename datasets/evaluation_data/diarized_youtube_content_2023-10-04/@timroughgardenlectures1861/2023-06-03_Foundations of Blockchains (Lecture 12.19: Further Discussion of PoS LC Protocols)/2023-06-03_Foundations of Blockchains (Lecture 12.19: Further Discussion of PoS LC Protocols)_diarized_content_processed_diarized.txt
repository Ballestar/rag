00:00:00.650 - 00:00:14.766, Speaker A: So that brings us to our third and final video about proof of Stake longest chain protocols. Also the last video of part three of lecture twelve. Now we saw in part two that proof of stake random sampling is not that easy.
00:00:14.766 - 00:00:28.034, Speaker A: We saw in the early lectures of this series that even permission to consensus is not that easy. We saw earlier in part three that putting them together, for example, with BFT type protocols was also not so easy. Still additional challenges.
00:00:28.034 - 00:00:44.490, Speaker A: And now finally, here proof of stake longest chain. It's somehow perhaps even a little bit more complicated. So we talked through a number of the issues in the last video, but all of those issues were there, even under this strong assumption that we have access to an ideal randomness beacon.
00:00:44.490 - 00:00:55.278, Speaker A: That of course is an unreasonable assumption. There aren't really ideal randomness beacons in the real world. So in any concrete deployment of a protocol you need to use some approximation of this.
00:00:55.278 - 00:01:14.834, Speaker A: Now you could going back to part two, the most advanced technique we talked about there was using kind of two phase protocols that involve verifiable delay functions. That may well be the right way going forward, we'll see. But speaking right now in early 2023, it's a fairly experimental, not super battle tested technology at this point.
00:01:14.834 - 00:01:39.114, Speaker A: So in this video, what I want to focus on is sort of what has been best practices up to this point, what most of the Sirius proof of stake longest chain protocols do, which is to instead use a pseudorandom seed derived from the blockchain state. As we've discussed multiple times, there's different ways to derive a pseudorandum seed from the blockchain state and the way you do it actually can matter. Some ways are much, much better than others.
00:01:39.114 - 00:02:09.480, Speaker A: For concreteness and for continuity with the rest of lecture number twelve, let's just assume we do it in the exact same way using the credential of the most recent block. Proposer the credential as usual, being the private computation that each owner of a public key does to check whether or not it's a leader of around. So it evaluates a verifiable random function using the appropriate private key on the input, which is the concatenation of the timestep where you're doing the computation concatenated with the pseudorandom seed for that time step.
00:02:09.480 - 00:02:28.326, Speaker A: So when you're talking about the credential of a previous block, that's going to be a VRF output with some private key in some previous timestep with the corresponding pseudorandum seed. Optionally, you can also pass this credential through a cryptographic hash function to get something which for all practical purposes is a random number between zero and one. But let's just set that aside.
00:02:28.326 - 00:02:49.810, Speaker A: Let's just think about the credentials directly we discussed both in part two where we introduced this idea, and also in the first half of part three where we used this idea in conjunction with BFT type protocols. We discussed that there's a drawback of this type of pseudorandom seed, which is at least to some extent biasable. It can be manipulated by the nodes running the protocol.
00:02:49.810 - 00:03:06.098, Speaker A: You might remember what the canonical attack looks like. So if you're sort of a validator with some amount of stake, what you can do is you can split that stake across many, many different sybils, each with its own public key, private key pair. So then at each time step, each of your sibyls is going to get its own credential.
00:03:06.098 - 00:03:28.202, Speaker A: Once in a while you'll get lucky and there'll be a time step where two of your sibyls have super low credentials, each one low enough to qualify for being a block proposer at that time step. And that means at that point you have a choice. You can choose whichever of those two credentials you want to use to make your block proposal, which will hopefully going to wind up being the next finalized block.
00:03:28.202 - 00:03:52.310, Speaker A: So by virtue of being able to choose between two credentials of the proposer of the next finalized block, because that's being used as the pseudorandom seed for the subsequent time step, you then also get to influence the pseudorandum seed of the subsequent time step. So that's the sense in which we discuss these RTS derived in this way. There is at least some amount of manipulability possible by the nodes running the protocol.
00:03:52.310 - 00:04:12.186, Speaker A: So that's an issue not just for the BFT type protocols we talked about earlier, but also for proof of stake longest chain type protocols. There are ways of mitigating that problem. I don't want to get too into the details, but, for example, one thing you can do is derive a pseudorandum seed not just from a single credential from a single recently proposed block, but actually look at a whole.
00:04:12.186 - 00:04:34.450, Speaker A: Bunch of recently proposed blocks like, look at the last thousand finalized blocks, for example, and concatenate the credentials of the thousand block proposers that submitted those blocks. Right? So maybe you sort of concatenate their credentials and sort of feed it through a cryptographic hash function and then that's going to be your pseudorandum seed for the next time step. So that's one issue and the ways it's typically mitigated.
00:04:34.450 - 00:05:16.442, Speaker A: What I actually want to focus on in this video is a new issue that did not plague us in the BFT consensus case and really rears its ugly head only once you pass the proof of stake longest chain protocols. Namely, if you look at how we're defining our pseudorandum seeds as a credential from the previous block, or even if it's some aggregation of the credentials from say, the previous 1000 blocks with the longest chain protocol, you have to ask the question, actually, wait a minute, what does the previous block actually mean? The answer to this question is obvious. If you're using a BFD type protocol under the usual kind of assumptions on Byzantine nodes so that you don't have any forks.
00:05:16.442 - 00:05:51.558, Speaker A: If you're talking about block number nine, there's only one possible thing you could mean by the previous block, which is the finalized block, and there is only one the finalized block at block height number eight, with longest chain consensus. Of course you might have competition between blocks that are vying to be the eventually finalized block at block height number eight. So for example, if we're defining pseudorandum seeds as written on this slide as the credential of the proposer of the previous block, well, if you have two blocks at height eight, quite possible they are proposed by different people that have different credentials.
00:05:51.558 - 00:06:12.530, Speaker A: So by choosing which of those two height eight blocks you want to extend, you actually get to pick the credential of the previous block proposer and thereby pick the pseudorandum seed that you yourself will be working with. And notice this would equally be true if instead we took our pseudorandom seeds as some aggregation of the previous 1000 credentials. It would still be the case.
00:06:12.530 - 00:06:43.150, Speaker A: You'd get different aggregations on the two different branches and therefore two different random seeds which you can then freely pick between. And so this means, and this was promised in the previous video, that even if you look at the definition of the credential, it seems like that's independent of the choice of predecessor right. The predecessor of the proposed block does not appear in the input to the VRF, but nonetheless, you get an implicit dependence on the predecessor selected because that determines the pseudorandum seed which gets fed into the VRF output.
00:06:43.150 - 00:07:24.246, Speaker A: And so that means nodes are now incentivized to grind over the various pseudorandum seeds that they're able to use or equivalently to grind over their choices of the predecessor block. So another way of thinking about this is that at every single time step t, you basically get an independent lottery ticket for each possible choice of the predecessor for each existing block in the blockchain, right? Because whatever block you choose that determines your pseudorandum seed that gets fed into the VRF to give you the credential under our usual kind of randomness assumptions about VRFs, these are basically independent events whether you win the lottery for one choice of predecessor versus another. So that's kind of a bummer.
00:07:24.246 - 00:07:51.140, Speaker A: We're actually not that happy about that fact for a couple of reasons. First reason I'm sure you can guess because it's a variation on a running theme. Although frankly, it's probably the less concerning of the two issues, which is that whenever you have grinding opportunities that's sort of getting away from what you're trying to accomplish with proof of stake, of having a protocol which is kind of trivial computationally for the nodes, you're kind of reverting a little bit back to the proof of work world.
00:07:51.140 - 00:08:09.110, Speaker A: Now, it's definitely not as bad as if you had a nonce because then there's basically an unbounded number of things to try to try to win the lottery. It's not as bad as if you were feeding the transactions in the block into the VRF as part of its input. That would again give you basically an unbounded number of lottery tickets to try.
00:08:09.110 - 00:08:21.226, Speaker A: So here all you can do is kind of grind on the choice of a predecessor. And remember, blocks that don't wind up on the longest chain are kind of going to be irrelevant anyways. So there might not be that many blocks that's even worth trying.
00:08:21.226 - 00:09:00.674, Speaker A: Maybe it's in the dozens, maybe it's in the hundreds, but it's much less than the Zillions of nonces or blocks you would generally be able to try. Now, to explain the second issue, let's drill down on the subtle difference between sort of the order of operations when you're using an ideal randomness beacon, as we were in the last video, where you're using pseudorandom seeds, as we are here. Now, if the Rspts really are just random bits that fall from the sky and there's nothing anybody can do about it, well, then an owner of a public key just gets a unique credential at each time step, right? They can't grind over their private key because that was sort of committed to well in advance.
00:09:00.674 - 00:09:22.874, Speaker A: They can't manipulate the time, the time is whatever it is, and they can't manipulate the random seed because it just fell from the sky. So you have exactly one lottery ticket. Now, because the winning lottery ticket says nothing about a block or a predecessor, we can't really stop sort of the winner of this lottery from proposing lots of blocks to different people with different predecessors.
00:09:22.874 - 00:09:45.974, Speaker A: So in effect, if you win the lottery, you get to propose blocks that extend all parts of the blockchain simultaneously. So that's certainly annoying, but it's not really an existential threat to the guarantees of longest chain consensus. We proved that in lectures eight and nine and we talked about it again in the last video, which is when you have this sort of ideal randomness beacon proof of stake, longest chain gives you the guarantees that you're used to.
00:09:45.974 - 00:10:14.110, Speaker A: So guaranteed consistency and liveness as long as you're in the synchronous model and as long as at least 51% of the stake is controlled by honest nodes. So let's now compare and contrast that with what we're talking about in this video, where R sub T is not random bits that fall from the sky, but is rather pseudorandomily derived from the preceding blocks on the blockchain. And so the big difference is that with pseudorandom Rspts you pick up dependence on the choice of predecessor, which was not there in the random case.
00:10:14.110 - 00:10:42.300, Speaker A: It's not very explicit, right? We're not actually feeding in the predecessor as an input into the VRF, but the predecessor is what tells you what's the pseudorandum seed that's going to be fed into the VRF input. So for that reason, as we discussed, you get one independent lottery ticket for each block, for each choice of a predecessor. So while in the random case, it was all or nothing, one lottery ticket, either you win and you can extend wherever you want, or you lose and you can't extend anything.
00:10:42.300 - 00:10:56.240, Speaker A: Here you're getting a collection of lottery tickets, one per choice of a predecessor. And a lottery ticket only grants you the right to extend that one block. So you're going to be able to extend whatever subset of blocks you happen to have winning lottery tickets for.
00:10:56.240 - 00:11:18.110, Speaker A: So as a result, you should have a different mental model for an attacker, say, trying to carry out some kind of double spend attack by growing an alternative longest chain. So in the first case where you have these random R sub T's, what's the adversary going to do? Right? They're just each time step, either going to win the lottery, they're going to lose. If they win, maybe they extend everything just to get as many of their blocks out there as possible.
00:11:18.110 - 00:11:43.580, Speaker A: For example, as we know, that doesn't actually affect the fact that the security threshold will remain. You need more than 50% on a stake, whereas in the pseudorandum case, each time step, you're going to get a collection of winning lottery tickets. And the obvious thing to do as an attacker is just extend all of the blocks where you have a winning lottery ticket, right? Then timestep moves on, you get a new set of wins, you extend all the blocks that you won a lottery on that time step and so on.
00:11:43.580 - 00:12:07.090, Speaker A: So it would be totally normal to have the intuition that you'd expect the story here to be exactly the same, that again, you have guaranteed consistency and liveness with 51% honest stake. That actually is not true. If you define pseudorandum seeds in this way, you actually fundamentally degrade the consensus guarantees of the protocol.
00:12:07.090 - 00:12:21.642, Speaker A: Specifically, let me tell you about a really neat fact from a paper I've already mentioned several times in the lecture series called Nakamoto Always Wins. I guess the full title is everything is a race and Nakamoto always wins. And this is by a bunch of people.
00:12:21.642 - 00:12:45.466, Speaker A: The first author is Dembo, and what they show using a nontrivial probabilistic analysis is they characterize exactly what the threshold is. And it's not 50%, it's roughly 73%. So that's pretty alarming, right? So, longest chain protocols, for all their many flaws, we have gotten used to their very nice property that they're consistent on live with an honest majority.
00:12:45.466 - 00:13:00.790, Speaker A: So with greater than half of the stake being controlled by honest nodes. And here that's just no longer true. So in addition to all their other problems, now all of a sudden, if Byzantine nodes control 27% or more of the stake, then you even lose consistency and liveness.
00:13:00.790 - 00:13:18.410, Speaker A: This fact number two is definitely not supposed to be obvious or intuitive. Let me just say a little bit about the intuition for why it's true and why you get this sort of separation between the random and the pseudorandom cases. I think it'll be easiest to understand this just through kind of a toy example.
00:13:18.410 - 00:13:32.366, Speaker A: So let's think about sort of a blockchain that's just currently a single chain. And let's suppose there's some target block on this chain that an attacker wants to orphan, for example, to carry out a double spend attack. So now let's think about what happens.
00:13:32.366 - 00:13:50.914, Speaker A: So the honest nodes, we know what they're doing, they're dutifully following longest chain consensus. So they're just going to be attacking blocks onto the end of this magenta drain chain I've drawn thus far. But now there's also an attacker and they want to orphan this target block, which means they're going to be extending the parts of this chain that precede the target block.
00:13:50.914 - 00:14:05.062, Speaker A: So as I've drawn it, there are two blocks earlier in the chain than the target block. The attacker is going to try to extend both of those. So each time step the attacker is going to look at the lottery tickets that correspond to these two blocks.
00:14:05.062 - 00:14:23.066, Speaker A: Maybe for a bunch of time steps it just loses and maybe even the honest nodes sort of successfully extend the magenta chain further. But at some point at least one of those lottery tickets is going to be a winner. So think about a case where the second of those two lottery tickets so the block that's just before the target, suppose that comes up winning.
00:14:23.066 - 00:14:44.610, Speaker A: And then of course the attacker is going to extend that with its own block, creating an alternative chain. This probably seems not so impressive, right? It seems like the attacker is not making much progress. It should seem to you like, well look, if the attacker has less than half of the overall stake, what are they going to do? Like the honest nodes are just going to extend the magenta chain faster than the attacker is going to be able to extend its orange chain.
00:14:44.610 - 00:14:57.094, Speaker A: So it's never going to catch up. However, there's something I want you to notice. Previously the attacker was interested in two lottery tickets.
00:14:57.094 - 00:15:20.942, Speaker A: It got at each time step the two correspond into those two magenta blocks that precede the target block. It only cared about those two blocks because it would be alternative branch out of those blocks that would orphan the target block, which would be the goal. Now there's actually three lottery tickets going forward that the attacker is going to care about, the same two for the magenta blocks as before, plus for the orange block.
00:15:20.942 - 00:15:37.718, Speaker A: Right. The attacker would be happy to extend those two magenta blocks or the orange block that would be on the road to eventually potentially orphaning the target block. So by creating this orange block, the attacker has actually made progress in two different ways.
00:15:37.718 - 00:15:52.230, Speaker A: The more obvious ray is like, look, you were trying to grow this alternative chain, this orange chain, you just extended it by one. That's your one block closer to catching up to and overtaking the honest chain, the magenta chain. So that's the obvious part of progress.
00:15:52.230 - 00:16:23.410, Speaker A: But the other part of the progress is that now it's increased the number of lottery tickets that it cares about at all future time steps, thereby increasing the probability with which it will get to create additional blocks at future time steps. So in the next step then the attacker is going to look at the three different lottery tickets it cares about for the two magenta blocks before the target and for the orange block some time steps. None of them will be winning lottery tickets and nothing happens except maybe some honest nodes successfully extend the honest chain, the magenta chain.
00:16:23.410 - 00:16:36.794, Speaker A: But at some point there'll be a time step where one of those three lottery tickets is a winning one. For the example, maybe, let's assume that it's again a lottery ticket associated with the magenta block just before the target. So the same block as before.
00:16:36.794 - 00:16:50.974, Speaker A: This is a different time step, this is a later time step. So it's a different lottery ticket, it's a different lottery win, but again we're going to be extending that exact same magenta block just below the target. At first blush it seems like this doesn't help the attacker at all.
00:16:50.974 - 00:17:04.242, Speaker A: Right, there was already an orange block at this block height. So what? Now it has a second orange block at the same block height. You're no closer to taking over the magenta chain than you were before, but it's still progress in that second sense.
00:17:04.242 - 00:17:29.686, Speaker A: It still gives the attacker more opportunities for creating blocks at future time steps. Right now there's going to be four lottery tickets it pays attention to at future time steps, not just three. And more to the point, while previously the attacker only had one lottery ticket that would get them closer to overtaking the magenta chain, now the attacker is going to have two different lottery tickets, either of which would enable them to get closer to overtaking the magenta chain.
00:17:29.686 - 00:17:51.726, Speaker A: If either of those two orange blocks generates a winning lottery ticket, then the longest orange chain is going to get one longer. So the intuition then for fact number two is that with these pseudorandum seeds, the attacker basically gets to grow a bunch of independent chains. And if any one of those independent chains takes over the honest chain, then the attacker can declare victory.
00:17:51.726 - 00:18:08.934, Speaker A: It will successfully, for example, execute a double spend. Now this may seem like a kind of hard to understand unruly random process, right? The attacker always getting these lottery tickets, extending whatever it can, everything's sort of growing piecemeal all over the place. To some extent it is kind of an unruly random process.
00:18:08.934 - 00:18:32.842, Speaker A: But what's cool is that for our purposes, the bottom line is very clean to state. So basically from the attacker's perspective, the benefit it gets from being able to grow these independent parallel chains and it wins if any of the parallel chains overtakes the honest chain. That's equivalent to as if it was just doing one chain, but it had e times as much stake.
00:18:32.842 - 00:18:50.294, Speaker A: And here by e I mean the base of the natural logarithm 2.7 118. So very, very roughly this factor e comes up because of the kind of compounding which is going on over time with the number of independent branches that the attacker is able to grow.
00:18:50.294 - 00:19:13.786, Speaker A: But honestly, you're not supposed to guess where this e comes from unless you have a little bit of background in branching processes. If we're willing to take this speed up fact on faith, then we can see exactly where the 73% is coming from. So as usual, let's, let alpha denotes the fraction of the stake which is controlled by Byzantine nodes.
00:19:13.786 - 00:19:25.066, Speaker A: What this fact tells us is that they have sort of an effective state of e times alpha. Meanwhile, at the honest nodes they have the rest of the stakes. That's going to be one minus alpha.
00:19:25.066 - 00:19:37.650, Speaker A: And so when is the attacker going to be able to exceed it's? When sort of its chain sped up by a factor of e grows faster than the honest chain. So that's going to be when e times alpha. So that's the sped up Byzantine stake.
00:19:37.650 - 00:20:17.214, Speaker A: When that's bigger than the honest stake, one minus alpha. So rearranging this shows that the attack succeeds if and only if alpha, the fraction of Byzantine state is strictly bigger than one over e plus one, which if you put it in your calculator, you'll see, is roughly 27%. Now what's kind of wild here is that if the Byzantine stake is, let's say 27, 28%, something like that, any given chain that the attacker grows, any given orange chain is exponentially unlikely, exponential in the security parameter, exponentially unlikely to overtake the honest chain, the magenta chain.
00:20:17.214 - 00:20:41.926, Speaker A: But if the attacker is in a position to grow an exponentially large number of different competing chains, well, if that gets big enough, then all of a sudden it's likely that one of those will actually be a super lucky chain that does overtake the magenta chain. That's kind of what's going on here. Now this 27%, right, it comes out of some pretty nontrivial math, but this is not academic, right? This is like practically meaningful.
00:20:41.926 - 00:21:08.018, Speaker A: If you really were using random seeds in this way, an attacker using kind of the most obvious attack possible literally would and you can check this with simulations if you don't believe me, literally would be able to double spend if it had 28% of the overall stake. That's just a true fact about this particular design. So that frankly, that's a pretty big blow to this specific proof of stake longest chain design.
00:21:08.018 - 00:21:29.234, Speaker A: I mean, you could deploy it, you could just sort of cross your fingers and hope that less than 27% of the stake are controlled by Byzantine nodes. Or if they control. More than that, you could cross your fingers that for whatever reason they're not going to carry out these frankly, fairly straightforward double spend attacks obviously would be much more satisfying to just come up with a better protocol.
00:21:29.234 - 00:21:48.170, Speaker A: So maybe we can make some changes to this design, for example, that gets us out of the 73% scenario and back to the familiar scenario where 51% of the honest stake suffices. That's kind of what we really want. So how are we going to do that? Well, we can go back to the purely random case with an ideal randomness beacon for inspiration.
00:21:48.170 - 00:22:05.630, Speaker A: So that's what we have on the leftmost part of this slide. Because in that scenario, we kind of got what we wanted, right? We really did have guaranteed consistency and liveness even with just 51% honest stake. And the way it worked in the purely random case is that each time step, it was kind of all or nothing, right? So as an attacker, you would get one lottery ticket.
00:22:05.630 - 00:22:26.202, Speaker A: Either you would win and you could extend all the blocks, or you would lose and you could extend nothing. And what we saw in the pseudorandum case, at least if you implement it the way we've discussed thus far, you get independent lottery tickets for the various blocks. And so if you compound that, over time, you get this sort of exponential growth in the number of competing chains that you can grow.
00:22:26.202 - 00:22:51.970, Speaker A: So it would seem that to get back to sort of the leftmost scenario, we have to somehow inhibit the rate at which an attacker can grow independent competing chains. So let's think about how we might do that to get the ball rolling. Let's think about a really extreme solution, which would just be to have all the RTS be exactly the same, all the pseudorandum seeds all equal just to some constant.
00:22:51.970 - 00:23:09.142, Speaker A: And by a constant I could mean, I don't know, like shot 256 of the genesis block of the blockchain protocol or maybe even just like the empty string. Now that probably sounds crazy. It is a little bit crazy, but maybe not as much as it first sounds like.
00:23:09.142 - 00:23:32.846, Speaker A: So even if you do this extreme case, you will be getting like a nontrivial set of credentials every time step because remember the credential for someone who owns a particular public key? What do they do? They evaluate the VRF using the corresponding private key on the input, which we were saying is the time step concatenated with the pseudorandum seed. Now there basically is no pseudorandum seed. So it's really just the VRF evaluated at the time step.
00:23:32.846 - 00:23:47.170, Speaker A: But still every time step, everybody's going to be getting some different credential. At a given time step, people are going to be getting different credentials because they're evaluating this VRF with different private keys. So that's the sense in which it's not completely crazy.
00:23:47.170 - 00:24:21.550, Speaker A: And moreover, there's sort of one obvious benefit, which is talk about not being manipulable, right? I mean, if you don't even basically have the pseudorandom T's R sub T, then obviously none of the nodes are in a position to manipulate them. So what's the big drawback? Well, it's actually kind of the same as when we talked about a similar scheme toward the beginning of part two. One of our sort of straw man proposals for proof of stake random sampling, which is that if you don't have the RTS coming from the ideal Ramness beacon and you don't have them depend on the blockchain state if they're just kind of some constant well then you have predictability of all future credentials.
00:24:21.550 - 00:24:40.594, Speaker A: In particular, the owner of this public key is going to know all of the future time steps where the credential is quite small, quite close to zero. Those are the time steps where they're going to be a leader or at least very likely to be a leader and therefore able to make a block proposal it. Now the good news is we are still using VRFs, which are private computations.
00:24:40.594 - 00:25:00.374, Speaker A: So as an owner of a public key, while you can just evaluate all your future VRF outputs till the rest of time all your future credentials, you have no idea what anyone else's credentials are going to be, right? Because those credentials come out of the VRF evaluated with their private keys. You don't know their private keys, so you can't guess what their credentials might be. So it's only your own credentials.
00:25:00.374 - 00:25:36.070, Speaker A: You're in a position to predict forever. But this type of predictability still leads to some pretty big problems. The first issue, which we've talked about several times in the past, is the worry about grinding on public private key pairs, right? So if you're a participant, you could imagine just you keep generating new public private key pairs until you get a private key whose future VRF outputs you like, right? So maybe you sort of want to do a double spend on some particular day on the calendar and you'd find a private key that gives you unusually small credentials during that period.
00:25:36.070 - 00:25:51.740, Speaker A: Now, normally the way we handle this issue is by forcing people to commit to their public private key pair before they know about the pseudo random seed R SubT. But here the R sub T's are literally all known right, when the protocol is deployed. So no warm up period is going to save you here.
00:25:51.740 - 00:26:10.990, Speaker A: So that would be an issue also if we were using BFT type consensus protocols coupled with this approach to proof of stake random sampling. The second issue I want to mention is actually specific to coupling this approach to longest chain consensus. And so this issue I'm going to call riskless forking attacks.
00:26:10.990 - 00:26:21.362, Speaker A: So forking attacks are kind of almost always foremost in our minds when we talk about longest chain consensus. That was true all the way back in lecture eight when we were worried about sort. Of double spend attacks.
00:26:21.362 - 00:26:41.034, Speaker A: So this would be where you have a block that's sort of deep on the longest chain so everybody thinks it's finalized. You're worried about an attacker kind of creating an alternative chain starting from behind that block. And if it ever succeeds in overtaking the main chain and becoming the longest chain itself, well, that's going to roll back this previously thought to be finalized block which can enable a double spend.
00:26:41.034 - 00:27:02.542, Speaker A: Similar story in lecture number ten when we talked about selfish mining. So there it was, deliberate forking attacks in order to orphan honest blocks, thereby boosting one's share of the overall block rewards. Now, forking attacks like this are risky business, right? There's some chance that they succeed that you overtake the longest chain or that you orphan an honest block.
00:27:02.542 - 00:27:23.690, Speaker A: But there's also some possibly large, frankly, chance that they'll fail, that you just don't create blocks long enough to ever overtake the longest chain. Or in the selfish mining context that actually an honest node winds up orphaning you rather than vice versa. Here, however, this is like being told the results of all future coin flips until the end of time.
00:27:23.690 - 00:27:46.074, Speaker A: So if you wanted to, for example, enact a double spend, right, so most of the time you're not going to be able to get away with it, but there will once in a while be periods of time where you're way overrepresented as far as how frequently you're able to produce a block. That's just going to happen sometimes by random chance. So if you know all of the future coin flips, you will know the day on your calendar.
00:27:46.074 - 00:28:20.698, Speaker A: You will say, hey, January 17, I get so lucky and I'm going to win so many times I'll actually be able to pull off that double spend, drive away with a Tesla without ever paying for it. So all of this discussion is now going to culminate in a proposed compromise that sort of interpolates between one extreme, namely just the pseudorandum seeds, where it's the credential of, say, the most recent block, and this other extreme, or actually the pseudorandum seeds are just completely independent of the blockchain state. Now, none of the problems we've identified with these two extreme solutions are going to totally going to go away.
00:28:20.698 - 00:28:43.250, Speaker A: They're just going to show up in this compromise in more muted form. So there will be at least a little bit of degradation in the fraction of honest stake that we need to guarantee liveness and consistency, although the degradation will be sort of under our control. And similarly, there will still be predictability of future credentials, but only for a period of time, not until the end of the universe.
00:28:43.250 - 00:29:01.640, Speaker A: The compromise I'm going to propose here is also more or less what you'll find in the cardano protocol. Again, for more details, you can look at the paper that describes OROBOROS Pravos. So how does it work? Well, first we're going to choose a parameter L for concreteness, maybe think of L as like a thousand.
00:29:01.640 - 00:29:22.910, Speaker A: So now we're going to define pseudorandum seeds in a way that's a variation of what we did before. So rather than take the pseudorandum seed as the credential supplied by the proposer of the preceding block, we're going to take it as the credential of the proposer of the most recent block. That's at a block height, that's a multiple of L.
00:29:22.910 - 00:29:45.080, Speaker A: So, for example, if L equals 1000, and we're in the middle of proposing a block at height 9723, then what you do is you trace back from your block. Back toward Genesis. And when you get to the block height 9000, whatever credential is in that block is going to be the pseudorandum seed you're using at block height 9723.
00:29:45.080 - 00:30:10.586, Speaker A: So in effect, you can sort of think of the pseudorandum seed R sub T as resetting every L blocks, like every thousand blocks. As soon as it resets, like as soon as you know what block number 10,000 is on the longest chain, well now you know what R sub T is going to be up until block 11,000. We're going to have the usual predictability properties during that period, during those L blocks.
00:30:10.586 - 00:30:31.750, Speaker A: In particular, if you own some public key, you will know what your credentials are going to be at all future time steps. While the longest chain is growing from that block at height 10,000 to that block at height 11,000, during that duration, you'll know all your credentials, you'll know which time slots. You're likely to be a leader who can propose a block.
00:30:31.750 - 00:30:40.774, Speaker A: I said you might want to think about L as 1000. I'd also encourage you to think about this duration of time between resets. Think of that as maybe order of days.
00:30:40.774 - 00:30:57.578, Speaker A: So it is a quite nontrivial predictability that we're suffering here. The good news is the consistency and liveness will look a lot more like it did for all our other longest chain implementations. Certainly one piece of good news of at least having like LB finite, at least having this limited predictability.
00:30:57.578 - 00:31:16.914, Speaker A: Then you can use a warm up period. It's going to be a pretty long warm up period, but you can use a warm up period to force people to commit to their public private key pairs before they know what the relevant pseudorandum seeds are going to be. Now nodes may still have some degrees of freedom in which pseudorandum seed R sub T they want to work with.
00:31:16.914 - 00:31:39.260, Speaker A: So for example, suppose at block height 9000, it just so happened that there were three different blocks created at that height. Well then if you're creating blocks later on, depending on which of those three blocks you claim as your ancestor, you're going to be working with a different pseudorinum seed. So in general, the picture you want to have in mind is what I'm about to draw in the upper left.
00:31:39.260 - 00:31:58.130, Speaker A: So imagine you have the genesis block at the far left. And then imagine at block height 9000, you have three blocks. Now, blocks that are proposed for later block heights bigger than 9000, they're going to naturally fall into one of three groups depending on which of the height 9000 blocks they claim as ancestor.
00:31:58.130 - 00:32:29.866, Speaker A: Now, within a group, meaning across the blocks that are contained in the same light blue circle, the pseudorandum seed is going to be constant across the blocks within a group. It doesn't matter which of those you're going to be extending, you're going to be working with the same pseudorandum seed, r sub T, that pseudorandum seed just being the credential included with their common ancestor block that's at height 9000, similarly for the blocks in the second group. So again, the blocks within the second light blue circle, they're going to be working with a common pseudorandum seed, r sub T.
00:32:29.866 - 00:32:46.340, Speaker A: Same thing for the blocks within the third group. But across the groups, the pseudorandum seeds are going to be different, right, because the three groups have different ancestors at height 9000. Those different blocks at height 9000 are going to have different credentials included in them.
00:32:46.340 - 00:32:59.170, Speaker A: So you really can think of this as kind of a hybrid between our two extremes. Within a group, you basically get one lottery ticket. So you can extend either all or none of the blocks within one of the light blue circles.
00:32:59.170 - 00:33:24.070, Speaker A: That's just like what we had initially with our ideal randomness beacon across groups, you get independent lottery tickets, just as we had in our initial proposal for how to do pseudorandom seeds. So single lottery ticket for each group, independent lottery tickets across the different groups. So remember the two different drawbacks that we're trying to balance with this hybrid solution.
00:33:24.070 - 00:33:39.678, Speaker A: So one is predictability. So when we just said suppose we don't have r sub T's at all, suppose r sub T's were just a constant, then the issue was that everybody knew their credentials until the end of time. So with this hybrid solution, we do still have predictability, but it's sort of tunable predictability.
00:33:39.678 - 00:34:06.214, Speaker A: So basically during the amount of time it takes to go up a multiple of L in block height, during that period, everybody will be able to predict the future time slots at which they're going to be a leader, but then there'll be a reset. On the minus side, there is still some aspect of independent lottery tickets in the hybrid approach. Like if you look at the figure in the upper left part of the slide, right, each of those three groups each does get their own independent lottery ticket.
00:34:06.214 - 00:34:57.610, Speaker A: So compounding over time, the number of different branches the attacker can grow will be increasing, but we've slowed down the growth tremendously. There is this aspect of independent lottery tickets, right? Like if we look at the figure in the upper left part of the slide, each of those three groups, each of those three light blue circles, they each do get their own independent lottery ticket. So if you just kind of squint and look only at these kind of block heights that are multiples of L, then it starts looking a lot like the problem that we had in our original pseudorandum seed proposal, where an attacker through these sort of repeated independent lottery tickets can keep growing the number of lottery tickets it gets in the future, growing the number of independent chains that it has at its disposal to try to overtake the honest chain.
00:34:57.610 - 00:35:22.498, Speaker A: The good news is that the attacker only gets these opportunities to kind of fan out with independent chains at blocks that are multiples of L, right? So within a group. So between sort of block height 9000 and block height 10,000, if you focus on a group, it's totally correlated. And so what we learned earlier is that sort of correlated lottery tickets are not really helpful to the attacker, whereas independent lottery tickets are.
00:35:22.498 - 00:35:36.150, Speaker A: And so here you're only getting independence of these multiples of L. Everything's totally correlated in between. So we're radically slowing down the rate at which an attacker is going to be able to create all of these different independent chains.
00:35:36.150 - 00:35:52.974, Speaker A: So from the perspective of consistency and liveness, it sure seems like we should be better off. The bigger L is like, the bigger L is, the harder it is for an attacker to actually sort of generate enough independent chains to eventually overtake the honest chain. And that is in fact true if you think about it.
00:35:52.974 - 00:36:10.510, Speaker A: L equals one that recovers our original pseudorandum seed proposal, where we know that the threshold is 73%. It seems like we should be doing better and better the bigger L gets. And indeed, as L tends to infinity, we do indeed recover our original 51% threshold.
00:36:10.510 - 00:36:33.162, Speaker A: So in particular, if we take L sufficiently large again, maybe think of L as in the thousands, then it's sufficient to have, I don't know, 51, 52%, something like that on a stake in order to get provable consistency on liveness. If you're curious about the proof of fact number three, there's sort of two sources for it, both of which I've mentioned several times before. One is the same demo at all paper from 2020.
00:36:33.162 - 00:36:42.300, Speaker A: Nakamoto always wins. The other is the research paper behind the OROBOROS Prowos protocol. Both of them basically imply this fact number three.
00:36:42.300 - 00:37:01.954, Speaker A: So that finally brings us up to the state of the art for proof of stake longest chain protocols. As we've seen throughout this lecture, designing proof of stake protocols with provable properties is not easy, and they tend to be more complicated than Nakamoto Consensus. And you also tend to have to make some compromises you'd rather not make.
00:37:01.954 - 00:37:23.482, Speaker A: So we saw that already with the proof of stake BFT type protocols in the first half of part three. We see it's kind of even more true with proof of stake longest chain protocols. I'm super curious if there's going to be future generations of proof of stake longest chain protocols that improve on the existing designs, that improve on the sort of ideas and guarantees that we've talked about here.
00:37:23.482 - 00:37:34.506, Speaker A: I don't know. It seems like there's really been a pretty strong migration away from longest chain consensus within proof of stake protocols, both the BFT type protocols into other non longest chain protocols. But you never know.
00:37:34.506 - 00:37:45.354, Speaker A: So that's going to be something to keep an eye on. All right, so congratulations. You made it to the end of part three of lecture number twelve, which in my opinion is the hardest of the four parts.
00:37:45.354 - 00:38:01.074, Speaker A: We do still have part four to go. And so there I want to talk about slashing, I want to talk about the dangers of costless simulation and in particular long range attacks. And I wanted tell you more than you ever wanted to know, comparing proof of work and proof of stake.
00:38:01.074 - 00:38:04.210, Speaker A: So that's what's coming up next. I'll see you there. Bye.
