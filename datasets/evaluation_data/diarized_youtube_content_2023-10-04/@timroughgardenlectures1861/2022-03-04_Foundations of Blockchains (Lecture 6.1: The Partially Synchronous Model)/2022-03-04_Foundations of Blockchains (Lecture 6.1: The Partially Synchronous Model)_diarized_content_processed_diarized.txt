00:00:00.410 - 00:00:13.214, Speaker A: Hi, everyone, and welcome to lecture six of this lecture series on foundations of blockchains. So in lecture six there's, there's three things I want to do. So first of all, I want to introduce you to what's called the partially synchronous model.
00:00:13.214 - 00:00:31.510, Speaker A: This is going to sort of interpolate between the two models we've looked at thus far, the synchronous model that we studied in lectures two and three, and the Asynchronous model that we studied in lectures four and five. And this is a real important model. If you only remember sort of one model of network communication, this is the one you want to remember.
00:00:31.510 - 00:00:49.114, Speaker A: Indeed, one of the main reasons we've gone through the synchronous model and the Asynchronous model is as prerequisites to introduce you to this very important partially synchronous model. Why is it important? Well, it's a really useful sweet spot between the synchronous and Asynchronous models. On the one hand, it'll make weaker assumptions than the synchronous model.
00:00:49.114 - 00:01:09.490, Speaker A: So we'll get protocols that are just much more robust and much more plausibly deployable in the real world. On the other hand, the goals will be a little bit relaxed compared to what we studied in the Asynchronous model. And as a result, there will actually exist good consensus protocols, which of course, ultimately our goal is to design good consensus protocols.
00:01:09.490 - 00:01:27.990, Speaker A: The second thing I want to do is establish limitations on what we could hope for in the partially synchronous model. And in particular, we're going to prove an impossibility result showing that if at least a third of the nodes are Byzantine, then you can't get what you want. You're not going to have a robustly good consensus protocol.
00:01:27.990 - 00:01:36.442, Speaker A: The proof of this impossibility result is not that hard. It's really not as hard as the one of the FLP theorem we did in the last two lectures. But this result is super important.
00:01:36.442 - 00:01:55.826, Speaker A: In fact, if you go and read different white papers for various blockchain protocols, many of them will sort of reference this mysterious 33% threshold. So they'll argue that the protocol has certain good properties as long as less than a third of the hash rate or the stake or whatever is Byzantine. This is literally that exact same 33%.
00:01:55.826 - 00:02:14.242, Speaker A: So you will learn where that 33% comes from in the second video of lecture six. The third thing I want to do is discuss a famous principle from distributed systems known as the Cap theorem. Here, the CA and P stand for consistency, availability and partition tolerance.
00:02:14.242 - 00:02:25.642, Speaker A: The theorem states you have to pick two out of the three. You can't have all three at the same time. And that's sort of a very similar takeaway to what we're going to learn when we study the limitations of consensus and the partially synchronous model.
00:02:25.642 - 00:02:46.254, Speaker A: So I want to clarify the relationship between those two things. And in particular, again, if you look at various sort of white papers for different systems, including some blockchain protocols, you will see appeals to the Cap theorem, right? So when someone's discussing a weakness of their system or of their protocol, often they will sort of say, well, we have to have this kind of weakness. That's what the Cap theorem tells us.
00:02:46.254 - 00:03:04.162, Speaker A: So it's again a very important thing for you to know what it says. So you can sort of assess when people make claims about it in white papers or elsewhere, whether or not they know what they're talking about. So let me set the stage for the partially synchronous model, which we'll define on the next slide by just reminding you of the context.
00:03:04.162 - 00:03:24.670, Speaker A: So what's the story so far in lectures two and three? Remember we were studying the synchronous model. So the synchronous model, remember really there's sort of two different assumptions. Assumption one is that all of the nodes sort of share a global clock, so there's a notion of time and all of the nodes agree on what time it currently is.
00:03:24.670 - 00:03:48.500, Speaker A: And then the second assumption, which is probably the less palatable one for us, is guaranteed message delivery. So the assumption was that there existed some known bound capital delta on the maximum message delay that anyone would ever suffer. So as a node, if you know some other node is sending some message to you at time T, if you wait around till T plus delta, you know you're going to hear what it is that they wanted to tell you.
00:03:48.500 - 00:04:10.534, Speaker A: Now there's both sort of some good news and some bad news about the synchronous model. The good news is that we got some super strong results. So remember in lecture two we talked about the dole of strong protocol, which in the synchronous model, assuming also public key infrastructure PKI, we showed how to solve Byzantine broadcast and therefore by a reduction also solve state machine replication.
00:04:10.534 - 00:04:28.910, Speaker A: No matter how many Byzantine nodes there are, which is very unusual, you could have 90% Byzantine nodes, doesn't matter. There's no way they could sort of stop the 10% honest nodes from coming to agreement. The bad news, of course, is that we got these strong results only under strong assumptions.
00:04:28.910 - 00:04:48.710, Speaker A: And in particular for a protocol that's supposed to be run by lots of nodes scattered all over the globe communicating over the internet, you really do not have an OPERATORI known bound delta on the maximum message delay. Really, there's going to be unexpected outages. And again, if you're talking about blockchain protocols securing billions of dollars of value, you also should expect attacks.
00:04:48.710 - 00:05:07.546, Speaker A: So because of this drawback, because we were unsatisfied with the strength of the assumptions in the synchronous model, we explored relaxing these assumptions and we sort of went to the polar opposite. We said, okay, no shared clocks at all and message delivery. Let's assume basically nothing, okay, let's at least assume the adversary can't starve nodes.
00:05:07.546 - 00:05:27.858, Speaker A: So every message sent eventually gets delivered, but without any operi known bound on exactly how long that delay might be. So that was the Asynchronous model. And what we liked about the Asynchronous model was that because the assumptions were so weak, it sort of captured almost anything that could conceivably go wrong with the communication network.
00:05:27.858 - 00:05:46.906, Speaker A: So any good consensus protocol in this Asynchronous model would automatically be very interesting because it would work really no matter what problems the communication network was having. The bad news is we sort of threw out the baby with the bathwater in this model. So any positive result would have automatically been very interesting.
00:05:46.906 - 00:06:05.374, Speaker A: But what we actually proved is that there are no positive results. The assumptions are so weak that you basically cannot solve Byzantine agreement even in the presence of a single faulty node. Now, these are probably the most two natural models of communication and message delivery I think one could think about.
00:06:05.374 - 00:06:22.130, Speaker A: So it's very natural to start with these two. But it's now clear that we're really not done. We're really going to need a third model of a communication network because remember, why are we doing all this exercise of this mathematical modeling, improving sort of theorems, positive results for protocols and possibility results, ruling out all protocols.
00:06:22.130 - 00:06:51.514, Speaker A: Ultimately, what we want the mathematical framework to do is guide us toward really interesting consensus protocols that have a chance of being useful in the real world. And neither of these two models has succeeded, right? In the synchronous model we get strong results. But sort of by abusing this sort of false assumption that you have bounded message delays, the Asynchronous model sort of fails because there's no consensus protocols to be designed, or at least not anyone's with provable guarantees in that setting.
00:06:51.514 - 00:07:11.014, Speaker A: So the good news is, and the subject of this lecture is a sweet spot between the two known as the partially synchronous model. And to motivate this model, let's remember sort of why we rejected the synchronous model and why we went to sort of Asynchronous. We rejected synchronous because there's going to be outages and it's going to be hard to know how long those are going to last.
00:07:11.014 - 00:07:20.406, Speaker A: There's going to potentially be attacks, denial of service attacks and other things. Hard to know how long those are going to last. And so synchronous protocols just weren't going to cut it.
00:07:20.406 - 00:07:46.234, Speaker A: On the other hand, you think about that, it's kind of like outages attacks. I mean, they probably end eventually, right? I mean, it might be like it might take a day or two days or a fairly long period of time, but presumably they have finite length. So with that in mind, the basic idea behind the partially synchronous model is to study protocols really in two different modes.
00:07:46.234 - 00:08:04.494, Speaker A: So mode number one, normal operating conditions when there's no outages, there's no attacks, where we're comfortable using the synchronous model as a model of communication. And under normal operations, we would like a protocol to give us everything we could possibly want. So for example, whatever consensus problem you're looking at, you'd like both safety and liveness.
00:08:04.494 - 00:08:18.806, Speaker A: So for state machine replication you'd like consistency and liveness. For Byzantine agreement, byzantine broadcast, you'd like agreement, validity and termination. But now we also want to sort of stress test our protocols and examine how they operate under an attack.
00:08:18.806 - 00:08:37.338, Speaker A: And so we will be identifying attack phase with the Asynchronous model that we discussed in the last two lectures. Now the FLP impossibility result says that if we're in some sort of Asynchronous phase, if we're under attack during that time we cannot have everything that we want. We cannot have both safety and liveness.
00:08:37.338 - 00:08:51.294, Speaker A: But we'd still like to aspire to giving up as little as possible while we're under attack. So at least we keep safety or at least we keep liveness. Now we're thinking that this attack or this outage is eventually going to end.
00:08:51.294 - 00:09:06.706, Speaker A: It might take days, but at some point it's going to end. And we want to make sure that the protocol isn't sort of irrevocably screwed up by the attack. So we would like a protocol that just very quickly resumes normal operation when the underlying communication network resumes normal operation.
00:09:06.706 - 00:09:24.086, Speaker A: So very soon after an attack ends, after we switch from Asynchronous to a synchronous setting, we would like to then have the guarantees we expect in the synchronous setting. For example, safety and liveness. Okay, so presumably we'll have a model that has a notion of a synchronous phase and an Asynchronous phase.
00:09:24.086 - 00:09:37.550, Speaker A: If you wanted the simplest possible such model, you would have only two phases. So one synchronous phase, one Asynchronous phase. And if you think about it, because we want to study recovery after attack, it makes sense to have the Asynchronous phase first followed by the synchronous phase.
00:09:37.550 - 00:09:51.800, Speaker A: You could easily write down sort of a model that just alternates between asynchronous and synchronous phases, between attacks, normal operating conditions and back. You can get basically the same results. You would just take this model and then chain it together a whole bunch of times with itself.
00:09:51.800 - 00:10:08.266, Speaker A: Before I write down the formal model, let me just mention that this is due to Dwark, lynch and Stockmeyer back in 1988. So we're still in the 1980s, we're still doing classic stuff. We have at least made it to the second half, the late 80s as opposed to the early 80s.
00:10:08.266 - 00:10:26.814, Speaker A: But I promise you, if you're hungry for 21st century stuff, starting in lecture seven will be in the 21st century and you'll pretty much never look back. But this model from the late eighty s is actually super important for reasoning about blockchain protocols. So the first assumption we're going to make is that same first assumption from the synchronous model.
00:10:26.814 - 00:10:40.594, Speaker A: So we are going to assume that there's a shared global clock. All of the nodes have a notion of time and it's common knowledge what time everybody's in at any given moment. And in fact, for positive results in this model, you can relax this assumption a little bit.
00:10:40.594 - 00:10:59.322, Speaker A: You can allow different nodes, clocks to drift away from each other as long as there is bounded drift. So one of the things Dwark, lynch and Stockmeyer showed is they showed how under a bounded drift assumption you can basically simulate a good enough approximation of a shared global clock. And obviously the fewer assumptions the better.
00:10:59.322 - 00:11:12.110, Speaker A: So we'd be happy to get rid of this assumption if we could. On the other hand, remember of the two assumptions in the synchronous model, this one bothered us much less. I mean, in practice you could imagine approaches toward ensuring that nodes have at least approximately synchronized clocks.
00:11:12.110 - 00:11:32.506, Speaker A: Second, we will be assuming that there's a notion of normal operating conditions which will again identify with the synchronous model. So part of this is going to be an operi known bound capital delta on the maximum message delay when you're operating normally when you're in the synchronous model. So the units of delta here are in number of time steps.
00:11:32.506 - 00:11:54.458, Speaker A: So if you prefer concrete numbers, maybe think of a time step as like one millisecond and capital delta maybe as 1000 or 2000, corresponding to 1 second or 2 seconds. Those are parameters you might use in an internet context. Finally, there's some point at which an attacker outage ends and we transition from the asynchronous phase to the synchronous phase.
00:11:54.458 - 00:12:18.022, Speaker A: And that transition time is known as GST, which stands for Global Stabilization Time. And again, I want to emphasize, unlike the parameter capital delta, which is known to the protocol in advance, that is the description of the protocol can depend on the value of capital delta. GST, we assume is unknown.
00:12:18.022 - 00:12:33.070, Speaker A: And so therefore a protocol's description cannot depend on the Global Stabilization Time. In other words, while we might be okay assuming that attacks end eventually, we don't want to pre commit to what that time frame is going to look like. Maybe it's minutes, maybe it's hours, maybe it's days.
00:12:33.070 - 00:13:01.462, Speaker A: Who knows? We want a protocol that will handle anything. Also, from a theoretical perspective, I mean, this model would be stupid if we made GST known in advance to the protocol, really, we would not have escaped the synchronous model had GST been because, you know, a protocol, if it knows GST can just wait till GST. So if it knows the GST is six days from now, it can say do nothing for six days and then we're going to run some synchronous protocol like dole of strong from there.
00:13:01.462 - 00:13:12.090, Speaker A: And we don't want a model that advocates that at all. So it's very important that the Global Stabilization Time is unknown to the protocol. The protocol should work simultaneously for all possible GSTS.
00:13:12.090 - 00:13:39.854, Speaker A: Another point worth appreciating is that it's not like so GST is eventually going to happen, but when it happens, it's not like anybody, notifies the nodes running the protocol that it's occurred. So as a node, at some point GST happens, nobody tells you, but nevertheless, you want to quickly resume the properties you have during normal operating conditions, for example, safety and liveness properties. So that's the gist of the partially synchronous model.
00:13:39.854 - 00:13:45.938, Speaker A: You start out in an asynchronous phase. You basically start out in the middle of a potential attack. At some point, that attack ends.
00:13:45.938 - 00:14:06.462, Speaker A: That's global stabilization time, or GST. A protocol is supposed to work no matter what GST is. And even though the nodes are not explicitly informed when GST occurs, so nonetheless, despite the fact it's unknown and not immediately detectable, nodes running the protocol should automatically sort of start resuming operation as if they'd been in the synchronous model all along.
00:14:06.462 - 00:14:33.254, Speaker A: So, for example, liveness and safety conditions should both hold very soon after the attack ends, very soon after GST. So a little more formally, the assumptions of the partially synchronous model are really precisely encoded by some assumptions, some guarantees about message delivery. So before GST, while we're in the asynchronous phase, messages can be delayed by any amount.
00:14:33.254 - 00:14:54.202, Speaker A: But once GST happens and we're back in the synchronous mode, well, then the extra delay that any message suffers should be at most capital delta. So it should be delivered as if it was sent at GST and you were in the synchronous model, meaning at most delta time steps later. And then secondly, after your past GST, it's just like the synchronous model.
00:14:54.202 - 00:15:10.878, Speaker A: So whenever a message is sent, it's going to be delivered at most delta time steps later. All right, so just quick review. So when we say a protocol in the partially synchronous model, what do we mean? Well, again, the job of a protocol is just to tell a node what messages to send as a function of what that node knows.
00:15:10.878 - 00:15:39.740, Speaker A: Okay? So like in the asynchronous model last week, a node knows its private input and it knows a sequence of messages it has received thus far, and so that's the protocol tells it its outgoing messages based on those two pieces of information. Unlike the asynchronous model here, a node has a third piece of information, which is the current timestep. So the protocol is just a function that tells a node what messages to send as a function of its private input, as a function of the current time step, and as a function of the messages it has received thus far.
00:15:39.740 - 00:16:01.890, Speaker A: So one of the main things that a protocol in the partially synchronous model is allowed to do, which protocols are not allowed to do in the asynchronous model, is basically wait for a specified amount of time before doing something, like before sending some messages. So, for example, you could set a timer and say, I'm going to listen on the network for incoming messages. If I don't hear any after 1000 time steps, then I'm going to send out the following messages.
00:16:01.890 - 00:16:38.494, Speaker A: Final thing I want to mention on this slide, is it's worth knowing that there's actually a second version also of the partially synchronous model, also introduced by Dwark, lynch and Stockmeyer? And it may annoy you that there are sort of two seemingly distinct models with the same name, but both of the models are sort of well motivated and they're also roughly equivalent, and you do hear about both. So let me just quickly tell you about the second version, which is the unknown delta version of the partially synchronous model. To motivate this second variant, let me remind you of a discussion we had at the beginning of lecture four.
00:16:38.494 - 00:16:57.810, Speaker A: So being the lecture four, we said, oh, we don't like the synchronous model, let's try to relax it. And we said, okay, well, what if instead of just assuming that every message gets delivered after one time step, it gets delivered after some number of timesteps between one and 1000, where 1000 is known, operate. And then we had this time inflation trick saying like, that actually doesn't change the model because now you get these protocols that they just wait.
00:16:57.810 - 00:17:16.454, Speaker A: Instead of waiting for one time step, they wait for 1000 time steps to make sure they've heard from everybody and then they proceed as before. And we said, okay, that was a bad idea, it didn't work. It led us to these sort of weird Bloated protocols that do this annoying time inflation trick, when really what we'd like is a protocol that sort of runs at network speed.
00:17:16.454 - 00:17:36.094, Speaker A: So if the maximum message delay happens to be small, then the protocol should run very quickly. Obviously, if the maximum message delay is really big, you might have to wait a while before the protocol can make progress. So we had this sort of intuition back then in lecture four that we want kind of a protocol that automatically adapts to the network speed.
00:17:36.094 - 00:17:56.050, Speaker A: And so this second version of partial synchrony maps very cleanly onto that intuition. So specifically in this second version of the partially synchronous model, we'll actually assume that we're in the synchronous model. So there literally will be a parameter capital delta so that every single message is delivered within delta time steps.
00:17:56.050 - 00:18:04.294, Speaker A: So in the second version, there's actually no GST. There's no transition from an asynchronous phase to a synchronous phase. There's a bound on the maximum message delay.
00:18:04.294 - 00:18:23.726, Speaker A: It's just that that bound capital delta is unknown to the protocol. So the protocol's description must be independent of any assumed value of capital delta. That's different than the main version of partial synchrony where the parameter capital delta is known priority to the protocol.
00:18:23.726 - 00:18:44.130, Speaker A: So the protocol's description can depend on it. However, delta only bounds message delay after GST in the synchronous space. Okay, so both of these models, I think, are actually quite natural, right? So the first version we sort of motivated is like you want to tolerate attacks and recover quickly after attacks.
00:18:44.130 - 00:18:56.220, Speaker A: I think it's a very natural model for capturing that intuition. We also had this idea that we wanted protocols that automatically adapt to the network speed. And this second model, I think, very nicely captures that idea.
00:18:56.220 - 00:19:09.162, Speaker A: So given that both of these models seem quite natural but also rather different, I mean, it now seems especially OD that they have the same name. They're both called the partially synchronous model. So why is that? Well, one is just historical.
00:19:09.162 - 00:19:32.854, Speaker A: I mean, so in this DLS 88 paper that introduced all this stuff, they basically said they considered two versions and they referred to everything as sort of the partially synchronous model. And that's persisted to this day. But a reason they did that and it's persisted is because as far as what kinds of consensus goals you can achieve, the two models are roughly equivalent, at least sort of to first order.
00:19:32.854 - 00:20:01.882, Speaker A: What you can do in one of the models is the same as what you can do in the other one. So, for example, on the next slide, we'll identify some goals we'd want of a consensus protocol, and then we'll proceed to give sort of an impossibility result for achieving those goals. If you have too many Byzantine nodes and a possibility result, a protocol that does achieve those goals, if you have a good bound on the number of Byzantine nodes, we're going to prove them in the original version of the partially synchronous model with the delta and the GST.
00:20:01.882 - 00:20:28.972, Speaker A: A good exercise for you to do is convince yourself that both the impossibility results and the positive result, the protocol, both of them achieve the same consensus goals in the unknown delta version of the partially synchronous model. So suppose we adopt the partially synchronous model. We want to solve some kind of consensus problem, maybe single shot consensus like Byzantine agreement or multi shot consensus like state machine replication.
00:20:28.972 - 00:21:12.300, Speaker A: What can we hope for? Well, an initial promising observation is that if you think about it, the key impossibility result for the Asynchronous model, the FLP impossibility result, it does not seem to at least immediately apply in the partially synchronous model. The reason it doesn't immediately apply is that the adversary controlling message delivery in the partially synchronous model really is fundamentally more constrained, really is fundamentally weaker than it is in the Asynchronous model. In the Asynchronous model, remember, it is true that every message has to eventually be delivered, but there's literally no constraints on the order in which messages are delivered at all.
00:21:12.300 - 00:21:30.228, Speaker A: Okay? So you can pick any pair of messages ever sent in the protocol, and I won't be able to tell you that one of those messages definitively arise before the other one. The Asynchronous adversary is so powerful, they can do whatever they want with ordering of the delivery of different messages. And that is not true in the partially synchronous model.
00:21:30.228 - 00:21:52.600, Speaker A: So it's true during the Asynchronous phase of the partially synchronous model. But for example, any message that's sent before Global Stabilization Time. So any message sent in the Asynchronous phase, it must arrive at the destination prior to any message sent after GST plus delta.
00:21:52.600 - 00:22:02.828, Speaker A: So remember, we had our promise on message delivery. Any message sent before GST arrives by GST plus delta. And so that means any message sent after GST plus delta must arrive afterwards.
00:22:02.828 - 00:22:26.708, Speaker A: Okay? So that is a non trivial constraint on the order in which messages must be delivered. And because the adversary was not so constrained in the Asynchronous model, it's not clear that the proof of the FLP impossibility result carries over a priori. It would be very natural to wonder, like, maybe you can just sort of tweak the proof of the FLP and possibility result so it still applies in the partially synchronous model.
00:22:26.708 - 00:22:43.164, Speaker A: I mean, after all, we said how, while we proved the FLP impossibility result for one Byzantine node, we talked about how you could tweak the proof. So it even holds just for one crash fault, which is kind of amazing. And so you might equally well wonder, well, maybe it's just another different tweak that actually extends to the partially synchronous model.
00:22:43.164 - 00:22:57.264, Speaker A: But as we'll see in Lecture seven, that's not the case. We're going to actually show a positive result in the partially synchronous model for attaining state machine replication. That is impossible by FLP in the Asynchronous model.
00:22:57.264 - 00:23:16.532, Speaker A: So there really is a formal separation between the two. You really can do fundamentally more stuff under the stronger assumptions in the partially synchronous model. Despite that, the FLP impossibility result is highly relevant for the partially synchronous model because in particular, it applies during the Asynchronous phase.
00:23:16.532 - 00:23:34.668, Speaker A: So if you're like trying to solve Byzantine agreement, for example, FLP tells you you're not going to satisfy termination and validity and agreement during the Asynchronous phase. You have to give up on at least one of those three things. You might hold out hope that you will satisfy all three of those properties after the Global Stabilization Time.
00:23:34.668 - 00:23:51.332, Speaker A: But up to that point, FLP applies, and definitely you're not getting all three properties at the same time. Now, let's actually talk through what we mean when we say a protocol solves a certain consensus problem in the partially synchronous model. Again, consensus problems.
00:23:51.332 - 00:24:05.836, Speaker A: I would think of Byzantine agreement as the canonical single shot consensus problem. Think of state machine replication as the canonical multi shot consensus problem. So first of all, we want a protocol that gives us everything we want.
00:24:05.836 - 00:24:37.952, Speaker A: So, for example, all the safety and liveness properties that we're interested in under normal operating conditions, including when an attack just recently finished. So in other words, not long after the Global Stabilization time and again, the adversary controls when GST is it's at some finite time, we don't know what. But not long after the attack ends, not long after the transition to the synchronous model, we would like safety and liveness to both hold so, for example, if we're talking about Byzantine agreement, we would like termination agreement and validity.
00:24:37.952 - 00:24:53.130, Speaker A: And if we're talking about state machine replication, we'd like consistency and liveness not long after the Global Stabilization time. We're never going to need to specify what we mean by not long after. I mean, you can imagine kind of more detailed research on this topic, kind of drilling down on that.
00:24:53.130 - 00:25:37.560, Speaker A: But in your mind, maybe think of it as like at the very least, you'd like it to be bounded above by some polynomial function of n, the number of nodes and capital delta, the maximum message delay once you're in the synchronous phase. All right? Now, secondly, why stop here? Why not try to also have nice properties in the asynchronous phase before GST? Well, okay, so FLP tells us we can't have everything we want before the Global Stabilization Time, so we have to give up something, but hopefully we give up only one thing. And indeed, the traditional approach to consensus and the partially synchronous model, it even sort of knows which one it wants to give up, which is you traditionally give up liveness during the asynchronous phase in favor of retaining safety.
00:25:37.560 - 00:25:55.234, Speaker A: So this probably is the most natural choice of what to give up on in the asynchronous phase to give up on liveness rather than safety. Because think about what those two words mean. So safety is about sort of some bad event you're concerned about.
00:25:55.234 - 00:26:05.270, Speaker A: You want to argue that it never happens. So it makes sense to sort of extend that to mean it never happens even if you're in the middle of an attack. Whereas think about what liveness means.
00:26:05.270 - 00:26:28.938, Speaker A: That means sort of eventually some good thing happens. So it's natural to sort of think of that as like, okay, well, I guess eventually means then sometime after GST, right? That's part of eventually, given that GST eventually happens. And possibly for this reason, I mean, the entire 20th century literature on consensus protocols, or at least the part of it that I'm aware of, adopted these same goals always under attack.
00:26:28.938 - 00:26:43.380, Speaker A: Maybe you have to give up liveness, but just make sure under no conditions do you ever give up safety, like, say, consistency in a state machine replication problem. And it's not just the 20th century protocols that have these properties. Many sort of modern blockchain properties also make this particular trade off.
00:26:43.380 - 00:27:13.706, Speaker A: However, it's very interesting to note that longest chain consensus as used, for example, in Bitcoin and Ethereum, actually does not make this traditional choice because it's actually an innovation that kicked off with bitcoin and its longest chain consensus protocol, which is under attack, to actually favor liveness over safety. So we'll talk more about that in a couple of lectures, but I just wanted to plant that seat. Now, we're going to be focused on these two goals for a couple of lectures, but we'll soon see that there's other interesting parts of.
00:27:13.706 - 00:27:37.580, Speaker A: The design space as well. So what in fact is possible in the partially synchronous model where there's actually a super crisp characterization of exactly when you can achieve these goals and when you can't in the partially synchronous model. And the magic threshold is 33% Byzantine nodes.
00:27:37.580 - 00:27:57.196, Speaker A: So this notice, this is really two results in one that kind of match up perfectly. So on the one hand, there's an impossibility result. And this is what we'll prove in the next video arguing that if you have at least a third Byzantine nodes, then in fact, these two goals cannot be achieved by any protocol.
00:27:57.196 - 00:28:08.804, Speaker A: No matter how clever in the partially synchronous model, it is not the case that you can get safety always and then also liveness after the global stabilization time. So that's coming up next. The proof of that impossibility result.
00:28:08.804 - 00:28:29.784, Speaker A: When you have too many Byzantine nodes, little F is at least a third times N. But then there's also a positive result here saying that if F is strictly less than a third, if you have less than 33% Byzantine nodes, then actually you can achieve both of these goals, goals one and two. And so the point of the next lecture, lecture seven will be to actually show you one protocol.
00:28:29.784 - 00:29:11.148, Speaker A: There's many protocols that achieve those two goals with F less than N over three. But I'm going to show you the tendermint protocol, which is one particular protocol that shows that when F is less than N over three, actually you can always be safe and in addition have liveness after the Global Stabilization Time. So this is a very famous results.
00:29:11.148 - 00:29:20.356, Speaker A: Let me say a couple of things about it. This sort of sort of threshold right at 33%. So I wrote here f less than N third at most of third nodes Byzantine.
00:29:20.356 - 00:29:37.440, Speaker A: To me personally, that's the most natural way of writing this condition. In distributed computing you will often see this phrased in the totally equivalent way saying that the number of nodes N should be at least three F plus one. So the number of nodes overall should be at least triple the number of faulty nodes plus one.
00:29:37.440 - 00:29:52.292, Speaker A: That's the same thing as saying that you need more than two thirds honest less than one third Byzantine. And that's a very famous inequality. I wouldn't be surprised if at some distributed computing conference people would have literally printed t shirts where this is what it said on it.
00:29:52.292 - 00:30:11.844, Speaker A: If they haven't done that, it's long overdue. So you will hear the sort of N at least three F plus one among kind of distributed computing specialists quite a bit. So secondly, also in the blockchain world, if you go and read various white papers, many of them, not all of them, but many of them will be very focused on a particular 33% threshold.
00:30:11.844 - 00:30:37.830, Speaker A: So like there's various proof of stake blockchain protocols which argue that their protocols work well, have sort of good provable guarantees as long as less than 33% of the stake is adversarily controlled. And this right here, this is the 33% that all of those white papers are talking about. So this is the fundamental impossibility result, which many different blockchain protocols refer to to justify why they can't do even more than they do already.
00:30:37.830 - 00:31:01.708, Speaker A: All right? So really, if you remember only one thing from our sort of boot camp on the fundamentals of distributed computing that were laid down in the 1980s by the brilliant computer scientists who preceded us, if you remember only one thing, remember the partially synchronous model. First of all, remember the definition of the partially synchronous model. And remember that consensus is possible if and only if little F is less than N over three.
00:31:01.708 - 00:31:13.516, Speaker A: This is really kind of the culmination of all of our study of the classical 20th century literature on this topic. So we'll start with the impossibility result. We'll prove that in full in the next video.
00:31:13.516 - 00:31:20.496, Speaker A: I encourage you to watch it. It's not as hard as the FLP impossibility result. I know some of you are kind of probably tired of the proofs and are going to skip it.
00:31:20.496 - 00:31:35.060, Speaker A: So I'm going to conclude this video with one slide of intuition behind that impossibility result. So why, intuitively, does it actually seem like 33% Byzantine is a very natural threshold to come up in the partially synchronous model. So we'll do that on the next slide.
00:31:35.060 - 00:32:07.354, Speaker A: Okay, so what's the intuition for this famous result that if you want to achieve consensus in the partially synchronous model, you really need to restrict to less than a third of the nodes being Byzantine? Well, actually, before I jump into that, let me point out, and you may remember this is not actually the first impossibility result we've seen where the magical threshold between possibility and impossibility was at one third Byzantine nodes. We also saw that way back in lecture three, that's when we were talking about the synchronous model. So there was no Asynchronous phase.
00:32:07.354 - 00:32:33.586, Speaker A: You always had guaranteed bound on the maximum message delay. And what we were showing in lectures two and three is that we're basically showing that cryptography matters in the sense that if you have the PKI assumption, the public key infrastructure assumption, then as we saw in lecture two, you've got the dole of strong protocol, which solves in that case we're talking about Byzantine broadcast. But it achieves consensus under literally no assumptions at all about how many nodes are Byzantine.
00:32:33.586 - 00:32:55.930, Speaker A: 90% of the nodes could be Byzantine, and still they're not going to be able to mess up and confuse the 10% of the nodes that are honest. Okay? And the Dolorestrong protocol, if you recall, really used the fact that we had public key infrastructure, right, that all of the nodes had public keys, which were common knowledge at the beginning of the protocol. That's what allowed them to do these sort of chains of signatures and convince each other of various values.
00:32:55.930 - 00:33:24.690, Speaker A: The point of the impossibility result in lecture three then, was that this cryptographic assumption, this trusted setup assumption, is really essential to getting the guarantees of the Doloth strong protocol. If you don't have a trusted setup, if you don't have public key infrastructure, then in fact you cannot solve Byzantine broadcast even in the synchronous model when a third or more of the nodes are Byzantine. And if you remember the role that the sort of lack of a trusted setup played in the proof of that impossibility result in lecture three, that was the hexagon argument.
00:33:24.690 - 00:33:44.922, Speaker A: We assumed that the Byzantine node had the capability to simulate the behavior of a bunch of honest nodes. And of course, under a PKI assumption, that might require you to forge certain signatures, which is going to be impossible, at least under the ideal signatures condition. But if you don't have a PKI, then the Byzantine nodes are perfectly capable of carrying out the simulation of honest nodes.
00:33:44.922 - 00:34:07.086, Speaker A: And that was enough to get the impossibility result to go through. Now this impossibility result for the partially synchronous model, this is going to be actually quite different and it's going to be driven by quite different forces. And the first indication that that's going to be true is that when you see the proof in the next video, you will notice that it holds whether or not you have a trusted setup assumption.
00:34:07.086 - 00:34:15.878, Speaker A: Okay? You never need to worry about Byzantine nodes simulating honest nodes. That's just not going to be relevant for the proof in the next video. So it really doesn't matter whether you have PKI or not.
00:34:15.878 - 00:34:52.638, Speaker A: So in other words, this impossibility result for the partially synchronous setting that you need less than a third node's, Byzantine to solve consensus that holds whether or not you have a PKI assumption, unlike the guarantees we saw in the synchronous model in lecture two. So evidently this sort of simulation of honest nodes by Byzantine nodes is not going to be relevant in this impossibility result. But what else we have going for us? The other possible driving force behind an impossibility result is that we're now in the partially synchronous model.
00:34:52.638 - 00:35:19.942, Speaker A: So we do not have this guaranteed bound on message delays. So what we should expect is that this impossibility result will be driven somehow by the threat of potentially unbounded message delays. So with that in mind, the fact that the threat of unbounded message delays must be somehow crucial to the argument.
00:35:19.942 - 00:35:27.706, Speaker A: Let me tell you the intuition behind the proof in two steps. Now, this is not a real proof. Both of these steps are going to be a little bit hand wavy.
00:35:27.706 - 00:35:45.938, Speaker A: They don't constitute a mathematical argument. Nonetheless, I think they give you pretty accurate intuition about what's driving this impossibility result, right? So some number of weeks or months from now, maybe you wouldn't remember the details of the proof in the next video. But I do think this sort of two parts of intuition, this is something actually, I think you can retain for a long period of time.
00:35:45.938 - 00:35:52.902, Speaker A: So when you hear about this 33% threshold, you should be able to kind of reverse engineer. Oh, yeah. Why was it 33%? Oh, yeah.
00:35:52.902 - 00:36:27.970, Speaker A: And it's going to be these two pieces of intuition right here. So the first part of the intuition is that as an honest node, you must be prepared to take action, meaning sort of conclude the protocol with some final value to take action, even though there may be some other nodes you've literally never heard from ever. And the reason for that is that one possible strategy for a Byzantine node is to literally never send out any messages at all, including after Global Stabilization Time, right? Messages sent by honest nodes, you know, will eventually be delivered after Global Stabilization Time.
00:36:27.970 - 00:36:51.180, Speaker A: A Byzantine node may give you the silent treatment forever. So because we want to satisfy termination, we want to sort of eventually have some output of the protocol, and up to little F nodes may be Byzantine. And giving you the silent treatment, you need to be ready to make a decision after hearing from potentially only N minus F nodes in total, counting yourself.
00:36:51.180 - 00:37:35.326, Speaker A: So the threat of silent treatment by Byzantine nodes forever kind of forces you as an honest node to make a decision before you might like you have to be ready to make a decision after you've only heard from N minus F nodes, counting yourself. Now, here's the real bummer, though, right? So you're making a decision early because of the threat that the nodes you haven't heard from are Byzantine. But there's another possibility, which is that actually the F nodes you haven't heard from are honest, and it's just that their messages have been delayed.
00:37:35.326 - 00:37:44.934, Speaker A: This is only possible if you're before the Global Stabilization Time. But remember, the global Stabilization Time could be at any point in the future. You have no idea whether you crossed it or not.
00:37:44.934 - 00:37:59.100, Speaker A: So it's indistinguishable from the situation where you're before the global Stabilization Time, and these F honest nodes are trying to send you messages. They're not trying to give you the silent treatment. They're trying to send you messages and you just haven't waited long enough to hear them.
00:37:59.100 - 00:38:44.674, Speaker A: And what this means is that of the N minus F voices you've heard, you cannot rule out the possibility that as many as little F of those are Byzantine, right? So you made the decision early because it's possible that these nodes you haven't heard from are Byzantine, but unfortunately, maybe they're not. Maybe those you haven't heard from are just delayed and actually like sort of wolves in sheep's clothing. You still have these F Byzantine nodes among the ones that have fed you some information, all right? So you wind up taking action having heard from only N minus F nodes in total and F of those might themselves actually be byzantine nodes feeding you bad information.
00:38:44.674 - 00:39:06.970, Speaker A: And so intuitively, if 50% or more of the nodes were Byzantine and feeding you false information intuitively, that could potentially lead you astray. So it feels like to make good use of the N minus F voices you've heard from. For example, to take a majority vote, it should be that a strict majority of the nodes you hear from are in fact honest nodes.
00:39:06.970 - 00:39:34.270, Speaker A: So we need the number of Byzantine nodes among these N minus F, the number of wolves in sheep's clothing to be strictly less than half of those N minus F nodes. So that gives us the constraint that F should be less than one half quantity N minus F. Or by simple arithmetic equivalently, f should be strictly less than N over three.
00:39:34.270 - 00:40:01.184, Speaker A: So overall, with this intuition, you kind of see the teamwork that goes on between the two different flavors of adversary we're dealing with here. On the one hand, sort of the behavior of Byzantine nodes and the potential for sort of permanent silent treatment and on the other hand, sort of the adversarial message delay at least sort of before the unknown global stabilization time. And because those two things working against you work in tandem, in effect, each Byzantine node sort of costs you twice.
00:40:01.184 - 00:40:40.864, Speaker A: Each Byzantine node kind of in effect cancels out the potential contributions of two of the honest nodes, right? So in step one, the threat that these nodes you haven't heard from being Byzantine, giving you the silent treatment that has the effect of causing you to potentially ignore contributions by honest nodes if they happen to just be delayed so that already there, you lose sort of f honest nodes just because you make a decision before you hear from them. But then you still can't rule out the possibility that the Byzantine nodes are amongst the N minus F nodes that are feeding you information. And there again, each Byzantine node can kind of cancel out an honest node by lying about what the output is supposed to be.
00:40:40.864 - 00:40:56.432, Speaker A: So at the end of the day, you sort of still need some honest nodes surviving after each Byzantine node has sort of knocked out two honest nodes from healthily participating. And so that's what gets you the F less than N over three threshold. So that, I hope, is some intuition.
00:40:56.432 - 00:41:10.616, Speaker A: It's not a proof, but it's both fairly accurate and perhaps something you can retain moving on into the future. This is such an important result, such a fundamental result. I do think it's really important, Gordon, to go through the rigorous proof.
00:41:10.616 - 00:41:12.810, Speaker A: So we'll do that in the next video. I'll see you there.
