00:00:00.410 - 00:00:13.678, Speaker A: Hello. So this lecture will be a segue of sorts into part three of the course. We will still talk a little bit about price of energy style guarantees for the end of lecture today.
00:00:13.678 - 00:00:49.660, Speaker A: But we're really going to shift our focus now to the question we've been talking about equilibria for seven weeks. Where do these equilibria come from? Do they grow on trees? How do players find them? It so can players reach an equilibrium for starters, even just in principle, even just forgetting about computation and how do they coordinate and so on, how would they find an equilibrium? This has been studied a little bit in economics, but not, in my opinion, enough. But as computer scientists, we really want more than this.
00:00:49.660 - 00:01:23.442, Speaker A: Players should reach an equilibrium, not just eventually, but in our lifetimes, quickly polynomial time. And this is something that really unsurprisingly, maybe was not studied at all pretty much until computer scientists took up the issue. And we'll see in the final in week ten that there are actually some complexity theoretic barriers in general to computing equilibria quickly, not just decentralized by players, but even by centralized computation.
00:01:23.442 - 00:02:02.594, Speaker A: But in the happy cases where you can compute equilibria quickly, at least in principle, then the question is how does this actually happen? So what are the learning algorithms or learning procedures by which players might plausibly reach an equilibrium in a game that they're trying to figure out how to play? So why do we care about these kind of questions? Well, we've been, like I said, reasoning about all of these systems, auctions networks and so on. We've been reasoning about their equilibrium. Essentially, we're sort of assuming that that's the operating point of these systems and drawing conclusions from it.
00:02:02.594 - 00:02:35.294, Speaker A: So giving a constructive argument about why these systems are going to be at equilibrium, that justifies all of this equilibrium analysis in particular, just as one example, the last couple of weeks we've been talking about efficiency properties at equilibrium. So this is going to justify the price of energy analysis we've been doing for the last couple of weeks. But if you're reasoning about some other properties of equilibria, maybe not their objective function value, but something else.
00:02:35.294 - 00:03:04.178, Speaker A: Again, these questions are what justify focusing on just the equilibria. Now, to reason about these questions, do players reach an equilibrium? If you think about it, we fundamentally need a model then for how players behave when they're not at an equilibrium. So, so far, pretty much all we've assumed is that an equilibrium persists.
00:03:04.178 - 00:03:29.070, Speaker A: If players reach there, they'll stay there and sort of intuitively, if you're not at an equilibrium, it shouldn't persist, something else will happen. So the question is what else is going to happen? And we need to pin that down to start making formal statements. So when people talk about learning dynamics, this is really what they mean.
00:03:29.070 - 00:03:52.118, Speaker A: They're sort of positing some way by which player behavior evolves over time. It. And so to be clear, our goal will not be so ambitious as to posit some model that seems to literally describe how people might actually learn in a game.
00:03:52.118 - 00:04:07.834, Speaker A: That's ambitious. Kind of any specific model is going to probably seem not fully convincing. So rather, what we're going to strive for is simple and natural models that give us predictions, that tell us about whether we'll have convergence or not, what things will converge to how quickly, and so on.
00:04:07.834 - 00:04:23.794, Speaker A: And then ideally, we'd like to draw the same conclusions from multiple different learning processes, multiple different dynamics. So if we can have different models that all lead us to the same conclusion, that lends plausibility and confidence to the conclusion that these models are predicting. Okay, so that's what we'll be looking at.
00:04:23.794 - 00:04:53.626, Speaker A: Simplistic learning dynamics that we can reason about with an eye toward hopefully kind of replicatable results across different choices of the dynamics we'll talk about. Mostly two different styles of dynamics in this class today is going to be devoted to best response dynamics. The idea is very simple.
00:04:53.626 - 00:05:10.590, Speaker A: This is just a process, an iterative process by which players might strive for a pure strategy Nash equilibrium. So at all times in this process, players will be playing pure strategies. The other dynamics we'll look at that will not be true, but for today, all pure strategies.
00:05:10.590 - 00:05:27.110, Speaker A: So if you're at an outcome. So here's our model of what players do out of equilibrium. So while an outcome is not a pure schedule equilibrium, that means there's some player with a beneficial unilateral deviation.
00:05:27.110 - 00:06:10.670, Speaker A: So we pick one of them for now, it's arbitrary, and we just let them pick a beneficial deviation, again, for now, arbitrary which one they choose. Okay, so before the player was playing its strategy si, its cost decreases or its payoff increases. If it switches to si prime and we just let it switch, we keep s minus I fixed.
00:06:10.670 - 00:06:21.494, Speaker A: So in each iteration exactly one player will update their strategy. The other K minus one players will stay fixed. So this is underdetermined, right? I'm leaving which player you choose.
00:06:21.494 - 00:06:29.930, Speaker A: If there are many underdetermined, I'm also leaving which deviation, improving deviation to choose, if any. underdetermined. We'll specialize those only as needed through the lecture.
00:06:29.930 - 00:07:08.030, Speaker A: So if this process converges, if it halts, what kind of outcome is it going to halt at? We just look at the stopping criterion, right? So the only way this thing will halt is if it finds a piranhasi equilibrium. And conversely, if it finds one, it will halt. So note if that's of course a big if best response converges, it is to a pure strategy Nash equilibrium.
00:07:08.030 - 00:07:26.940, Speaker A: So the contrapositive then says in a game with no pure Nash equilibrium, of course best response dynamics will not converge, it will cycle. As you'll see on the exercise said, best response dynamics might even converge in the presence of a pure Nash equilibrium. Just because there isn't one doesn't mean that this procedure is automatically going to find it from an arbitrary starting point.
00:07:26.940 - 00:07:55.170, Speaker A: But where best response dynamics do really well is in potential games, which includes almost all of the applications we've been studying for the last few weeks. So recall a potential game. So we discussed potential functions, we used them a couple of different times on Monday and we introduced them last week to prove existence of period equilibrium in routing games originally.
00:07:55.170 - 00:08:34.210, Speaker A: So in general it's a game that emits a potential function which I've been calling phi, with a property that attracts the deviations by all players simultaneously. So meaning for all starting states, s for all players, I for all deviations, beneficial or otherwise, that I might take. The change in fee is exactly equal to the change in cost incurred by that player, that deviating player.
00:08:34.210 - 00:08:59.750, Speaker A: So if player number seven deviates from some outcome and its cost drops by ten, the potential function value also drops by precisely ten. We've seen a number of examples. The first one was atomic selfish routing games.
00:08:59.750 - 00:09:18.160, Speaker A: Then there were location games, those were also potential game where the surplus was the potential function. And just last lecture we introduced network cost sharing games which are also potential games with the Rosenthal potential. So most of the examples from the last couple of weeks fall under this class.
00:09:18.160 - 00:09:27.726, Speaker A: We've mentioned a couple times that potential games always have pure strategy. Nash equilibrium, the outcome that's the global minimizer. The potential function of fee has to be a Nash equilibrium.
00:09:27.726 - 00:09:32.526, Speaker A: All deviations only make the potential bigger, so they only make the deviators bigger. It's a nash. Equilibrium.
00:09:32.526 - 00:09:52.570, Speaker A: But if you think about it, even more is true. There's a rather more constructive proof that every potential game has a pure Nash equilibrium, namely, pick any starting state you want, let best response dynamics run. It's going to stop at pure Nash equilibrium.
00:09:52.570 - 00:10:23.170, Speaker A: So this was really articulated by Mondar and Shapley. So in a potential game it should be finite like the ones we've been talking about. Best response dynamics converges to a pure Nash equilibrium.
00:10:23.170 - 00:10:50.476, Speaker A: The proof is one line. What's the proof? Why does best response dynamics have to halt in a finite potential game? Right? That's the key point. In every iteration some player moves they switch to it's a beneficial deviation.
00:10:50.476 - 00:11:00.660, Speaker A: So their cost drops by the defining property of a potential function. If the cost drops, the potential drops. So you can't cycle it's strictly decreasing every time.
00:11:00.660 - 00:11:03.350, Speaker A: It's a finite game. So you run out of outcomes. Got to stop.
00:11:03.350 - 00:11:20.492, Speaker A: Good. So that's cool. So remember we were saying, thinking about equilibria, can players reach equilibrium? So this is basically a yes to the first question.
00:11:20.492 - 00:11:47.696, Speaker A: In principle, sure, they just follow best response dynamics. If you're in a potential game, you will converge. How about the second question? How about quickly? So what can we say about the speed of convergence? Well, it sort of depends how strongly we want to define what it means to converge.
00:11:47.696 - 00:12:02.936, Speaker A: So we're going to talk about sort of three different notions of what it means to converge. The first one only briefly, the first one's the strongest, which is you get to a Pyreneesh equilibrium. It's sort of the obvious definition that need not be fast.
00:12:02.936 - 00:12:24.392, Speaker A: We'll understand that more why it has to be slow in the last week of the class, when we talk about the complexity of these problems. So you could make some strong extra assumptions. So, like, if you assumed that this potential function phi was integral, and if you assumed it was polynomially bounded, then you'd be fine, right? Because then every iteration, if the potential drops, it has to drop by at least one, because it's integral.
00:12:24.392 - 00:12:39.536, Speaker A: If it's polynomially bounded and non negative, then you run out of potential in a polynomial number of iterations. And there are examples which satisfy those hypotheses. But in general, if the potential function is not polynomially bounded, it can take an exponential number of iterations to reach a pure equilibrium.
00:12:39.536 - 00:12:50.296, Speaker A: So that's all I'm going to say about that strongest notion of convergence. But we'll revisit it in a couple of lectures. So the other two notions I'm going to talk the rest of the lecture about.
00:12:50.296 - 00:13:10.248, Speaker A: So I'll talk about both of them at length. So the next idea to the first of the two main approaches we'll discuss would be, okay, maybe we don't want to, maybe it's not important. We get to an exact Nash equilibrium.
00:13:10.248 - 00:13:40.688, Speaker A: As long as we're at almost a Nash equilibrium, that's good enough. So can we reach an approximate pure strategy Nash equilibrium and a polynomial number of iterations? And that would be a pretty good positive result if we could do that by an approximate Kiranash equilibrium. We mentioned this briefly last week.
00:13:40.688 - 00:13:58.220, Speaker A: This just means that you might have a deviation that could decrease your Cost, but not by very much. So in this lecture, we'll use the definition, at an epsilon Nash equilibrium, you can only go down by, you can only get multiplied by a one over one minus epsilon factor. So you might want to think of epsilon as like 0.1,
00:13:58.220 - 00:14:05.728, Speaker A: something like that. That would say that any deviation your cost is going to be at least 90% of what it is now. So that would be a 0.1
00:14:05.728 - 00:14:31.968, Speaker A: approximate pure Nash equilibrium. Now, one reason, okay, so intuitively, it seems like being at an almost Nash equilibrium should be basically as good as being at a Nash equilibrium. And I even asked you on the exercise set to work out sort of a formalization of that idea, which is at least if you're in a smooth game, you just proved that epsilon pure Nash equilibria have price of Anarchy, almost as good as exact pure Nash equilibrium.
00:14:31.968 - 00:14:44.030, Speaker A: So if you care about the price of anarchy and it's a smooth game, like all of the examples we've seen, then you really don't care if it's an epsilon Nash or a real Nash. So we'd be pretty happy with this result. Good.
00:14:44.030 - 00:15:11.620, Speaker A: So we're also, out of respect to the epsilon, going to change the dynamics a little bit in the obvious way, and this is really the key to the speed up. So I'm going to show you a positive result for epsilon pure Nash equilibrium, which does not hold for exact Nash equilibrium. And the reason is that we can insist in best response dynamics on deviations that actually help the player not just a tiny bit, it doesn't just save you a penny, but that helps you a lot.
00:15:11.620 - 00:15:38.204, Speaker A: And we're only going to focus on deviations that offer a significant improvement. So that's epsilon best response dynamics. So while there exists a player that can decrease its own cost by at least one minus epsilon factor, so again, if epsilon was 0.1,
00:15:38.204 - 00:16:16.648, Speaker A: this would say if you can cut your cost to 90% of what it is now, then you're eligible. So I'll call this an epsilon move if it multiplies your cost by one minus epsilon or less. So while there's a player that has an epsilon move, let one such player take an arbitrary such movement, okay? Yeah, right.
00:16:16.648 - 00:16:44.268, Speaker A: So can so let's say with deviation such that new cost is at most one minus epsilon old cost. Sound good? Thanks. So I'm still leaving underdetermined.
00:16:44.268 - 00:16:51.172, Speaker A: So if there are many players that have an epsilon move, you pick one of them. Arbitrarily. If the player has multiple epsilon moves, any one of them, I don't care.
00:16:51.172 - 00:17:26.356, Speaker A: The thing you're not allowed to do is take improving moves that improve only a tiny bit, okay? And that's key to the speed up. All right? So this thing and epsilon best response dynamics fits naturally with epsilon pure nash equilibria, because if this thing converges, the stopping criterion is nobody has an epsilon move, so nobody can multiply their cost by one minus epsilon or less by deviation. So that's our definition of an approximate nash equilibrium for today's.
00:17:26.356 - 00:17:47.290, Speaker A: So if it converges, it converges to an epsilon move, and if it's in a potential game, and that's all we'll be talking about today, is potential games again, every one of these decreases the potential. So there can't be an infinite number of these. We're even hoping there's only a polynomial number of these, but it's clear there's only a finite number of these.
00:17:47.290 - 00:18:31.860, Speaker A: So converges to an epsilon whoops pure showed you national equilibrium and a potential gain. So finite convergence is clear. And what's interesting to think about and which we'll be talking about for the next half hour or so, is how fast are there interesting conditions under which we can get a polynomial time guarantee on the number of iterations of epsilon best response dynamics before we converge necessarily to an approximate pure and ash equilibrium.
00:18:31.860 - 00:19:26.500, Speaker A: Any questions about the setup? Okay, so here's we're going to spend a lot of the lecture on the following theorem by Shen and Sinclair 2000. And so what Shennons and Claire do is they identify some conditions on a routing game that are sufficient for a polynomial time guarantee for epsilon best response dynamics. So they're not going to prove it for every single routing game and it's not going to be true for every single routing game, but they identify a nice class where you can get this really quite strong result that you get convergence in polynomial time to one of these almost equilibria.
00:19:26.500 - 00:19:45.230, Speaker A: So here's what they say. So consider an atomic selfish routing game. It need not have affine cost functions, but if you want to have that case in your mind, that's perfectly fine.
00:19:45.230 - 00:19:57.712, Speaker A: So that so let me tell you what the assumptions are. So here's the biggest one. The biggest one is the assumption it's going to be a symmetric game.
00:19:57.712 - 00:20:15.536, Speaker A: That is, every player has exactly the same source and exactly the same sync. So in particular, every player has exactly the same set of strategies, the st paths. Other than that, the network topology can be arbitrary, be an arbitrary network.
00:20:15.536 - 00:20:45.180, Speaker A: So that's good. So here's a nontrivial assumption, but it's less severe. We're going to call this the alpha bounded jump condition, sort of a Lipstitz condition on the cost functions, which just says when you add one new player to an edge, the cost doesn't totally blow up like crazy by most an alpha factor.
00:20:45.180 - 00:20:51.850, Speaker A: So for all edges, for all possible load amount.
