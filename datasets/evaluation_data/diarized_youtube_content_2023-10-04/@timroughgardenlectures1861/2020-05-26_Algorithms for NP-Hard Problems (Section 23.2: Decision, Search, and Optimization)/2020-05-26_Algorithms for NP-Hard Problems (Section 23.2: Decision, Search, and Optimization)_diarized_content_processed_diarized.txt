00:00:00.490 - 00:00:10.670, Speaker A: Hi everyone, and welcome to this video that accompanies section 23.2 of the book Algorithms Illuminated, part Four. It's a section about decision search and optimization.
00:00:10.670 - 00:00:39.930, Speaker A: So before we move on to formally defining what we mean by problems solvable by naive exhaustive search, which will correspond to the complexity class NP, let's take a step back and categorize the different types of input out put formats that we've seen in the computational problems that we've studied thus far. It's worth differentiating between three different types of computational problems. So let me list them in what would seem to be increasing order of complexity.
00:00:39.930 - 00:00:54.534, Speaker A: First, we have the decision problems. So these are problems where an algorithm is only responsible for outputting a binary answer yes or no. So for example, the decision version of the three set problem, the input would be the same as always, a three set instance.
00:00:54.534 - 00:01:10.370, Speaker A: So a bunch of disjunctions of at most three literals each. And for the decision version, all an algorithm would have to do is either say yes it's satisfiable, or no, it's unsatisfiable. It would not, for the decision version, be responsible for actually producing a satisfying assignment when one exists.
00:01:10.370 - 00:01:36.826, Speaker A: Decision problems are convenient when developing computational complexity theory, but in real applications, they're also going to sort of the rarest of the three that we're going to talk about. Usually in applications, you actually want a feasible solution, not just to know that one exists. And accordingly, in this entire video playlist, we've only seen one decision problem, which was in the opening sequence when I was giving you that glimpse of the two step recipe for proving problems NP hard.
00:01:36.826 - 00:01:55.060, Speaker A: So back in that reduction, we reduced the directed Hamiltonian path problem to the cycle free shortest paths problem. And if you go back and look at that reduction, we were actually using the decision version of directed Hamiltonian path. So the algorithm was only responsible for outputting yes or no, depending on whether the graph had a Hamiltonian path or not.
00:01:55.060 - 00:02:22.182, Speaker A: Moving on to a category of problems which you do see in applications are search problems. So here an algorithm's responsibility is given an instance to either hand back a feasible solution or to correctly report that none exist. We've seen several search problems in this video playlist sat and threesat are really canonical versions where I give you a bunch of disjunctions of literals and you either have to report a satisfying truth assignment or correctly report that nonexist.
00:02:22.182 - 00:02:44.080, Speaker A: Graph coloring that was also a search problem, either exhibit a k coloring or correctly report that it's not K colorable. Similarly, the versions of Hamiltonian path that we used in the previous chapter for NP hardness reductions, those were also search problems. Either report a Hamiltonian path or correctly report that nonexist subset sum, now that I think about it also a search problem.
00:02:44.080 - 00:03:04.930, Speaker A: The majority of the problems that we've discussed in this video playlist are optimization problems. So an algorithm for an optimization problem is responsible not just for figuring out whether or not there's a feasible solution, but then if there is at least one feasible solution, it's responsible for handing back the best one. So in an optimization problem, you also specify an objective function to be maximized or minimized.
00:03:04.930 - 00:03:19.882, Speaker A: And an algorithm needs to, among all feasible solutions, return one with the best possible objective function value. Or if there are no feasible solutions, the algorithm should, as usual, correctly report that fact. We've been studying several different optimization problems.
00:03:19.882 - 00:03:38.322, Speaker A: So just to rattle off a few, right, the traffic salesman problem, you want a minimum cost tour, the knapsack problem, you want a maximum value feasible solution and similarly makespan minimization maximum coverage and influence maximization. So all three types of problems reference a feasible solution. And what that actually means is problem specific.
00:03:38.322 - 00:04:02.806, Speaker A: Sometimes it's going to correspond to satisfying assignments, or it might correspond to Hamiltonian Paths or traveling salesman tours, whatever. And for optimization problems, the objective function is also going to be problem specific, right? Minimizing the total cost, maximizing the total value, et cetera. Now, complexity classes, as we'll be discussing in this chapter, they usually stick with problems of only one of these three categories to avoid type checking errors.
00:04:02.806 - 00:04:28.020, Speaker A: And so when we define the complexity class NP formally in the next video, it will be defined as a class of search problems. I should warn you that most books in both complexity theory and algorithms define the complexity class NP in terms of decision problems rather than search problems. The reason they do that is because it's more convenient for developing complexity theory.
00:04:28.020 - 00:04:52.930, Speaker A: The reason I'm not doing it is because decision problems are further removed from the natural algorithmic problems that are our focus in this video playlist. You shouldn't really worry about the distinction, though, as all the algorithmic implications of NP hardness, including whether or not the P not equal to NP conjecture is true, is false. All of that remains exactly the same, no matter whether you define the complexity class NP in terms of decision problems or in terms of search problems.
00:04:52.930 - 00:05:12.496, Speaker A: Now, you might be concerned that in restricting our definition of the complexity class NP only to search problems, we're leaving optimization problems like the traveling salesman problem out in the cold. And obviously those are problems that we care about quite a bit. But not to worry, optimization problems have a natural search version.
00:05:12.496 - 00:05:31.516, Speaker A: So for example, you can turn the traveling salesman problem into a search problem by the input. In addition to specifying a graph with edge costs, as usual, you also specify a target objective function value. So the search problem would be, for example, if there's a traveling salesman tour with cost at most 1000, give me one.
00:05:31.516 - 00:06:00.150, Speaker A: Otherwise correctly report that no tours of that quality exist. Or in the Napsack problem, you would say, give me back a collection of items with total value at least 10,000 or correctly report that no such subsets of items exists. In general, you can turn an optimization problem into a search problem by specifying the subjective function target capital T and asking whether there's a feasible solution with objective function value at least as good as T.
00:06:00.150 - 00:06:12.532, Speaker A: The search version of an optimization problem is only going to be easier. So if you can solve the optimization problem, you could certainly solve its search version. But there's actually also a reduction in the other direction.
00:06:12.532 - 00:06:43.004, Speaker A: So if I gave you a box solving the search version efficiently. So, for example, if for the traveling salesman problem I gave you an efficient subroutine that took his input a Tsp instance and a target tour cost and either reported back a tour with cost at most of the target or correctly reported that no such tour existed. I could just use that subroutine over and over again inside a loop that's binary searching over the target objective function, value capital T and I could use that subroutine to compute a minimum cost traveling salesman tour.
00:06:43.004 - 00:06:57.568, Speaker A: So given a magic box solving the search version, I actually can solve the optimization problem as well. Now, this is generally not how you'd want to actually approach an optimization problem in practice. Generally an optimization problem, you want to just solve it directly, the way we've been doing throughout this book series.
00:06:57.568 - 00:07:34.986, Speaker A: But for the purposes of this chapter only, where we're just trying to figure out which problems are polynomial time solvable and which ones appear not to be, there's no reason to distinguish between the search and optimization versions. One of them is polynomial time solvable if and only if the other one is, and similarly, one of them is NP hard if and only if the other one is. With these preliminaries out of the way, now that we know that our focus for the moment will be squarely on search problems, we're ready to formally define the complexity class NP in the next video.
00:07:34.986 - 00:07:35.640, Speaker A: I'll see you there.
