00:00:07.770 - 00:00:23.322, Speaker A: Today I will be talking about subgraphs that are fed by substreams, which is a new technology by the Graph, built by one of the core teams of the Graph Streaming Fast. First about Me my name is Sandra, I am a med student at Weekend University, Turkey. I'm from Turkey.
00:00:23.322 - 00:00:41.930, Speaker A: I also work as a developer at Ops, which is another core team at the Graph. Today we'll be talking about what the Graph is and then bounties quickly about subgraphs. And then we're going to compare the subgraphs with substreams and then talk about substreams and subgraphs by substreams, which is the main point of this workshop.
00:00:41.930 - 00:00:53.802, Speaker A: About the graph. Graph is the data layer of Bigtree. It allows you to index and query blockchain data and we'll see how it does that in detail in a moment about the prices.
00:00:53.802 - 00:01:11.154, Speaker A: So if you build a subgraph or use an existing subgraph, you might be eligible for Bounties. And also if you use substreams or deploy your subgraph to the Subgraph studio, you get bonus points to use substreams. You should pay attention because I'll show you how.
00:01:11.154 - 00:01:24.514, Speaker A: So the subgraphs quickly, they are in ETL process extraction, transformation and load of blockchain data. And the way they do it is, I mean they consist of three components. The first is subgraph.
00:01:24.514 - 00:01:31.722, Speaker A: YAML is the Manfest file, which is a configuration file. Here we see that we're listening to Ethereum. You can see it here.
00:01:31.722 - 00:01:39.110, Speaker A: And subgraphs listen to the contract events. So we have to specify which contracts we're listening. We have one contract here, which is the GRT contract.
00:01:39.110 - 00:01:54.826, Speaker A: In my example, GRT is a token of the Graph. And then for each event we have a handler which transforms the event data to the entities we want in the schema in the store of the subgraph. Here we are seeing a simple handler.
00:01:54.826 - 00:02:11.554, Speaker A: It takes the event data and then populates the fields of an entity. In the schema, we define the shape of the data we want in the store. As I said, okay, substream is a new technology and if you know about subgraphs, it might be a bit confusing.
00:02:11.554 - 00:02:18.210, Speaker A: So we're going to compare them. As I said, subgraph is an ETL process. The whole thing extraction, transformation and load.
00:02:18.210 - 00:02:38.426, Speaker A: But when it comes to substreams, I write that they're Et, but actually it's the transformation layer. But extraction also comes built in. If you are developing substreams, the extraction happens by Firehose and other technology developed by streaming fast and transformation is done by substreams, but there is not necessarily a load layer.
00:02:38.426 - 00:02:46.066, Speaker A: So you have to define where you store your data at the end. And we call them syncs in substreams. That's the term that we used.
00:02:46.066 - 00:02:59.122, Speaker A: And in my case, Mysync will be a subgraph. That's why a subgraph fed by substreams, that's the name. And another difference is that subgraph handlers, the functions that transform the data, they are written in SM script.
00:02:59.122 - 00:03:10.170, Speaker A: But in substreams we write them in rust. Also, substreams are composable. So substreams consist of modules, many modules that transform and filter data.
00:03:10.170 - 00:03:32.846, Speaker A: And if you have a module or even the whole substream developed and then processed, you can reuse it and other developers can use it as well. And substreams are parallelizable, which means that, let's say you're processing, I don't know, two millions of blocks, you can process the first million in parallel, the second million, which makes things a lot faster. That's why they're faster.
00:03:32.846 - 00:03:53.158, Speaker A: I mean, one of the reasons why they are faster than subgraph. Also in subgraph case, you can only listen to the events and maybe occasionally make contract calls. But in substreams you have the whole block data, which is my favorite about substreams, you have the calls, transfers, logs, even the stored changes.
00:03:53.158 - 00:04:11.740, Speaker A: So everything that happens to block you can see in your substreams. Also, since you get the whole block and the block comes with ordinals so everything that happens has an order, has an order in the block. So you know what happened before, what you know, the rank in the block of everything, that's another thing.
00:04:11.740 - 00:04:32.850, Speaker A: Now, when it comes to substreams back subgraph, we get rid of the mappings where the transformation happens, we replace it with substreams and we keep the subgraph YAML and the schema. But subgraph YAML will look a bit different. I will show you in a moment, because our subgraph no longer listens to the block, but it listens to a module from the substreams.
00:04:32.850 - 00:04:42.802, Speaker A: substreams, as I said, they consist of many small modules. Here I will show an example. And this is the module graph of a substreams.
00:04:42.802 - 00:05:00.122, Speaker A: We have the block, the block is the input of the map, map transfers. This is a module, and this map just filters data and feeds the data to downward modules. And then the other modules do their own transformation and filtering and then feed it to the downward modules at the end.
00:05:00.122 - 00:05:20.530, Speaker A: In our example, since it's a subgraph head by substreams, we have a special module which is called Graph Out, which will feed the data to subgraph store. And I have two more maps, map accounts and map block, total supply chains, that's just for demoing, just showing you how to use stores. There are functions of stores, but we're not going to use it for our subgraph.
00:05:20.530 - 00:05:38.162, Speaker A: So substreams, we have two types of modules, as you can see, maps and stores. The maps, they take bytes as input and then output bytes, and in the meantime they transfer and filter data. And these bytes are encoded as protobuff messages.
00:05:38.162 - 00:05:54.926, Speaker A: Here you can see protobuff definitions that you should do if you're a substream developer, you should define what type of output your handler will have. I defined a transfer just to keep it simple. And here you can see the input of my module is the block and the output is the transfer.
00:05:54.926 - 00:06:14.002, Speaker A: protobuff I defined when it comes to stores, okay, stored are stateful, but they're not the final store. This shouldn't be confused because in subgrass when we say stored we mean the permanent store, the database. But here we have the stateful temporary stores where your modules will use.
00:06:14.002 - 00:06:27.158, Speaker A: So whatever you put in the store will not be queryable or anything. You're just going to use it in your other modules while your substream is running. Here we see this guy has the value type and update policy.
00:06:27.158 - 00:06:39.178, Speaker A: So the reason is that for the value type, every store has a value type because stores consist of key value pairs. So you set it in the beginning and you cannot change it. Every store will have a specific value type.
00:06:39.178 - 00:06:55.338, Speaker A: Update policy comes from the fact that as I said, modules can be run like the run times, they can be parallelizable. So if you don't have an update policy, you cannot really merge them. So let's say you process the first million block and then the second million block.
00:06:55.338 - 00:07:05.726, Speaker A: Now they have to be merged. So this is where the update policy comes in. If I have an Ed here, this store is going to be storing balances of GRT for users.
00:07:05.726 - 00:07:16.022, Speaker A: So the first million block will have a balance for a user, the second million will have a balance and then we're going to edit because that's how you calculate the balance. So we have different value types. You can check this.
00:07:16.022 - 00:07:23.278, Speaker A: This is from the docs of Streaming Fast. And we also have different update policies. Set if not exist.
00:07:23.278 - 00:07:36.206, Speaker A: In the Set case, the last key wins and in Set, if not exist, the first key wins. We have the Admin, Max and Append. Okay? Now let's see how a substream looks like.
00:07:36.206 - 00:07:48.158, Speaker A: So we start with the substreams YAML. This is the configuration for the substreams. And here we defined, I don't know the file for photo imports, et cetera, but the important part is the modules.
00:07:48.158 - 00:07:58.850, Speaker A: This is what I showed you before. I have the Transfer Modules store modules, other store and transfer modules. Sorry, map and stores.
00:07:58.850 - 00:08:12.230, Speaker A: And here, as I said, you define the val tag, update policy, input, output, everything. And in the protofap file I also showed you this. You define the input output shape of your data in deliveries.
00:08:12.230 - 00:08:23.920, Speaker A: This is where you actually write your modules, the handlers. The first example of a module is the met transfers that we have seen. Here the first guy here.
00:08:23.920 - 00:08:36.766, Speaker A: So what this does is that we have the GRT token contract. Again, GRT is the graphs token and we just look through all the logs coming from the block. As you can see, the input of this map is the block, the whole block.
00:08:36.766 - 00:08:51.986, Speaker A: But I stick to the events because it's more beginner friendly. But if you want to see more advanced stuff about the block information, I like store changes. If you want to learn about them, I can also show that to you if you come to our booth.
00:08:51.986 - 00:09:10.826, Speaker A: So we look through logs here and we just skip everything that's not from GRT token contract. And whenever we see a transfer event, we create a protobuff transfer that we defined and we output this. Now, where does this go? We have seen that here we define input output.
00:09:10.826 - 00:09:27.470, Speaker A: So this is where the substreams graph is defined here. This map transfer's output is the input of store balances. Store balances is where we keep track of the balances of each user on each transfer.
00:09:27.470 - 00:09:41.106, Speaker A: We just add like increase the balance of a user if it's to that user and decrease it if it's from that user. That's very simple. But the reason why I have it here is because I want to show how to use the stores in delta mode.
00:09:41.106 - 00:10:01.558, Speaker A: So the logic of delta mode comes from the fact that, let's say again, you're calculating the balance of a user, but a user might be making ten transfers in one block. Maybe they did a multiple, maybe they have a bot, something like that. And then the value of their key, the account address will be the key, the value will be the balance.
00:10:01.558 - 00:10:10.970, Speaker A: It will be changing ten times in one block. So these are called deltas, the changes in one block. So the whole substreams graph is executed on each block.
00:10:10.970 - 00:10:22.494, Speaker A: So that happens on each block. So we have the deltas of the block. If one store changes multiple times, even if it's one, we're going to have one delta.
00:10:22.494 - 00:10:41.110, Speaker A: So in a store, when we get the store as an input from another map, this map account gets the store balances as an input. You can look through deltas. And here, just to show you how we do that, we get for each delta we create an account protobuff.
00:10:41.110 - 00:10:50.826, Speaker A: This is just for an example. You wouldn't really do this, but we can run this map account to see what it does. I have map transfers.
00:10:50.826 - 00:11:05.006, Speaker A: Let's make map accounts. And also we can run it or we can use the GUI, which looks a bit cuter. So here this is the output of map accounts module.
00:11:05.006 - 00:11:16.310, Speaker A: As you can see, there is apparently only one transfer so far. This is right now streaming from the block, by the way. So there's only one GRT transfer.
00:11:16.310 - 00:11:30.610, Speaker A: So we see that protobus here. So if there is any other, I can switch, but there is none. And also I can switch from module to module.
00:11:30.610 - 00:11:42.014, Speaker A: We can also see map transfers here. It's because map transfers was an input to store balances and store balances was an input to map account. So all the map is running at the moment, as we can see.
00:11:42.014 - 00:11:56.020, Speaker A: There is another we can just jump here, another activity, another transfer, another transfer, another transfer, and so on. So it's really fun to use the glee. So let's stop it and continue.
00:11:56.020 - 00:12:06.882, Speaker A: We have another mode that we can use stores. In that mode is the Get mode. So with the deltas you can see all the changes.
00:12:06.882 - 00:12:23.990, Speaker A: With the Get mode you can have access do you remember the Ordinals? You can have access to a specific Ordinal, the value of a key at a specific Ordinal. So in this example, we are calculating the total supply in the first store. That's very straightforward.
00:12:23.990 - 00:12:47.854, Speaker A: In the other map, in the other module, which takes that store as an input, we are using the Get functions. So here I just created, let's say, let's calculate on each block how much the total supply of TRT has changed. The way we do it is by we have a special function which is Get first, which gives you the value at the beginning of the block, the keys value at the beginning of the block.
00:12:47.854 - 00:12:54.660, Speaker A: And this is the key we get at the beginning of the block here. And we have the Get loss. We also have get.
00:12:54.660 - 00:13:08.280, Speaker A: If you know the Ordinal, let's say you want to know the balance of a user at a specific transfer. You would get the Ordinal from the transfer and then ask for the value here using it. That's another one.
00:13:08.280 - 00:13:16.214, Speaker A: Let's not run that. Okay, from here this is just substream so far. We want to actually build a subgraph set by substream.
00:13:16.214 - 00:13:32.462, Speaker A: So we did all these transformations and I think you can use this project, it's in GitHub and I'm going to share the link with you. You can use this as a template because there are many files that you have to create and many things that you have to do. I would just clone this and change stuff.
00:13:32.462 - 00:13:43.806, Speaker A: So from here we actually want this data to be stored in subgraphs. How do we do it? In a subgraph we have the schema. Again, very simple schema.
00:13:43.806 - 00:14:00.438, Speaker A: For today's example, we have the GRT entity which holds the total supplied transfers. Maybe I want to list all the GRT transfers in my front end and the account, just balances of each account. Now the subgraph YAML will look simpler and will take graph out as the input.
00:14:00.438 - 00:14:12.350, Speaker A: As I said, no longer it's not interested in the block anymore, no handlers, nothing. And the way we do it is, as I said, there is this special graph out module. We use entity changes.
00:14:12.350 - 00:14:30.094, Speaker A: So entity changes are again protobuff definitions which just go and change the store on each entity changes protobuff coming from the graph out. So let's say your transfer entity, this is the name of the entity. From the subgraph store there comes a transfer entity.
00:14:30.094 - 00:14:40.562, Speaker A: You give the ID, specify the ID and the order. And then there's the operation here. It can be update, delete, create, but if the entity doesn't exist, it will be created when you use the update operation.
00:14:40.562 - 00:14:50.874, Speaker A: So I always use the update operation and this change function will just update the field of your entity. With the new value. This how it does it.
00:14:50.874 - 00:15:04.350, Speaker A: And the other entity change is using the deltas. It's just updating the balances of accounts on each delta. And this guy is updating the total supply on each delta.
00:15:04.350 - 00:15:18.110, Speaker A: And the output will go to the subgraph, as I said. And eventually we're going to have the subgraph fed by substreams. Now let's run Breath Out just to see what it outputs.
00:15:18.110 - 00:15:27.650, Speaker A: Breath out. Again, I'm using GUI. We can also run like use the normal run command.
00:15:27.650 - 00:15:31.670, Speaker A: Let's see. Okay, the pref out. We're seeing entity changes.
00:15:31.670 - 00:15:37.862, Speaker A: What happens in this specific block? This is the current number. Current block number. There was a transfer.
00:15:37.862 - 00:15:58.666, Speaker A: So we are seeing a transfer entity change. Of course, if there is a transfer entity change, there will be an account balance entity change and a GRT total supply entity change. So since this is running a bit slow because of the Internet, I don't have any other activity happening until this block.
00:15:58.666 - 00:16:17.490, Speaker A: So we can stop this. And finally we will be deploying our subgraph to the studio to be eligible for not only bounces but also get bonus points the way we do it. Let me open Subgraph Studio.
00:16:17.490 - 00:16:38.800, Speaker A: Actually, here we connect with our wallet. And here I already deployed this. But when you create an account, connect with your wallet and just let me show you.
00:16:38.800 - 00:16:47.570, Speaker A: Just create a subgraph. You're going to enter the name and select the network. This is not really important because you're not going to publish it, you're just going to deploy it.
00:16:47.570 - 00:16:59.826, Speaker A: Those are two different things. You come here if you already built the subgraph and it's running, you already have the graph CLI. And you don't do this because this is for initializing a usual subgraph.
00:16:59.826 - 00:17:12.150, Speaker A: You just skip this in it, you authoritate the studio and then code gen graph build and deploy it. Then your subgraph. This is a subgraph fed by substreams.
00:17:12.150 - 00:17:21.366, Speaker A: This is the example I showed you I deployed. It can be queried just like a normal subgraph. So to finish, we have where is it? Update.
00:17:21.366 - 00:17:31.906, Speaker A: It was here. We have a QR code where you can see the prices. There are job openings and hacker resources and link to the repo and to this slides as well.
00:17:31.906 - 00:17:32.820, Speaker A: Thank you.
