00:00:09.050 - 00:00:22.014, Speaker A: All right, everybody, I guess we can kick this session off. Thank you for joining. After an extremely long day of very info dense talks, I know you all must be very tired, so hopefully we'll keep it a little bit fun and trolley here.
00:00:22.014 - 00:00:35.400, Speaker A: That's my request to all the panelists. Um, so I've prepared some questions, I've prepared some troll questions that I just made during the day. So no one here has had the opportunity to see them, so that should be pretty fun.
00:00:35.400 - 00:00:59.440, Speaker A: First, I'll let people do two rounds of intros because we have a 40 minutes long panel and I need to fill space. So first I'm going to ask everyone on the panel to tell me about batch auctions and why they're interested in batch auctions, the potential they see in batch auctions and generally what makes them excited. So we'll hand the mic over.
00:00:59.440 - 00:01:03.540, Speaker A: Sure. Go down the line, I guess, and then we can do Eric last.
00:01:05.990 - 00:01:30.810, Speaker B: So, my name is Lev. I've been interested in batch auctions because they have the potential to reduce unproductive games around marketplaces and hopefully reduce rent paid to Arbitrage and other unproductive participants.
00:01:32.190 - 00:01:51.674, Speaker C: Hi, I'm Felix. I am the technical lead on Cow Protocol. My interest in batch auction comes from, I think it being a mechanism design answer to a real problem that we have on Ethereum and them being particularly well suited to work on Ethereum because we already have a discrete time mechanism on Ethereum.
00:01:51.674 - 00:02:12.758, Speaker C: We have blocks every 13 seconds and batch transactions together, yet we don't clear trades at the same uniform clearing price. And that, to me, kind of was always something that doesn't make a lot of sense. And the other thing that I'm excited about in batch auctions is the opportunity to re aggregate liquidity, which we fragment on Ethereum today.
00:02:12.758 - 00:02:25.718, Speaker C: It's super cheap to create a new token. We see it with US dollars. There's 1015 different stablecoins, all representing the same token, and that inherently fragments the automated and well active liquidity that's being provided.
00:02:25.718 - 00:02:32.800, Speaker C: And by virtue of batching trades, together we can make use of ring trades and re aggregate that liquidity space.
00:02:34.290 - 00:03:00.642, Speaker D: Hey, I'm tarun. I would say that my main interest in batch auctions comes from actually trying to analyze privacy in DeFi. And it turns out when you batch things, as we saw in a couple of the talks earlier, you can actually get much better provable guarantees for privacy, both in trading and potentially lending and crosschain activity.
00:03:00.642 - 00:03:11.100, Speaker D: So it more comes from the stance that it's actually theoretically analyzable, and you could imagine, like, a zero knowledge system, like Penumbra that takes advantage of it.
00:03:13.070 - 00:03:14.730, Speaker A: All right. You're next, Eric.
00:03:15.630 - 00:03:24.014, Speaker E: Hi. So I've been interested in doing research. I've been doing research on batch auctions for dozen years now at this point.
00:03:24.014 - 00:04:00.150, Speaker E: And my interest in them is that I think they can make real world financial markets work better. They can make markets more efficient, more fair, more transparent, less complex. Also solve a lot of problems that may not legally be cheating, but kind of stretch our notion of what should be allowed in real world financial markets, whether that's various forms of front running in traditional financial markets or the kinds of front running that have manifested in decentralized financial markets.
00:04:01.210 - 00:04:08.860, Speaker A: Amazing. If you see me typing on my phone, by the way, I'm not tweeting. I'm taking notes on everything people here are saying because I'm going to use it to troll them later.
00:04:08.860 - 00:04:15.882, Speaker A: So great. We've had the batch auction intro. Now we have the second subject of today's intersectional panel, which is mev.
00:04:15.882 - 00:04:24.530, Speaker A: So I would love to hear a brief description of everyone's story or personal experience with mev, maybe in the same order, starting with Lev.
00:04:30.950 - 00:04:34.882, Speaker B: Like your personal opinion on sure, whatever you want.
00:04:34.936 - 00:04:39.270, Speaker A: Say yeah, you two minutes to say whatever you want about mev personal opinion story.
00:04:39.420 - 00:04:40.482, Speaker B: And it has to be trolling.
00:04:40.546 - 00:04:44.838, Speaker A: Qualitative feeling. No, not at all. Provocative is encouraged, for sure.
00:04:45.004 - 00:05:10.302, Speaker B: Yeah. I think since the term emerged, I've always felt like there was a lot of there's a certain perspective embedded in how people were describing it, and people were very excited to quantify and formalize what it means. And I think that obviously these are very interesting pursuits, but I think that it's quite easy to go wrong with this.
00:05:10.302 - 00:05:26.586, Speaker B: So from this perspective, I think it's quite fruitful to challenge how people think. What people think mev is. For example, I don't think it's an objectively measurable quantity, which is inherent in the names.
00:05:26.586 - 00:05:34.550, Speaker B: Usually things that have value are not necessarily objectively measurable. So I think this is one of the things that we should never forget.
00:05:36.890 - 00:05:41.238, Speaker A: Well, all value is subjective, I guess. All right, I guess Felix next.
00:05:41.324 - 00:06:13.374, Speaker C: Yeah, I think the first time I heard about mev was when I joined Gnosis back in 2018, and we were talking about how can we make prediction markets tradable? And Martin Kupelman, CEO of Gnosis, was talking about logarithmic scoring rule or some variant of it, which is now famously known as X times Y equals K. And the reason why we didn't double down on it back then was because we thought that, well, this market mechanism is flawed inherently. And I think it was later that year that I listened to your talk at Defcon Four and read the paper on coining the term mev.
00:06:13.374 - 00:06:34.490, Speaker C: And, well, since then, we've tried to build a market mechanism that actually reduces the mev potential at the protocol layer and not how maybe a lot of other projects in the space have been thinking about how to redistribute it, which is also important. But really our focus has been how can we reduce the total amount of mev that exists on ethereum.
00:06:36.750 - 00:07:07.618, Speaker D: Yeah. For me, I've spent a lot of time trying to formalize sort of some of the math and different DeFi protocols and one kind of consistent thorn that has defied formalism to Lev's point is mev. One of the reasons I actually find it most interesting is that there's a lot of ways you can separate the sort of security and economic differences of proof of work and proof of stake.
00:07:07.618 - 00:07:34.234, Speaker D: But mev is currently one of the kind of largest differences. And it's actually kind of interesting to think about this notion of value in different security models actually has sort of it becomes like non translatable. And so, you know, I think personally, I'm still hoping one day know the Maxwell's demon of Mev.
00:07:34.234 - 00:07:37.040, Speaker D: But unfortunately, we are quite far from that.
00:07:38.290 - 00:07:39.790, Speaker A: Amazing, Eric.
00:07:40.850 - 00:08:02.726, Speaker E: So I'll give a slightly intellectual answer to this question. So when I first heard about high frequency trading, this is a long time ago at this point, at some level, just genuinely didn't understand it because efficient Markets Hypothesis training says you can't make money from technical patterns in financial markets. To make money, you have to know something the rest of the market doesn't know.
00:08:02.726 - 00:08:24.910, Speaker E: And so I kind of didn't get why speed was so important in traditional financial markets and then it kind of clicked. This is about a dozen years ago at this point that a lot of high frequency trading is based on relatively simplistic arbitrage strategies. So you got a market bids and asks, there's some piece of news and high frequency trading manifests as a race to pick off an out steel quote.
00:08:24.910 - 00:08:57.646, Speaker E: When I first learned about Mev, which was from the Flash Boys 2.0 paper, like, oh God, this is even simpler. You have a batch that's got three orders to buy a and three orders to sell a and instead of just trading at the price that clears the market, you can kind of front run buy, then execute the three orders to buy, then sell, then execute the three orders to sell and just extract money from the sequence of trades.
00:08:57.646 - 00:09:25.460, Speaker E: It's like an even simpler to understand rent extraction from financial markets. So I kind of thought, like, figuring out how high frequency traders make their money was, I thought required an insight. And then when I saw the Mev extraction, I was like, oh God, that's just another in a way, like, simpler and more obviously in need of fixing market structure issue.
00:09:26.870 - 00:09:37.162, Speaker A: Amazing. All right, let's get right down to the trolling. So one thing we've heard a lot of connections about in the last few talks and just in general is mev and HFT.
00:09:37.162 - 00:09:53.082, Speaker A: And there's also an obvious link between HFT and batch auctions. So, like, the original frequent batch model evolved as a response to HFT, and in some ways, deployments of batch auctions in crypto are a response to mev. So there's some obvious analogy there.
00:09:53.082 - 00:10:22.082, Speaker A: I guess I'm curious. In your views on the panel, where does that analogy fall apart or is there anything non obvious? There is HFT and Mev really a pure kind of analogy in terms of the games being played? Or are there meaningful differences for deploying batches in response to HFT and in response to mev in the types of work we need to do to do that? This is anarchy, by the way, so just jump in.
00:10:22.136 - 00:10:25.060, Speaker B: Did you pick this on purpose so that it's very hard to disagree with.
00:10:26.250 - 00:10:27.798, Speaker A: It'S hard to disagree with me.
00:10:27.884 - 00:10:31.558, Speaker B: Yeah, I'm still thinking about how to.
00:10:31.724 - 00:11:14.802, Speaker D: This yeah, I think the analogy is actually sort of poor in one particular dimension, which is that composability doesn't really exist in HFT, right? Like, I'm not like taking a loan and then in a single transaction, taking that loan, providing it into an automated market maker, then manipulating a price, changing something else, somewhere else downstream and then closing out the loan. I feel like the composability aspect makes the state space significantly more complicated and batching only corrects some portion of that. I think Staking derivatives in particular, interacting with batching is like a very complicated system, much harder to reason about than an order book.
00:11:14.802 - 00:11:40.162, Speaker D: And then I guess the other thing I think that's quite important in mev versus traditional HFT stuff is you really do, generally speaking, trust the Exchange to keep accounts private. Now, of course that doesn't always happen, but there's a sense, especially in constant function market makers, that mev is exactly equal to loss of privacy. And that's not true in HFT.
00:11:40.162 - 00:11:53.920, Speaker D: It's like you kind of assume perfect privacy from the account level. And I think those two things like composability and privacy are extremely, completely changing analysis in my mind.
00:11:55.250 - 00:12:13.154, Speaker C: I think another core difference on Ethereum in particular is the I mentioned it earlier, the fragmentation of the token space. So in traditional finance you have the US dollar, which is your numera, and you have markets always denominated to that. So you tend to have a simpler, I would say, market structure in traditional finance.
00:12:13.154 - 00:12:34.430, Speaker C: Whereas on Ethereum you might have your token have one balancer pool against USDC, then a uniswap pool against ETH and then, I don't know, a curve pool against another derivative of your token. So you have a much more multi dimensional space to begin with. And so the games or also the Arbitrage opportunity might tend to be higher on Ethereum.
00:12:37.490 - 00:12:57.220, Speaker D: Actually, one other thing to that point is that in DeFi you create and destroy assets all the time. You completely mint and burn nude synthetic derivatives in the middle of a transaction. You can never do that in hot, right? Getting a security listed on the Exchange is already hard enough, let alone destroying it.
00:13:00.630 - 00:13:26.698, Speaker A: I'm hearing a lot about complexity because it seems like the response like deploy batch auctions, at least suggested by the previous talk, seems to be the same in both settings. So how does this complexity interface with the batch auction? And also this is like a little bit of a question for Eric that's kind of related to this. The original batch auction model that was proposed is much simpler than the batch auctions we're seeing deployed in crypto.
00:13:26.698 - 00:13:35.490, Speaker A: So does this relate to this complexity? Is it like a response? And how does it change the modeling and security properties we need to do on these systems?
00:13:38.310 - 00:14:24.320, Speaker E: Why don't I take a crack at that? Last question first. Felix kind of alluded to this with the mention of the word numer, which is a technical term, but is there traditional frequent batch auctions 1.0? So, as proposed in our paper in 2015, each asset, so each stock, if you will, trades in its own frequent batch auction market, where the market is that asset apple stock or Google stock or whatever, in exchange for dollars and dollars are the numerator good that you can use as what you get if you sell, what you give if you buy.
00:14:24.320 - 00:14:56.662, Speaker E: Frequent batch Auctions 2.0, which I've been working on recently with we call it flow trading, but I've been working on it with Peter Crampton and Pete Kyle, Mina Lee and David Malek. Allows for batch trading in a more combinatorial portfolio style manner where you could, for instance, user define a portfolio consisting of Apple and Google and Amazon stock or whatever stocks you're interested in with positive, arbitrary, user defined positive or negative weights.
00:14:56.662 - 00:15:18.194, Speaker E: But there's still a numerator good. The dollar kind of underpinning the discovery of prices in which prices are denominated. Crypto markets raise this additional layer of complexity where you want to swap arbitrary assets for arbitrary assets, and there isn't a natural numerator good.
00:15:18.194 - 00:15:43.260, Speaker E: And that at some level raises a technical design challenge that I think there's a lot of innovation grappling around how to solve that design challenge. I think it's just a genuine it's a harder problem if you don't have a numerator good, you don't have a common denominator. You can think of it as like a way of netting stuff, but let me leave it at that.
00:15:44.590 - 00:15:46.966, Speaker A: Cool. Any other thoughts on complexity?
00:15:47.158 - 00:16:13.150, Speaker C: Yeah, I think part of the complexity comes from the trustlessness and permissionlessness of the network. And I think this complexity can actually be used for good and for bad, or in some sense, at least on cow protocol. We actually make use of the permissionlessness and say, well, we don't have just a single matching engine, a single clearinghouse, like you would maybe have in traditional finance, your broker who tries to find a perfect matching.
00:16:13.150 - 00:16:39.286, Speaker C: But instead we spread that out as a competition to what we call solvers and basically let them offboard the complexity, off to a it's almost like another auction that is loaded behind where people compete. We know what a good solution looked like, or at least we are able to rank two solutions against one another and say, this one is better or more fair. And so we can offload some of the complexity and said, well, let's make it a competition.
00:16:39.286 - 00:17:06.574, Speaker C: Let solvers compete for that challenge and they may use whatever heuristic or approximation algorithm they want to use. And at the end of the day, that kind of is one way to cope with complexity. But on the other hand, of course, the trustlessness issue like that, you can't trust any tokens, you can't trust any accounts per se, has to make the mechanism much more resilient against bad actors.
00:17:06.574 - 00:17:18.390, Speaker C: Whereas in traditional finance, I feel like you can always rely in some sense on regulation or know at least not a bad actor completely coming up with some attack and acting in bad faith.
00:17:19.690 - 00:18:01.366, Speaker B: Well, there haven't been any sufficiently trolley comments, so I would just like to say that I think that Tarun is very right to bring up privacy and composability in this context because to put it in the most provocative way possible, these are both the two major problems for successfully implementing batch auctions on decentralized exchanges. Because on decentralized exchanges you can't have privacy, which you need to faithfully implement Eric's design without sacrificing permissionlessness. And batch auctions don't have composability, which makes them not useful in decentralized exchanges because that's one of the main things that people want out of them.
00:18:01.366 - 00:18:02.520, Speaker B: So what do we do?
00:18:03.930 - 00:18:30.798, Speaker C: Right, so we definitely agree that having a lit batch auction has its drawbacks. I think one of the arguments we would say against that is, well, today we're trading on pseudo continuous time model in a lit mempool, and having a lit batch auction is a strict improvement over that per se. I would say in the long term, of course, we need to find ways of how we can conserve privacy in batch auctions as well.
00:18:30.798 - 00:18:59.660, Speaker C: I think Tarun has some thoughts and work on that in our mind. We've been looking at using either VDFS or DKG distributed key generation to basically split the batch auction into two phases. One is a phase where people can place orders and basically secretly place sealed bids on the auction, and then at some point t the auction closes, no cancellations or changes are possible anymore, and only then the contents get revealed and so solvers would start solving the batch at that point in time.
00:19:00.670 - 00:19:26.590, Speaker D: One other complexity that I think is a little harder to reason about is sort of what I would call like, distance based sort of measurements. So what that means is if I think about a sandwich attack, it's a very local type of mev, it only puts two transactions before and after another transaction. If the slippage limit is pretty loose, you can basically permute it anywhere in the block and it'll still execute.
00:19:26.590 - 00:19:54.598, Speaker D: However, if I, say, want to cause a liquidation, I could basically front run an oracle, wait for a couple other loans to fail, and then put in another transaction after that. Or I could even do things like the inverse finance hack where there's multiple blocks worth of space sort of used to execute kind of an attack, and there's sort of this notion of distance. The metric that's used is not Euclidean.
00:19:54.598 - 00:20:30.360, Speaker D: It's like, whatever. This dependency graph has some implied sort of distance metric on it, but that distance metric for these attacks really should somehow be reflected in the auctions, right? Of like am I stopping? Sort of shorter term type of sniping, like things like in the original batch auctions paper, or am I doing these like, long range? When I say long range attack, people think proof of stakes. I don't mean the proof of stake long range attack, but I mean there's some notion of distance due to composability and that makes it much harder to reason about sort of like these types of things.
00:20:30.360 - 00:20:34.840, Speaker D: The inverse finance attack. Amazing case study for this.
00:20:36.810 - 00:20:50.762, Speaker E: Can I jump in with just I want to make two quick points. I'm not sure I get all of the technical issues around the composability discussions that I'm constantly learning. I'd love to learn more about that offline.
00:20:50.762 - 00:21:21.000, Speaker E: But one thought, just picking up one aspect of that discussion is that one of the benefits of a discrete time batch process marketplace is that you can then be thoughtful about how you design competition in traditional financial markets as we propose it. At least you use the discrete time batch processing to then run a thoughtfully designed uniform price auction. For example.
00:21:21.000 - 00:21:57.598, Speaker E: The batching on its own isn't a miracle cure unless used in conjunction, unless you take advantage of the batch process discrete time design space, if you will, to then design thoughtful marketplaces. Some of the clever trades that involve flash loans and trades across lots of different venues, again, which I'm still learning about in real time, I think relates to that point. On the privacy point, I think that's really a really important topic.
00:21:57.598 - 00:22:30.300, Speaker E: And the thought I want to add to the discussion is economists think about that issue in terms of what we call information policy. So what information is public to the rest of the marketplace? What information is private? And I think in a financial exchange, the distinction I'd like to draw is if I'm trying to provide liquidity to the rest of the market. So I want to make a market bid 29 90, ask 30 ten for Ethereum, for example.
00:22:30.300 - 00:22:51.678, Speaker E: I want that information to be public because I'm trying to draw in buyers at 30 ten and Sellers at 29 90. So I can make a spread. If what I want to do is I want to buy 1000 e at 30 ten, I don't want to display that demand to trade a large quantity before I actually get to trade the large quantity.
00:22:51.678 - 00:23:16.490, Speaker E: And frequent batch auctions, as we've proposed it allow both of those participants to do exactly those two things. So if I want to make a market, I make a market and my liquidity is displayed to the rest of the market and it shows up batch to batch to batch to batch to batch in discrete times. And if I want to trade at market, my order isn't displayed publicly until after the trade actually executes.
00:23:16.490 - 00:23:37.060, Speaker E: I guess I'm saying this just to flag that you can think and design around privacy and again, what economists call information policy. The key is to just be thoughtful about it. Think game, theoretically think as a mechanism designer, think about what financial problems you're trying to solve and then go to work.
00:23:38.630 - 00:23:46.040, Speaker A: All right, thank you for all those answers. That was amazing. And also, Trolley, I want to zoom in on this composability thing and troll you all some more.
00:23:46.040 - 00:24:01.354, Speaker A: Many people may not know this, but I'm actually an advisor to the Uniswap protocol who no longer really advises actively because my ideas are never really listened to. For the best, in my opinion. No, not at all.
00:24:01.354 - 00:24:04.550, Speaker A: Not at all. It doesn't suck. So I'm about to tell you why it doesn't suck.
00:24:04.550 - 00:24:22.794, Speaker A: Part of my journey in batch auctions was like, I saw one of Eric's talks, I believe it was like EC 18 or 17 or something like that in Ithaca. And I went to Uni before V one came out because Hayden was kind of brainstorming this idea. Should I do it? Should I not? And I was like, dude, this is terrible.
00:24:22.794 - 00:24:27.886, Speaker A: This is like the worst thing ever. Look at all this mev. Look at all these degrees of reordering freedom.
00:24:27.886 - 00:24:39.750, Speaker A: Like, people are just going to get absolutely screwed over on this protocol. Do not release this. Make sure you batch an entire block and then execute the trade as a batch on this design because otherwise very smart.
00:24:39.750 - 00:24:53.020, Speaker A: It's FUBAR. And then I actually got an email from Vitalik that at the time made me very mad, which was, you know, this is not a big deal. We can just use these as transaction fees one day and like, yolo, it's still a good design.
00:24:53.020 - 00:25:02.394, Speaker A: And at the time I was like, look, this is just NIH syndrome. They just don't want to hear it from me. I'm like an outside researcher kind of coming in and trolling them.
00:25:02.394 - 00:25:17.102, Speaker A: And then let me say they launched the exchange and became the number one dex on ethereum. Instant billion dollars a day of volume, 100 billion dollar company and token the TLDR is you should never listen to my advice. First of all, that's not like the intent of the story.
00:25:17.102 - 00:25:58.510, Speaker A: This was all leading up to a question. So one of the things we were thinking about a lot in when that happened and they said, okay, we're not listening to you is could we actually combine the liquidity on a batch version of Uniswap and this native composable version of Uniswap that these DApps just really want? Like they want this atomic in transaction? UX. How do you share liquidity across these without just ultimately making it a front running game on the fastest possible exchange? And this brings me to my trolley question about batch auctions, which is one of the things I realized in thinking about all this is it's very hard to model the way batch auctions truly interact with many other auction structures that are occurring in parallel.
00:25:58.510 - 00:26:16.280, Speaker A: And a lot of the models kind of look at them in isolation. So how do you all feel on this panel? That's almost a general pattern for mechanism design. How does it affect the guarantees we're offering users? How does it affect batch auctions? And what should we do about this? Basically? Sorry for the super long intro.
00:26:19.610 - 00:26:53.146, Speaker C: Yeah, one way I think about it is that today when you're in a liquidity provider in an AMM, then you're basically and somebody tries to trade against you and slot one of the block, that basically means they are running you over, right? There's some information outside of the ethereum ecosystem, maybe the price change on a centralized exchange and they're just trying to run you over. So the reason why you have to charge quite high liquidity provision fees is because of that impermanent loss and basically the fact that you're just getting run over all the time. However, if you could make your AMM choose to be let's just pick one extreme only be used by a batch auction layer.
00:26:53.146 - 00:27:34.458, Speaker C: So for example, you say if Cow protocol reaches out to our AMM, then we know there's actually much less risk that this is an adversarial trade, there's real demand and maybe the information from outside might still get incorporated, but it gets first of all matched against general liquidity inside the batch. And so the adverse selection impermanent loss I face from Cow protocol trades is on average much lower than if I just have a permissionless access to my liquidity. And so in theory at least, of course not don't block your AMM off from other trading at all, but maybe you could have a lower LP fee for batch protocols that tap into you than you have for permissionless interactions.
00:27:34.458 - 00:27:43.890, Speaker C: And that in a sense could then just make batch auctions even more attractive to users because you have actually a structural price advantage.
00:27:47.430 - 00:27:50.850, Speaker A: More bearish takes. I'm just trolling.
00:27:51.750 - 00:28:28.186, Speaker D: I think one thing that if we take the more distributed systems lens of this, right, and we're seeing this with bridges and kind of like why half the talks today were like cross chain DEXes don't exist or can't. Exist very well is at the end of the day, there's sort of some sort of contracts that most parallel systems agree on, like futures and promises and sort of deferred computation and guarantees on when deferred computation gets executed and doesn't get executed. And there's a sense in which once you break atomicity with the batch auction, the only way to sort of recover some guarantees is to guarantee a future scheduling.
00:28:28.186 - 00:28:53.170, Speaker D: Sort of like callback that post batch auction can run on whatever liquidity is there and then return some portion of the composability back. Kind of like when you've seen Await when you're writing a multithread program. Somehow we just have not put that in at the mempool and execution layer in a way that you can schedule operations post auction.
00:28:53.170 - 00:29:00.860, Speaker D: And I feel like that's the next step for blockchains to kind of recover composability if they start breaking Adamicity, if that makes sense.
00:29:01.870 - 00:29:36.798, Speaker B: I think one practical sounding way would be basically to take how Cowswap currently works, which is like a transaction, and then inside it has orders. If we instead make it so that the orders are what we currently think of as transactions, and we use the same batch auction idea to structure the entire block, then we can keep Atomicity and we can still have maybe like a uniform clearing price. What I think is interesting is that this sounds kind of like what Flashbots is trying to do, or people who are trying to optimize, but they're actually optimizing the mirror objective function because Flashbots wants to optimize the amount of minor revenue in a block.
00:29:36.798 - 00:30:16.622, Speaker B: And this meta Cowswap generalized to transactions is trying to get a uniform clearing price, which is literally the opposite. So it's two optimizations which are literally completely in conflict with each other almost always, which I think is really interesting, but for some reason the one that we're paying more attention to is the one that's not optimizing for user outcomes. So Cowswap wants to get a uniform clearing price because that's the best for users, while the complete opposite of that would be to optimize for minor fees, which is we've to, thanks to your work, is the same thing as optimizing for Arbitrage revenue.
00:30:16.622 - 00:30:17.394, Speaker B: Right.
00:30:17.592 - 00:30:45.254, Speaker C: And I would even go a step further there and say that by going the route that bashwood proposed is trying to maximize the extractable value, we are actually going down a route that I think it was a follow up paper of Eric 2018 or so. Will the market fix the Market why batch Octaves weren't adopted for traditional finance. The reason that exchanges like Nasdaq CMSE actually make so much money by selling these colocation rights, by actually saying, well, this HFT revenue is part of our revenue.
00:30:45.254 - 00:31:03.886, Speaker C: And to me, when we hear about, well, let's do PBS, let's maximize Mev and put it into the e security budget, we're exactly doing the same thing. So we're moving Ethereum into a way where some big players will make a lot of money and a lot of small users will maybe not lose a lot of money on each trade, but in some basically get wrecked by the mechanism we build.
00:31:03.988 - 00:31:06.980, Speaker B: Yeah, I completely agree. I think this is quite messed up, actually.
00:31:07.990 - 00:31:20.310, Speaker E: I was struck by one talk earlier, just the percentage of rent that gets extracted. The number is like 90 plus percent. In traditional finance, it's like a third a quarter.
00:31:20.310 - 00:31:38.506, Speaker E: So the rent extraction by miners, it was Will Warren's talk earlier. Just huge numbers and I think. Let me kind of riff on the Uniswap story Phil told because that really rang true for me too.
00:31:38.506 - 00:32:15.160, Speaker E: That was my reaction intellectually when I first heard about Uniswap's design, and I think what its success teaches us is that there's a ton of noise trading. So the reason Uniswap shouldn't work in finance theory is that if you make a market in Uniswap, you're exposed kind of algorithmically to just tons of adverse selection, because if prices go up on centralized exchanges, you're just vulnerable to getting picked up. It's like built into the protocol, this X times Y equals K thing.
00:32:15.160 - 00:32:42.254, Speaker E: But if there's enough noise trading, if there's just enough speculation, gambling, uninformed order flow, whatever you want to call it, then that can actually override the harm of being adversely selective. And I think what we've learned from Uniswap's success is a lot of revenue from what finance theory people call noise trading. My collaborator Peter O'Neill has his job.
00:32:42.254 - 00:32:46.450, Speaker E: Market paper was trying to measure exactly that, and it's much higher than traditional finance.
00:32:47.510 - 00:33:20.122, Speaker A: So amazing trolling. First of all, especially Lev, you literally predicted my next question, like, wow, now I feel bad for doing so many intros because we could really get into this topic. So my next question was actually going to be like, is the Flashbots auction for the mempool a batch auction, a discrete batch auction? And if yes, how does it differ from the batch auctions we want to build? If no, then why not? And I think we already kind of answered this, but curious to hear some more expansion, if some is available.
00:33:20.122 - 00:33:22.090, Speaker A: If not, I'll provoke further trolling.
00:33:23.230 - 00:33:43.982, Speaker C: I remember the flashboards team reaching out to us because they wanted to implement frequent batch auctions for basically the bidding of bundles or block proposals. And to me, it's obviously not a batch auctions. We're not trying to find a uniform clearing price or we're not trying to line up multiple bids and offers on two sides.
00:33:43.982 - 00:33:51.394, Speaker C: It's literally just an English auction on who is paying the most for this right. Exclusive right. To propose the block.
00:33:51.394 - 00:33:56.626, Speaker C: So in my eyes, I always wondered why Flashbots were talking about batch auction. In that sense. I disagree.
00:33:56.626 - 00:33:58.150, Speaker C: I think it's not a batch auction.
00:33:58.890 - 00:34:11.686, Speaker D: Yeah, it's not a batch auction. It's definitely a combinatorial auction that has sort of like some downstream effects. This is why I was mentioning this sort of like long range versus short range purchasing power, right? Like sandwich attack, very boring.
00:34:11.686 - 00:34:35.302, Speaker D: Kind of very short range. Doesn't really impact other trades in the block at all because usually sandwich attack participants are risk neutral, so they don't impact the price that much. But on the other hand, a lot of the liquidation stuff or things that are Oracle manipulation over multiple blocks, especially Twaps, that stuff actually is very different.
00:34:35.356 - 00:34:35.526, Speaker B: Right.
00:34:35.548 - 00:35:09.854, Speaker D: You're really bidding on some very long term downstream in the transaction ordering process, and that's probabilistic also. And so there's sort of this fact that you're sort of bidding on a very highly diverse set of goods and the goods are also constantly being created and destroyed. For instance, a Rebase token is a great example of something that is effectively that just like in a batch auction would be kind of extremely scary in some sense.
00:35:09.854 - 00:35:17.280, Speaker D: And all the mev against say, Rebase tokens effectively just doesn't look like a batch auction probably never could.
00:35:18.290 - 00:35:42.134, Speaker A: I don't know. I'm going to take like an opposing position just for the troll sake of discussion, right? Like you said, there's no uniform clearing price, but that's not necessarily a feature of the flashbots auction. The flashbots auction is like discrete time, one bid per epoch, right? And if DApps want to enforce a uniform clearing price on top of that, or enforce batching, for example, the way cowswap does when they submit to flashbots, they can and then it becomes about aggregating.
00:35:42.134 - 00:35:53.510, Speaker A: Which of these preferences is valuable enough to be included in this current batch against this economic metric. So does that change your answer or does it not converge? Am I missing something here?
00:35:53.600 - 00:35:59.914, Speaker C: I think you're auctioning off a batch, right? And you're not actually trying to find to batch bids and offers.
00:36:00.042 - 00:36:02.990, Speaker A: I mean, you can there's no reason that you don't. Right?
00:36:03.140 - 00:36:03.742, Speaker D: Yes.
00:36:03.876 - 00:36:24.486, Speaker B: So the feature that's not in the name is the uniform clearing price part. So I think just getting triggered by the words in the name probably isn't so productive. But I think the point is that empirically it looks like you have to squint a bit to make the objective functions kind of in the same space because orders are not the same thing as general transactions, but you're basically optimizing for the opposite thing.
00:36:24.486 - 00:36:42.762, Speaker B: So the best possible flashbots block is the block where you get basically the most dispersion in clearing prices of trades in the I mean, you could literally prove that in the case of uniswap, for example, like the best. Uniswap. If all you have is uniswap transactions, the best thing is to make all the prices that are in the block as different as possible.
00:36:42.762 - 00:37:12.598, Speaker B: So it's actually literally the opposite thing. And then if you sort of squint and you compare that to utility of the natural users of the thing, then you're literally trying to minimize that. So of course, to say something a bit more optimistic, I think when I asked earlier about how can we without privacy, how will we ever make batch auctions work? Well, Felix had some plausible sounding suggestions involving some cryptographic primitives that you can somehow magically use for this, which I don't know much about, but I believe.
00:37:12.598 - 00:37:35.542, Speaker B: And I think that that actually shows us a way forward for Ethereum, which is that if you can solve this privacy, batch auctions keep privacy while keeping also permissionlessness for batch auctions. We can generalize that idea to Ethereum transactions. And instead of trying to maximize mev in blocks, we can actually try to maximize something akin to a uniform clearing price in blocks.
00:37:35.686 - 00:37:53.586, Speaker A: Amazing. I'm going to take the trolling one level further, and then I'm going to cut it off, which is you mentioned the uniform clearing price. So if you did enforce that on a uniswap level, on top of the flashbots auction, does it become a batch auction? Like, if uniswap were able to say, we need all our bids in any flashbots bundle to clear at the same price, or they're not valid at the.
00:37:53.608 - 00:38:01.000, Speaker D: Contract, not because it has non zero curvature. The problem is the design of constant function. Market makers can never have that.
00:38:01.000 - 00:38:15.322, Speaker D: Effectively, you can't have a zero actually zero curvature thing unless it's a fixed price. In Uniswap's case, it has non zero curvature. So I think it would have to be designed as a different system.
00:38:15.322 - 00:38:18.554, Speaker D: It wouldn't work in the way it is designed now.
00:38:18.752 - 00:38:27.294, Speaker A: All right, great trolling. So we have two minutes left. I would like random people on the panel to chime in, and we've talked a lot about time.
00:38:27.294 - 00:38:35.860, Speaker A: How does mev and batch auctions relate to the general philosophy of time in these systems? And say something trolley for the audience to go home with. Today.
00:38:37.830 - 00:38:39.970, Speaker D: Lamport clocks don't exist.
00:38:41.910 - 00:38:48.338, Speaker A: That was pretty good. No time trolling.
00:38:48.514 - 00:38:51.958, Speaker B: Can you reassociate on this a little bit to give us something to think about?
00:38:52.044 - 00:39:11.210, Speaker A: Okay, so Mev is about reorgang, right? It's like, about changing the time at which transactions executed, where the time is, like, the relevant time of the state. And exploring the Mev State. Space search could be viewed as exploring multiple possibilities in spacetime and deciding on which one to gravitate the current universe towards.
00:39:11.210 - 00:39:17.550, Speaker A: So in this model of time, what do we do next? And we have, like, 30 seconds, so maybe nobody knows.
00:39:18.210 - 00:39:31.140, Speaker C: So I would say with batch auctions, at least we don't have different concept of time in the instant, whereas with the traditional model, even the instant has different time orderings. I don't know if that makes sense.
00:39:31.750 - 00:39:32.882, Speaker A: Any thoughts on time?
00:39:32.936 - 00:39:59.702, Speaker E: Yeah, Eric, thoughts on time? I feel like I'm in college again. So discrete time batch auctions let you have a unit of time that allows for a notion of ties. In traditional financial markets, you could batch at, like, once per millisecond and do a whole lot of good, because the Sniping races that we're able to measure empirically, they take place at the level of millions of seconds.
00:39:59.702 - 00:40:20.914, Speaker E: The typical Sniping race is five millionths of a second. So what's kind of fun about the design space here is that you could batch at a much more human, meaningful time interval, and that also allows you to do a lot more kind of cool commentators. But deep thoughts on time.
00:40:20.914 - 00:40:25.186, Speaker E: You're giving me flashbacks to freshman philosophy, so let me leave.
00:40:25.208 - 00:40:25.746, Speaker C: That great.
00:40:25.768 - 00:40:33.158, Speaker A: So my trolling works. All right, so I will leave everyone with their flashbacks to freshman philosophy. I think our time here is over.
00:40:33.158 - 00:40:36.360, Speaker A: Thank you very much. And thank you to the panelists. That was amazing.
00:40:36.360 - 00:40:39.490, Speaker A: Thanks for putting up with all my trolling.
