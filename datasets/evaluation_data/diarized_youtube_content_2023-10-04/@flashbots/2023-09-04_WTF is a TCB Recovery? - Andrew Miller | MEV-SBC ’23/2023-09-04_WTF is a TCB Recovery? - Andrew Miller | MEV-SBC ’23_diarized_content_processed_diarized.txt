00:00:00.410 - 00:00:00.670, Speaker A: Okay.
00:00:00.740 - 00:00:51.062, Speaker B: Hi, I'm Andrew, and today I'm going to be talking about TCB Recovery, which is a really important concept that I think is not so well talked about. Maybe some of you have never heard of it before. TCB Recovery is not just the worst frozen yogurt flavor, it's actually a term associated with trusted hardware enclaves and SGX. It's actually a term that more generally for secure systems, comes from old military security writing and it refers to the process by which a designed to be secure system that has become insecure through a failure or vulnerability. It's about how this recovers eventually to a secure state. But today I'm just going to be talking about this in the context of trusted hardware enclaves and SGX.
00:00:51.206 - 00:01:55.479, Speaker A: I'd wanted to talk about all sorts of research topics, but this is something that I think is so poorly understood for how important it is that I just want to go into detail on this one topic about TCB recovery and SGX. So give a high level and then I want to go over some observations about how TCB Recovery has gone so far from the most recent SGX vulnerability downfall, which is from earlier this month. And I'll try to wrap up with some thoughts on what we as distributed systems decentralized designers, should do for mitigations and best practices on this topic. There's a bunch of mistakes that I already know on here, so don't quote me for specific terminology, but had to do this in a hurry and put this out there for if you notice something that's wrong, please correct me. We'll have more documents along these lines coming up in the future. So for the sake of the high level overview, let me just introduce a couple of the basic components of a blockchain architecture that is based on trusted hardware enclaves. My view of this really comes from the Akitan research paper from 2019.
00:01:55.479 - 00:02:38.510, Speaker A: And sort of broadly, not all these systems have all of these components, but very broadly, this is what it looks like for Secret Network, Oasis, Fala, Obscuro and also upcoming Suave. And the basic components of this are there is a blockchain, the blockchain has consensus mempool, things like that. You don't have to have an enclave node to participate in the consensus protocol necessarily. The enclaves are used for storing and computing on sensitive data without revealing it. That's the point of them. And I would also say I'm not going to give too much background on trusted hardware enclaves in general, but Kushal gave a talk earlier today that did a nice self contained job of that. So just scroll up on YouTube to see that if you want some more background.
00:02:38.510 - 00:03:28.186, Speaker A: Really broadly, there are kind of two ways of using enclaves in this system. One is to do a threshold or multiparty computation on them. In the Akiden paper this is used for key manager nodes only. And the idea is that you need to not just break the SGX, but also break many instances of the SGX among the set of nodes that are participating in order to do anything with the MPC portion of those nodes. And again in Akitan, these are like the ones that hold the root or most important keys. The main reason to use trusted hardware enclaves is for performance compared to something like multiparty computation, also for collusion resistance and multiparty computation. Anyway, practically to get the full speed out of this, you want to be able to do computing on sensitive data, not just in a threshold fashion, but all on one enclave for best performance.
00:03:28.186 - 00:04:06.220, Speaker A: So these could be called execution nodes or something like that. And roughly the flow is like the consensus protocol might be in charge of setting the policy and making sure people are registered. Key managers, again maybe are a smaller number and hold the most sensitive root keys. And execution nodes maybe carry out individual tasks at a very high level. That's kind of what the architecture looks like. Each one of these systems has some kind of different take on it, but that's maybe enough to follow along with the rest. Now, the main caveat about working with SGX is that it has a history of really terrible security failures that really invalidate all of the security goals that you want to get out of them.
00:04:06.220 - 00:04:51.500, Speaker A: The last big one last year was APEC leak. That happened right around when I started paying attention to SGX. And again, downfall is the one that's happened just this month, but there have been a bunch more and sidechannel's researchers absolutely love this because they just keep racking up the decorated metals. They have just the ones with logos here if I remember like cash out SGA, axe load value injection, APIC leak mentioned, downfall I mentioned, but these are just the ones with fancy logos. There's even more like this. What TCB recovery has to do with is what happens when a new vulnerability is found. So one observation is that vulnerabilities that are found often affect a subset of the processor types, but not necessarily all of them.
00:04:51.500 - 00:05:45.850, Speaker A: Totally random assignment of examples, but it doesn't necessarily mean that every single processor on your system is invalid, but some classes of them are. And the thing that's interesting about TCB recovery, the reason why intel has a whole process for this is because your processors aren't just hardware, they're really software. You can update the microcode software in your processors. You usually have to do this by updating the BIOS with a memory stick and booting into BIOS control. But anyway, so when a vulnerability is found and studied and then publicly disclosed, it eventually comes along with an update patch. So in other words, you don't have to get rid of the affected hardware forever, but if you want to keep using it securely, then it has to apply one of these microcode patches. So from Intel's point of view, TCB Recovery is really about what they have to do to provide updates so that you can update your processor to be secure.
00:05:45.850 - 00:06:16.286, Speaker A: However, TCB Recovery is something that us as distributed systems designers also have to do our own TCB Recovery. It's not like what intel does automatically fixes our systems. There's still a lot for these systems to do. Remote Attestation plays a key role in understanding what happens with TCB Recovery. So I will give a little bit of detail still high level about what this is like. This is from the viewpoint of an execution node that is joining the network. It wants to say it's a legitimate enclave.
00:06:16.286 - 00:06:40.506, Speaker A: So it deserves to be read into some of the secret keys, get permission to compute on some of the sensitive data. So to do this, it shows the network or the other nodes that already have the sensitive data. An attestation report. This is basically a certificate. This is one of the place where I'm using some of the terminology wrong, but the broad idea is right. This is a certificate that has a chain of trust. Like it's signed by a public key from the device.
00:06:40.506 - 00:07:14.678, Speaker A: And that public key from the device is signed by a chain of signatures that goes all the way up to Intel's root private key. It also has a description of the current configuration of the hardware. I'm just going to mistakenly call that the CPU security version number for now. So just think of it as the description of the processor and its current microcode version. You have the Mr enclave, which is the hash of the program that's currently running. That's the key thing. You can tell that you're interacting with a real enclave that's running the particular software binary that the network is using right now.
00:07:14.678 - 00:08:08.982, Speaker A: And it comes with some report data that's application defined. Often this is like a public key to carry on the discussion with this enclave once it's approved. So these nodes that already have the data or the consensus layer, if that's in charge of it, they need to look at the certificate and say like yes or no, is this valid or not? Largely this involves checking that chain of certificates that it comes all the way from Intel's root certificate, which should be well known and stable, easy to find. The other part that you have to do though, is you have to check whether or not the current hardware and microcode configuration is known to be vulnerable or is thought as best as we know today to still be secure. And so what happens with TCB Recovery is basically that this gets updated. So here's a little bit of a view of one of the components of the Remote Attestation system in SGX. It's either called the verification collateral or the TCB info.
00:08:08.982 - 00:08:36.000, Speaker A: And there's an API query that you can call to get this from intel. It comes with a digitally signed package as well. Before downfall. If you requested the TCB info for, say, whatever Xeon processor type, I had to do this, it returns a report that looks like this. It comes with a little warning software hardening needed. But let's just say we've already done the software hardening that's something like the application can be responsible for. So this is okay.
00:08:36.000 - 00:09:09.340, Speaker A: After TCB recovery, you get a different kind of view of this for the same processor configuration. It now has a spooky concern that's out of date, rather than just hardening needed, it has a whole list of each. One of those is like a name of a kind of possible vulnerability that could affect this configuration. And your system should say, that's not valid. Out of date is not a good sign. You should not give any secret keys to a node whose certificate looks like that. So to summarize kind of the timeline and maybe give names to this, this might be a good thing to refer back to for questions.
00:09:09.340 - 00:09:38.542, Speaker A: One of the concepts is about forward secrecy. So say you submit some confidential to the system. At time A, it's no longer relevant. After some later time at T Zero, a vulnerability is found, but only by attackers. We don't know it publicly yet. If we have forward secrecy, what this means is that the enclaves should be discarding their access to this data. If it's meant to be discarded, like if it's erased in the smart contract, the enclaves should delete their key that allows them to access it.
00:09:38.542 - 00:10:37.558, Speaker A: This should give us the property that if the data was discarded prior to a vulnerability being found by any attacker, then that data at least should be safe because it's in the past and no longer susceptible data that is submitted in between. When a vulnerability is found by an attacker and when it is discovered by researchers and eventually publicly announced, that data is kind of hard to protect. Only like other kinds of things like defense, in depth or mitigations, we could talk about have the chance of protecting it there after the vulnerability is publicly announced. TCB Recovery completing means not only has intel done everything they're supposed to do, but all of the systems that are relying on it need to do what they need to do as well. Hopefully, the time in between that public disclosure and the system doing its own TCB recovery, this should be made as small as possible. There's no reason it has to be long. There's also no guarantee that it's a quick time either.
00:10:37.558 - 00:11:26.466, Speaker A: So part of the goal to be responsive should be to make this as quick as possible. Now, data that is sent to the system after TCB recovery has completed, if the system has recovered, then new data sent should be safe. Key rotation is kind of the concept that goes along with this. If the system's using a new key after that time t two, then this data C sent under the new key will have never been on one of the vulnerable systems. This is kind of the high level framework. I want to make a couple of observations about what we noticed by paying close attention to it while Downfall was announced. So one of the things that's different from Downfall versus APIC leak last year is that the information that we need, those TCB info packets, those were made available right on the day of public disclosure.
00:11:26.466 - 00:12:04.498, Speaker A: In the past, we actually had to wait for the microcode was available, but the information to respond to it was not yet available until a bit after. But now it's available right away. We noticed that there were some inconsistent updates, though, when we queried it, it was actually sort of surprising. It had like a case sensitivity. Like you query it by your processor type as like a hex code, but if you queried it with a lowercase hex string, you would get the correct value. But if you did it with an uppercase hex string, you would get the wrong stale one. And we even made like a snapshot on the web archive so you can kind of see them like, got you.
00:12:04.498 - 00:12:53.614, Speaker A: And the little packets are signed anyway, so even if I didn't get it onto web archive, I'd still have the signature to kind of point at it. One of the things that this implies might be a good idea is that even though these little packages are signed by intel, it would be really nice to have a kind of public vantage point and mirror for these. So my analogy is to certificate transparency. Maybe some of you are familiar with this. This is something that's meant to prevent man in the middles from certificate authorities. When you visit an Https website, you get that whole chain of certificates on the web server's key signed by the magic six root authorities all the way up at the root of the TLS PKI, that sort of thing. But we know that a lot of certificate authorities have gone bad and the only reason you go find out they've gone bad is if someone's noticing and recording their certificates in order to show evidence.
00:12:53.614 - 00:13:59.510, Speaker A: And most browsers just get the certificate, dump it, and forget about it. So there's no guarantee that a certificate authority who injects bad certificates would ever get caught unless people are paying close attention. So the certificate transparency project is all about inserting a public mirror service where your browser shouldn't, if you participate, won't show you the website and indicate it's safe. Unless not only is this certificate signed by the whole root of trust of the certificate authorities, but it also has to be stored and mirrored on these public repositories so that if it later turns out that was an invalid certificate, that evidence is not only checkable, but it's also recorded. So there's a better chance of holding those certificate authorities to account in a very broad stroke. I think we need a very similar thing for the remote Attestation ecosystem. I'm just going to go through some very high level bullet points about what I think are best practices that in the decentralized systems community we should be doing to do our part to build secure things that are relying on these fairly fallible, vulnerability prone hardware systems.
00:13:59.510 - 00:14:53.434, Speaker A: There's a lot of things that we can do in the design that basically mitigate these vulnerabilities by making it harder for attackers to effectively make use of these. Using that threshold operation where you don't just have to break one, but you have to break several. And maybe they had to have been in the system for a while. That increases the difficulty of an attacker exploiting an SGX vulnerability. It's expensive. That's the reason why execution nodes typically have to do something kind of on their own, not in a threshold environment, but whatever you can afford to put into a threshold operating mode, you probably should. I think one of the most important things that I'm very sad about because it's not the best for decentralization, but I think it's the compromise incompatible with geographic decentralization that I think we need to do in suave for example is to restrict the enclave nodes to not just be from anywhere like in one of the side channel labs, but to only be in a reputable clouds data center.
00:14:53.434 - 00:15:34.614, Speaker A: Because now you have to not only exploit the vulnerability, but you also have to have access to the cloud if it requires physical access to exploit or hypervisor level access even. There's lots of ways of using enclaves. Some involve more interactions, others involve less interaction, requiring more interaction in order to keep computing. Like if you don't check in with the blockchain and redo your Attestation every so often, then you don't get access to more of the sensitive data that comes through. That's something that also mitigates the attack. Compartmentalization is one of the main concepts from the Akedon paper. And roughly it just means saying don't give everything to the execution nodes, just give them what they need to know.
00:15:34.614 - 00:16:32.826, Speaker A: Maybe that's on a per application by application basis in general, the point is that even if you have to accept some vulnerability in some part of your system, it doesn't have to affect absolutely everything I mentioned in the little graphic kind of what forward secrecy can do. So it would be good to be able to have a way that enclaves can discard and say you have to prove you've discarded whatever should be discarded in the last block before you can get sensitive data corresponding to the new block. This is something that basically protects your historical data rather than just the current active data. Ideally, key rotation should happen as soon as the TCB recovery occurs. So just for example, and I will mention it this way, but I need to double check on this. But so I'm quite certain that secret network in responding to Downfall has rejected new nodes joining that are joining from a new processor configuration. But I know that key rotation requires a hard fork and so I don't think that key rotation has occurred yet.
00:16:32.826 - 00:17:56.794, Speaker A: So data sent today could still be attacked by old nodes that haven't yet upgraded and are still stale based on the ambient authority that they still have from having registered before Downfall was announced. Finally, I think that's something that's kind of missing, and this is an important best practice that all of these systems need to really kick it up a notch is transparency. So what are the exact policies that the blockchains are enforcing for acceptable configurations or not? How many execution nodes are there currently on the system? In what configurations that could have access to this? When and where was key rotation performed? And to the extent that there's like a governance policy that's involved in updating or responding to these things, I know that many of those systems have essentially like a structure like that. I haven't seen them publish clear documents on what it is that their councils are considering with regards to things they have to do to cope with SGX. I'll mention now, kind of just going back up from just the TCB recovery stuff, there are a bunch of interesting open questions. One that I'm really interested in is how to combine the best components of hardware enclaves as well as all of the sexy cryptography gadgets FHEs or knowledge proofs and all. After looking at this for a long time, I'm not just saying this to get along with everyone in their fields, but all of these are really complementary.
00:17:56.794 - 00:18:45.780, Speaker A: They don't all do the same things, no one of them subsumes the others. And I think that the ideal endgame architecture will incorporate elements of all of these simultaneously, something that's on my mind but is hard to tackle. So if you're interested in this, would love to talk with you about it. But I think we shouldn't be just relying on intel and AMD to do this for us. We should be threatening to build our own blockchain native smart contract execution environment in a dedicated piece of hardware, SGX AMD. None of these are designed with physical tamper resistance as their goal, they're designed for software isolation and they're really motivated by cloud applications. But maybe we can find a way to build one that serves our purposes and has the security level that's like blockchain grade security level, which should be several clicks better than enterprise grade security, which isn't as much.
00:18:45.780 - 00:19:29.250, Speaker A: There are a bunch of ways of designing this kind of key management thing. I gave the sketch of there being some threshold operations, some non threshold operations, but how to actually manage those together in an effective way is still somewhat of an open design problem. And I won't go into any of this now, but Mitigating side channels, even when the SGX is doing its thing correctly. Like side channels are still, even then, a challenge that as software people we have to mitigate. I like a lot of oblivious Ram and other oblivious algorithms. Those are things that are appropriate to fit there but have to look at other talks for info about that. I'll just wrap up by saying that tes are really powerful, but they really create like a big tech debt that we have to pay off.
00:19:29.250 - 00:20:05.902, Speaker A: The reason to use tes isn't because they're so easy to use, because to do it correctly they are not easy to use. The reason to use them is when there's no other alternative that fits the bill other than them and then you have to use them and you just have to pay the cost of doing your extra security design and mitigations and the like around it. And this is basically the case for, I think, many of the most interesting applications that have the quality of having global state. That is contended by many users, but none of those users know the value of the state. Otherwise you could do zero knowledge proofs. But that's the case for many of the most interesting applications. I think we're still at the beginning of doing these.
00:20:05.902 - 00:20:53.280, Speaker A: It's one thing to say SGX sucks, it keeps having those vulnerabilities, but we know this by now and can anticipate it. There's still good reasons for us to build systems around it, but we still have, I think, a lot to do and a lot more that we can do as the decentralized systems designers to do our part for security around this kernel of a system. So okay, that's all, thank you. Questions? I just had a quick one. Is chip diversity important for Mitigation or are there downsides to it? Chip diversity, it's a great question. Chip diversity is, I think, very important for that, especially in those threshold settings. You can make it where a break would need to be on multiple platforms at the same time.
00:20:53.280 - 00:21:04.340, Speaker A: It's definitely a great idea to have a trusted hardware strategy that involves developing on AMD and intel simultaneously. So yeah, that definitely plays a role. Awesome, thank you.
00:21:07.030 - 00:21:20.920, Speaker C: You mentioned at some point that for downfall they for the first time released some portion of information simultaneously with like with the public vulnerability being disclosed. Could you go into more detail about that? Again, I didn't quite catch that part.
00:21:21.450 - 00:22:14.886, Speaker A: When APIC leak was announced, there was not at the time the information released that would allow you to still accept registrations, but only non vulnerable processor types. You had to wait for more of the TCB recovery process from intel to happen after the public disclosure. Basically, at the time of public disclosure, there was not a way that you could safely use remote Attestation without getting at least like a list of hardware type you may have been able to reject by hardware type in a certain within the DCAP configuration, but not otherwise. This is a little subtle. I can't give like a super clear answer right there. But basically before we had to wait for a period after the public disclosure, even before remote Attestation could be effectively used. Now the information was available somewhat inconsistently right on that day.
00:22:14.886 - 00:22:25.740, Speaker A: Also, the embargo period was a lot longer with APIC leak. It was like a nine month embargo period. So this one was twelve month embargo period. So the difference was they just didn't tell us about it for an extra three months, I guess.
00:22:26.590 - 00:22:28.140, Speaker C: All right, thank you.
00:22:33.090 - 00:22:57.650, Speaker D: I know there's a bunch of software based approaches to preventing side channel attacks like the oram research and stuff like that. You mentioned that we should maybe be researching a direction of preventing physical tampering in our enclave design. I know there's like the grid plus wallet, but can you present examples of other research in that direction?
00:22:58.070 - 00:23:22.206, Speaker A: Yeah, I mean, the main challenge with this is so there are a lot of trusted hardware enclaves. The critical feature for us to use is remote Attestation and ideally publicly verifiable remote Attestation, there's a secure hardware element in every iPhone, things like that, hardware wallets. But they don't generally support remote Attestation, so it's not suitable to be a secure node on a decentralized so, like.
00:23:22.228 - 00:23:26.618, Speaker D: The combination of networking and remote Attestation.
00:23:26.794 - 00:23:36.342, Speaker A: Yeah, exactly. Hi Andrew. Good talk.
00:23:36.396 - 00:24:06.690, Speaker E: Thank you. So this has come up before in one of Phil's talks, and you mentioned now as well, like developing a blockchain specific Tee or some contender with the enterprise solutions. I'm curious about the manufacturing process because I understand that a lot of the trust assumptions come in just as the hardware is produced. I know Phil, there's some ideas, but I don't remember. Do you have any of your own ideas of how we can go through this manufacturing process without having to trust the manufacturer?
00:24:07.110 - 00:24:45.946, Speaker A: Yeah, that's a perfect question. So there have been a bunch of efforts to do an open source trusted platform Tee design. Like Keystone was the most recent academic one of those. But that only solves a tiny portion of the problem because now you have a spec for an open source secure hardware, and you have some piece of hardware that claims to be that you only interact with online, but there's no guarantee that it was made according to that spec. And you can't just use remote Attestation to check that. And right now it's just we trust intel, trust AMD, but for an upstart like, former mining company, that's not going to be the same kind of environment. So I just have like a shred of an idea that kind of has two components.
00:24:45.946 - 00:25:28.410, Speaker A: So one is that we should make designs that are not only open source, but have a way that you can analyze them, maybe even destructively, in order to check that they were built according to the design. Although doing that if it really involves a destructive analysis. Well, it's great. I know it was secure, but now I can't use it. What could go along with that is something like cut and choose, but for hardware enclaves where you have to register a bunch of them at once, maybe 40, and then some of them will be randomly selected to go through that destructive analysis. At the end of that, maybe you have good confidence that the remaining ones that you didn't analyze, at least most of them with high probability, are secure. Even then, that really only works well if they're running among themselves a threshold operation as well.
00:25:28.410 - 00:25:43.120, Speaker A: If you want the crypto grade security there, but that's just like a sketch of an idea. It would need to be out. But yeah, the manufacturing process, let alone the design, is just as important and probably harder to solve. Thanks. Yeah.
00:25:45.110 - 00:25:51.966, Speaker C: Is there always an implicit trust assumption for intel as the root CA for the PKI infrastructure?
00:25:52.158 - 00:25:53.860, Speaker A: Yeah. With SGX? Absolutely.
00:25:54.790 - 00:26:02.534, Speaker C: So in the future, would you perceive having multiple root CAS as a viable option to opt out of that?
00:26:02.732 - 00:26:40.830, Speaker A: Yeah, absolutely. I mean, so in the suggestion that I made about a cloud environment being mandatory, that's almost saying that to let you on the network you have to both have a signature of responsibility from intel and also a signature of responsibility for, you know, Microsoft's taking responsibility for this. So that's one way, even with one processor. And if you can do like MPC among an intel node, an Nvidia H 100 and an AMD node, then that's kind of two out of three security among all of those different root CAS. Yeah, definitely. Thank you. Sweet.
