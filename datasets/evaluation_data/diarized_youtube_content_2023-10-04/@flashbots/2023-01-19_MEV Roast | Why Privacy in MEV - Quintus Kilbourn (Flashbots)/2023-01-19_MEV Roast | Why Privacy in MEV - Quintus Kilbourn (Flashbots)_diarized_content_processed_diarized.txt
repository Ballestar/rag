00:00:03.080 - 00:00:37.510, Speaker A: I'll be motivating. Why are we having this roast in the first place? And my name is Quintess, and I'm from the Flashpots research team. Right. So why do we want privacy in mev? When someone asks me this question, I kind of feel like there's two points to the answer to my answer, at least. One is cooperation. In particular, we want cooperation between entities that don't trust each other and that might have conflicting incentives. And I think this is particularly difficult in mev, and I'll sort of expand on why privacy is important for that in a second.
00:00:37.510 - 00:01:47.260, Speaker A: And the second reason why privacy is important in mev is because it affects user outcomes. Now, this is a very broad term, I realize, but I think it's broad intentionally because it's not exactly clear what the outcome should be. It depends on the application. But an example you can keep in mind is like a uniswap swap. For example, the user's price is a measure of outcome, but then you might have some other outcomes, like, for example, a payment you receive via an order flow auction or something along those lines. Now, looking at cooperation first, what do I mean by cooperation? What are some examples of things we can think of? And really, if you think of the sort of the primitives the building blocks, no pun intended that we see pun intended in the Mev supply chain is we see bundles, bundles of bundles and blocks. And really what's happening here is we have some end output, a block or an ordered list of transactions, which represents some sort of utility to multiple agents that contributed the transactions that make up this ordering.
00:01:47.260 - 00:03:05.984, Speaker A: And so if we think about it, we have a bunch of agents who want to submit transactions into a block, and somehow they have to all get their transactions together into a single block. But in order to build this final block, they need to share this information, these transactions and some other information, perhaps to actually have the transactions executed. But this is more difficult than it seems on the surface, in part because information is very valuable. Right. What information am I talking about? I'm talking about transactions on one level. So a basic example is someone is executing some complicated arbitrage with a transaction or a series of transactions, and if someone else sees these transactions, they can just copy their strategy, which significantly reduces the profitability of the trader or the searcher or whatever you want to call them. But then there's also, like, meta information that's important, right? So, for example, bids, if the coordination mechanism you're using requires you to bid to pay someone for something, having someone know what you're bidding, especially when they're competing with you, is obviously a disadvantage because they can just bid epsilon more and suddenly you're down in the dumps.
00:03:05.984 - 00:03:56.870, Speaker A: And so clearly, privacy is important. And one sort of mapping we can think of one sort of different use case that seems very similar is high frequency trading in traditional finance. These firms are known to be super secretive, to not even be willing to tell you how many members they have in teams and these kind of things. Because even that little bit of information can be alpha. It can be very profitable for someone else. And profit for someone else often means a loss of profit for these firms. But why do we care about cooperation? Right? Seems very nice, but can we be a bit more specific about what's nice about it? If we look at the mev supply chain, we can see in particular between the search and build and validator, that a lot of this sensitive information is being passed around.
00:03:56.870 - 00:05:16.288, Speaker A: But passing the sensitive information around means that there's a barrier to cooperation, or there can be, because there's a high degree of trust required if we don't have the proper mechanism for cooperation. And the risk here is that this barrier to cooperation means that the sort of most efficient outcome is just these entities being amalgamated into one large centralized entity. And this is not something we want. And I can give a couple of reasons why. So we want to avoid decentralized entities because we think often, or they will likely be monopolistic or oligopolistic in the sense that there'll only be a handful of these ones of these decentralized entities because the market can only support so many. Right? And the reason you want to avoid this is because we want to avoid rent seeking, for example, right? If there's not enough competition, then these entities can internalize a lot of the value that we might want to direct elsewhere. We want to avoid regulatory centralization, centralized entity is probably based in some sort of jurisdiction and we don't want a sort of credibly neutral blockchain to be subject to the whims of some government.
00:05:16.288 - 00:06:35.640, Speaker A: And then also we want to avoid undue or disproportionate influence over protocol incentives. Blocks are very valuable or can be, and they're also a very key component to blockchains, obviously. And so having one entity or one handful of entities controlling this process can be detrimental to the system. But where does privacy come in? Right? We've talked about cooperation, but what does privacy allow us to do? Well, like I hinted at earlier, privacy allows us to lower the barriers to cooperation, which means that the market can sustain, or rather I should say, in order for entities to work together, we don't need to build trusted relationships and we don't need to maybe sign legal agreements. We can have a permissionless system where entities can interact with each other, can coordinate without requiring this massive overhead or someone's permission. And what's nice about this is that permissionless systems mean that agents can join whenever it's profitable to do so, which hopefully means the system is more competitive. And like I said earlier, this avoids rent seeking, it pushes value back into the chain to the validators or perhaps back to the users.
00:06:35.640 - 00:07:35.836, Speaker A: But it also hopefully allows more entities to participate in this system, making it more decentralized. What's also nice about cooperation is that it might unlock additional value. What do I mean by this? I think maybe the most basic example we can think of today is that many searches building a block together or aggregating many different bundles together into one block might see that block being more profitable than the block than that any individual searcher could produce. Right. And how is this being done at the moment? Well, some of the proposals or some of the implementations as far have just been trusted private channels. Mev geth was an example of this which allowed searchers and miners to cooperate without searcher bundles being stolen. We had builder OPCs at the moment is another way for searchers to submit bundles privately without other searches seeing them.
00:07:35.836 - 00:08:05.328, Speaker A: But obviously there are very heavy trust assumptions involved here. Similarly commit reveal schemes like Mev Boost have been implemented. Right. Mev Boost allowing validators and builders to cooperate without the builder worrying that the validator will steal their block. So that's it for cooperation. What about user outcomes? This sort of very abstract term I referenced earlier. What's an example of this? Well, a very easy one is sandwiches.
00:08:05.328 - 00:09:07.844, Speaker A: I don't really have to explain this too much, we're all very familiar with sandwiches. And so maybe moving on to another example, we have generalized frontrunners. So a generalized frontrunner is one of the first forms of Mev that was spoken about when Mev became popularized in the Dark Forest post. If you accidentally leave some money available to the world in a smart contract and you try to get that out with the transactions through the Mempool, you're probably not going to see that money again. Then a slightly more intricate example than order flow auction. So maybe leaving out the implementation details, we can imagine some order flow auction or some black box called the order flow auction where users and searches both participate and the output is supposed to be some bundle which is beneficial to the user according to some rule. So the user's execution is good, their payment is good and we can imagine the output maybe being like a user being background by a searcher.
00:09:07.844 - 00:09:50.810, Speaker A: But if we have the wrong privacy sort of environment in the Ofa and more information is exposed than we would like, a searcher could for example act outside of the order flow auction and outside of the rules that the ORderflow auction can enforce to effectively, for example, sandwich the user, which could end up with the user execution being much worse than anticipated and there actually having been a much better way to execute the user's transaction. Maybe just without the bundle, who knows? But the point is that it's very hard to reason about what's good for the user within the order flow auction. If agents are also acting on the same information outside of it.
00:09:52.140 - 00:09:52.504, Speaker B: Right?
00:09:52.542 - 00:10:33.510, Speaker A: And why do we care? I guess why do we care about user outcomes? Should be a bit of a silly question. I think most of us probably agree that it's a very important thing to do. But maybe just to motivate it a little bit, we can say that we want to make trustlessness appealing. Again a very general statement. But we believe in blockchain with cryptography and all the incentives and decentralization going into this. We believe that the trust assumptions and the applications that we're building are better than the trust assumptions in the traditional world, like a Dex versus a sex, for example. However, we don't want this trust to come at a very heavy cost to users in the form of worse prices or higher fees or these kinds of things.
00:10:33.510 - 00:12:32.804, Speaker A: Similarly, one can argue that blockchains were invented to address mev, and this is a bit like a bit more of a philosophical point, but really what I'm trying to say is that when Bitcoin was created, we're trying to disintermediate remove this very powerful intermediary that can impose their objective function and extract value from users at the user's cost. Right? And if we think about what mev is, often this is basically the same thing because a validator or a miner, whoever is in a very powerful position and they sort of intermediate between all these other users who want their transactions executed, they're able to extract value, often at the cost of users. And so addressing mev is in keeping with the sort of philosophical tradition of blockchains, which is arguably a good thing in itself, but also, I think can teach us many lessons that hopefully can be applied outside of the very specific case of sandwiching or whatever it is. Maybe that was a bit too abstract, but I'll just say bottom line, many people have this semi utopic vision of what blockchain can accomplish for people. And in order for us to reach that, I think most people would agree that sort of in order to reach a world where users outcomes are improved, we need to improve user outcomes. Right? And then how has this been done, how people propose to do this? So again, trusted private channels, Protect RPC is an example of this where users can submit their transactions directly to Flashbots Builder, so it's not seen at the mempool and then this transaction sort of end up in a block without anyone else seeing it until it's executed. There are many cryptographic proposals as well threshold encryption, mempools commit reveal schemes, trusted execution environments and I'm sure we'll hear about all of these in the coming talks.
00:12:32.804 - 00:14:05.640, Speaker A: There are also non private approaches, so decentralized sequencing, trusted marketplaces, et cetera. I should mention that all of them have their benefits, all of them have their drawbacks and each of them merits its own talk. So I won't go into them individually but maybe to motivate that this is a very interesting problem and that the most naive solution definitely isn't necessarily the best one. I'll give this example, right? So why can't we just slap an encryption scheme on top of this to stop the validator to act on it? Or maybe why wouldn't we want to? Right? One reason is the specific challenges specific to the scheme. If you have a commit reveal scheme, how can you ensure a reveal after the commit was made? Or something along those lines. But I think another question that's maybe more interesting to me is that the outcomes in an encrypted environment, if the encryption is successful, is that the outcomes are blind in some sense, right? What does this mean? Well, if we assume that the outcome is blind, we assume that the transactions are ordered roughly randomly. But how does a random ordering compare to something which is like a buy sell, buy, sell with regard to swaps? Especially if the random ordering ends up seeing buy, buy, sell, where the second buy and the second sell revert because the prices aren't within their range.
00:14:05.640 - 00:14:55.316, Speaker A: This is obviously not desirable. And obviously we can go into the nitty gritty here. We can say, well, actually, the ordering wouldn't be random because people would be spamming the chain to try sort of compete for jockey for beneficial positioning and these kind of things. But that's not the point I'm trying to get to. I'm really just trying to say that this is a hard problem and we can't just make mev private and then we've solved the problems. And so I'll introduce a buzzword before I close off, which many of you hopefully have heard of programmable privacy. And it's just basically this idea that privacy doesn't need to be binary, it doesn't need to be public or private, but rather there's this very large design space in between the two where users can choose maybe some components of the information is public and maybe only to some entities and maybe only under some conditions.
00:14:55.316 - 00:16:15.952, Speaker A: And playing around with this is really something that we've been thinking about and that might solve a lot of the problems in mev and hopefully will. So before everyone goes into a very technical talk later on, I'll finish like a hand wavy, abstract conclusion. Which is to say that we can think of the Mev supply chain as a negotiation between these many different entities who are trying to go from these many different entities, some who can do the execution and some who want execution to be done according to their specification. And what we've seen is an imbalance of power where some entities, for a variety of reasons, including the information they have, have been able to draw an advantage at the cost of other users. And so what we're trying to do is we're trying to provide the tools to users to enter this negotiation and get sort of the best possible outcomes for themselves. And these tools, we believe, are ways of expressing or choosing how the information is exposed so that they can get the best outcomes for themselves without other agents taking advantage of the information they've exposed. So I hope that made sense.
00:16:15.952 - 00:16:26.390, Speaker A: I think it's Q and A now. I actually don't know if you guys have been listening to me for the last 20 minutes. I hope I haven't been speaking into nothingness. Yeah, cool.
00:16:27.720 - 00:16:47.852, Speaker C: Thank you, Quintess. Yeah, we have been able to hear you. Anyone has a burning question? I'm mindful of the schedule. We only have two and a half hours, so we might only have time for one question. I mean, one kind of small. Yeah, go ahead.
00:16:47.906 - 00:17:10.950, Speaker B: I can ask a question that's a bit spicy. Has anyone looked into how would it look like with privacy on and off? Is this something that can be quantified in some way besides the general notion that we probably all understand that more privacy is better?
00:17:13.720 - 00:17:47.020, Speaker A: I'd love for someone else to jump in here, but my understanding of this is that it's an open research problem and there are people working on actual implementations. And so I guess we'll tell with experiments. But also one of the things we're working on internally and I think Phil will sort of touch on this in the next talk is how do we sort of theoretically understand the trade off between privacy or, like, the relationship between privacy and the sort of economic state of the outcome and also the trade off perhaps?
00:17:47.360 - 00:17:48.716, Speaker B: What are you paying?
00:17:48.898 - 00:17:55.764, Speaker A: Yeah, I do think that there's a trade off, and I think that's what will hopefully touch on the next talk book.
00:17:55.962 - 00:17:59.760, Speaker C: Okay, great. Fantastic. Thank you, Quintessential.
