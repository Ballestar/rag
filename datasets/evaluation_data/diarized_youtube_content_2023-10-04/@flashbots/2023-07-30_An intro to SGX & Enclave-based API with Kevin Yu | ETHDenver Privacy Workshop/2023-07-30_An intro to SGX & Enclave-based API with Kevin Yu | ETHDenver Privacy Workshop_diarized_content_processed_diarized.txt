00:00:02.890 - 00:01:26.818, Speaker A: Yeah, so today I'll be just giving a quick intro to SGX and then what we're building here at the new Oracles that are in a way like we're having a solution that has this heavy reliance on SGX. But yeah, let's get started. So what is SGX? This is a very philosophical question as well. So SGX is a form of trusted execution environment for Tes, right? Basically Tes are just like you have this kind of like secure area, your main processors, and then it can guarantee that the code and data being loaded into your processor is protected against a malicious host that can potentially have administrative privileges. Right? So for example, for your operating systems, for your hypervisors, for your BIOS, for your firmware, for your SMMS, and then for any form of remote attacks, even if a lot of these malicious administrators want to do potential attacks against whatever program you're running, the enclaves, at least this is what intel is promising. You're having a much smaller attack surface here, right? You have some side channels here, you have this interface towards hardware, but then you're basically relieving from the potential attack surfaces you can have for Dos and the VMM. And of course for whatever code you're running in the enclaves, you have confidentiality and the integrity both being guaranteed.
00:01:26.818 - 00:02:33.414, Speaker A: This is also kind of like the two core features that the basis of Andrew and Phil's talks. When you're running your enclave based auctions or your private contracts, you need to make sure that the programs are being executed with integrity. And then of course there's like a privacy element to that as well. So the core components of SGX we're listening for here, there's much more than this, but then due to the time constraints we have so TCB, or trusted computing base, you can think of this as a measurement basically that's made on all the security parameters of the underlying hardware. So this is used for a lot of key generation and then annotation creation as and then so hardware secrets. We have the root provisioning key and then the root ceiling key. The provisioning key is basically intel has this huge registry of all these RPKs that they would use to basically verify say, a particular enclave is being produced or manufactured by them, or not the RSK.
00:02:33.414 - 00:03:09.622, Speaker A: They're claiming that this is something that they do not know. Right? So this is being hard coded in the hardware when it's being produced. But then intel has basically eliminated all the traces for production for the Rs keys. So this is used more in actual production for key generation and then for the ceiling process that Andrew was telling about as well. Remote adaptation. This is kind of like a core component of SGX that makes it very powerful. And then there's also like the differentiation with I think, trust zone and then for MD there as well.
00:03:09.622 - 00:04:23.850, Speaker A: But basically what it allows is that say, a third party like software is trying to access a service that's running in an enclave. Right? Remote adaptation basically allows them to verify that whether this program is actually being run in a natural enclave that's being verified by intel. But then you can also have your custom DC AP pipelines which we'll get into later as well. Sealed storage. This is when you're basically say, like your program is running in SGX and you have some intermediate results and you want to save that into an untrusted environment, say, to your computer's own storage, like own disk, for example. And then you basically use the assuming keys here to kind of make sure that the data that's being offloaded into the underlying disk is actually being priced preserved. This is a really simple kind of description of how a usual program would work when you're running this when you're running it in an enclave, right? So E calls which are used to enter the enclave and the Ocas which are used to call outside the inputs of E call and the output of OCAW are usually not trusted.
00:04:23.850 - 00:05:57.966, Speaker A: But then for an application design here you can see that you have this very nice partition where you have an untrusted part of the app, right? And then you do this enclave creation process which basically you just run these four I mean the enclave would run these four commands to create the enclave and then yeah, you do the E call for entrance and then there's like whenever you're interacting with something that's outside of your enclave, you use the call command. Here we'll have a much kind of concrete example of how this would actually work in production with what we're building later. I'll go through this real quick, but these are just some of the core components of your enclaves, right? So your PRM or processor reserve memory is being carved out your normal DRAM and they also have like an enclave page cache that's being put in here. There's some mappings for your cache here. The linear address ranch here is also used to basically manage your address tables with all of your pages and then the control structure there TCS here basically means that it's a piece of software within enclave that can support multithreaded execution for a lot of programs. So yeah, I think there's a huge design space potentially, I mean there's a huge design space of whatever you can run within the enclaves and then there are also very robust developer tooling right now that allow you to do that. Now in the attic part.
00:05:57.966 - 00:07:12.806, Speaker A: So on a high level, the SGX attachments are just you're just cryptographically proving application integrity based on some of your hardware information. Right? One of the core components of that would be the TCB or trusted computing base that we're talking about, where it basically establishes an identity for the enclave. There are two types of Attestations that are most commonly used. One is local attestation which happens usually when you're running like two different enclaves on the same piece of hardware and then you want them to establish a secure channel between the two and then do some kind of communication or whatever. Say you're running an MPC or collaborative scenarios or whatever remote association is as I was describing, where basically you have a third party, say, like software or whatever, trying to access the code that's being run within the SGX and then they want to make sure that the code is actually being executed in the secure enclave. Yeah, these are usually when you're having the out of state results which you have here. So this is the TCP information, this is reported that this is more relevant to a challenge process that we'll get into later.
00:07:12.806 - 00:08:11.606, Speaker A: And then there's like some hardware info there as well. Okay, so this is what you're having for local allocation. But then before we get into A, I don't know if everyone can see this picture very clearly, right, but this is the root provisional key or the RPK we were talking about. This is the root ceiling key or the RSK that we're talking about. This one, you can see that it's used both for generating the key that's used for annotations, for provisioning as intel would call it. And then it's also used for the ceiling process here. When you're trying to offset the data to some underlying hardware, there's a few transformations and then derivation algorithms that they're running to basically just KDFs that they're running to get out these keys that can be used for Attestation, but then for local Attestation, what you're usually having is this really neat challenge process.
00:08:11.606 - 00:09:27.106, Speaker A: Say AA is trying to prove to B that the program here is running in the enclave b would send over the Mr enclave here. Ereport is basically a command that allows A to generate a report or response to the particular challenge that he is sending over. And then the challenge itself is not being described here, but then you can think of that as whatever challenges you may use. For example in the DP helmet exchange protocol and then the response is being sent back here, it's being verified by who also gets a key using the EGETKEY command and then yeah, he does processing rewards, right, where basically at this point you would have a secure communication channel being established between these two applications. This is for remote attestation. Obviously this is much more complicated compared to local Attestation, but in the high level idea it's very similar. One of the major differences here is that first of mean, this entire process is being run in a thing called provisioning enclave or PvE, where you're basically provisioning against intel servers with this particular.
00:09:27.106 - 00:10:32.710, Speaker A: So whenever you're doing the annotation against intel servers. You'd use this Epid, or, like, Enhanced Privacy ID thing, which is basically used by intel to kind of verify that you're actually an enclave that has previously registered with them before. So you have Epid groups that are created based on prototypes, and then there's like an anonymous signing process here to make sure that whenever people are testing here, the admin information is not directly being leaked. And then so Epid is usually generated when you're first kind of like registrying with intel. If you haven't done this before, they would just do it in the first time when you're trying to perform this process. But then I think they do have once you have done this already, the idea is that you don't have to do this every time when you're trying to perform, like, remote adaptation. Your Epid is being generated in the first time when you're trying to perform remote.
00:10:32.710 - 00:11:59.806, Speaker A: So this is actually what is causing a lot of the attacks. That, for example, the one that Andrew was previously working on. So intel, the thing when you're verifying your hardware against intel, like their adaptation service or IAS here is that intel is usually slow in terms of enforcing a lot of the patches for the recent hacks or side channel attacks that researchers have discovered for SGX. So this basically means that even if patches have been released outside, hardware that haven't enforced, these patches can still successfully verify against IAS, which basically means that you do have a little bit of client diversity there, right? You're not enforcing this upon everyone, but then this definitely increases the attack surface for your application. And then, so here we're having a different set of pipelines here through ECDs signatures. So here you're not really verifying against Intel's annotation service anymore. You're basically testing against the custom security pipelines that's being set up by, say, for example, your cloud provider.
00:11:59.806 - 00:12:24.422, Speaker A: Right. In this case, it can be Azure. If you're running some servers yourself. You can set up like a blacklist, for example, for a list of hardware who haven't implemented particular patches. Here's a really neat demo of I mean, it's not a demo, it's just a GIF of how this usually works. Right. But it's very much the same as IIS.
00:12:24.422 - 00:12:54.260, Speaker A: It's just that instead of interacting with IIS, you're interacting with the DCAP pipelines that you're setting up yourself. And then I always forget this, but then I think the full name for DCAP is Data Center. Ada Station. Primitives. Yeah, this is one of the things that people rand about SGX as well. Right. I think the nine slides we've been through, there's way too many acronyms and then all this kind of like whatever when you're getting to the developer tooling, even.
00:12:54.260 - 00:13:12.154, Speaker A: It's a nightmare. But yeah. Field storage. So this is what Andrew was talking about. You have the ceiling with Mr. Enclif, and then you have the ceiling with some Mr signer, right? So Mr. Enclif is where you're basically ceiling to the exact piece of hardware there.
00:13:12.154 - 00:13:54.178, Speaker A: So whenever you're doing an upgrade, you need to do what Andrew was describing there. There's bit of overhead there. So I think in web two people in general prefer to use the enclave, the second approach, but then definitely under a blockchain setting. This is not ideal as Manju was describing, but yeah, this is a Seal process. You have some really words, you have some really interesting we're not interesting, not so interesting commands here. So for the development tooling, right now we're having four GX, right? This is the intel official SDK. There's a c SDK.
00:13:54.178 - 00:14:40.214, Speaker A: There's a rust SDK. This is what we've been using. T Club is more of a high level computing platform in that aside from sex, they also support, I think, Mdsev and then Arm Truss Zone. But yeah, it's kind of like just like wrapping everything together in this kind of like Pass model, I guess. Or Pass for US infrastructure as a service where people can just run applications on top, a Lib OS or like SOS this is usually if you want to run something more complicated within enclave, this is what you would use. We also have a more concrete example for this later, but then the more commonly used one is graphene SGX. Yeah, there's a few other know, graphing, et cetera, SGX step.
00:14:40.214 - 00:15:07.362, Speaker A: This is very helpful for debugging. Andrew just recommended this to me the other day. But you can simulate a lot of side channel attacks here in research. Yeah, so very helpful tooling. These are just like some of the common attacks against SGX here for cache timing, page branch shadowing, and the speculative execution. I would say actually all five. They're very common, just like normal side channel attacks against normal CPUs.
00:15:07.362 - 00:15:35.586, Speaker A: So SGX is just that. I think one of the reasons is that because they're trying to have this protection against your OS or your VMM with administrative privileges. So whenever these happen, the results are oftentimes even just even worse than you do. Like a speculative execution attack on a normal piece of hardware. But yeah, I think we're a bit overtime here. So getting quick to what we're building. Identity Oracles.
00:15:35.586 - 00:16:08.322, Speaker A: Fundamentally, we're bridging data from one adeni layer to another. Like the first identity layer here usually is some off chain requesting data sources. It can be like, say, your behaviors on Twitter, Instagram, Spotify, et cetera. Can be your bank account information, can be your behaviors. For example, you're trying to prove your behaviors on Ethereum to some optimism contract or whatever. Another here. The other end of the pipeline for our Oracles is basically any custom data vehicles that's being used to host information.
00:16:08.322 - 00:16:37.930, Speaker A: It can be like on chain, like NFTs SPDs, your normal action triggered Oracle contracts. It can be verifiable credentials within the system, right? It can even be like a centralized ID system. Like for example, with some Singaporean government, they have this centralized ID system called Syncpass. So these are all interesting experiments we're running there. But then for this design problem itself, you have four steps. First of all you need to authenticate someone's identity. And then this is usually down to for example, parsing someone's product Credential or OAuth.
00:16:37.930 - 00:17:43.246, Speaker A: And then you retrieve the data from that third party server, whatever third party server. Or like for example in the case of blockchain, you'll just be fetching that data on chain. But this is usually where you need to access establish a TLS session to some third party server and do your normal Https request and then you perform some computation and finally you feed that into different launching vehicles. Some of the primary design challenges here. So first of all we have the privacy versus integrity issue, which is what exactly Andrew was talking about for CKP generation as well, because you need valid witnesses whenever you're generating these proofs. And then when your witnesses are basically private user information or user information that can only be authenticated in a private way, it basically means that you run into this appliance problem. If you just allow users to do this proof generation directly in their front end, then the user might temper with data, right? I can change something before I can even change my HTML copy for generating the proof in my browser, right? So you need to guarantee integrity here as well.
00:17:43.246 - 00:18:42.478, Speaker A: But then if you do this proof generation process through a centralized server, you're just like losing your privacy there as well. And then there's the decentralization problem there as well. If you're using a centralized server to guarantee integrity, obviously you can't have a permissionless or trustless set up for anyone to run these nodes because everyone would be able to see the user private information. So that's why we have designed this modular privacy layer here. So on top we have two types of zero knowledge proofs that are being enabled to protect user anonymity and then user data confidentiality. So for set membership proofs or your normal inclusion proofs, whether you can do that through a Merco root accumulator or you can do that through like a RSA accumulator, you have different implementations for this. But in the high level idea is to decouple users like off chain and off chain identities.
00:18:42.478 - 00:19:24.650, Speaker A: Wrench proofs are just used for basic data desensitization, right, instead of having the exact number you're having like a ranch there. But then to solve this problem. So we have two different types of solutions. One is based in Tes, this is the one I'm going to dive deeper into later. So Andrew also mentioned this old paper by my professor at Duke of Fan which is called Tongue choir. Tongue choir is kind of like a more general purpose, like authenticated smart contract data feed problem. We do share similar designs there, but then for us here it's more about generating xeon truths within a secure environment where you can have both privacy and then integrity guaranteed.
00:19:24.650 - 00:20:01.662, Speaker A: And then the final solution there is a POS level MPC. This is where you can run it in the front end directly with a browser extension, do some WASM based proof generation. There's a paper behind this as well called Deco, but yeah, we won't be getting too deep into that today. So SIBO SIBO is what we are naming our Te based, like, network knows. But in the overall architecture here, you can see this is like the client. Someone is trying to fetch data from a confidential data provider. This usually can be just like some third party server here.
00:20:01.662 - 00:20:58.986, Speaker A: And then you're establishing basically a Tis connection here with a server that's being run within an enclave. You establish the connection here. There are some additional steps for you to fetch the data here, do some computations here and then send the data back. We have a local allocation enabled here as well. This is for remote allocation because whenever your client is trying to interact with the Oracle node that's being run in the enclave, I mean, we're the Ti server, the TLS server that's being run in the enclave, you need to ensure that it's an actual enclave. But then we also have this local attachment thing where basically we're running a library OS within the second enclave to do the proof generation because right now we're doing DKP generation with Circum and Snarkjs. So to efficiently run JS within SGX, we're using a second enclave.
00:20:58.986 - 00:21:49.674, Speaker A: But then you can also abstract this layer out and then put that into another server. And then you just do remote association instead of local association. We support both ECDSA and Epid Attestations. So this would allow us to have more custom rules against Intel Station service orm, which is something that Andrew and Elaine are especially obsessive about. It's not extremely relevant to our use case. But then because we're running a HTPs server here, there are certificates that we need to protect and then ideally to achieve forward secrecy, there are some of these private keys you want to rotate whenever you're doing a new session. Right? But then right now we're being lazy.
00:21:49.674 - 00:22:25.942, Speaker A: So there are keys that we're using for like two days or three days. So that's why we also have a really simple layer of orm there. It's just like the most, I think, basic square root or M, which is a paper proposed back in 1980s or something like 20 years before I was born. So it might not be super robust in these days. But yeah, this is like the proof generation has been done here within the Lib OS. And then we also have the server set up with some non blocking I O. This is a really cool rust library.
00:22:25.942 - 00:22:56.834, Speaker A: Mio. I was used to it enable just like in general, non blocking iOS. But yeah, so I know we're running out of time. So a brief kind of rundown of how the handshake process works with the clients. This is just a normal TLS connection. But then there are elements for remote analyzation that's being integrated here through this interaction with the server as or generate a key pair for signature the code that's being produced here from the coding enclave. This is basically what intel is calling their reports whenever they're doing remote, right.
00:22:56.834 - 00:24:06.394, Speaker A: And you do like IAS or your tests or DCAP to make sure that the server is actually running in an enclave and the report is being concatenated into the certificates that's being sent back to our client. And the client would verify basically intel roots CA it would verify the Attestation report. And then yeah, I would also get the public key for the attitude report. And then this is where when the client basically you're done with the handshake phase, right? This is like in a normal TL session, you first go through the handshake phase and then you do the actual query, right? So here, for example, here we're just trying to query whether a user has a balance in a bank that's for example, within this particular range because we're doing like a decay ranch poop here. So send the request here and then the server like the enclave would come check the query and then construct the full request body and then send the relevant credentials here. It's responded. And then yeah, we would have the CK ranch poop being generated here.
00:24:06.394 - 00:24:48.040, Speaker A: And then a quote is being produced from the enclave alongside for the report data that's going to be sent back to the client as a part of the annotation. And then here you need to do the annotation generation and finally it just goes back to the client. I also have a really short demo here as well. Let me quickly show that. Yeah, this is the query we're constructing here. And you can see these are results, the outer stations. There's a few different signing keys here.
00:24:48.040 - 00:25:29.586, Speaker A: This is the signing key that's correspondent to the certificate for the server that's running the enclave. And the other signature is created by the private key that's generated per session. Rather one I was talking about. Ideally we need to rotate that per session for secrecy, but yeah, this is pretty much it for the entire presentation. I know there's a lot of things that we're packing to here. Let me get with this here. So slides, you can scan this, right? And then on Twitter, yeah, I mean just like showing our company for like 30 seconds.
00:25:29.586 - 00:25:42.666, Speaker A: Andrew, please. So on Twitter I'm a dolphin. This is my twitter. Click. Recently we have the second highest dau on optimism. Check our company out as well. We're doing some cool stuff.
00:25:42.666 - 00:26:10.370, Speaker A: And then yeah, slide you can scan for here. There's much more information that's placing the speaker notes that I didn't have the chance the time to go through. First of all, yes. Is your code open source at all to have Circon and even like SGX? That's really cool. Yeah, it is. Dude, I invited you to a repo? No, it's not fully open source. Yeah, we're still doing, like, testing.
00:26:10.370 - 00:27:03.740, Speaker A: I've been trying to figure this out thing or it's just a cache. It's not really, like, trusted. I feel like it's more the former compared to the but, I mean, if you're running on Azure, it's easier because they have their, like, I think DC we three and then DC we two. They have different one of the two only supports IAS, but then the other, like, you have the actually, it's not is one of them only support the DCAP data in Azure. So Microsoft is running and the other where you can have more customizability, where you can set up your own decap rules as I mean, right now we're just using that to have a blacklist of hardware. Good questions.
