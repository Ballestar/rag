00:00:08.810 - 00:00:46.090, Speaker A: So my name is Henry. I'm going to be talking to you about some ideas for minimizing mev with sealed input batch swaps. And so for context, it's maybe helpful to explain sort of, you know, how I got here because it's a little bit different from many of the other people at this event, right? So I'm working on building a project called Penumbra and that really came from kind of more of a privacy background or perspective rather than from DeFi.
00:00:46.090 - 00:01:45.258, Speaker A: And so I've kind of like stumbled backwards into this mev mitigation thing by accident. And as a result, the design that we've ended up with I think looks pretty different from a lot of the approaches that are coming sort of evolving the existing DeFi model on ethereum to be more protected. And so it's maybe useful to kind of get to that motivation, right? So the motivation is basically this question of like, how do we provide useful functionality on a private ledger? So I used to work on Zcash and around the time of the DeFi summer, you sort of have this feeling of like, cool, there's all these people who are doing stuff and finding a lot of value in actually doing things and all of the privacy projects that I'm working on are not really as useful.
00:01:45.258 - 00:02:05.060, Speaker A: So how could we fix that? The idea is to build essentially a private proof of stake l, one that works as a cross chain shielded pool and has a private decks in it. So that's like giving people sort of a positive reason to use this thing. That's not really the point of the talk.
00:02:05.060 - 00:02:46.018, Speaker A: The point of the talk is to kind of get into what is the main challenge there and how does that inform the kind of design that accidentally has some interesting properties around mev mitigation? The challenge there is the state model. So if we think about the normal kind of state model for any kind of conventional transparent blockchain, right, you've got this big pile of global state, and then there's all these transactions, and every transaction just sort of says, like here's some changes that are going to be making to the state and to execute them, you just take the transaction, execute it against your state, you get a new state. You get a new state.
00:02:46.018 - 00:02:56.222, Speaker A: And you just sort of roll this forward. But in order to have a shielded chain you need to have composable state. So you have this collection of state fragments.
00:02:56.222 - 00:03:29.466, Speaker A: This is kind of like more of a UTXO style model but I prefer to avoid using that term because it carries a lot of baggage from bitcoin that we could maybe just not have. And the idea is instead of just like any transaction can be executed, can edit whatever part of the state you say you have these state fragments and every transaction is going to compose together its input fragments and then produce some new state fragments. And those get appended into this big collection of state fragments.
00:03:29.466 - 00:03:44.926, Speaker A: And why would we want to do that? We want to do that so that we can have private state transitions. So we're first going to take all of those state fragments, replace them just with commitments to state. So now we've moved all of the actual chain state off chain.
00:03:44.926 - 00:04:12.640, Speaker A: And then we're also going to move the execution off chain by saying, you just have a ZK proof that, oh, I have proved that I've consumed these state fragments that were valid. I've produced some new state fragments, and I did all of that according to the chain rules. So that's all very cool and everything, right? And that's why everybody today is entirely using private blockchains and they've taken over the world.
00:04:12.640 - 00:04:28.306, Speaker A: No. Okay, so what's the problem with this? The problem is that this only works when there's no shared state. And why is that? It's because if you look at what's happening inside of this transaction so there's two problems.
00:04:28.306 - 00:05:11.274, Speaker A: The first problem is the execution has to be early binding and not late binding, right? So when I make a ZK proof of a valid state transition, I'm basically doing a little roll up, like a micro roll up of the entire sort of actions of that transaction, right? Like every Zcash transaction, for instance, is this like, little micro roll up. And as a result, I have to know all of the data that was used as part of that state transition. I can't do like if and that's totally different from how any part of DeFi works, right? If someone makes a transaction to uniswap, they're not signing.
00:05:11.274 - 00:05:39.690, Speaker A: Like, here is the output price that I got from the pool because that's not known until it's actually executed. And in a more traditional setting, you have this mix of here's some data that is bound early when someone is signing the transaction, like their input amount, their address, whatever. And then there's these other slots that will just like, they'll take what they can get as it's executed on chain.
00:05:39.690 - 00:06:15.090, Speaker A: And you can't really do that in this model. The second problem is that the prover has to know the entire state transition, right? So whoever is actually doing this proof needs to know all of the relevant data. And that means that if you're ever having something that has two people's data, either one of them has to tell the other or they both have to tell some trusted third party, right? So like, a ZK roll up does not actually really provide you with privacy because you've just introduced this new trusted third party that's doing the roll up proofs.
00:06:15.090 - 00:07:25.914, Speaker A: And so where we get to this is like, okay, we've sort of thought of like, oh, wouldn't it be cool if we could do this thing? But there's this bigger problem of like, how do you actually build useful functionality that works privately? And what I think that this problem reduces to is a slightly different framing, which is how do you have private interaction with public shared state? So if you think about basically any kind of useful thing that you could do on a public chain that has to have some kind of public shared state for people to interact with, but you want those interactions to not reveal that person's entire history. And I think that a general kind of way to think about this problem is you have sort of value that is serving different roles in some protocol or some application, and you want to be able to have transactions that cause value to flow between those different pools or areas, but without revealing what each individual entity's contribution to that flow is. Right.
00:07:25.914 - 00:07:52.290, Speaker A: Because if you can see, oh, here's this amount, the total was this before the transaction and then after the transaction it increased to this amount. You just do a subtraction and you figure out exactly what the transaction did. And so we have this problem of like, how do we hide the individual values while still revealing the kind of aggregation of everybody's private interactions.
00:07:52.290 - 00:08:19.626, Speaker A: Some examples of that, right, is like how do you hide trade amounts while revealing the AMM reserves? It's not possible to just say like, oh, well, we have the AMM state and that's know public, but the trades aren't you can work backwards. So there's also some bridging tie in. But basically just fast forwarding a little bit.
00:08:19.626 - 00:08:32.718, Speaker A: The point is that there's two basic strategies for how you can conceal this information. So they work in kind of opposite directions. One direction is you have some flow and you're going to split it up.
00:08:32.718 - 00:08:59.270, Speaker A: And the other is in the opposite direction, you have a bunch of flows and you're going to bash them all together. So looking at splitting flows to start, right? This picture is like, okay, somebody has some secret amount, they're going to split it up into some randomized sub amounts, and then they're going to create some different transactions, send those off to the chain at different times or something. And then they're going to hope that whoever is looking at this doesn't know statistics.
00:08:59.270 - 00:09:19.290, Speaker A: So this is kind of suboptimal, right? You're basically maybe better than nothing, but not something that you want to build a whole protocol around. And the alternative is batching. And in this case, you have a bunch of people who each have their own private amounts.
00:09:19.290 - 00:09:47.126, Speaker A: And what we're going to have them do is encrypt just the integer amounts using a construction that we've been calling flow encryption. This is essentially additively homorphic encryption for integers, but then with a bunch of extra properties that makes it actually useful in a blockchain, right? Like you need robustness for the decryption. You need to have some kind of end to end verifiability of all the ciphertext that people can't inflate value.
00:09:47.126 - 00:10:30.738, Speaker A: But whatever the idea is that you want people to be able to encrypt here's my contribution to some sort of flow of value between different parts of this protocol and then have the validators be able to aggregate all of those encryptions over some interval and do a joint decryption just of the batch total. And why would they want to do that? That's because then you can take that batch total and you can feed it into some public on chain computation. So there's this kind of general picture of how you can use this to solve the problem of private interaction with public shared state, at least in some limited contexts.
00:10:30.738 - 00:11:20.054, Speaker A: And the basic flow, right, is somebody is going to start off with their private input and they're going to do some transaction and as part of that transaction they'll do whatever other stuff they're going to do, but they'll also produce as one of the things in that transaction, this encrypted input. Another thing that that transaction is going to produce is some kind of private state NFT that privately records details about how they were participating in this protocol. As that transaction is going to be included into a block, it'll get batched together with some other inputs and then the validators can jointly decrypt a batch total, feed that into some public computation, and commit the output of that computation into the public chain state.
00:11:20.054 - 00:12:19.910, Speaker A: And now all of those outputs are accessible for a future private state transition where the original contributor is going to consume effectively their receipt and prove that whatever further actions they're doing are consistent both with whatever they did to contribute in the beginning as well as with the public computation that's based on everybody's participation. So you have this kind of multi phase protocol, but you can actually have private interaction with shared state in this way. And if you kind of follow this through to its conclusion, you end up with a kind of slightly different or, well, actually fairly different state model, which is this idea of almost like frequent batch transactions, right? So each kind of smart contract or piece of application logic is going to execute exactly once per block.
00:12:19.910 - 00:12:44.350, Speaker A: But instead of taking every individual transaction, it's going to process all of the inputs in one batch and it could do whatever it wants with those, but it has to process all of them at once. So you give out some things like for instance, you can't do like a kind of atomic composability of different smart contracts. So that's sad, but there are upsides.
00:12:44.350 - 00:13:11.302, Speaker A: Like the resource cost of executing this contract gets to be amortized over every input. And so you can potentially have significantly more complex logic in the contract because you know that you're not going to have to be calling it like 1000 times a block. The batching means that there's no ordering in this system, right? And if you think about it, in a blockchain you have these transactions.
00:13:11.302 - 00:13:44.180, Speaker A: People are coming to consensus on transactions and the minimum sort of unit of consensus is the block, right? Until something is part of a block, it doesn't exist from the perspective of the system. And the minimum increment of state change at the consensus level is the block. So if you build a mechanism that relies on some kind of higher precision notion of time or ordering, then of course you're going to create all this mechanical arbitrage, but you just could not do that.
00:13:44.180 - 00:14:20.080, Speaker A: Okay, there's reasons that you might want to do that. And the other thing too is that assuming that the rest of your transactions are operating in a sort of Zcash style shielded model, if you think about what's accessible to the block proposer, there's no real metadata in the transactions other than a description of what type of action they're doing. Their particular contributions are all encrypted up until the point that the block has actually been voted on.
00:14:20.080 - 00:14:40.022, Speaker A: And so the users are also going to be able to get some long term privacy, unlike a kind of commit and reveal scheme for, well, we'll just encrypt all the transactions individually and then decrypt them so we can execute them. Assuming that you have some sufficient batch sizes. But that's an inherent problem.
00:14:40.022 - 00:14:58.454, Speaker A: So it's in a small text as an example of how you could do this. Just to finally kind of tie all this together. Back to the original topic of the talk, here's kind of how you can use this to do some sealed input batch swaps.
00:14:58.454 - 00:15:32.322, Speaker A: And I think that this design is actually pretty cool even though we've sort of stumbled into it backwards. So you have some block, you have all the input trades, you have the consensus system, just groups those inputs by their trading pair and then batches up all of the encryptions of the inputs, decrypts the batch totals. And now the application has sort of this global view of all of the trading intent that has been expressed in this block.
00:15:32.322 - 00:16:16.446, Speaker A: So you could take those individual trades and just say like, oh, well, we'll execute each one in sequence as a different trade. But then it's sort of like how would you pick what order to do them in? How do you net out flows that are in opposite directions? And it's much cooler to just say, well, why don't we take all of these batch input totals that are representing the aggregate trade intent, put them into this graph of all of the possible asset pairs and then just globally resolve all of the trading intent simultaneously using optimal arbitrage. And we can do that because we're only doing this once per block, so we don't have to pay that cost for every single transaction.
00:16:16.446 - 00:16:29.580, Speaker A: And the result is that then you compute all your clearing prices and everybody who had submitted their swaps can mint the output assets of whatever type they have. So that's basically the design. Happy to have any questions.
00:16:43.700 - 00:16:54.930, Speaker B: Hi, thank you for the talk. So, as one of the previous speakers mentioned, this batching of transactions has results in a higher price impact, right?
00:16:56.520 - 00:16:57.172, Speaker A: Yeah.
00:16:57.306 - 00:17:22.520, Speaker B: So my question is then, if there's, like, a whale trade in the batch, is there any incentive for small users to be part of that batch? In other words, how can whales swap privately if there's no incentive for regular users to be part of those batches?
00:17:23.920 - 00:17:48.380, Speaker A: Yeah, so I think that the optimal way to interact with this is to okay, just to back up a second. Exactly as you mentioned, there is definitely execution risk in this system. I think that on average, it's actually going to end up substantially better because there's a lot of noise in trading in the non whale case.
00:17:48.380 - 00:18:04.516, Speaker A: Right. Like, that just kind of cancels out and you get better execution. And so I think that the kind of optimal move is at the user agent or wallet level to have a way for people to express, here's my time preference.
00:18:04.516 - 00:18:34.380, Speaker A: And based on that, have the client sort of split their trade into randomized sub amounts and submit those at sort of randomized intervals to spread that execution risk over multiple batches. And if you do that well, you can also increase the anonymity set of the whole system. Are we good? Clipping?
