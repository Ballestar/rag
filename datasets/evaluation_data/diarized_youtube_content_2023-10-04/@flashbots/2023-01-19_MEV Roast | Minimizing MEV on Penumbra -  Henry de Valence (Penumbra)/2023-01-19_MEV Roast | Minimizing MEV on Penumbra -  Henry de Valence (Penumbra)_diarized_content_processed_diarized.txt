00:00:03.370 - 00:00:04.046, Speaker A: All right.
00:00:04.228 - 00:00:13.758, Speaker B: So I'm going to be talking about minimizing mev on Penumbra as a kind of like high level as kind of.
00:00:13.764 - 00:00:18.974, Speaker A: Like a high level perspective of where.
00:00:19.012 - 00:00:20.718, Speaker B: We'Re coming from and where these sort.
00:00:20.724 - 00:00:21.998, Speaker A: Of thoughts are coming from.
00:00:22.164 - 00:01:07.774, Speaker B: Two kind of framing questions. The first is like, what is mev about fundamentally? I think that this is a question or the whole field is fundamentally about how do the economics of an application interact with the consensus system that's being used to execute to replicate that application in some decentralized way so that you can execute it without a trusted party. And a perspective that I have that comes out of that is that properly handling mev fundamentally is going to require vertical integration between the economics of a particular application, whether that's, I say, app.
00:01:07.812 - 00:01:10.530, Speaker A: In a kind of big general sense.
00:01:10.600 - 00:01:47.950, Speaker B: You could imagine that being like a single smart contract or you could imagine that being like a constellation of contracts that someone wants to interact with. But whatever that kind of high level application is somehow needs to have its economics integrated with the consensus mechanism that's actually executing it. And so my opinion, which people may or may not agree with, is that I think that app specific chains or roll ups are going to, in the medium to long term, outcompete general purpose attempts at sort of dealing with mev.
00:01:47.950 - 00:02:06.454, Speaker B: Because ultimately the mev is linked with what is the actual application that you're doing. And so if you can integrate that with the consensus mechanism, you can be more powerful, you can do more things. And I think that at least for applications that are important enough for people.
00:02:06.492 - 00:02:10.790, Speaker A: To build some specific thing that'll kind of outcompete.
00:02:11.290 - 00:02:28.570, Speaker B: The second question is like, okay, well, where does med occur? It's going to occur wherever the miner or proposer has actionable information about future execution. One term that I really don't agree with is rebranding. Med is like maximal extractable value.
00:02:28.570 - 00:02:39.038, Speaker B: I think if you don't have a block proposer in a privileged position, then that's just arbitrage and we have a word for that already.
00:02:39.124 - 00:02:40.750, Speaker A: Let's not sort of dilute.
00:02:41.810 - 00:02:56.982, Speaker B: And so from that perspective, you can say, well, we can minimize mev basically in two words or in two ways corresponding to those two words. Either you've reduced the amount of information disclosure. You're probably not going to ever get.
00:02:57.036 - 00:02:59.174, Speaker A: Sort of perfection on that front.
00:02:59.292 - 00:03:14.010, Speaker B: But then second, how do you do mechanism design so that the disclosed information that you do reveal, not actionable in a privileged way by the block producer?
00:03:14.430 - 00:03:17.322, Speaker A: So all of the other talks here.
00:03:17.376 - 00:03:27.642, Speaker B: So far, as far as I know, are about general purpose solutions for arbitrary programmability, which is the case for Ethereum.
00:03:27.786 - 00:03:29.054, Speaker A: The thing that I'm going to be.
00:03:29.092 - 00:04:08.794, Speaker B: Talking about instead is, okay, well, what could we learn instead from building one single application? So I'm not going to claim that this is like a solution to all problems. But what I think is interesting about this approach is that although you're taking a very narrow scope of what the problem is, within that narrow scope, you can have a complete solution to the problem, right? So when people talk about, say, the Med supply chain, I actually would say instead that should just be considered like.
00:04:08.832 - 00:04:11.414, Speaker A: End to end protocol design, right?
00:04:11.552 - 00:04:26.242, Speaker B: When you're designing a decentralized protocol, the design of that protocol should start from the actual end user and their key management, their custody solution, their client, all the way through that whole pipeline out.
00:04:26.296 - 00:04:29.202, Speaker A: To the ledger where the execution happens.
00:04:29.256 - 00:04:37.966, Speaker B: And then all the way back to where the client learns about it. And if you don't consider that, then you end up with sort of recentralization in all the places that you missed.
00:04:37.998 - 00:04:41.062, Speaker A: Like infiro so what are we building?
00:04:41.116 - 00:04:50.254, Speaker B: We're building Penumbra. It's a private proof of stakeholder one. It does this interchange shielded pool with IBC and it has a private Dex.
00:04:50.254 - 00:05:26.178, Speaker B: So the motivation for building a private dex is that if you're going to pick one application that you're trying to zoom in on, this is a really interesting one because every market is a market also in information. And so we have this idea that privacy can unlock capital efficiency and maybe you can have a situation where a private alternative can outcompete transparent ones. So coming back to this idea of like, okay, mev is occurring where there's actionable information, let's sort of zoom in on those two pieces.
00:05:26.178 - 00:05:40.854, Speaker B: First, the information on Penumbra, we have base layer privacy. I personally think that you can't really hope to solve mev without having privacy at the base layer.
00:05:40.902 - 00:05:45.146, Speaker A: And the reason is that privacy thought.
00:05:45.168 - 00:06:07.780, Speaker B: Of as being control over information disclosure. You can't ever undisclose information at a higher level that you've already revealed at a lower level. And so if you have a transparent basis and you have all of these problems where you're like paying fees, who's paying for the gas? There's all of these account.
00:06:07.780 - 00:06:30.238, Speaker B: It's a lot harder to kind of retroactively layer on sort of a fix to metadata that's revealed at a lower level. So what we've started with is a multi asset shielded pool that's similar to Zcash. And all of the value, unlike Zcash, is recorded privately in that shielded pool.
00:06:30.238 - 00:06:47.354, Speaker B: So when you do like a cross chain transfer in, it just records that in the shielded pool. And this means that everything is happening in and out of that common private base layer. So you have no accounts, there's no other transaction metadata.
00:06:47.354 - 00:07:11.766, Speaker B: The fees are all paid privately. And the super powerful thing about building in privacy at the base layer is that it allows transactions to have precise disclosure for interaction with public state. So even if we just stopped here and said like, oh, and we're going to have a completely transparent deck state or whatever, there's still mev problems that.
00:07:11.788 - 00:07:17.554, Speaker A: Will come out of that. But from a privacy perspective you've already.
00:07:17.612 - 00:07:27.770, Speaker B: Achieved each individual transaction is only revealing the specific interaction with the public state and not all of this other metadata.
00:07:28.670 - 00:07:30.798, Speaker A: And once you have that, you're in.
00:07:30.804 - 00:07:52.258, Speaker B: A good position because every useful blockchain revolves around having this public shared state, right? That's why people want to use these systems. And so the question really is about how do you allow people to have private interactions with that public shared state.
00:07:52.424 - 00:07:54.354, Speaker A: So we have sort of I think.
00:07:54.392 - 00:08:09.754, Speaker B: That there's two kind of like ways that that breaks down. One direction is to try to do splitting of flows, the other is to do batching. So with splitting, let's say there's some action that someone wants to do.
00:08:09.754 - 00:08:36.530, Speaker B: They want to affect some change, move some value around on the chain. If they split that value into randomized sub amounts and spread that over distinct transactions, then they can privately reassemble all of the output effects. But this is only actually possible if you have a shielded base layer, right? If you're doing this on a transparent chain, you just see where all the funds go and this is completely useless.
00:08:37.910 - 00:08:40.690, Speaker A: The other approach is trying to do batching.
00:08:42.470 - 00:08:46.866, Speaker B: What we've been thinking about is rather than trying to say, oh, well, we'll.
00:08:46.898 - 00:08:49.910, Speaker A: Have threshold encryption where we're going to.
00:08:49.980 - 00:09:33.714, Speaker B: Treat this transaction as this totally opaque object, if what we're actually trying to conceal is like, what is this transaction's specific contribution to a particular kind of, like, round of public interactions, public state changes, then we don't actually want to be doing threshold encryption for the entire transaction because the entire transaction already is shielded. Because we have this shielded base layer. All we actually need is the ability to encrypt individual contributions to the public state.
00:09:33.714 - 00:10:00.942, Speaker B: And so what we do instead is have threshold encryption that works just on integer amounts and has additive homophism. So you can have the chain aggregate all of the encryptions in some interval and then have the validators jointly decrypt that batch total and do some public on chain computation. So that's sort of how we're thinking.
00:10:00.996 - 00:10:08.430, Speaker A: About the information side on the actionable piece of MEB.
00:10:10.290 - 00:10:12.962, Speaker B: This is about sort of the mechanism design.
00:10:13.016 - 00:10:16.270, Speaker A: So how do we make a mechanism.
00:10:16.350 - 00:10:44.250, Speaker B: Design that minimizes the impact of a block? Proposer messing around with transactions? So again, we're focused on one very narrow use case, which is billing a Dex on the market taker side of that. We have sealed input batch swaps. So the idea is that some user wants to swap some amount, they have their private input amount.
00:10:44.400 - 00:10:50.650, Speaker A: They encrypt that using flow encryption to a threshold controlled by the validators.
00:10:51.070 - 00:11:24.694, Speaker B: And because this is going to be batched, they don't know what the output price is going to be, right? So you need to have some mechanism for doing late binding of the execution. To do that, they make a private swap NFT to themselves that commits to exactly what their private input was, what the trading pair was, what address they're going to claim funds to, and so on. What that means is that once the chain sort of gets this batch of swaps, whether that's in a block or.
00:11:24.732 - 00:11:28.914, Speaker A: A longer interval, they can aggregate decrypt.
00:11:28.962 - 00:11:56.562, Speaker B: Only the batch total and then execute all of the swaps with a common clearing price. And once that data has been posted to the chain, each user can consume their private swap NFT to privately mint their prorata share of the output. So that's kind of the market taker side.
00:11:56.562 - 00:12:12.662, Speaker B: But from that perspective, how you actually do that execution is sort of a black box on the market maker side. What is in that black box? We have a concentrated liquidity mechanism where effectively every position is its own little.
00:12:12.716 - 00:12:16.246, Speaker A: AMM, but it's an AMM of the.
00:12:16.268 - 00:12:29.162, Speaker B: Simplest possible form, which is just a line. And this means that the optimal routing problem is easy because it's basically like the closest thing to an order book.
00:12:29.216 - 00:12:30.300, Speaker A: That you could have.
00:12:31.010 - 00:13:14.938, Speaker B: So you can walk along this graph and because all of these positions are created out of this private base layer and returned back into it, any individual participant can privately approximate whatever trading function they want by creating various different liquidity positions. And although you have transparency of what the aggregate state of the market is, you don't know which positions correspond to which users to which accounts, because they can all be created through these distinct unlinkable transactions. So when you put these things together, the mechanism design basically is a frequent batch swap system.
00:13:14.938 - 00:13:26.666, Speaker B: So there's multiple phases at the end of each block. First you open all of the positions that someone has requested to open in some transaction in the block.
00:13:26.778 - 00:13:32.590, Speaker A: Then you execute all the swaps, ARB all of the positions.
00:13:34.450 - 00:13:54.162, Speaker B: Into having consistent prices with each other and then close out all of the positions that were requested to be closed. This is pretty cool because you're only doing this execution once a block. You can afford to be considerably more computationally sophisticated because you're amortizing that execution.
00:13:54.226 - 00:13:57.406, Speaker A: Cost over every transaction in the block.
00:13:57.538 - 00:14:20.400, Speaker B: So you can do routing on the whole liquidity graph. And because you have all of your liquidity and all these different little concentrated liquidity positions, you can have liquidity be sort of like active, passive, or anywhere in between. Like if you want to simulate, say, like a univ two pool, you can just do that.
00:14:22.290 - 00:14:26.754, Speaker A: But all of that liquidity is kind of on a common footing and the.
00:14:26.792 - 00:14:47.094, Speaker B: Chain is capturing all of the internal arbitrage of is this price consistent with this other price? So when you put these things together, kind of the implications are the batching means that there's no ordering effectively of transactions within a block, right?
00:14:47.132 - 00:14:49.098, Speaker A: So if you actually look at the.
00:14:49.104 - 00:15:22.770, Speaker B: Data structure, sure there's like a list of transactions, but the actual execution is happening in a batch and so the ordering of transactions has no economic value, so there's no real sequencer. The proposer is only choosing whether or not to include or exclude transactions. And because of the way that the mechanism is designed, their decision of whether or not to include a transaction or not only has a marginal effect on the outcome because there isn't ordering.
00:15:22.770 - 00:15:35.442, Speaker B: In order for a block proposer to prevent anyone from doing arbitrage on a specific trading pair, they'd have to censor.
00:15:35.586 - 00:15:39.562, Speaker A: Many more transactions and sort of only.
00:15:39.616 - 00:15:46.806, Speaker B: Have theirs be present. They can't just sort of play games with like individual transactions.
00:15:46.918 - 00:15:50.402, Speaker A: And even if you try to censor.
00:15:50.486 - 00:15:54.670, Speaker B: One specific trading pair because you're doing this kind of graph routing.
00:15:57.570 - 00:15:58.666, Speaker A: The proposer's.
00:15:58.698 - 00:16:19.990, Speaker B: Ability to block people from doing ARB is limited by the way that the ARB will sort of flow through the liquidity graph. It also means that the dex is going to step between discrete sets of consistent prices. When I say consistent, I mean internally consistent.
00:16:21.050 - 00:16:23.846, Speaker A: But that means that you don't have.
00:16:23.868 - 00:16:36.330, Speaker B: To have a bunch of seekers who are competing to race in some kind of mechanical arbitrage. You just do the mechanical arbitrage.
00:16:38.030 - 00:16:38.630, Speaker A: Relative.
00:16:38.710 - 00:17:03.938, Speaker B: To automatically as part of the protocol and the external ARB against reference markets ends up being shared prorata among seekers. So there's a kind of interesting paper on this by the Banecap Crypto research.
00:17:04.024 - 00:17:07.302, Speaker A: Team that I have like a small.
00:17:07.356 - 00:17:14.360, Speaker B: Part in helping with, but it turns out that the game theory of this type of game is that.
00:17:17.050 - 00:17:17.906, Speaker A: The seekers.
00:17:17.938 - 00:17:33.614, Speaker B: Just like share prorata ARB against external reference markets. So I think there's a bunch of interesting pieces here. It's obviously a very application and use.
00:17:33.652 - 00:17:37.758, Speaker A: Case specific for the moment, but I.
00:17:37.764 - 00:17:59.640, Speaker B: Think there's some interesting design pieces or lessons that might be useful for either other application specific solutions or for building general purpose applications. And I think some of the pieces that we built in the longer term will end up.
00:18:01.610 - 00:18:03.174, Speaker A: Being useful for more.
00:18:03.212 - 00:18:10.102, Speaker B: General kind of contract interactions. Here's a bunch of links if you want to find out more and otherwise.
00:18:10.166 - 00:18:13.660, Speaker A: Happy to just answer any questions that people have.
00:18:18.170 - 00:18:34.246, Speaker C: Thank you Henry. I guess one question I have is on the previous slide around the internal arbitrage profits being captured by the protocol, is there a reason to not give them back to the users?
00:18:34.278 - 00:18:39.120, Speaker B: I guess well, I guess when I say capture I don't necessarily mean.
00:18:41.330 - 00:18:41.646, Speaker A: And.
00:18:41.668 - 00:19:10.614, Speaker B: This actually goes back to points that was made like a while ago in the chat, during a previous talk. I think it was, yeah, it was Phil saying there's no free lunch, it's coming from somewhere. And what I would say is yes, that's true, but if you capture it as part of the protocol, then the protocol can decide how to distribute that.
00:19:10.732 - 00:19:11.400, Speaker A: Right?
00:19:12.430 - 00:19:51.190, Speaker B: So one option which is I think like the simplest is to just do ARB burn mechanism, but you could also try to direct it in various ways if you could try to rebate to users who swapped or to LPs. Actually doing that I think is kind of tricky because once you're redistributing that value, now you need a way to you have to convince yourself that that mechanism itself is not going to be gamed.
00:19:52.730 - 00:19:54.886, Speaker A: But yeah, when I say capture, I.
00:19:54.908 - 00:20:06.202, Speaker B: Don'T necessarily mean sort of like permanently held, but just captured and then like okay, now to do what with?
00:20:06.256 - 00:20:07.660, Speaker A: Well, we'll figure it out.
00:20:12.580 - 00:20:20.390, Speaker C: Okay, so just to make sure I understand, is there some sort of global convex optimization going on?
00:20:21.160 - 00:20:24.710, Speaker B: Because that yes, but for.
00:20:27.880 - 00:20:28.692, Speaker A: A very.
00:20:28.826 - 00:20:38.904, Speaker B: Specific special case of the problem. So the liquidity positions are made to.
00:20:38.942 - 00:20:42.284, Speaker A: Have the simplest possible form so that.
00:20:42.322 - 00:20:46.590, Speaker B: The convex optimization problem is easy.
00:20:48.640 - 00:20:49.820, Speaker A: Or easier.
00:20:52.160 - 00:21:12.310, Speaker B: There's actually a bunch of interesting questions there that come from the fact that you're doing that routing in a batch. One thing that is more difficult about that is that you lose the ability to have precise accounting for resource use.
00:21:12.680 - 00:21:18.564, Speaker A: Right? Like if somebody makes a bunch of.
00:21:18.682 - 00:21:30.360, Speaker B: Sort of dust trading positions, how do you avoid that blowing up the complexity of the routing algorithm?
00:21:31.920 - 00:21:46.752, Speaker A: Because you don't really have a way to impute that cost to a specific use. So the approach you have to take essentially is just like get good and.
00:21:46.886 - 00:21:50.256, Speaker B: Make it fast and have heuristics that.
00:21:50.438 - 00:21:54.320, Speaker A: Bound the size of the optimization problem.
00:21:54.390 - 00:21:58.100, Speaker B: Even if you don't necessarily get a perfectly optimal solution.
00:22:01.070 - 00:22:07.174, Speaker C: I think we're out of time. There is one more question in the chat for Andrews maybe to be answered.
00:22:07.222 - 00:22:14.880, Speaker B: Yeah, long range leakage attacks. Yeah, it's a problem. There's not really a great solution to that.
00:22:14.880 - 00:22:17.920, Speaker B: On the other hand.
00:22:20.210 - 00:22:20.926, Speaker A: If you look.
00:22:20.948 - 00:22:26.942, Speaker B: At sort of what role does the threshold encryption play in penumbra relative to.
00:22:26.996 - 00:22:27.600, Speaker A: In.
00:22:29.890 - 00:22:51.960, Speaker B: Some other protocol? Even in the situation where you have no flow encryption at all? Well, exactly how much information are you leaking? Well, you're leaking just the amount that someone contributed to a batch and.
00:22:54.650 - 00:22:57.540, Speaker A: There'S no possibility to leak the account.
