00:00:09.130 - 00:00:29.320, Speaker A: We're going to talk. I think the next segment of talks are all about batching in different shapes and forms. And this talk is going to be about sort of like the sort of theoretical limits of what you can get with batching and sort of like what privacy looks like in AMMS, whether it can exist or not.
00:00:29.320 - 00:00:47.980, Speaker A: This joint work with shithage who isn't here, alex and Guillermo, who are both here somewhere. Audience cool. So most people here probably already know a lot about DEXes that they've used or sandwiched people on, whatever.
00:00:47.980 - 00:01:11.620, Speaker A: So maybe we'll start with a little history of the automated mark maker. Actually goes back to 1971 with this scoring rule from Savage, and it was popularized by Robin Hansen 2002 with the logarithmic market scoring rule. But the idea is that people are able to pool their assets into a contract, say two assets, A and B.
00:01:11.620 - 00:01:23.590, Speaker A: Those are reserves. And the arbitragers trade between kind of this pool and external markets. The price is too low relative to an external market.
00:01:23.590 - 00:01:44.510, Speaker A: Someone will buy and sell externally, vice versa. Buy low, sell high, nothing special. And one question you might have is, hey, is there an invariant? Is there some sort of function of the reserves asked to be held constant, which is what we're going to talk about.
00:01:44.510 - 00:02:02.130, Speaker A: But the two simplest versions are one that's a fixed asset price at all amounts. So I will always sell you five Guillermo coins for $1. And then the other is sort of which most people are familiar with is uniswap.
00:02:02.130 - 00:02:27.802, Speaker A: But we should actually think a little bit more generally mathematically about what the sort of space of these mark makers looks like. And to do that, we'll basically formalize this somewhat. I see Guillermo's face for my one typo on this slide, but a constant function.
00:02:27.802 - 00:02:42.990, Speaker A: Market maker is a contract that has N coins. Each of them has a reserve. Ri liquidity providers supply these reserves and traders can add and remove the coins, provided they keep sort of this invariant constant, really greater than or equal to a constant.
00:02:42.990 - 00:03:04.178, Speaker A: The super level set of this function is called trading set and it turns out to have some nice properties. And the simplest version of this invariant is the constant product, which is unison. So let's actually think about this geometrically because I think it makes it a lot clearer.
00:03:04.178 - 00:03:10.860, Speaker A: The trading set is the thing shaded in blue. The dark blue is the boundary. This is this x y equals K.
00:03:10.860 - 00:03:31.630, Speaker A: All the points on the boundary are sort of the sort of feasible points. Those are the trades you can do that sort of keep you at no arbitrage, but you could trade inside, but then basically you would be giving away free money to someone. And so in this case, we have the set.
00:03:31.630 - 00:03:51.142, Speaker A: It turns out that there's a lot of sort of mathematical properties about it, namely convexity of it, that's quite important. And you might say, well, why do I need convexity? Well, suppose we have a non convex trading set like this. Draw a supporting hyperplane that intersects two points.
00:03:51.142 - 00:03:58.810, Speaker A: You get basically the same price for two different reserves. So you might as well fill it in. It might as well be flat across that region.
00:03:58.810 - 00:04:23.630, Speaker A: Okay, that's the high level, kind of like 101 into constant function market makers. Now we're going to talk a little bit more about how different constant function market makers have sort of a notion of price impact. So when you go into a uniswap pool that has no liquidity, you look at the price you're quoted, you're oftentimes unhappy.
00:04:23.630 - 00:04:45.106, Speaker A: You go to one that has a lot more, you're oftentimes happy. But one question is, how do we generalize that notion to other types of market makers? Say curve, balancer, any functional form that satisfies this sort of convexity property. So kind of a natural thing you might think of from calculus is curvature.
00:04:45.106 - 00:04:58.474, Speaker A: Curvature is usually represented by, like second derivatives of functions. A little bit different here because there's an implicit function from the constraint. But what we do is we actually can define something that's called a price impact function.
00:04:58.474 - 00:05:22.340, Speaker A: Price impact function tells you, if I make a trade of size delta, how much does that change? Sort of the function in asset one versus asset two, that ratio, that slope is the price. So if we go back here, the slope of this line is the price at the point, the slope of the tangent line. And so this is a way of sort of generalizing that.
00:05:22.340 - 00:05:47.962, Speaker A: And we define two constants that are important to think about called mu and kappa, which are sort of upper bounds on how much that slope changes. And that's sort of this notion of price impact that you see. So let's look at it in pictures, because I think it's sort of I've certainly forgot the statement of the implicit function theorem because I don't know, I learned it 15 years ago.
00:05:47.962 - 00:06:04.242, Speaker A: But it's not that interesting to kind of understand where that ratio comes from as much as it is to see what it looks like in pictures. So suppose we have two AMM curves. We have uniswap in blue in the upper left.
00:06:04.242 - 00:06:20.850, Speaker A: We have balancer in green underneath. And suppose they're basically at different prices. So the dashed line, the dashed blue line, is the price that uniswap is quoting the slope of that, and the dashed green line is the price that balancer is quoting.
00:06:20.850 - 00:06:27.414, Speaker A: And so now there's an arbitrage. There are two different slopes. So an arbitrager goes in, makes the money.
00:06:27.414 - 00:06:51.040, Speaker A: And what happens afterwards? Well, we see that the two slopes are equal, but more importantly, we see that the green line, the slope changed more. And that's sort of this notion of curvature, the more it changes when you kind of have to do these types of arbitrage. And similarly with curve, we see something flatter than uniswap, right? We basically have the same sort of thing.
00:06:51.040 - 00:07:29.686, Speaker A: And so this sort of gives you an idea of what this notion of curvature is. It really captures slippage and price impact in a more mathematically formal way than, hey, I'm just going to keep plugging in terms into the invariant and looking on the UI if I'm causing a lot of slippage. So one question that's actually kind of dogged people since the invention of constant function market makers is, can you ever make them private? And they have this sort of inherent problem that you can't really hide your trades in these systems.
00:07:29.686 - 00:07:49.794, Speaker A: I mean, that's sort of the reason that you can sandwich people. So certainly in the 2017 boom, there were tons of ICOs that raised money on the premise of, hey, we're just going to add ZK proofs to A decks and boom, it's going to work. And no one's going to know your trades, no one's going to front run you.
00:07:49.794 - 00:08:26.362, Speaker A: Unfortunately, it turns out a short note we wrote, you can prove that for all constant function mark makers, you can basically never preserve privacy because you can always invert the trade sizes if you know the liquidity at one point in time and the price changes. And the idea very intuitively is that while this is a convex set and I'm looking at how the convex set is changing under each iteration, well, it's naturally going to have sort of a minimum point or a supporting point. And you can sort of invert kind of the prices invert the trade sizes.
00:08:26.362 - 00:08:46.358, Speaker A: So that's bad. That means that everyone can kind of even if you try to use some ZK proof to be like, I'm going to hide the reserves. The fact that you're quoting prices publicly, like, people have to see the price in order for them to decide to trade means that they can figure out from the price changes exactly your trade size, and then they can do all sorts of other things with that.
00:08:46.358 - 00:08:58.280, Speaker A: So there's only really two options to avoid this. Number one is batching. So that's the next series of talks, I think that this is batching hour, not bitching hour.
00:08:58.280 - 00:09:17.082, Speaker A: And randomizing. So randomizing is adding noise to the prices so that people, when they invert it, they don't invert the correct trade size, they invert something that's wrong. Blockchains are great for the latter, of course, because we have verifiable randomness, we have provable randomness.
00:09:17.082 - 00:09:35.874, Speaker A: I can't fuck with the randomness. But the problem is how you randomize the prices actually can affect your privacy quite dramatically. So suppose for simplicity, I say, okay, I'm just going to draw some, IID, random variables CI to each person's price.
00:09:35.874 - 00:09:52.860, Speaker A: I'm going to add that noise in the quoted price. Well, this is bad. The central limit theorem says, like, actually, either you're adding a huge amount of variance from these CIS, or basically you can filter and figure out what the real prices were.
00:09:52.860 - 00:10:06.042, Speaker A: So now it's time to talk about adversaries. And given that this was done in beamer and latex, I didn't have very good emojis. So this is my emoji for adversary.
00:10:06.042 - 00:10:24.654, Speaker A: I don't even know what it is. It's like a vampire and the joker had a baby. So basically there's this concept and this is a concept that's actually quite common in the machine learning and privacy literature of privacy utility tradeoffs.
00:10:24.654 - 00:10:56.798, Speaker A: So I can start hiding your data, I can start kind of like obfuscating the data but I also make the machine learning algorithm worse. Like the moment I start adding noise, your Netflix recommendations start getting worse, right? And there's this inherent trade off between how much I am able to hide your data and preserve it from an adversary trying to invert it versus how much am I reducing your utility, what you're actually getting out of the algorithm. And you could view an automated market maker as a similar type of thing.
00:10:56.798 - 00:11:18.194, Speaker A: It's an algorithm that gives you a price impact as a function of something and if I'm adding some type of noise that's maybe increasing your privacy, I'm also inherently giving you a worse price. And so there's a natural way to measure this privacy versus utility trade off is price impact versus privacy. Price impact.
00:11:18.194 - 00:12:00.770, Speaker A: How much more money do I have to pay to get privacy? And then privacy is what is the number of bits sort of how much precision can an adversary estimate my trade size with? So batching great for privacy, bad for price impact in the worst case. So the worst case for batching is I have let's say a trade vector where there's T trades and one trade is of size T and T minus one trades are of size one. Well, in the kind of earlier thing I talked about, if the curvature is sort of lower bounded, well, you actually now cause omega of T, so lower bounded by T price impact.
00:12:00.770 - 00:12:21.082, Speaker A: Which means that the trades that are of size one, they got screwed by the big whale trade, right? They basically have to pay. They're basically subsidizing that trade in some sense. So these constant function market makers, bad for privacy but very good for price impact in that you can kind of understand what's happening.
00:12:21.082 - 00:13:03.750, Speaker A: So how do we parameterize something in the middle so that the user can kind of choose what they want? So the model of the adversary, adversary just has a couple sort of simple state has reserves, it knows what the liquidity of the market maker is, it has a marginal price calculation, it can compute the current price and it can take a trade and compute is valid is this trade in the trading set. And we don't assume they know any identifying information which could be hidden by zero knowledge proof. So one way of thinking about privacy is from the perspective of the user who's losing their privacy and getting sandwiched.
00:13:03.750 - 00:13:25.534, Speaker A: Another way of thinking about privacy is from the perspective of the adversary. How efficiently can the adversary learn the trade size given the data? How fast can they invert it? And so in statistical learning theory, you may have learned of things like VC dimension or sort of notions of complexity. So this is sort of related to that.
00:13:25.534 - 00:13:41.730, Speaker A: So you have an adversary, they want to front run the whale trade. So you have a bunch of trades of size one, this huge trade of size t you could think of an adaptive adversary. And so in like layer one security proofs, you also see these notions of adaptive adversaries.
00:13:41.730 - 00:14:12.170, Speaker A: Your adaptive adversary wants to learn a bunch of boolean functions where if the whales trade is the ith trade, then it says true, and if it isn't, says false. And if it turns out the adversary can find any advantage, they can basically do a tiny bit better than a coin flip. There's sort of classical statistical bounds that say the adversary can start imputing the actual true trade size with very high probability.
00:14:12.170 - 00:14:42.994, Speaker A: So in some sense, how much noise you add controls how well the adversary can invert, can construct a learning algorithm that can learn your trades. So probably one of what I consider the top theoretical computer science results of the last five years is something that shows that online learnability. So, like whether you can learn something, you get a sequence of data and you're trying to learn some property of it, that online learning is equivalent to something called differential privacy.
00:14:42.994 - 00:15:06.622, Speaker A: And differential privacy is the notion of privacy that if you have an Apple phone, for instance, that's what Face ID uses. So Apple doesn't get your local data for your face because they add some noise to it so they can't recover it perfectly. And so the cool thing is that basically people showed from a complexity standpoint algorithms that can online learn.
00:15:06.622 - 00:15:24.020, Speaker A: So I give you a sequence of things and I learn some property of them. Just like learning, these trade sizes are the same as these differentially private ones. And so this suggests that if we want to try to analyze how well an adversary can do, we should actually try to look at what differential privacy guarantees we can get.
00:15:24.020 - 00:16:08.046, Speaker A: So what is differential privacy? So differential privacy is effectively, if there's someone who gets a data set and I randomly remove one element of the data set, they basically don't have a very high probability of being able to tell whether that person was added or removed. So let's say we took everyone in this room's height, we made a data set, and someone rolls a dice and we randomly pick one person's height out. If I compute the average height and that one person is like nine foot tall or is Will Price, basically you can tell, right? The average may have moved by like five inches.
00:16:08.046 - 00:16:25.320, Speaker A: So what you have to do is you have to add some noise so that someone can actually tell to that precision. Formally, this definition not that important, kind of boring, but it's sort of a bound on the KL divergence with some additive correction. All right.
00:16:25.320 - 00:16:50.030, Speaker A: So absolutely no proofs. Just only going to explain the high level result, which is if you have a constant function market maker, you can achieve differential privacy by basically splitting up trades randomly permuting the order of the trades and then chopping up whale trades. That's what these three things and adding some noise to the trade quantities.
00:16:50.030 - 00:17:16.470, Speaker A: And the way you reason about this and the way you should reason about mev often is you have to construct combinatorial objects that sort of represent the dependencies between different transactions. And it turns out for trades, you happen to get a very simple dependency graph. It's this thing that we call the trade tree and it's made of the partial sums of permuting the trades.
00:17:16.470 - 00:17:48.530, Speaker A: And so here's what it looks like in pictures if it's balanced. And the main thing to know about this is that if you remember from sort of if you've taken an algorithms class, you'll learn that Quicksort has this expected log n runtime. Well, that's because you construct this sort of heap of your kind of sorting algorithm and that heap on average has login height, which basically is how you get the complexity.
00:17:48.530 - 00:18:16.406, Speaker A: It turns out this kind of expected runtime thing is also extremely highly concentrated. So Quicksort actually works a lot better than you might think because there are very few bad instances and the bad instances shrink really fast as the number of samples goes to infinity. So, long story short, we basically construct this tree.
00:18:16.406 - 00:18:50.360, Speaker A: We're able to bound this and then basically use a bunch of things where we add noise, split trades and show that you can get differential privacy. So what this says is in this most general adversarial model, where you want to sort of thwart mev or Sandwiching, you force the user to pay this cost. Either they pay this price impact to get this privacy or they kind of basically either they get perfect utility or they get perfect privacy and this sort of interleaves between the two.
00:18:50.360 - 00:19:13.922, Speaker A: So what does this really say kind of in the long run about mev? This is more technical stuff. Well, we should actually be thinking a little bit about what strategic behavior in automated market makers look like. These sort of differential privacy bounds are sort of they assume the arbitrary adversaries and that's why they have sort of like not so great price impact.
00:19:13.922 - 00:19:24.980, Speaker A: You have to pay a lot of money for privacy. And at some level, if your utility is how much you're paying, there's just some natural trade off at which you're like, I don't care, sandwich me. Right.
00:19:24.980 - 00:19:54.460, Speaker A: So what happens, on the other hand, if agents are strategic, they choose their slip ledge limits based on what they think everyone else is choosing their slip ledge limits at and they choose their slip legitimate limits based on their estimates of searcher behavior. And searchers similarly are strategic and they try to choose their behavior in response to what they think other searchers best behavior is. As we saw in some of the panels earlier, that is actually true.
00:19:54.460 - 00:20:28.930, Speaker A: And you may say, okay, what's sort of the stable state? What are the equilibria that come out of these kinds of economic systems, at least with automated market makers where we can study them? And there's sort of this concept in algorithmic game theory called the price of anarchy. And the price of anarchy measures sort of let's say I have a social equilibria that's sort of the best outcome for everyone in an economy. And I have an equilibria where everyone acts selfishly and just tries to optimize their own profit.
00:20:28.930 - 00:21:02.750, Speaker A: The price of anarchy is just a ratio of those two. How much worse is the economy when everyone is selfish versus trying to find the minimum, which requires coordinating or cooperating? And it turns out you can sort of write out what that looks like for these AMMS and basically show in some scenarios it's actually not that much worse with sandwichers than without them. So, end of the day, we all know constant function mark makers are powerful, right? There's billions of dollars traded on them every day.
00:21:02.750 - 00:21:19.316, Speaker A: We also know there's billions of dollars of lifetime extractable value from them. But in some ways, we can kind of mitigate this by providing users something in the middle. And there's also sort of this natural question of how stable these equilibrium are.
00:21:19.316 - 00:21:41.930, Speaker A: And effectively, I think we're at the point where we can actually study those and have data for it. And I'm done five minutes. I guess we have five minutes for for questions.
00:21:41.930 - 00:21:55.680, Speaker A: Any questions? None? Fine. Also, you say you had three points. Three way to fix the privacy house.
00:21:55.680 - 00:22:17.956, Speaker A: Yeah. So the first thing is randomly permuting orders. So if you look at the literature of what people call fair ordering solutions in blockchains, a lot of them end up basically trying to do this where they randomly permute the set of orders in a block so that you can't really predict where a certain transaction will be.
00:22:17.956 - 00:22:30.372, Speaker A: And so if you try to sandwich it or submit a bundle, you can't do it. Of course, fair ordering requires a lot more extra work and so it's harder. But in the AMM case, it's actually a little bit easier.
00:22:30.372 - 00:22:50.848, Speaker A: You can just randomly permute the trades within a contract. A lot of proof of stake networks have randomness as a first class citizen in contracts, and so it actually ends up being relatively easy. The second thing, remember how I had this example of we have a whale trading size T and then people trading sizes one, like T minus one people.
00:22:50.848 - 00:23:05.584, Speaker A: So one of the reasons the random permutation doesn't work there is there's T factorial permutations. But if I apply all the permutation, I look at sort of the Orbit set of applying every permutation to that thing. I only have t elements.
00:23:05.584 - 00:23:13.144, Speaker A: I've lost a lot of entropy. I went from N log N bits of entropy to log or log T log T bits of entropy to log T bits of entropy. Right.
00:23:13.144 - 00:23:25.980, Speaker A: And so that makes it much easier to invert. So you need to add some noise to recover that sort of amount of entropy in the Orbit sets. And so that comes from splitting up the big trades and adding noise.
00:23:25.980 - 00:23:47.624, Speaker A: And the math around that is like, there's some concentration inequalities on sort of randomly permuted sums. Cool. Thanks for your talk.
00:23:47.624 - 00:24:05.936, Speaker A: Taurims, how fast have you seen the Price of Anarchy change? It's a good question. So we've only written up how to calculate it. Basically, what you can show is it's lower bounded by a constant, which means let's say the constant was one third.
00:24:05.936 - 00:24:19.780, Speaker A: Just for Harris. For example. That means that the market with searchers and selfish behavior is 33% as efficient as if the market was trying to find the total optimum optimizing everyone's utility.
00:24:19.780 - 00:24:32.330, Speaker A: So, effectively, most of the results, theoretically are all lower bounds, but you can use those to calculate what the true observed thing is in production, and that's, like, future work.
00:24:38.570 - 00:24:46.502, Speaker B: Thanks. Dr. Turin, I had a question regarding specifically ordering for dex chains with private mempools.
00:24:46.502 - 00:25:08.014, Speaker B: So when you talk about the size of how large these systems can get, I'm assuming that for most public blockchains, you have essentially an infinite size for the amount of liquidity that you're anticipating. Is there an upper bound on the privacy that can be enabled via private mempools on these dex chains? That is not comparable to what we see on Ethereum or other chains.
00:25:08.062 - 00:25:36.300, Speaker A: Relative to that, I don't think it's strictly just the private mempool piece. I think it's also just like, how do you guarantee that the ordering is also sort of executed randomly? And if we look, say, at Flashbot's auction right now, right. It's a sort of greedy combinatorial auction and greedy auctions, for instance, you can measure the price of anarchy of those, and those also are quite low.
00:25:36.300 - 00:26:02.126, Speaker A: So we're not even close to efficient in how we order bundles or choose these kind of ordering constraints. And I think the private mempool piece doesn't provide you that much privacy if people are, like, depending on the number of people who have access to it relative to the total number of users. I do agree that there's probably some benefit, but it's not, at least theoretically.
00:26:02.126 - 00:26:18.340, Speaker A: I don't think you could really say much mathematically about it. Cool. Thanks, Clipping.
