00:00:00.570 - 00:00:54.458, Speaker A: So this is going to be the last lecture which really focuses on quantifying the inefficiency of Equilibria per se. And the point of today's lecture is to change basically two things in the games that we've been looking at so far, the first thing that's going to change is we're going to switch from a domain domains with negative externalities to domains with positive externalities. So externality that just means in general that's sort of the aspect of the social cost or social benefit which an individual is not taking into account. When individual makes its own decisions according to its own objective function, there's usually some difference between that and what you care about globally and the externality in effect is that difference. So in the examples we've looked at so far, like routing games, the externalities are negative. So when you drive on a road you don't take into account the fact that you make everyone else's lives worse. In the location games, when you colocate near somebody, you don't really care about the fact that you take some of their profit away.
00:00:54.458 - 00:01:32.330, Speaker A: So from the player's perspective, sort of players near you were a bad thing routing and location games. But if you think about it, there's other application domains where there are positive externalities. So if you join something like a campus organization or a social network or whatever, hopefully not only do you get benefit but you enrich other people's experience by being there. So again, that's something you're not really directly accounting for yourself but in this case it's a good thing for everybody else. So I want to talk about a model. It's again going to be a network model which explicitly has positive externalities and we'll see what changes and then the main thing that's going to change, at least in this particular model, is there'll be multiple Equilibria. Okay, we're used to that.
00:01:32.330 - 00:02:27.798, Speaker A: We've seen examples with multiple Equilibria but here actually some of them will be wildly better than others and so it's going to motivate wanting to select down and discuss only subsets of the equilibrium, which is something we haven't done so far. We've always looked at worst case Equilibria, so we'll talk about a couple of ways that you could look at particular subsets of Equilibria. Okay, so those are the main takeaway points for the day. So the model I want to illustrate these points with is called the network cost sharing games. So we're still going to have a graph, could be undirected or directed. The description of the model is the same either way, although technically it seems to behave differently depending on whether it's an undirected network or not. Now instead of a cost function like we've been having in the routing games, we're just going to have a fixed cost on an edge.
00:02:27.798 - 00:03:28.720, Speaker A: So basically for an edge of this network to be built or to be formed, there is some fixed cost which gets incurred by everybody. So you might think about building a trench, digging a trench, you might think about installing some really fast internet to a neighborhood. There's some fixed cost from which many people benefit. So call it gamma e. For this fixed cost player's objectives are the same as in the routing games. Each player we're going to assume, has a source and a destination and they're going to want to pick the path that has the smallest cost for that player. So we're going to say player I needs to connect a source vertex si and a sync ti by a sum path pi and g.
00:03:28.720 - 00:04:12.014, Speaker A: And then given these choices of paths some subset of this graph gets formed. So namely the edges that are chosen by at least one person. So network union over I of the paths gets formed. So this is one type of what's called a network formation game and that's a whole area in its own right. So for example Professor Matt Jackson often teaches a course on that over in the econ department. A lot of the models, including this one are pretty ad hoc. It's actually a really hard topic trying to get sort of good game theoretic models of how networks form.
00:04:12.014 - 00:05:07.918, Speaker A: But this is going to be the one that we discuss today. Now what are the payoffs? So the assumption is so you pick a path that comprises all of these edges and just like in routing games, a given edge might also be picked by other people, they might be in other people's paths. There's some fixed cost gamma e that has to be paid jointly by everybody. So we're just going to do the simplest model and assume it's split equally amongst all of the users. So cost gamma e of an edge that's in at least one path split equally among users. And so hopefully now you see what I mean when talking about positive externalities, right? If there's some edge and it costs ten and you're the only one on it, you have to pay the full ten. If you're one of two people then you only have to pay five.
00:05:07.918 - 00:05:59.386, Speaker A: If you're one of five people you only have to pay two. So here you really want to be joined by your comrades. All right? And then as usual players pick paths to minimize their cost. And again the cost as in routing games is just the sum over the amount that you pay on each of the various edges. So hypothetically, if we had full control over the system, what would we want? Well, argue we'd want everybody to get connected and we want the overall cost to be as small as possible. Okay, so minimize the total cost of the formed networking. So that's the formal description.
00:05:59.386 - 00:06:38.890, Speaker A: Let's develop our intuition for the model with some examples. So one thing that can happen in these gains with positive externalities is you can have miss coordination problems. So here's an example. I call this the VHS or beta example, which gets more obscure with each passing year. This was even kind of like when I was a kid. So basically before DVDs, if you can imagine that civilization actually existed, then before DVDs, they were basically just starting to be able to rent movies. This is like mid 80s, early eighty s.
00:06:38.890 - 00:07:19.670, Speaker A: And there were two technologies there's, VHS and Betamax. And at least all the nerds said that Betamax was better. That was sort of the consensus among the kind of gear heads. Yet VHS just sort of got a lead in the market share and it just kind of took over because you needed coordination. You wanted the liquor store down the corner, you wanted to have whatever, something compatible with the most convenient place to pick these things up. So VHS took over and dominated for a while till whenever it was early ninety s or something. So how would that play out in a network cost sharing game? Well, imagine that there's K players, so you can think of these two links as different technologies that could be chosen.
00:07:19.670 - 00:07:50.590, Speaker A: They're sort of accomplished the same task. They go from the same start node to the same end node, but they have different qualities. In particular, one is way more expensive for society than the other. So imagine all K players just want to connect s and T. And let's look at the pure equilibrium. Well, first let's look at optimal. So what's the optimal solution? No prizes.
00:07:50.590 - 00:08:19.290, Speaker A: What's the optimal solution? Um, we want to minimize, right? Yeah. So it's a cost minimization version. Yeah. If it was payoffs, we'd want the bottom, but we want to minimize cost. So we want the top. Okay, so all on top for a cost of one plus epsilon. Yeah.
00:08:19.290 - 00:08:48.786, Speaker A: What are our consequences here? What's epsilon? What's K? In the K is the number of players. Epsilon is any positive number. And as usual, I'm labeling the edges with their costs. Now here the costs. Remember these gammas? So these are the fixed costs of an edge. So if anybody uses an edge with some cost gamma e, then the collection of users split that cost equally. So when all K players are on the top edge, they're all paying basically one over K.
00:08:48.786 - 00:09:10.006, Speaker A: They each pay their fair share of that. And that's a Nash equilibrium. Right. A unilateral deviation would multiply your cost by like K squared. So it's not a good idea, but unfortunately, if everybody miscoordinates and we can get a second Nash equilibrium. So if all K players choose the bottom link, the fixed cost is K. It splits evenly among K players.
00:09:10.006 - 00:09:36.694, Speaker A: So each individual cost share is only one. And if you deviate unilaterally to the top, then you're solo. You're flying solo up there. You play cost one plus epsilon, which you don't want to do. So this is an extreme stylized example to make the point. But of course it's not hard to think about examples of this in real life where people could have coordinated on option A or option B, one of them is a little bit better, but people coordinate it on the one that's a little bit worse. I encourage you to think about real world examples of that.
00:09:36.694 - 00:10:03.786, Speaker A: So here's a very sort of stark illustration. So another pure strategy, Nash equilibrium. Everybody is on the bottom. And so that has cost K. So this is sort of a disaster. This is kind of the simplest kind of example you could think about. And so what we've just proven is that the price of anarchy with these network cost sharing games, remember, the price of anarchy is the worst of all of the Equilibria.
00:10:03.786 - 00:10:41.830, Speaker A: So this can grow as quickly as linear in the number of players, which is not so good. All right. It's also quite easy to prove that it can't be higher than the number of players. We'll put that on the next exercise set. Now, I don't know about you, but I look at this example and I get a little angry. I kind of feel like we were trying to model something very sensible. We have this nice Nash equilibrium concept and somehow and we have this nice price of anarchy concept, which has guided us well through many applications, and we don't get very interesting insight into this model.
00:10:41.830 - 00:11:45.326, Speaker A: And what's holding us back is this kind of stupid equilibrium that we probably don't believe anybody would really play if it was really such a stark difference between the two outcomes. Okay, so it's sort of back not back to the drawing board, but we got to take a step back as modelers and ask, well, if we still believe this is a model worth understanding, and we'd still like to somehow measure the inefficiency of equilibrium in some sense, how are we going to do it? The price of energy is not the right concept. It's too sensitive to pathological worst Nash Equilibria. All right, so issue how to focus only on the reasonable Nash Equilibria. Okay, yeah. Don't you just need like two people yeah, that is a good question. Or that is jumping ahead.
00:11:45.326 - 00:12:19.720, Speaker A: So that'll be the back half of the lecture. We'll talk about coalitional deviations. One thing to point out is if I made that a little bit smaller than K and two people switched, then so if I made that K over two, then two people switching wouldn't help. So it doesn't go away as soon as you allow sort of small deviations. But we'll talk about once you allow sort of arbitrarily large coalitions, what happens here. That'll be one of the two solutions that we talk about for addressing this point. I want to point out contrast with last week.
00:12:19.720 - 00:13:08.082, Speaker A: So last week when we talked about routing and location games, that was sort of a big success, right? Because we had the set of pure Nash equipment of the pure Nash Equas being so small they might not even exist. And there are all these bigger concepts we care about much more. And we were just spoiled, right? We could be arbitrarily greedy. It felt like last week we could just keep making the set bigger and bigger and bigger, and we kept getting these great constant bounds. So the story is a little different in this model and other models as well, which is already the set of pure Nash Equilibria is sort of too big to reason about inefficiency of equilibria. And we're trying to pick some subset. Okay? A so called refinement of the pure Nash equilibria that we're hoping has two properties.
00:13:08.082 - 00:13:58.790, Speaker A: Two properties that are actually pretty hard to satisfy simultaneously, as we'll see. So the first property being plausibility, meaning we can tell some convincing story about why those equilibria are more important than the others, number one. And two, that actually we can prove much better worst case bounds on this subset of Nash Equilibria than we can on all pure Nash Equilibria. Okay? So that would be the dream. We're not really going to fulfill that dream today, but I'll show you kind of the best we can do, the best we know how to do, right? Good. Okay. So to make sure we understand, um, sort of what we might hope to accomplish, let me show you example number two, which shows a sort of more robust form of inefficiency that can arise in these network cost sharing games.
00:13:58.790 - 00:14:50.300, Speaker A: Example number two. So that was the VHS or Beta example. This is the opting out example. So all the players are going to have the same destination now, but they're going to have different sources. Also, unlike the previous example, it's going to be crucial here that the graph is directed here. It doesn't really matter if it's undirected or directed here, it matters. So remember, with positive externality sharing is good.
00:14:50.300 - 00:15:37.320, Speaker A: So the players will have a way to rendezvous. In fact, they'll be able to rendezvous at a personal cost of zero and then share the remainder of the route to their common destination, T. Okay, where the joint cost of T is one plus epsilon. So if everybody took it, they'd each pay a little bit more than one over K. Now if this was the network, there'd be nothing to do because everybody only has one strategy. So let me give people an opt out strategy so they can be antisocial if they want and just go straight to T instead of sharing the ride with everybody else. You can tell your own story about cars and public transit if you want.
00:15:37.320 - 00:16:30.220, Speaker A: So what's the cost of opting out? Well, it's going to vary with the individual. So let's say it's cheap for SK to opt out costs one over K because they really like their car or they live close to work or whatever. One over K minus one for the player, k minus one and so on. So the cost is one third for the third player, one half for the second player, and one for the first player. So let's think about how players make decisions in this game. Actually first, let's start the same way we did before. Let's ask what the optimal solution is.
00:16:30.220 - 00:17:27.914, Speaker A: So from a societal perspective, what do you want people to do? Yeah, you want them all to rendezvous, right? Because then all you need to do is pay the one plus epsilon from V to T. So opt is one plus epsilon. So is that a Nash equilibrium? Why is it not a Nash equilibrium? Who wants to change? SK wants to change. So when everybody is sharing the VT link, everybody pays slightly more than one over K. In particular, player K is paying a little bit more than the cost of its opt out option. Actually, if you think about it, player K has a dominant strategy to go straight to T. Given that it's a dominant strategy for SK to go to T, that means that in any Nash equilibrium it has to be the case that player K is going directly to T.
00:17:27.914 - 00:18:15.702, Speaker A: That means in any Nash equilibrium there can only be at most K minus one. Players Rendezvousing and V to go to T. That means in any national equilibrium, each of the first K minus one players has to be paying at least one over K minus one. But player K minus one is unwilling to pay this slightly more than one over K minus one because it has an opt out option that's only one over K minus one. And so that's how the dominoes start falling. And of course inductively this unravels completely at the only Nash equilibrium by this process that we did, which is called the iterated removal of dominated strategies. The unique remaining outcome that could potentially be a Nash equilibrium is with all players taking their direct routes from their source to the sink.
00:18:15.702 - 00:19:10.560, Speaker A: And that is indeed a Nash equilibrium. So while the issue in the first example was multiple equilibria, that is not the issue here, okay? There is only one equilibrium in this example, okay? So the price of anarchy per se is not what's giving us problems here. It's really more fundamentally about equilibrium and efficiency. So unique pure strategy, nas equilibria, all players opt out. So the cost is the sum of everybody's opt out options. That's just the sum of I equal one to k of one over I. I'm going to use the notation script h sub k for this, the KTH harmonic number.
00:19:10.560 - 00:20:15.300, Speaker A: This is essentially the natural log of k plus a constant known as Euler's constant, which is less than one. Okay, so this is where things stand at the moment in these network cost sharing games. You can have inefficiency, you can have crazy inefficiency, linear inefficiency for intuitively stupid reasons, and you can have logarithmic inefficiency for what feel like more robust fundamental reasons. Yeah, that's right. Okay, so now let's so these are lower bounds, in effect, showing that equilibria can be bad in various senses. So let's switch to the upper bound side. Can we say anything positive about equilibria in network cost sharing games? And we can.
00:20:15.300 - 00:21:08.398, Speaker A: I'm going to offer you two results. So here's the first one. So this is an old theorem by Ancho Levich and many others. So here's the statement, and then we'll sort of talk about what the statement means it. So in every such game, doesn't matter what the network is, doesn't matter if it's undirected or directed, doesn't matter what the edge costs are. The claim is. So first of all there exists a pure strategy Nash equilibrium.
00:21:08.398 - 00:21:48.960, Speaker A: So that's already a nontrivial statement. Remember, we know models where there are no pure strategy Nash equilibrium. So first of all there always is at least one pure strategy Nash equilibrium, but also of those there is one whose cost is not too far from an optimal solution. So what do we know is not true? We know it's not true that every Nash equilibrium is at all close to an optimal solution. We know it can be offer a factor of k if we wanted a bound that held for every equilibrium. We also know that even for the best equilibrium, there's only one equilibrium in the opt out example. So the best possible approximation ratio we could write right here is h sub k, the lower bound provided by that example.
00:21:48.960 - 00:22:53.054, Speaker A: And that's what we're going to get. Okay? So in every network cost sharing game, first there exists at least one Nash equilibrium. Secondly, one of those equilibrium is a logarithmic factor away from the optimal cost. And we know that for a statement like this, this cannot be replaced with any smaller number. So there's a name for this, it's called the price of stability. And so what this theorem is asserting is that the price of stability in network cost sharing games is at most logarithmic. Now I said when you're trying to restrict yourself to a subset of pure Nash equilibria, what you want are two properties.
00:22:53.054 - 00:23:47.746, Speaker A: One property is that you get a significant benefit in terms of the worst case upper bound that you can prove. And you do. So in contrast to this linear bound for arbitrary equilibria, we get a logarithmic bound for this best case, if you will, equilibrium probability two was there should be some convincing story, some narrative that makes it plausible that you care about these equilibria and not others. And frankly that story is a little weak with respect to the price of stability when you have multiple equilibria. Some might be good, some might be bad. And this doesn't really provide an explanation about why this is the one that players will play as opposed to some other one. That said, there are situations where the best equilibrium makes sense, particularly places where as a designer you get some opportunity to suggest sort of a norm, sort of the initial play of the game.
00:23:47.746 - 00:24:36.260, Speaker A: We touched on this topic when we talked about correlated equilibria last week, this idea of a mediator with this known distribution where once this trusted third party has picked this distribution, it's stable, no one wants to switch. So similarly, maybe you're designing a piece of software and there are some parameters that can be free to set by the user. Like for example, how aggressively you decrease your rate once you have network congestion in a network. And you can envision initial default settings of those parameters that you ship the product with as perhaps an equilibrium that you're wanting to initialize people in. And so then if you're in a position to kind of set the default parameters in some situation, then it makes sense to focus on the best of all of the equilibrium. So you want it to be stable subject to that. You want it to be as good as possible in some sense.
00:24:36.260 - 00:25:14.426, Speaker A: So those are some of the reasons why people think about the price stability. But again, I don't want to oversell it. It is a much weaker guarantee than the price of anarchy. Okay, so for the proof, let me jog your memory about Rosenthal's potential function, which is a key tool in both of the two proofs we're going to do today. The first time you saw Rosenthal's potential function was last week. A week ago. The context then was we were talking about atomic selfish routing games.
00:25:14.426 - 00:25:59.870, Speaker A: And we said, well, we're proving these bounds about the price of anarchy, about pure natural equilibria at that point. And we wanted to know, are these vacuous bounds or not? Do equilibria exist? And I showed you a proof that in fact, pure equilibria do always exist in atomic selfish routing games. And the proof applies equally well to these network cost sharing games. So let me just remind you the potential function. So Rosenthal's potential function, so the definition, so it's defined on outcomes of the game. So last week, this corresponded to paths in a self routing network. Now this is just paths in one of these network cost sharing networks.
00:25:59.870 - 00:26:39.560, Speaker A: And how is this defined? You sum over the edges and on a given edge e, you look at how many people are choosing paths that are using it. So we were using the notation f sub e. And then what you do is you look at the cost function on that edge. I'll explain what this is in our context in a second. So in selfish routing, this was just the usual cost functions. And you evaluate the cost functions with one player, with two players, with three players, and so on up until the number of FCB of players that are actually using it in your outcome. So this is exactly what I wrote on the board exactly one week ago.
00:26:39.560 - 00:26:51.420, Speaker A: Now, I commented at the time that in the proof we used nothing about the cost functions whatsoever. The proof of the existence did not depend on the cost functions being nondecreasing. It could have been anything. Same proof would work.
