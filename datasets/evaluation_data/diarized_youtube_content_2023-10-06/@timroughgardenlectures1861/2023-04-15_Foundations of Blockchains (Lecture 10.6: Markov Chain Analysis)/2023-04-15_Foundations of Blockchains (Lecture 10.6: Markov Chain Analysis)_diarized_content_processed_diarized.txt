00:00:00.490 - 00:00:49.110, Speaker A: All right, let's proceed to the analysis of the strategy that we suggested on the last slide. As we discussed, it's not at all obvious if that strategy is a good idea for a node a to carry out. And in fact, as we'll see, it depends on exactly how much hash rate that node a has. And remember the reason for that is a sort of tricky tug of war between two competing forces and that deviation from just obediently following longest and consensus. On the one hand, there are cases where you orphan honestly produced blocks which is good for node a. It increases, it boosts the share of the longest chain blocks that belong to a. So that happens both in case three when successful and then also in case four when you drop down to that sort of gap of only one between the sort of secret chain and the publicly known chain.
00:00:49.110 - 00:01:40.170, Speaker A: On the other hand, there's also the cost of that strategy, which is sometimes, unlike in the past couple of videos, sometimes blocks produced by node a are themselves going to get orphaned. And specifically that happened in case three in the failure case of case three you might recall. So unlike the strategy that we saw when node a had the benefit of being able to control tiebreaking by honest nodes, unlike that case here, it's really not at all clear how the cost benefit analysis is going to resolve. Really the only kind of possible way forward to figure it out is to do some nontrivial analysis. And so let's go ahead and do that. We're going to be using an approach known as Markov chain analysis, or roughly the same as thinking about random walks in directed graphs.
00:01:47.720 - 00:01:49.108, Speaker B: And here when I say graph, I.
00:01:49.114 - 00:02:03.310, Speaker A: Mean it in the sense of combinatorics and graph theory. So think of like a network for example. And so a graph has two ingredients. It has a set of vertices and then it has a set of directed edges with each directed edge going from one of the vertices pointing to another.
00:02:04.880 - 00:02:06.348, Speaker B: So to specify a graph, you got.
00:02:06.354 - 00:02:44.724, Speaker A: To specify the vertices, you got to specify the edges. So Markov chains. Same thing. The vertices are going to be called the states of the Markov chain. And then in addition to edges, there's going to be sort of edges with weights and those are going to be known as transition probabilities. So the probability that you transition from one state of the Markov chain to another in one step, kind of very high level, it'll be a little more complicated like this, but not much. You could almost imagine a Markov chain with four states, one for each of the four cases that we saw in the strategy, and then the transition probabilities just tell you the likelihood of going from one case to another one with the creation of a single block.
00:02:44.724 - 00:03:04.944, Speaker A: We'll see it's a little bit more complicated than that. But not much. And I should say I'm not going to assume that you really have any prior familiarity with Markov chains. I'll assume that you've seen a graph before. I'll assume that you have at least some intuition about probabilities. Otherwise this will be basically self contained. If you've never looked at Markov chains before, they're super cool.
00:03:04.944 - 00:03:49.632, Speaker A: So I do recommend reading a bit about them. And the Wikipedia article is a fine place to start. So there's going to be one state for each non negative integer and you should interpret that non negative integer as tracking how big a lead in terms of the number of blocks how big a lead node A has in its secret chain relative to the publicly known chain. So for example, zero, no lead at all. That's going to correspond to case one. That's the case where node A has nothing better to do than to just try to extend the end of the publicly known longest chain state one. That's the lead of one.
00:03:49.632 - 00:04:18.584, Speaker A: So that's going to correspond to case two. So that's where the node A was in case one. But then it actually was the next one who succeeded in extending the longest chain. It did it before any honest node did it. And remember in the strategy in that case, node eight keeps that block secret. So that's basically a lead of one in its secret chain over the publicly known chain. Markov chain states 234-5678 and on up, those all correspond to case four.
00:04:18.584 - 00:05:00.452, Speaker A: So remember if you're in case two you've got this lead of one and then node A succeeds again and creates another block before any honest node creates a block. That gives it a lead of two over the public chain. That puts it in case four. And remember, you can actually stay in case four a long time. You stay in case four as long as node A has a lead of two or more over the public chain and the Markov state number just corresponds to exactly how big that lead is. So the Markov state chain I is just all cases where the length of the secret chain is I bigger than the length of the longest publicly known chain. There's also case three.
00:05:00.452 - 00:05:29.200, Speaker A: So we're going to introduce one more state which we're going to call state F for case three. The F here stands for fork. And so this case doesn't really fall into our other category because remember what happens. This is where node A did have a lead of one. So it was in case one successfully extended the longest chain, kept that block private, wound up in case two. But then it was unsuccessful in case two. So the honest nodes were the next ones to produce a block and at that point you have a fork in the blockchain.
00:05:29.200 - 00:05:49.972, Speaker A: So on the one hand it's sort of like there's a lead of zero because there's a tie between the maximum height of a secret block and the maximum height of a public block. On the other hand, it's definitely not the same as case one. We wouldn't want to lump this in to Markov chain state zero. So we're going to give it its own state, which again we're calling little.
00:05:50.026 - 00:05:50.630, Speaker B: F.
00:05:56.880 - 00:06:33.008, Speaker A: So that specifies the states of the Markov chain. So that's a good start. So that's like specifying the vertices of a directed graph. Obviously we still need to specify the edges, which in a Markov chain are called the transition. Probabilities all right, so what's the transition and transition probability? Well, that's moving from one Markov chain state to another. When does that happen for us? That happens whenever a new round of Nakamoto Consensus begins, whenever there's a newly created block that potentially leads to a change in state. So those are the transitions you go from one state to another upon sort of the creation of a new block.
00:06:33.008 - 00:07:19.050, Speaker A: But at any given moment, it's random what happens next, right? So maybe A creates the next block that's probability alpha, assuming as usual the random oracle assumption and with the reigning probability one minus alpha, the next block is created by an honest note and we never know what's going to happen. So that's a way of tradition. Probabilities so we want to say given that we're at a particular state, so again, roughly like given that we're in one of the four cases, what is the chance, what is the likelihood that after the next block creation we're in one state or one case versus another? The easiest way to describe these is just to be literally draw out the directed graph and all of the edges that correspond to transition probabilities that are bigger than zero, that is, transitions that might conceivably happen.
00:07:20.140 - 00:07:21.416, Speaker B: So the first thing we do is.
00:07:21.438 - 00:07:29.470, Speaker A: Write down a bunch of vertices. Those are going to be labeled according to the Markov chain states. So we're going to have non negative integers plus the special state F.
00:07:32.120 - 00:07:32.436, Speaker B: And.
00:07:32.458 - 00:08:13.996, Speaker A: So now let's just sort of keep revisiting the strategy from the previous slide and let's just sort of look, given that we're in one case, what's the likelihood we wind up in one case versus another? All right, so here's the strategy to jog your memory. And so again, cases one, two, and three, those correspond to unique states of our markup chain. Case one is state zero. Case two is state one. Case three is state F. And then case four kind of unfolds into this infinite number of states labeled two, three, four and on up according to the gap between H sub S and H sub P. And now no matter which of the four cases you're in, there's two things that could happen, right? So the next transition is the creation of some new block.
00:08:13.996 - 00:08:36.760, Speaker A: The only two possibilities are one, the next block is created by node A, or two, the next block is not created by node A. That is, it's created by some honest node. So in each of these four cases there's going to be a probability alpha that something happens that's if node A creates the next block and a probability of one minus alpha, that something else happens that's going to be the creation of a block by an honest node.
00:08:37.260 - 00:08:38.776, Speaker B: And one thing to notice is that.
00:08:38.798 - 00:09:13.508, Speaker A: Once you know which state you're in right now, like say, whether you're in case one, two, three or which of the case four subcases you're in, if you know what state you're in right now, that is sufficient information to deduce the likelihood of being in any state after a transition. For example, if you're in case two, you don't care how you got there, right? You know, as always, there's an alpha probability. The next block is created by A. There's a one minus alpha probability. The next block is created by an honest node. And in each of those two cases you're going to transition in exactly the same way. The past of how you wound up in case two doesn't matter.
00:09:13.508 - 00:10:06.480, Speaker A: So that's why this is a memoryless process and that's what the Markov and the Markov chain usually indicates. We are sort of implicitly assuming that whether the next block is created by node A or by an honest node, that that event is independent of everything that's happened in the past. But if you think about it, that's one of the key properties of proof of work under the random oracle assumption, it is indeed the case that every event, every next block creation is for all practical purposes completely independent of what happened in the past. So now let's just sort of walk through the strategy case by case and use that to specify our transition probabilities. And again, in each of the four cases there's only two things that could happen. A creates a block, an honest node creates a block, their probabilities alpha and one minus alpha respectively. So as we walk through these cases, we're just going to be drawing in some edges in that graph annotated with either alpha or one minus alpha as appropriate.
00:10:06.480 - 00:10:33.488, Speaker A: For example, let's start with case one corresponds to state zero of the Markov chain. Again, two things could happen, either success or failure. Probabilities alpha and one minus alpha. So in this case, node A is just sort of not doing anything clever. It's just trying to extend the end of the longest chain. If it succeeds, then it keeps that private and transitions to case two. And remember, it's Markov chain state one that corresponds to case two.
00:10:33.488 - 00:11:06.250, Speaker A: So the transition from case one to case two corresponds to a transition from state zero to state one that's with probability alpha with one minus alpha probability. In case one node A fails. That is, an honest node is the one that successfully extends the longest chain. And at that point node A just resets it just starts trying to extend the new, the newly announced end of the longest chain. In other words, node A is still in case one, just like before. So summarizing from case one, we have an alpha chance of going to case two. We have a one minus alpha chance of staying in case one.
00:11:06.250 - 00:11:25.650, Speaker A: So now, over in our Markov chain, we add an edge from zero to one. This is like going from case one to case two. That happens when node is successful. That happens with probability alpha. And then on the other hand, the remaining probability one minus alpha, you just stay in state zero. That is, you just stay in case one.
00:11:29.590 - 00:11:30.002, Speaker B: Right?
00:11:30.056 - 00:12:03.066, Speaker A: So that wasn't so hard. So now let's just walk through the other four cases and do the exact same exercise. So case two corresponding to state one of the Markov chain. Again, alpha one minus alpha, probability of success or failure. What happens in the event of success? Well, at that point, the node A's secret chain has a lead of two over the publicly known blocks. And so that's a transition to case four. And in particular, because the gap between the secret chain and the public chain is going to be exactly two.
00:12:03.066 - 00:12:44.810, Speaker A: When you transition out of case two on a success, that's going to be a transition to state two of the Markov chain. Remember, the numbers of the Markov chain states are meant to correspond to the gap, how much bigger the secret chain is compared to the public chain. So success from case two leads you to case four leads you from Markov chain state one to Markov chain state two. That's with probability alpha with one minus alpha probability, right? So that's when you get this fork, that's when the honest nodes create a block at the same height as the one that node A is keeping secret. And that's the transition to case three. Case three, remember, corresponds to Markov chain state F. So that's a one minus alpha chance of transitioning from state one.
00:12:44.880 - 00:12:49.146, Speaker B: To state F. So going back to.
00:12:49.168 - 00:13:26.164, Speaker A: The Markov chain, we have a transition from one to two. That is from case two to case four, with probability alpha and a transition from one to F. That again corresponds to a transition from case two to case three, with probability one minus alpha. Now, case three is pretty interesting, so let's talk that through. Case three, remember, corresponds to that Markov chain state little F. So this is where there's currently a tie between one block that node A is keeping private. So that would be like the B four prime on the slide here.
00:13:26.164 - 00:14:15.830, Speaker A: And then there's also been a publicly created, publicly announced block B four at exactly the same height. And what happens next determines which of those two blocks is going to get orphaned, right? So if node A succeeds, in the example, manages to create B five prime before the honest nodes create b five. Well then according to the strategy, A is immediately going to kind of cash in its chips, announce both of the blocks. So like in the example, announce both B four prime and B five prime that's the unique longest chain will be recognized by all of the honest nodes. And so B four prime and B five prime are then guaranteed to be in the longest chain forevermore. So that's a big win obviously for node A. On the one hand, it got two of its blocks guaranteed in the longest chain forever and on the other hand it orphaned one honest block, which would be the block B four in the example.
00:14:15.830 - 00:15:04.416, Speaker A: Now if you think about it, after node A has done this announcement, after it's made all its secret blocks public, well now we're actually back in case one, right? I mean now there's no longer a gap between what's publicly known and the secret chain. The secret chain has all become public. So with alpha probability, node A caches and chips gets two of its blocks guaranteed on the longest chain and you transition back to case one. What about in the failure mode in case three, which happens with probability one minus alpha, well then that's when the honest nodes so in the example, the honest nodes would for example, create B five before node A manages to create B five prime. And so now node A is in a deeper hole than ever. And according to the strategy, it then gives up. It says, you know what, let me just concede b four prime is a loss cause that's one of my blocks.
00:15:04.416 - 00:15:46.204, Speaker A: It's not going to get on the longest chain. Let's just sort of cut our losses and then restart trying to extend the end of B five, the end of the publicly known longest chain. So if you think about it, so that's obviously very different from node A's perspective. Rather than getting two blocks guaranteed in the longest chain, it has one block guaranteed out of the longest chain. But you again still transition to case one, right? So if the honest nodes create, like in the example B five, well then actually the public chain is of higher heights than any of the secret blocks. So you actually transition back to case one either way from case three. But when we start counting up block rewards, it's going to matter which way you transition.
00:15:46.204 - 00:16:01.160, Speaker A: So with alpha probability, the success case, you transition to case one and then collect two sort of block rewards as a consequence. And if you fail with probability one minus alpha, you also transition to case one, but you collect zero blocks of block rewards.
00:16:03.180 - 00:16:05.076, Speaker B: So returning to our Markov chain picture.
00:16:05.108 - 00:16:30.800, Speaker A: Let me actually sort of denote this in a somewhat nonstandard way. Let me actually put two arrows going from F to zero annotated with the probabilities alpha and one minus alpha. Now really strictly speaking, there's just one edge that has probability one. If you're in F, you're guaranteed to be in zero after one step. But again, we want to separate the two reasons you make the transition so that we can count up block rewards appropriately.
00:16:39.060 - 00:16:39.456, Speaker B: All right?
00:16:39.478 - 00:17:23.840, Speaker A: So all we have left to do is talk through the remaining case. Case four. Case four, remember, really corresponds to an infinite number of Markov chain states, 23456 and so on. Remember, the label of the Markov chain is meant to indicate the gap between the secret and public chains. So it's the extent to which the highest height of a secret block is bigger than the highest height of a publicly known block. So let's do the boundary case last, and let's start by just talking through some state that's, well, kind of entrenched in case four. So, like, imagine currently node A is doing really well, and it has like a lead of four in its secret chain over the publicly known chain.
00:17:23.840 - 00:17:55.720, Speaker A: So, as always, there's two things that could happen. Probability alpha, node A creates the next block, probability one minus alpha. An honest node creates the next block. If node A creates the block, well, now it's doing even better, right? Its secret chain is even one longer than before. The public chain hasn't changed, so the gap has gone up from one. So you would go from state four, for example, to state five with probability alpha. On the other hand, if an honest node is the next one to produce a block, so that's going to extend the longest public chain.
00:17:55.720 - 00:18:49.230, Speaker A: Meanwhile, the secret chain has not changed, so that's going to decrease the gap by one. So that would be, with probability one minus alpha a transition from four to three. So going back to our picture of the Markov chain, we have a transition from four to five with probability alpha, so that's if node A manages to create yet another secret block from state four, on the other hand, with one minus alpha probability, the honest nodes narrow the gap and you go from four to three. Now, this argument applies not only at state four, it applies to all of the case four states, except for the earliest of them. So state three, state four, state five, state six, all the way up. With alpha probability, you transition to the state with one higher index. With the remaining one minus alpha probability, you transition to the state with an index which is one less.
00:18:49.230 - 00:19:35.792, Speaker A: So that leaves only one thing to discuss, which is the boundary case of case four. So suppose you enter case four just barely in case four, meaning that the lead of the secret chain over the public chain is exactly two. Well, here, success looks exactly like it does in the other case for states, right? So if you're in state two and the next thing that happens is node A produces yet another secret block that's probability alpha. Well, then the lead goes from two to three. So that's just a transition from state two to state three happens with probability alpha. But what if actually node a is unsuccessful? Okay, so if honest nodes create the next block there by narrowing the gap down to one. So remember what the strategy does.
00:19:35.792 - 00:20:02.232, Speaker A: It's basically the same as what it does in case three in the success version, which it says, oh, I've only got a lead of one. That's very precarious. I don't want to run the risk of having any of these blocks I've created be orphaned. So let me just publish everything. Now I'm going to announce all of the secret blocks that I know of because I still have a lead of one. Those secret blocks are going to constitute a new, unique longest chain that will be recognized by the honest nodes. They'll extend it.
00:20:02.232 - 00:20:39.540, Speaker A: Node a will extend it. So all of those blocks that get announced at that time are guaranteed to be in the longest chain forevermore. So just like in case three in the success version, when all of the secret blocks become public, all of a sudden there's obviously no gap at all between what's secret and what's public because everything secrets become public. So that's a transition back to case one. Same thing here in case four. So if you enter in with the minimum sort of gap of two and you're unsuccessful and the gap drops to one and you just make everything public, that again is going to be a transition back to state zero. And that's going to be happening with probability one minus alpha.
00:20:39.540 - 00:21:26.052, Speaker A: So going back to our Markov chain, again, probability alpha, just like in the other case, for states probability alpha, you increase the lead, you go from state two to state three. But what's different about the boundary condition is in the unsuccessful case with probability one minus alpha, you do not return to state one, but rather you publish everything. You announce all your private blocks, thereby returning to state zero. All right, so that completes our description of the strategy as a Markov chain. Okay, so what we've done so far is really just modeling. We've taken something that was written in one form as the 4K strategy. On the previous slide, we've re encoded it in a different form.
00:21:26.052 - 00:22:15.648, Speaker A: This Markov chain that you see here in blue and orange on this slide, why do we do that? Why are we happy to phrase everything in terms of Markov chains? Well, if you studied everything or if you've looked a little bit about the wikipedia page for Markov chains, you maybe know that they have some really cool mathematical properties. They're both pretty expressive but also quite analytically tractable. And we'll see that we have exactly that same sweet spot here in this analysis. In particular, Markov chains like this one have what's known as a stationary distribution. There's various ways to think about stationary distributions. You can kind of think about it as some kind of equilibrium in a sense. You can also think of it as like if you just sort of ran an experiment and you just sort of took random transitions, according to these probabilities, for like a million or a billion steps.
00:22:15.648 - 00:22:21.044, Speaker A: It would be the frequency, sort of the relative amount of time that you would spend in each of the states.
00:22:21.082 - 00:22:22.420, Speaker B: Of the Markov chain.
00:22:23.640 - 00:23:07.856, Speaker A: So let's give that concept some notation. So by pi sub I, so here I here indicates one of the Markov chain states. That's just the stationary probability of state I, which we're going to think of as just the sort of long run frequency with which you spend time in state I. Another way to think about it, if you want to be a little more rigorous, is you can think of pi I as the ratio of two things, or rather the limit of the ratio of two things as a parameter, capital T goes to infinity. So on the denominator of this ratio, you just have capital T. So a number of sort of consecutive transitions that you look at with the transitions taken according to these transition probabilities. And then on the numerator, you just look at the number of visits you make to state I over the course of those transitions.
00:23:07.856 - 00:23:51.596, Speaker A: Now that numerator, it's a random variable, right? It sort of depends on how the coin flips come up, how many times you actually visit state i. But you can look at its expectation and then you can look at the limit of sort of the expected number of visits to I divided by the time horizon and take the time horizon to infinity. Now, for those of you that have studied Markov chains in some depth, you know, there's sort of subtleties around when do you have existence or uniqueness of sort of stationary distributions. But actually we just care about this one Markov chain that I've written down on this slide and there's really no subtleties with this Markov chain. Everything kind of behaves exactly as you expect. And let me summarize sort of the key things we need in a fact. So first of all, in this Markov chain, the pi eyes are well defined.
00:23:51.596 - 00:24:25.516, Speaker A: There's really no ambiguity about what they are. So for example, when I gave you the ratio definition of pi I's, if you think about it sort of implicit in that definition should be like, okay, well, where do you start the capital T transitions in a row? You need some sort of starting state and that seems like sort of an arbitrary choice. So in particular it doesn't matter, right? So in the long run, you take T going to infinity. You get the same ratio in the limit in any case. So pi eyes, they're well defined. Furthermore, as you would think, as you would hope, they form a probability distribution. So they're all non negative and they.
00:24:25.618 - 00:24:29.884, Speaker B: Overall sum to one, lest it seems.
00:24:29.922 - 00:25:26.930, Speaker A: Like this couldn't possibly not be true, let me mention that we are actually, in this fact, using our assumption that alpha is less than a half, that this node a in question has less than 50% of the overall hash rate. If it had more than 50% of the overall hash rate, then actually it turns out all of the pies of the Markov chain would be zero. So they certainly wouldn't sum to one. But like I said, the Markov chain we're working with here, it kind of has all of the intuitive properties you would expect it to have. All right, so what have we done? We've taken our strategy on the previous slide. We've reencoated it as a Markov chain, markov chains of stationary distributions. But actually, why do we care? Why do we care about the Markov chain? Why do we care about the stationary distribution? Well, on the rest of this slide, I'm going to show you that actually the stationary distribution is a super convenient way to talk about what we really care about, which is how good is this strategy under consideration? What share what fraction of the blocks in the longest chain does it give node A.
00:25:26.930 - 00:26:10.144, Speaker A: So, in other words, we'll see on this slide that if you knew the pies, if you knew the stationary distribution of this Markov chain, you would be in a position to very quickly answer the question of whether or not. This strategy is better than just Obediently following longest chain. And understanding how that depends on the hash rate alpha of the deviating node. Now, on the next slide, there's still going to be the matter of actually computing the pies, computing the stationary distribution of this Markov chain. But as we'll see on the next slide, with a little bit of algebra, there actually is closed form formulas for all of the PiS, and that's going to complete the analysis. Next slide, we'll have closed form formulas for all of the pies. We'll plug those into the closed form formulas, we're going to put on the bottom of this slide, and boom, we'll be good to go.
00:26:10.144 - 00:26:16.240, Speaker A: And we will be able to characterize exactly which alphas for which this is an improving strategy.
00:26:19.920 - 00:26:20.316, Speaker B: All right?
00:26:20.338 - 00:27:02.516, Speaker A: So next order of business is to understand how, given the pies, we could very cleanly express what we care about the fraction of the blocks on the longest chain that were produced by node A. So that's fundamentally a block counting exercise, right? We need to count sort of the number of honestly produced blocks that get on the longest chain. Again, that'll be some, but not all of them. We need to count the number of blocks produced by node A that make it under the longest chain. And again, unlike previous scenarios, that will be some, but not all of them. So as the markov chain proceeds, as we're transitioning from state to state, we're going to count. Blocks as it becomes clear whether or not they'll wind up on the longest chain.
00:27:02.516 - 00:27:31.940, Speaker A: So remember, each transition corresponds to the creation of a new block. But when a block is created, we may be unsure about whether it's going to wind up on the longest chain or not. Like, remember case three, right? That's where you have the fork that's sort of Markov chain state F. Basically you have this competition between these two blocks. One's going to be on the longest chain, the other is going to be orphaned. And it's just going to depend on whether the next block is created by node A or by some honest node. So at the time of a block's creation, you don't necessarily know whether you should be counting it or not.
00:27:31.940 - 00:28:27.412, Speaker A: But what we're going to see is that if we just go through the transitions one by one, it will be clear the moment in time at which some block we're sure that it is or is not going to be on the longest chain. And that is the moment at which we will do the counting. And again, we're going to keep tracking of both honestly produced blocks and blocks created by node A. So we're literally just going to go through the orange edges in this graph one by one. We're going to inspect each type of transition that could possibly occur and we're going to ask, okay, when that transition occurs, are there any kind of further blocks that we're now newly sure, 100% confident are going to be on the longest chain? Let's just go ahead and start with case one. So start with Markov chain zero and look at the two transitions out of state zero, the self loop back to it, and the transition from state zero to state one. Remember, that the transition from zero to one.
00:28:27.412 - 00:29:04.544, Speaker A: That's the probability alpha case. That's when node A is successful and actually manages to extend the longest chain, which it then keeps private, the block that it did that with, and then the self loop with probability one minus alpha. That's when A fails in case one. And actually it's the honest nodes that manage to extend the longest chain. So let's start with that second case, the failure, which is the self loop from zero back to itself. If you think about it, we are newly confident about some block's membership in the longest chain, which is the block that was just now, just now created by an honest node. So like in the example, it would be the block B four.
00:29:04.544 - 00:29:27.032, Speaker A: Actually, we are newly confident that's going to always be in the longest chain. Why? Well, look at the strategy. What is node A going to do? It's going to just give up and say like, okay, fine, I'll give you B four, I'm going to start extending B four. The honest nodes of course, are also extending B four. So everyone's always going to extend B four. It's always going to be on the longest chain. And in general, in case one, whenever the honest nodes win.
00:29:27.032 - 00:29:34.200, Speaker A: So probability one minus alpha, that's self loop, that's one more honestly produced block that we're sure is going to be on the longest chain.
00:29:39.860 - 00:29:40.256, Speaker B: All right.
00:29:40.278 - 00:30:13.036, Speaker A: So I hope you're getting a sense of what I mean by we're going to sort of count blocks at the moment in time that we're sure that they're going to wind up in the longest chain. And indeed, let's go back to kind of case one. So Markov chain state zero and think about the other case, right. So the alpha probability transition from state zero to state one, that is from case one to case two. And notice so that's A block created by node A. But we are not actually confident that that block is going to wind up on the longest chain. It's possible with nonzero probability that the block that node A just created actually winds up being orphaned.
00:30:13.036 - 00:30:48.712, Speaker A: So it'd be inappropriate to count it now specifically. So when A finds that block, it transitions from case one to case two. If it's unsuccessful in case two. If honest nodes create the next block, then that's a transition from case two to case three where you have the fork. And now if node A is unsuccessful again in case three, at that point the block that it created originally in case one is going to be orphaned. So point being is it would too early to count the block created by node A when it creates it in case one. Exactly.
00:30:48.712 - 00:31:41.064, Speaker A: This same reasoning applies in case two. The part of case two where node A is unsuccessful and the next node to create a block is an honest node in particular, that block created by an honest node in case two. It would be inappropriately early to count it. At that time, we are not sure whether a block produced by an honest node in case two will wind up on the longest chain or not. So how would it not wind up on the longest chain? Well, that block's creation is a transition from case two to case three if node A is successful in case three. So if it creates in the running example, if it creates B five prime before honest nodes create B five, well, then it publishes, then it announces its two private blocks and that orphans the honest block that had been created in case two. So the block B four in our running example.
00:31:41.064 - 00:32:15.796, Speaker A: So the honestly created block, if an honestly created block happens in case two, we can't yet count it toward the longest chain. We're not sure it's going to wind up there. All right, so that's everything there is to say about Markov chain state zero corresponding to case one. Let's now actually move on to the quite interesting Markov chain state little f, which corresponds to case three in the strategy. This was the time this was the, this was the state where you are actually guaranteed to transition to state zero. That is in case three. Doesn't matter who finds the next block either way you're going to find yourself in case one.
00:32:15.796 - 00:33:04.768, Speaker A: But everybody does care. There's two different ways it can happen and everybody has a vested interest in which way it happens. Remember, in case three, you have two competing blocks at the same height. So like in our running example, it's the blocks B four, which is the publicly announced one, and B four prime which is the block that node A is keeping secret. And at this point it's kind of a winner take all zero sum game, right? So either the honest nodes are going to find the next block that would be the block B five in this example, or node A is going to find the next block that would be B five prime. And let's see. So if node A is successful and it finds in the example B five prime, it's going to announce both of its secret blocks that's going to be the unique longest chain.
00:33:04.768 - 00:33:49.696, Speaker A: Those are then guaranteed to be in the longest chain forevermore. It's the unique longest chain. All the honest nodes will respect that and extend it. And also the honestly produced block b four in the example is going to be orphaned. But in any case, plus two for node A, if it happens to be the one to find the next block in case three by exactly the same reasoning, right? Because if honest nodes create a block node A according to the strategy, abandons its secret chain and just switches to trying to extend sort of the public chain. It's exactly the same thing in reverse. So if the honest nodes produce the next block, like in the example if they produce B five before B five prime is produced, that has the effect of guaranteeing two honest blocks in the longest chain, namely the block.
00:33:49.696 - 00:34:08.836, Speaker A: B four that was created back in case two. And the block in the example, the block B five that was just created now in case three. So that's two honest nodes that now we can be sure, newly sure, are going to wind up in the longest chain. Meanwhile, a block by node A, like b four prime in the example is going to get orphaned.
00:34:08.868 - 00:34:09.064, Speaker B: Okay?
00:34:09.102 - 00:34:44.546, Speaker A: So upshot is whoever wins case three gets two blocks, two new blocks guaranteed on the longest chain. So we've gone through everything there is to say about case one and sort of the block counting for transitions out of state zero. Also we've talked about all of the transitions out of state F. So that handles case three. So let's talk about case two and finish the job there. This corresponds to state one in the Markov chain. With probability alpha, you'll see, you transition to state zero.
00:34:44.546 - 00:34:48.740, Speaker A: And with probability one minus alpha you transition to state F.
00:34:50.790 - 00:34:51.458, Speaker B: So how did.
00:34:51.464 - 00:35:28.894, Speaker A: We find ourselves in case two in the first place? Well there's only one way it can happen actually, which is you're. In case one, node A creates a block. That's how you get to case two. So that would be like the block B four prime in our running example. And that block node A is keeping secret to itself for the time being. We've already argued that when you make that transition from case one to case two, it would be inappropriate to at that time count that newly created block toward node A's total. The reason being is there's a nonzero probability that that block is going to get orphaned, right? So if from case two honest nodes create the next block, that puts you in case three.
00:35:28.894 - 00:36:18.314, Speaker A: If honest nodes again create the next block, then that actually orphans whatever block node A created back in case one for exactly the same reason. If honest nodes happen to be successful, meaning they produce the block in our example before, in case two, again, it's inappropriately early to count that toward the total running total for the honestly produced blocks. Again, there's a non zero chance that block is going to get orphaned specifically after the transition to case three. If node A is the next node to create a block, that's going to orphan the block created by an honest node in case two. So all that remains to discuss is the transition from case two to case four. So suppose you're in case two. And suppose it just so happens that node A is the next one to create a block.
00:36:18.314 - 00:36:54.490, Speaker A: So notice this means that sort of node A succeeded twice in a row. It was in case one, it found a block, transitioned to case two, immediately found another block. That's how it transitioned to case four. And so that's a really happy transition for node A. It's left the anxiety ridden case two where there's still a chance of its block being orphaned. So that's like the block B four prime in our example. And it's transitioned to sort of the comfort of case four, where now that the lead is two, by construction of the strategy, there's literally zero chance that any of the secret blocks created by node A will ever be orphaned again.
00:36:54.490 - 00:37:35.880, Speaker A: Because remember, in case four, if you're ever in danger, if the lead ever shrinks to one, at that point you cash in your chips, you announce all of your secret blocks and all of those are guaranteed to be on the longest chain. So what all that means is when you transition from case two to case four, there's actually two blocks created by node that we are newly confident, 100% confident are going to be in the longest chain. Whatever block node A created in case one to get to case two. And whatever block node A created to get from case two to case four, both of those are now guaranteed to belong to the longest chain forevermore. So from case two with a transition of case four, that's a plus two blocks for node A.
00:37:42.260 - 00:37:44.672, Speaker B: So all that's left to discuss is case four.
00:37:44.726 - 00:38:23.896, Speaker A: So the Markov chain states labeled two, three, four, dot, dot, dot all the way up. So for starters, imagine you're in case four. So you're at one of these states, two, three, four, or maybe a higher number. And consider the case where node A is successful and it creates yet another new block that it again keeps secret. It extends its own secret chain. Well, remember the way case four works? Every single secret block at the end of the day is going to become public and belong to the longest chain forevermore. The strategy is explicitly defined so that there's no way that any secret blocks in case four are ever going to get orphaned.
00:38:23.896 - 00:38:39.120, Speaker A: They're all going to be on the longest chain. So whenever node A creates one new secret block while in the safe confines of step four, that's one more block we can put in a's total. That is one more block created by node A that's guaranteed to be in the longest chain.
00:38:39.780 - 00:38:41.056, Speaker B: And if you think about it, this.
00:38:41.078 - 00:39:46.836, Speaker A: Strategy actually also guarantees that any block created by honest nodes while in step four is going to be orphaned. So if you're in one of these case four states and the honest nodes create a block, well, actually too bad that does not increase the honest nodes total at all because we already know for sure that that block is going to wind up orphaned. That's what the case four strategy achieves. So we've covered all our bases. We've stepped through all of the transitions in the Markov chain and figured out how many blocks we should be counting with each step. Each block that winds up on the longest chain is going to get counted once and only once as we transition through this Markov chain. So getting back to the question that we actually care about, does this strategy improve over naively following the longest chain protocol or not? So to do that, we got to get some handle on how many blocks created by Node A wind up on the longest chain.
00:39:46.836 - 00:40:37.092, Speaker A: Again, it's going to be some, but not all of them. How many blocks created by honest nodes wind up on the longest chain? Some, but not all of them. And the good news is we can now combine the pies. So if we know the stationary distribution using this block counting, it's actually very simple to express sort of the relative frequencies with which node A and the honest nodes get blocks into the longest chain. So let's begin by understanding sort of how frequently blocks produced by honest nodes get added to the longest chain. So we're going to look over the results of our block counting exercise and we're going to see exactly for which kinds of transitions do we need to add to the sort of running total of honestly produced blocks on the longest chain. And what we see is there's exactly two different types of transitions where we have something to count.
00:40:37.092 - 00:40:45.450, Speaker A: The first one is when we do the self loop. So already the public chain is the longest one. And it just so happens that the honest nodes are the next ones to extend it.
00:40:48.030 - 00:40:49.462, Speaker B: The other thing we have to count.
00:40:49.536 - 00:41:26.554, Speaker A: Is when we're in state F. So that's case three. That's sort of the ambiguous state where you have competing public and secret blocks at the same height. So there remember, if honest nodes wind up finding the next block in case three, that's actually two new honest blocks that are confirmed for the longest chain. So how frequently do these events actually happen? Start with the first one, that sort of plus one H block. When does that happen? Well, two things have to be true. First of all, you got to be at state zero in the first place.
00:41:26.554 - 00:42:08.460, Speaker A: You got to be in case one for this to be relevant. Secondly, given that you're at state zero, given that you're in case one, you need honest nodes to be the next ones to find a block, you need to follow that self loop. Now, we know the probability of that second event. It's one minus alpha, right at any moment in time. It's always a one minus alpha chance that the next block is created by an honest node. But if you think about it, the stationary distribution, the pies tell us the likelihood that at a given transition is going to be from state zero. The stationary distribution, what is it? By definition, it is the long run frequency with which you are at each state.
00:42:08.460 - 00:42:32.660, Speaker A: So pi sub zero is the fraction of time steps that we're going to be at state zero of that pi zero fraction of time steps. A one minus alpha fraction of those times an honest node will create the next block leading to the self loop back to state zero, leading us to the plus one block H block to the honest node's accumulating total.
00:42:33.670 - 00:42:35.186, Speaker B: So in other words, the rate at.
00:42:35.208 - 00:43:27.874, Speaker A: Which H blocks are added to the longest chain for the first reason is going to be the fraction of time that you're at state zero in the first place times the probability that from state zero you transition right back to state zero, which again is going to be pi zero. The frequency of times at which you're at state zero. Times one minus alpha. The chance of the honest nodes finding a block exactly the same deal at state F. So the other way that H blocks get confirmed for the longest chain. If you're at state F, which is going to be a pi sub f fraction of the time, and if an honest node is the next one to find the block, which happens with probability one minus alpha, then actually not one, but two new blocks, we can now be 100% confident are going to be.
00:43:27.912 - 00:43:29.330, Speaker B: In the longest chain.
00:43:30.790 - 00:43:56.514, Speaker A: And at this point, I hope you can start to appreciate why we've been tying ourselves in knots. I'm phrasing everything in Markov chain terminology, talking about stationary distributions, talking about these PiS, because in terms of the pies, it's extremely easy to express exactly how frequently honestly produced blocks are getting added to the longest chain. For blocks created by node A, it's exactly the same exercise. So the expression is slightly more complicated.
00:43:56.582 - 00:44:00.346, Speaker B: But barely looking over the block counting.
00:44:00.378 - 00:44:42.390, Speaker A: Exercise, you'll see there's sort of three different spots that we need to look at. So first is in the transition from state F to zero. So when the fork in case three gets resolved, if it gets resolved in favor of node A, which is with probability alpha, then that's two blocks that we're newly 100% confident of will be in the longest chain. We had the case where node A actually just finds two blocks in a row. So it's at case one, finds a block, goes to case two, finds another block, goes to the safe confines of case four. At that point, we have two new blocks, the ones created in case one and case two that we're sure are going to be in the longest chain. So that's another plus two a blocks.
00:44:42.390 - 00:45:03.460, Speaker A: And then finally, every block that's created in the safe confines of case four is going to eventually wind up on the longest chain. So whenever you transition from a state I to a state I plus one with I at least two, that's going to be one more block. You get to add to the running total of blocks produced by A that are going to be on the longest chain.
00:45:04.760 - 00:45:06.068, Speaker B: And now we can write down sort.
00:45:06.074 - 00:45:26.524, Speaker A: Of exactly the same type of expression. Right, so for honest nodes from state F, we had pi sub F, the fraction of time you're in F times one minus alpha, the chance of an honest block times two. So here our first term is going to be the same, except with one minus alpha replaced by alpha. Right, because node A is going to get its two blocks. If it's the one that finds the next block from case three, which is.
00:45:26.562 - 00:45:30.844, Speaker B: Probably alpha for the transition from state.
00:45:30.882 - 00:45:41.088, Speaker A: One to state two to happen, you got the first place be at state one. So the likelihood of that is pi sub one. And then the probability of that transition, again, it's an alpha. It corresponds to node A finding a.
00:45:41.094 - 00:45:50.334, Speaker B: Block rather than an honest node. And then finally we sum up over.
00:45:50.372 - 00:46:45.716, Speaker A: All the markup chain states two, three, four, all the way up, multiply the corresponding stationary probability times, the probability that node A creates a block probability alpha. And then here we just get a plus one to the running total. So expression two, it's a little messier than expression one, but still not so bad. So, again, this kind of shows the utility of framing this whole analysis in terms of this Markov chain and its stationary distribution. So this is the first part of the analysis that I promised. This shows that sort of given the stationary distribution, we could assess how good the strategy is relatively quickly. So given the pies, we could just evaluate one and two and compare them and compare to what it would be if node A instead simply obediently followed longest chain consensus.
00:46:45.716 - 00:48:06.074, Speaker A: There's still the matter of actually figuring out what that stationary distribution is actually computing the pies. So on the next slide, I'm going to sketch an argument about how you would solve for the PiS. Then, given the PiS, we're just going to plug those into expressions one and two, and then we'll just evaluate for exactly which alphas does this strategy beat, honestly following longest chain consensus. All right, so we now see that it'd be really nice if we knew the stationary distribution of this Markov chain that formalizes the strategy, right, given those pies, given the stationary probabilities, we'd be off to the races. Right, we have expressions for the frequency with which both node A and the honest nodes get blocks on the longest chain. And just for reference, let me just sort of repeat slightly cleaned up versions of those expressions here at the top of the slide. Now remember, what node eight cares about is the fraction of blocks on the longest chain.
00:48:06.074 - 00:48:34.810, Speaker A: So that's going to be the ratio between on the one hand, to the second quantity. So the rate at which node A gets blocks included in the longest chain and the overall rate at which blocks are added to the longest chain. So that's going to be expression one plus expression two. And that's the ratio that we really want to know. Is that bigger or smaller than alpha? Because after all, node A, just by honestly following the longest chain consensus protocol, could guarantee itself an alpha fraction of the blocks on the longest chain.
00:48:44.610 - 00:48:45.998, Speaker B: All right, to answer this, we're just.
00:48:46.004 - 00:48:50.430, Speaker A: Going to have to compute the stationary distribution. We're just going to have to compute those pies.
00:48:55.780 - 00:48:57.236, Speaker B: The good news is there's plenty of.
00:48:57.258 - 00:49:39.596, Speaker A: Techniques for doing that. Again, that's part of the popularity of Markov chains. They're actually surprisingly analytically tractable in many cases, despite the fact that they're actually quite expressive and express lots of different interesting random processes. So the way we're going to go about it is we're going to write down a few constraints, a few conditions, which it seems like, at least intuitively, any stationary distribution would have to have to satisfy, just given the meaning of the stationary distribution. And it's not hard to make precise the fact that all of those conditions, these conditions we'll write down, must in fact hold for any stationary distribution of this particular Markov chain. All of these conditions are going to be simple. They're just going to be linear relationships between different pi's.
00:49:39.596 - 00:49:51.940, Speaker A: So that gives us a linear system which the PiS are going to have to satisfy. And that linear system is going to turn out to have a unique solution and we're just going to, frankly, just solve for it. It'll be a little bit like in the spirit of, say, Gaussian elimination.
00:49:52.760 - 00:49:53.156, Speaker B: All right?
00:49:53.178 - 00:49:56.340, Speaker A: So without further ado, let's write down those conditions.
00:50:01.870 - 00:50:03.406, Speaker B: All right, so first of all, I.
00:50:03.428 - 00:50:11.360, Speaker A: Claim that pi one should be equal to alpha times pi zero. So again, a linear, simple linear relationship between pi zero and pi one.
00:50:11.970 - 00:50:12.366, Speaker B: All right?
00:50:12.388 - 00:51:11.380, Speaker A: So why should that be true? Well, let's remember the meaning of the pi's, right, as sort of frequencies of visits, right? So think about sort of running the Markov chain for a billion steps, meaning you just keep taking state transitions with probabilities, as they're described in the Markov chain. And so then pi zero, for example, is over those billion steps, the fraction of time that you find yourself in state zero. Pi one is over those billion steps, the fraction of times that you find yourself in state one. So why this relationship between pi zero and pi one? Well, if you look at this Markov chain, you'll see that state one has only one incoming arc. That's an arc coming from state zero labeled with alpha. So what that means is the only way you're ever going to visit state one is if, first of all, you're at state zero and then node A is the next node to create a block which happens with probability alpha. That is the unique condition under which you transition from zero to one.
00:51:11.380 - 00:51:41.180, Speaker A: Well, we know the fraction of the time we're at zero. That would be pi zero. And an alpha fraction of those visits are going to translate to a transition to state one. The other one minus alpha fraction are just going to self loop back to zero. So what that means is that the frequency of visits to one should be equal to the frequency of visits to zero times alpha times the fraction of those visits to zero that turn into visits to one.
00:51:43.230 - 00:51:44.766, Speaker B: So that's the intuition for why it.
00:51:44.788 - 00:51:57.700, Speaker A: Seems like this first condition has got to be true for any stationary distribution pi. And indeed, again, not hard to formalize that that is in fact the case. We can use exactly the same reasoning to relate states F and one.
00:52:01.060 - 00:52:02.336, Speaker B: So again, if we look back at.
00:52:02.358 - 00:52:31.930, Speaker A: The Markov chain, we will see that state F is also a state that has only one incoming arc. There is one and only one way to get to state F. You have to be at state one. And then honest nodes need to be the next ones to produce a block, which happens with probability one minus alpha. So that means visits to f. Well, you should just look at how frequently you visit one and then the fraction of those visits to one that translate to visits to f. And so that gives us the pi sub F should be one minus alpha times pi one.
00:52:31.930 - 00:52:38.510, Speaker A: The third condition is really going to be an infinite family of conditions, one for each positive integer i.
00:52:39.200 - 00:52:41.144, Speaker B: And here the claim is that pi.
00:52:41.192 - 00:53:04.324, Speaker A: I times alpha should be equal to pi I plus one times one minus alpha. So, for example, think like, let's take I equals six. So we're thinking about states six and seven, both sort of deeply embedded in case four, both corresponding to node A having some big lead in its secret chain over the publicly known longest chain. So how do we interpret this?
00:53:04.442 - 00:53:06.736, Speaker B: Well, let's look at the Markov chain.
00:53:06.848 - 00:53:42.896, Speaker A: So, again, we're thinking about states six and seven. Certainly at least once in a while you're going to have a transition from six to seven. It's bound to happen eventually. But here's the thing to realize, right, so eventually you're going to get back to zero in this Markov chain. And this is using the assumption that alpha is less than a half, the assumption that honest nodes produce blocks more frequently than node A. So you're not going to have some private chain, some secret chain that just wanders off to infinity. You would if node A had more than half of the hash rate, but it has less than half of the hash rate.
00:53:42.896 - 00:54:36.924, Speaker A: So honest blocks are coming on average more quickly than node A's blocks, which means eventually this Markov chain is going to return back to zero. And looking at the structure of this Markov chain, if you're at state seven, the only way you can get back to zero is by, first of all going back to state six. So in other words, for every six to seven transition, we can match it with a subsequent seven to six transition. So the next moment in time where this random walkthrough, this graph, comes back to node six. And again, because it's visiting zero infinitely often, you know that's going to happen eventually. So for each six to seven transition, there's a matching seven to six transition. So what does that mean? That means the frequency of each of those two transitions has got to be the same because they're in one to one correspondence.
00:54:36.924 - 00:55:08.872, Speaker A: So what is the frequency of six to seven transitions where you got to, first of all be at state six, so that's with frequency pi sub six, and then in fact, node A has to be the next one to find a block. So that's alpha, that's the left hand side of this condition. What's the relative frequency of seven to six transitions? Well, you got to, first of all be at state seven, so that's the pi sub I plus one, pi sub seven. And then honest nodes need to be the next ones. To produce a block. So that's the one minus alpha. So the left part of this condition is the frequency of six to seven transitions.
00:55:08.872 - 00:55:57.244, Speaker A: The right hand side is the frequency of seven to six transitions, and those are in one to one correspondence. There's a slight twist if I equals one, although the math, the condition is exactly the same. So if I equals one, we're pairing up transitions from one to two with transitions from two to zero. So if you recall from state two, actually, you don't go back to one. That's sort of where instead of going to one node a is just going to publish all of its secret blocks and you're just going to go all the way back to zero. But still, one to one correspondence between one to two transitions and two to zero transitions, the frequency of the former transitions, one to two, that's going to be pi one times alpha. The frequency of the latter type of transitions, that's going to be pi two times one minus alpha, which is exactly what the condition says.
00:55:57.244 - 00:56:51.150, Speaker A: So the condition is true even for the I equals one case. So this is a very powerful set of conditions in that it allows us to express every single pi, every single stationary probability as pi zero times some closed form formula that's a function of alpha. So for example, in condition one, we already see that, all right, so pi one by this condition is pi zero times a closed formula of alpha, namely alpha. But then if you chain that together with a condition in two, pi sub f is one minus alpha times pi one. Oh, but wait, pi one is alpha times pi zero, so that's pi one and pi f. So what about the rest of them? Well, let's actually rewrite this condition three a little bit. Okay? This relationship between pi I and pi I plus one, let's actually think about the rate at which pi I plus one is dropping as I increases.
00:56:51.150 - 00:57:24.490, Speaker A: So rearranging, we see that each pi I plus one is a factor of alpha over one minus alpha times the previous one. Now remember, we're assuming alpha is less than a half. So this ratio alpha over one minus alpha is strictly less than one. Okay? So the pi's are decreasing with i. Every time you bump up the index i, pi gets multiplied by a factor less than one, the factor alpha over one minus alpha.
00:57:24.990 - 00:57:26.186, Speaker B: And so now if you think about.
00:57:26.208 - 00:58:12.552, Speaker A: It, we're done, right? So like take pi two, right? So pi two is going to be alpha over one minus alpha times pi one. What's pi one? It's just alpha times one minus alpha times pi zero. What's pi three? Well, it's just another alpha over one minus alpha times that. What's? Pi four, it's another alpha over one minus alpha times that. So that shows us that these conditions, these linear relationships, allow us to express every single stationary probability as pi zero times some multiple that we have an explicit formula for. Now we're in a position to solve for pi knots. That's using the fact that we mentioned on the last slide that the PiS, as one would hope, form a probability distribution that they sum to one.
00:58:12.552 - 00:59:04.094, Speaker A: All of our pi's are sort of multiples of pi zero that we understand. And if we sum up all of those numbers, we got to get one. And that allows us to solve for pi zero explicitly as a function of alpha. In case it seems scary that there's this sum over an infinite number of things, notice that by the third condition, most of those things, everything from pi two on up, that's basically just going to collapse with a geometric series. So using the fact that the pi is summed to one, and using the fact the geometric series have a closed form formula that allows us to just solve explicitly four pi zero. So I'll spare you any further gory algebraic manipulations. If you want, they're elementary.
00:59:04.094 - 00:59:40.622, Speaker A: If you want, I encourage you to do them in the privacy of your own home. Let me just cut to the chase and tell you what you get for pi zero if you solve for it in this way. Turns out the answer is one minus two alpha divided by two alpha cubed minus four alpha squared plus one. I don't know how you would guess this. This is just what you get when you do the calculation. And now, of course, now that we've solved for pi zero, all the dominoes start falling. So as we've discussed everything else, all of the other pi's can be expressed as just this pi knot that we just solved for times a simple function of alpha.
00:59:40.622 - 01:00:37.186, Speaker A: So now we know all of the pi's explicitly. And so now if we go back to the light blue and magenta expressions at the top of the slide, the rate of frequency of additions to the longest chain by blocks produced by honest blocks, by honest nodes, and by node A respectively, those are all just simple linear functions of PiS. So we have closed form formulas for all the pi's. We can plug those formulas into the expressions one and two, and then we can compute that ratio one over one plus two. I feel like there should be a drum roll. We've worked so hard to get up to this moment. So if case the suspense is killing you again, I will spare you the gory details, encourage you to do them in the privacy of your own home, if that's something that interests you.
01:00:37.186 - 01:01:18.600, Speaker A: Let me cut to the chase and just tell you what this ratio is. Let me phrase it as alpha. Let me write it as alpha times something else. So alpha remembers the fraction of blocks that node A is going to get on the longest chain. If it just follows longest chain consensus in the naive way. So we're very curious if this ratio is bigger or less than alpha, that is, if this coefficient of alpha is bigger or less than one. And so what is it? Well, turns out to be four alpha cubed minus nine alpha squared plus four alpha over alpha cubed minus two alpha squared minus alpha plus one.
01:01:18.600 - 01:01:24.406, Speaker A: So I don't know if that's what you had in mind all along, but that's what the answer turns out to.
01:01:24.428 - 01:01:27.366, Speaker B: Be so obviously you're not supposed to.
01:01:27.388 - 01:02:13.990, Speaker A: Really know what to make of this the first time you see it. But good advice in general is that whenever there's some crazy function you don't really have a handle on, go ahead and graph it, especially if it's a univariate function, you should always just plot the function to see what it looks like. So that's what I've done here. On the lower right part of the slide, you'll see there's the straight line, which begins as the higher curve and then ends as the lower curve. So the straight line is just the identity function, so that corresponds to just alpha. So that's the reference point of just honestly following longest chain, getting an alpha fraction of the blocks on the longest chain, and then the curve which starts below the line, but then ends above the line. That is just a plot of this function here in dark blue.
01:02:13.990 - 01:02:26.060, Speaker A: And eyeballing the plot, what you can see is that those curves cross somewhere between 0.3 and zero point 35. Turns out their intersection point is at exactly one third.
01:02:32.870 - 01:02:34.546, Speaker B: So, just as a sanity check, I.
01:02:34.568 - 01:03:12.426, Speaker A: Encourage you to sort of look at this ratio here in blue and just plug in alpha equals one third and confirm that it does equal to one. The numerator equals the denominator. So you can just sort of express, just you can think in terms of like 27. So like four alpha cubed equals a third. That's going to be four over 27 nine alpha squared, that's one. So that's -27 over 27 so it's -23 over 27 and then you're adding back in four three, which is 36 over 27 so that gives you 13 over 27 in the numerator denominator. Similar story, alpha cubed is 127 minus two alpha squared.
01:03:12.426 - 01:03:50.170, Speaker A: That's going to be like minus six over 27. So that's a minus five overall. Plus one will bring you back up to 22 over 27 minus alpha, that's minus nine over 27 getting you back to 13 over 27. So both numerator and denominator, 13 over 27 equal to one. If you take the derivative, you find that it's a strictly increasing function in the range that we care about. So in fact, you're doing worse than alpha below a third, you're doing better than alpha above a third. So the upshot is that even when you have honest nodes conspiring to break ties in, the worst possible way for you is the deviator as the deviator as that node A.
01:03:50.170 - 01:04:40.130, Speaker A: If you're big enough, you don't need to be a 51% attacker. But if you're at least more than 33% of the hash rates, then in fact you are not incentivized to follow the intended behavior of Logan Shake consensus. You are instead incentivized to deviate from it. And that, in my opinion, is pretty cool. And this is really the main result from that famous AOL and Surreyr paper that I mentioned. I think the proof is cool. I think this Markov analysis approach is really nice with the strategy sort of carefully constructed so that the analysis, while a little hairy, is still sort of pretty doable.
01:04:40.130 - 01:05:56.000, Speaker A: And then I think the takeaway is really cool, which is that well below the sort of 50% threshold that was the tacit assumption in the early days, for example, of Bitcoin. Even when the amount of non honest hash rates is much less than 50% anywhere above 33%, then really with no assumptions at all about how much honest nodes conspire to prevent them from deviating, it doesn't matter. Selfish mining actually will boost the block rewards, the share of block rewards for that large node that does selfish mining rather than just obediently following the longest chain protocol. So again, I think quite surprising results, quite nontrivial analysis, really nice. So one final comment for those of you just wondering what's going on with alphas that are less than one third? Because notice I just wrote down one particular strategy that node A could use if it wanted. And then we've now proved, we've done math that shows that that suggested strategy is in fact better than just obedience to longest chain when the node sufficiently big, when alpha is bigger than a third. But who's to say that the node can only pick between these two strategies, right? Maybe there's strategies that are sort of even better than the one I wrote down that will let you boost your share of block rewards even when your hash rate is less than a third.
01:05:56.000 - 01:06:45.226, Speaker A: So as it turns out, the strategy of this video is not optimal, but it's close. So while this analysis shows that one third is the right answer for this strategy, this strategy is helpful to you if and only if alpha is bigger than a third. There are in fact more sophisticated strategies in the same vein but somewhat more complicated that do slightly better than this one. So even if your hash rate, even if alpha is, I don't know, something like maybe zero point 33. So like 33% instead of 33.3%, if you use a more complicated strategy, you can actually boost your rewards a tiny bit right there, a little bit below a third. But maybe more interesting is that it has been proved, I should say there's a big academic literature, all kinds of extensions of this selfish mining analysis of AOL and Surre.
01:06:45.226 - 01:07:19.350, Speaker A: I'll put citations to some entry points in the lecture notes. And in one of those follow up works, what was proven is that in fact, there are not strategies much better than this one. So if your hash rate is less than something like 33%, then in fact it is in your best interest to honestly follow longest chain consensus. If everybody else is behaving honestly and you're smaller than 33%, that honesty is contagious. You also want to follow the protocol to maximize your share of block rewards. So that's pretty neat.
01:07:31.820 - 01:07:32.856, Speaker B: All right, so if you made it.
01:07:32.878 - 01:07:53.980, Speaker A: To the end of video, when you watch the whole thing, you should give yourself a pat on the back. You just learned one of the most academically famous results in the history of blockchains. So coming up next is going to be the last video of lecture ten. We're going to discuss these results, and in particular, to what extent they are relevant to practice.
01:07:54.060 - 01:07:55.250, Speaker B: So I'll see you there.
