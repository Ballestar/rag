00:00:00.330 - 00:00:25.334, Speaker A: Okay, so just a quick reminder recap of where we left off on Tuesday. So Tuesday we introduced linear programs. And so we talked about a language for encoding problems with linear programs. We did a toy example. We also did many real examples. Max flow min cause flow fitting a line, learning linear classifiers. Here's the toy example from last, last time.
00:00:25.334 - 00:00:46.486, Speaker A: Actually, I tweaked it a little bit. Last time, this four was a two and this two was a one. I wanted to break symmetry, so I modified it slightly. But the picture is almost the same. I really just took one of the constraints and kind of lifted it up a little bit. And so this is the intersection of four half planes. You want to find the best point, what's best? Maximize the sum of the two coordinates.
00:00:46.486 - 00:01:28.678, Speaker A: Just like on Tuesday, that corresponds to moving northeast as far as possible. And so here last time it was one third, one third with the Tweaked constraint. The new optimal is 3727. So you can check that this 03727 satisfies both of these constraints with equality, and it achieves an objective function value of five seven. And so in general, what is a linear program? What's the recipe? Well, there are decision variables, like here x one and x two. There are linear constraints, linear meaning that each decision variable can't be multiplied against anything else, nor can you apply any nonlinear function to it. You can just multiply it by a constant and then add up a bunch of those terms.
00:01:28.678 - 00:02:00.334, Speaker A: The constraints are allowed to be either inequalities or equalities. Remember, that was one of the points of linear programs. If you only have equalities, you can use Gaussian elimination to look for solutions. But lots of problems like all of the ones we saw on Tuesday naturally have inequalities. So those are also allowed. Okay, so any questions about that? Any questions about where we left off on Tuesday? So the plan for today is we're going to start talking about linear programming duality. So last lecture.
00:02:00.334 - 00:02:03.374, Speaker A: Oh, yeah, question, explain why exactly maximizing.
00:02:03.422 - 00:02:12.230, Speaker B: X one plus x two is going in the direction of the vector eleven. It seems like I could draw a different graph which does not have lines in which that is not the case.
00:02:12.300 - 00:02:42.430, Speaker A: Does not have lines. So I would again think about the level sets of the objective function. Okay, why is the vector well, so if you prefer, think about it this way. Think about the subset of solutions. Just think about the subset of the plane that has a given value of x one plus x two. Like x one plus x two equal one. Okay? So that's going to be a line 45 degree angle going from southwest to south sorry, northwest to southeast.
00:02:42.430 - 00:03:35.978, Speaker A: So basically the plane gets chopped up into these parallel lines, each one corresponding to a particular objective function value. And the objective function value is getting bigger as I go northeast. We're really just trying to maximize the dot product of x one comma x two with the vector one comma one. So that's just the definition. What is x one? Think of x one plus x two as eleven dot products x one x two. This is the same thing, right? Okay, good. So the topic for today's lecture is linear programming duality and LP duality.
00:03:35.978 - 00:04:06.300, Speaker A: Honestly, it's really the heart and soul of this entire course of CS 261. We'll talk about it all lecture today. We'll talk about it some more on Tuesday. I want to spend some quality time with LP duality so that you have a sense to really kind of absorb it at more than just a superficial level. And at some point it'll be clear that actually all of the last three weeks, I was also teaching you about LP duality. That won't be obvious immediately, but it'll become somewhat clearer through the lecture today. So to start the story, let's just look at this toy example.
00:04:06.300 - 00:04:51.466, Speaker A: So we solved it by inspection. It's just in the plane and it's a simple one. So we just said, oh, let's move as far this way as possible. That's the right point. But as we scale the number of decision variables, the number of dimensions, we're not just going to be able to eyeball some picture. So how can we get a handle on what the optimal might be? And so stopping shy of actually computing it, let's actually just think about how would we convince somebody that given a feasible solution, what would convince you that it actually is an optimal solution? Just like when we talked about flows, what would convince you that a flow is actually maximum? What would convince you that a matching is actually maximum cardinality or minimum cost? So let's think about this. Let's suppose we didn't know what the optimum was.
00:04:51.466 - 00:05:32.598, Speaker A: We were just staring at this linear program. We wanted to understand upper bounds on how big the optimal solution could possibly be. So so one kind of very trivial upper bound would be an upper bound of two. How can we derive that? Well, if you have a feasible point, x one x two. So feasible meaning satisfying all four of these inequalities, and we look at the objective function value I-E-X one plus x two. Well, certainly that's bounded above by four x one plus x two. Actually, I'm using something here.
00:05:32.598 - 00:05:41.658, Speaker A: What am I using? X one is non negative. Right? So if x one was negative, this would be wrong.
00:05:41.744 - 00:05:41.994, Speaker C: Okay.
00:05:42.032 - 00:06:27.190, Speaker A: But with x one non negative, a bigger coefficient only makes it a bigger quantity. And so this is by the first constraint. And now using the third constraint, just sort of by definition of feasible, we find that it can't be bigger than two. Okay, so it's kind of an obvious argument about whatever the optimal solution to this linear program is, it's not going to be bigger than two. Okay, everyone clear? All right, so hopefully you found that sort of trivial. Actually, if you think about it, this was really stupid. It'd be better to use the last constraint instead of one on the optimal solution.
00:06:27.190 - 00:06:31.738, Speaker A: So this is a tighter upper bound, better upper bound. This is a stronger statement than the last one.
00:06:31.824 - 00:06:32.460, Speaker C: Okay?
00:06:33.230 - 00:07:18.918, Speaker A: But actually, if you think about it, there's no reason to just use a single constraint to derive upper bounds on the optimal solution. We should feel free to blend them as it suits our purposes. So to see what I mean, notice that I can write x one x two as a convex combination of the two constraints. So I take one seven times four x one plus x two plus three seven times x one plus two x one. This holds with equality, okay? It's just algebra. I actually only need an inequality like in the first two cases, but I happen to have equality.
00:07:19.094 - 00:07:19.818, Speaker C: Okay?
00:07:19.984 - 00:08:44.654, Speaker A: So again, this is just algebra. And now, because assuming that x one and x two are feasible, by the third constraint, we know this number cannot be bigger than two no matter what. By the last constraint and feasibility, we know this cannot be bigger than one. So that gives us an upper bound on five seven. So this you should find a quick and convincing proof that whatever the optimal solution to this linear programming is, the objective function value is definitely not bigger than five seven, okay? All right, now in this particular case, we actually know this is a tight upper bound because we know there's a feasible solution to this linear program, 3727, that actually does attain this upper bound that actually has objective function value as high as five seven. So clearly we're not going to prove any better upper bound, okay? This is the best as it gets. So any questions about that's? All right, so that's more or less duality in a nutshell, but so let me develop it more generally.
00:08:44.654 - 00:09:33.680, Speaker A: So if you think about it, nothing about this argument uses the fact that we're in the plane or uses the fact that there's only a very small number of constraints. We're just saying, oh, if you can just use suitable linear combinations of constraints to derive upper bounds on the optimal objective function value. So what does that look like in general? Here's what it looks like in general. So suppose we have not just two decision variables and four constraints, but an arbitrary number. So consider a linear program of the following form, and I'll call this p for reasons that will become obvious. It so maximize linear combination of decision variables. Decision variables are x one through x n.
00:09:33.680 - 00:09:52.966, Speaker A: Then we have our linear constraints one to n. And so let me just go with, for the moment, linear programs that have the same form as the one up there where we're maximizing, we have inequalities, and we have non negativity constraints.
00:09:52.998 - 00:09:53.194, Speaker C: Okay?
00:09:53.232 - 00:10:12.602, Speaker A: We'll talk about other forms in a second. So that's what one linear constraint looks like. In general, we have M of theme, and then again, let's think about scenarios where all of the decision variables have to be non negative.
00:10:12.746 - 00:10:20.400, Speaker C: Okay? U.
00:10:22.310 - 00:11:01.294, Speaker A: Now, we talked a little bit on Tuesday about how there's a lot of different forms of linear programs, but they're all equivalent. It's easy to go back between one and another. If you have a minimization linear program, you can just multiply the objective coefficients by minus one to turn it into maximization. If you have inequalities going the opposite direction, you can flip them by multiplying by minus one. And if you have equations, you can simulate those with two inequalities going both directions. So there's a sense in which it's basically without loss of generality to talk about this form, but still I'll talk about other forms a little bit later. Just in this generality, there's no way to eyeball anything and just sort of deduce what the optimal solution is.
00:11:01.294 - 00:11:44.186, Speaker A: So let's again take a step back and say, well, what if we at least wanted to just convince ourselves of legitimate upper bounds on what the optimal solution could be? Okay, so let's just follow the previous approach. So suppose all right, so what were we doing in these arguments? Okay, we were taking a multiple of the first constraint plus a multiple of the second constraint, and we were playing around with what multiple we should use. So we're going to have y one through y m. These are just going to be those multipliers on the constraints.
00:11:44.298 - 00:11:44.814, Speaker C: Okay?
00:11:44.932 - 00:11:49.914, Speaker A: So because there's m constraints, there's going to be m multipliers.
00:11:50.042 - 00:11:50.720, Speaker C: Okay.
00:11:53.430 - 00:12:56.898, Speaker A: So suppose you have non negative multipliers that satisfy. So what was really driving the argument here, right? So let's look at those first inequalities. What was important was that your convex combination dominated the objective function, coefficient by coefficient. Okay? So four and one or at least one in one, one and two or at least one and one, that's what we need. So in general, what does it mean that your linear combinations dominate the objective, dominate the CJS? Well, what it means is that for every coefficient of the objective function so of which there's n so for all I equal j equal one up to n. It should be the case that if I look at the coefficient that I get on a given decision variable which in general is written like this, this should dominate that coefficient of the objective.
00:12:57.074 - 00:12:57.800, Speaker C: Okay?
00:12:59.370 - 00:13:15.980, Speaker A: So we're going to call this star. So for example, in the first argument up there, we took y one equal to one and y two equal to zero.
00:13:16.990 - 00:13:17.738, Speaker C: Okay?
00:13:17.904 - 00:14:15.840, Speaker A: And it was the case that, for example, for the first decision, variable four was bigger than one, and in the second decision, variable one was bigger than one. In the second argument, we took y one equal to zero and y two equal to one. And again, this was satisfied. And then the final argument, we took y one equal to one seven, y two equal to three seven. And actually, this wound up holding with equality for both j equal one and two. In that case, okay? All right, so suppose this is true. From this we can extract an upper bound on how big the optimal solution to our linear program could possibly be.
00:14:15.840 - 00:14:22.570, Speaker A: And it's just a generalization of this argument here.
00:14:22.740 - 00:14:23.074, Speaker C: Okay?
00:14:23.112 - 00:15:10.058, Speaker A: So suppose y are non negative and satisfies star. Then for all feasible solutions x to our linear program p, we can write as follow, we can write the following. This is the objective function value of x by definition, remember, we want an upper bound on the optimal objective function value. So I'm taking your favorite feasible solution. I'm going to upperbound its objective function value. Here it is. Okay, so now we just follow our nose, right? So what do we know? What do these y's satisfy? Well, if we take the non negative linear combination of the constraints as specified by the y's, it dominates the c's.
00:15:10.058 - 00:15:28.854, Speaker A: It's at least as big as the c's. So what that means and again, this is just corresponding to these two lines here. It means I can replace CJ by the left hand side of star.
00:15:29.052 - 00:15:29.462, Speaker C: Okay?
00:15:29.516 - 00:16:18.200, Speaker A: That's what star means. Again, I'm using here that each of the x's is non negative. So boosting its coefficient only gives me a bigger number. So CJ times sum over I equals one to M-Y-I-A-I-J okay, times ah, goodbye. About that. Okay, so this is star plus x non negative. All right? So whenever you have just the general rule, whenever you have your double summation and you don't know how to interpret it, just reverse the order of summation and see if you get something you can make use of.
00:16:18.200 - 00:16:36.890, Speaker A: So we'll do that here. So instead of summing over j and then i, we sum over i, and then j. So let's yank out the part that doesn't depend on j. So we get a yi there, and then a sum over j equal one to n of AI j XJ.
00:16:39.310 - 00:16:39.926, Speaker C: Okay?
00:16:40.048 - 00:17:19.850, Speaker A: So that's just algebra. Rearranging well, this is something we know something about. X is a feasible solution. It satisfies every constraint of the linear program p. In particular, this linear combination has to be at most b sub i, okay? By feasibility. And so this is using that x is feasible, and we're again using non negativity this time that the y's are non negative.
00:17:20.590 - 00:17:21.340, Speaker C: Okay?
00:17:25.950 - 00:17:59.080, Speaker A: So that is the natural generalization of these simple upper bounds for our toy example. And so, again, what is the upshot? The upshot is that for all y, again, these are m vectors such that star holds the optimal solution. The optimal objective function value of our linear program is bounded above by the dot product of b with I.
00:18:00.730 - 00:18:01.480, Speaker C: Okay?
00:18:05.930 - 00:18:11.860, Speaker A: And so, if you think about it, this right hand side is exactly the upper bounds we were getting in our toy example when we took.
