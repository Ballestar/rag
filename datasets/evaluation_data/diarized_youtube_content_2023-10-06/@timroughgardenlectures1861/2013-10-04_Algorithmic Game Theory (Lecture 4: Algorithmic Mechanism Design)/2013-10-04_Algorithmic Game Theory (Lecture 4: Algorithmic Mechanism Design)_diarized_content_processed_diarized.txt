00:00:01.210 - 00:00:32.440, Speaker A: Just a couple of quick reminders. So, the first exercise set is due now, you should have either already emailed it to the Tas, or you should have already given them a hard copy of your solutions. The second exercise set has been posted. You can find that from the website. In general, I don't plan to print anything and bring it to class. That seems like an antiquated sort of ceremony at this point. So check out the website, the second exercise set, which covers this lecture and the previous lecture you can find there.
00:00:32.440 - 00:01:33.798, Speaker A: So, any questions before we get started? Okay, so last lecture we stated and proved Myerson's Lemma, and this lecture and next week are going to be devoted mostly to applications of it, to using that as a foundation on which we build further mechanism design theory. To remind you, Myerson's Lemma is a characterization of the allocation rules that can be extended to dominant strategy incentive compatible mechanisms. So an allocation rule, remember, is your decision of who wins what. And the question then is, given such a decision, can you come up with payments? Who pays what? So that that coupling of the allocation and the payment rules is dominant strategy incentive compatible. Sometimes you can, sometimes you can't depends on the allocation rule. But in a very simple conceptually way, it depends on whether that rule is monotone. So there exists such payments if and only if the allocation rule is monotone.
00:01:33.798 - 00:02:04.980, Speaker A: And we saw examples of monotone allocation rules last time. We'll see more today. Furthermore, in the case where you have a monotone allocation rule, there is no ambiguity in how to define the payment rule. There is only one way to do it if you normalize things, so that zero bidders pay zero. And moreover, we derived an explicit formula for what those payments are. We did that in the course of proving Myerson's Lemma for the case of a piecewise constants allocation function x. I have rewritten that payment formula on the board here.
00:02:04.980 - 00:03:02.306, Speaker A: So the first brief thing I want to do today is give you further intuition for this payment rule. We discussed how it's in some sense the area to the left of the allocation curve on Monday, but now I want to apply it to sponsored search auctions, show you fully, explicitly what is the awesome sponsored search auction. That is, how do you define payments when you use the surplus maximizing allocation rule, which, you'll recall, is to assign the jth highest bidder to the jth slot. And as usual, we're assuming that higher slots are better. So we have this notion of click through weights or CTRs, which is your probability of getting a click given you're displayed in the j slot. And those only go up as the slots get higher and higher. So we argued on Monday that this is a monotone allocation rule.
00:03:02.306 - 00:03:47.906, Speaker A: The higher you bid, the higher the slot you'll get and the better your CTR so Myerson's Lemma gives us an explicit payment formula for how you should assign payments if you want to be DSIC. So let's just go through what those are. That is all we're going to do at the moment is instantiate this formula, interpret it for this particular single parameter environment. This is just a special case to which Myerson's Lemma applies. Here. B is a bid profile, a bid vector I is a particular bidder. And we're asking what should it pay?
00:03:48.088 - 00:03:48.820, Speaker B: Okay.
00:03:50.730 - 00:04:13.226, Speaker A: So the way to think about this formula here so we're thinking about a particular bidder I and we fix the bids, b minus i, the bids of everybody else. We want to compute the payment that bidder I makes, and it bid something. It bid like ten, whatever. The way to think about this formula is as a thought experiment just in our minds. We start bidder I's bid at zero again. The other N minus one bidders. We keep their bid fixed.
00:04:13.226 - 00:04:38.398, Speaker A: B minus I is fixed. And we raise bidder I's bid from zero all the way up to what it actually bid B sub i. Okay, so we have a piecewise constant allocation curve. So along the way, the allocation that gets awarded to bidder I at this current imaginary bid will jump. Initially, it'll be zero. Then it'll jump. Maybe it jumps multiple times before it finally gets its actual allocation at its actual bid.
00:04:38.398 - 00:05:22.130, Speaker A: And recall the payment formula. You just track the jumps every time there's a jump. You add that to the running sum. What do you add? You add the magnitude of the jump in the allocation times, the position, the bid at which you saw that jump. So what does that mean in the context of sponsored search? Well, I think it's easiest to think about the highest bidder, which is the one that gets the best slot. So just to keep the notation down, let's reindex the bidders so that in this bid profile, bidder number one has the highest bid, and so on. Okay, so assume, without loss of generality, that we're looking at a bid profile which is sorted just for ease of notation.
00:05:22.130 - 00:05:33.510, Speaker A: So now think about bidder one, the one with the highest bid. So what is its allocation? So what is its x value in this bid profile?
00:05:35.970 - 00:05:36.750, Speaker C: Alpha one.
00:05:36.820 - 00:05:59.240, Speaker A: Alpha one. It gets to the top slot. The CTR of the top slot is alpha one. Okay, now imagine that we reset in our minds, we reset its bid to be zero. So it's going to be the lowest bid, and then we slowly increase it from zero up to its actual bid, b sub one. How is its allocation going to change? What's the trajectory of the allocation as we move its bid in that way?
00:06:03.980 - 00:06:04.488, Speaker B: Good.
00:06:04.574 - 00:06:51.556, Speaker A: So initially it's zero because it's the worst bidder of all. At some point, the imaginary bid is the KTH highest. At that point, it gets the KTH slot and the allocation is alpha sub k, then it becomes alpha k minus one, alpha k minus two, and so on all the way up to alpha sub one. So the magnitude of the jumps in the allocation of bidder one is going to be the jump in consecutive CTRs that is a generic jump will have the form alpha j minus alpha j plus one. Okay, so this difference corresponds to a term of this form, a jump in its allocation. So now the next thing to figure out is what are the positions, what are the bids at which the allocation jumps.
00:06:51.668 - 00:06:51.944, Speaker B: Okay.
00:06:51.982 - 00:07:35.992, Speaker A: And I think it's easiest to think about the final jump, the jump. So remember, this is the top bidder, b sub one. We're fixing everyone else's bids, they're lower and they're in sorted order. And eventually the allocation of this bidder is going to jump from alpha two to alpha one. What is the location? That is, what is the imaginary value of this bid at which you trigger this jump from alpha two to alpha one? B two, you have to beat out everyone else and the nearest competitor is b sub two, the second highest bid. Okay, so when j is one, when we're looking at alpha one minus alpha two, the point at which that happens is b sub two. And in general the position at which you have this jump in the allocation is going to be b sub j plus one.
00:07:36.126 - 00:07:36.810, Speaker B: Okay.
00:07:37.820 - 00:08:14.944, Speaker A: And now we sum over all of the breakpoints. And so there's a jump starting from the worst slot, the K slot, all the way up to the slot that it actually receives, whoops should be j equals I excuse me, up to the slot that it actually receives, which is the Ith slot. Okay, so that's it. Okay, so that is exactly the payment. So if you're the ith highest bidder and you get the Ith slot, this is what you should pay. That's what myoson lemma dictates. Now this becomes.
00:08:14.944 - 00:08:34.010, Speaker A: So this is already reasonably simple. Obviously you could easily write an algorithm to compute these that would run blazingly fast. Let me just point out. So I guess I'm interpreting here, alpha k plus one as being equal to zero. Now remember, in the context of question.
00:08:35.100 - 00:08:39.710, Speaker C: I is what it actually did. So then what's b sub j plus one.
00:08:41.760 - 00:08:43.452, Speaker A: That would be b I plus one.
00:08:43.586 - 00:08:44.524, Speaker C: Sorry, it's farther down.
00:08:44.562 - 00:08:44.860, Speaker B: Okay.
00:08:44.930 - 00:09:20.410, Speaker A: Yeah. So remember the top slot is one and then they go down. So you're looking at all the slots below you on the page, which are higher indices. Now remember in sponsored search the way we modeled it is we said we were thinking of advertisers as bidders as not having a value for an impression for being shown per se, except inasmuch as an impression leads to a click. So their value is really fundamentally for clicks. And with that modeling, the way it actually works in practice is payments are assigned when you get a click, okay? Not when you get shown. It's free to get shown, but if you get clicked on, that's when you have to pay.
00:09:20.410 - 00:09:35.484, Speaker A: So this is just the payment that you're supposed to assign someone for being shown. If we're only going to charge per click, which is only going to happen an alpha I fraction of the time, then we should scale this up by one over alpha I for the payments to be correct.
00:09:35.602 - 00:09:36.270, Speaker B: Okay?
00:09:39.460 - 00:09:57.030, Speaker A: So you multiply this by one over alpha I to get per click rather than per display, rather than per impression payments. Okay? So it's just going to be a one over alpha I up front here.
00:09:59.960 - 00:10:00.710, Speaker B: Okay?
00:10:03.000 - 00:10:42.916, Speaker A: And if you think about it, you have to think about this for a minute or two to see this. But once you divide this by alpha sub I, actually, this has a really simple interpretation. So basically what you pay per click is just a suitable average, a suitable Condex combination of the bids, of the advertisers in the slots worse than yours, okay? So you're just going to place some average of the lower bids. That's what you pay per click. And this is in fact very close to the auctions used in practice for sponsored search. Full disclosure, the auctions used by all the major search engines are a little bit different. It's because of a historical accident actually.
00:10:42.916 - 00:11:08.900, Speaker A: So by historical accident, the auctions used in practice are based on what's called the generalized second price auction. And it's a little bit simpler to describe than this one, where if you're an advertiser and you're assigned to slot J, you don't play an average of the slots below you, you just pay the bid immediately below you. So you're going to play bid BJ plus one, not an average of BJ plus one through BK.
00:11:09.060 - 00:11:09.384, Speaker B: Okay?
00:11:09.422 - 00:11:47.928, Speaker A: So the pricing is a little bit more aggressive in the auctions used in practice. Now by Myerson's Lemma, we know that if you want to be dominant strategy incentive compatible, you have no choice. This is the only thing you can do. So as soon as I tell you that the auctions in practice use a slightly different payment rule, you already know they cannot be dominant strategy and center compatible. They cannot be and they're not. They are a little bit harder to figure out how to bid in strategically than this auction would be. That said, there's some nice theory and you will go through the major points in problem three of your problem set, which shows that these two auctions are in know equivalent in a reasonably strong sense.
00:11:47.928 - 00:11:57.912, Speaker A: They're not the same auction and in particular the one in practice is not DSIC, but it always has an equilibrium which in some ways is simulating the dominant strategy outcome of this auction.
00:11:57.976 - 00:11:58.156, Speaker B: Okay?
00:11:58.178 - 00:12:05.070, Speaker A: So again, that's problem three on the problem set. So questions about sponsored search, that's going to be all I say about it for now.
00:12:09.140 - 00:12:10.690, Speaker C: Why is it different?
00:12:12.180 - 00:13:07.244, Speaker A: Essentially because they didn't know this theory. Yeah, to the point that there are people at these search engines that in some sense would prefer to that discuss and perhaps would even prefer to switch to this payment rule because this is requiring bidders to work a little bit harder than they would have to otherwise. Yeah, that's the reason. So it was not necessarily intentional to deviate from this theory when they first designed it. And of know, once you design it and it's making billions of dollars, it's it's high overhead to change other questions. Okay, so that's our first application, instantiation of Myerson's Lemma for the day. What I want to do next is talk about another type of auction, knapsack auctions.
00:13:07.244 - 00:13:42.684, Speaker A: This is going to be yet another single parameter environment. So it is yet another special case. It's yet another instantiation of the general tool which I've given you. All right, so here's the setup. So it's a single parameter environment. So we have N bidders, each with a private valuation, as usual. But in addition, each bidder I has a size W sub I.
00:13:42.684 - 00:14:27.836, Speaker A: Everybody knows what this is. This is common public information. And then the usual private valuation. For example, bidder I might have a television ad and the size is the length of this television ad, which is verifiable and known. And then it's some willingness that has some value, which is its willingness to pay to have its TV ad shown during the Super Bowl. The seller has a capacity, capital W. Perhaps that is the length of some commercial break, perhaps that's three minutes.
00:14:27.836 - 00:14:47.088, Speaker A: And the bidder sizes are 20 seconds, 30 seconds, 45 seconds and so on. Question no, those are different units. Okay, so your size might be 20 seconds and your valuation might be $10 million, but it's $10 million for the.
00:14:47.094 - 00:14:48.768, Speaker C: Whole 20 seconds rather than per second.
00:14:48.854 - 00:15:09.236, Speaker A: Right. So you cannot split an item in two. Okay, so it's just an indivisible item. You cannot show half of the TV app. Okay, so that's one story. You can of mean napsack problems, as you know, come up everywhere whenever you have a shared resource with some budget on its use. Maybe these are files you're storing on a server.
00:15:09.236 - 00:16:06.964, Speaker A: Maybe these are data streams you would need to pack into a communication channel. Maybe they're processes you need to schedule on a supercomputer whatever. Okay, all right, so what are the possible outcomes? So, remember, in a single parameter environment, there's this set, capital X, which says what you can legitimately do as the designer. Well, so the feasible set are just the correspond to the subsets of bidders whose sizes actually obey your capacity. So these are zero one vectors such that so again, one here means you've chosen a bidder as a winner, and a zero indicates you have not chosen this bidder. It's a loser. And so if you look at the sizes of the bidders that you've chosen that should be at most the available capacity.
00:16:07.092 - 00:16:07.770, Speaker B: Okay?
00:16:09.580 - 00:17:47.870, Speaker A: So if you like a single item auction, it's just the special case where every size is one and where the capacity is one. If you had K copies of an item, one per customer, then you'd have capital W equal to K and again all the sizes equal to one. Here different bidders can have different sizes. All right, so what I want to do next is apply the same two step design approach I've been advocating all along toward designing allocation and payment rules. First step without justification, we assume that the bids are equal to the true valuations and we ask what would we do then? How would we maximize surplus? What algorithm would we use then having made that decision in step one we try to get the payments right so that we have a dominant strategy instead of a compatible mechanism, thereby justifying our assumption that the bids were equal to the actual valuations. So step one, if in fact the bids equaled the valuations, what would we do if again we were striving for one of these awesome auctions? So we want to maximize surplus. So what our allocation rule would be? Well, assuming the bids equal the values, again, for now without justification, we would just look at the surplus of the various feasible solutions and we take the highest number we could get.
00:17:50.400 - 00:17:51.150, Speaker B: Okay?
00:17:51.760 - 00:18:35.796, Speaker A: So remember, X is just all of the subsets of bidders who actually fit in the knapsack, who obey the capacity. Amongst all of them we're going to select the one that maximizes the surplus. Or at least if the BIS equal the vis, this would be the choice that maximizes the surplus. That is we would solve the Napsack, the instance of the Napsack problem induced by the bids that we were given and the sizes which we already know are priori, right? So I'm assuming so I list algorithms as one of the prerequisites of this class. So I assume you've seen the Napsack problem before. If you haven't, or you need a reminder, I teach it in 161. And algorithms here and there's some videos of my lectures on Napsacks.
00:18:35.796 - 00:19:05.444, Speaker A: I'll go ahead and post those on the web page if you need to review. But in any case, this is the Napsack problem. I give you values, I give you sizes. And you want to maximize the value in the Napsack subject to capacity. And so what I'm saying is this allocation rule, this surplus maximization problem is exactly a Napsack problem. The values are given by the bids, the sizes you knew up front. So this is step one.
00:19:05.562 - 00:19:06.180, Speaker B: Okay?
00:19:06.330 - 00:19:37.996, Speaker A: Assuming without justification that bids equals values, what would you do if you want to maximize surplus? Well just by definition you'd solve this Napsack problem with the bids equal to values. So step two says given that design choice, let's get the payments right now that we have Myerson's Lemma. We understand what that means. Basically, we cross our fingers hoping the allocation rule is monotone. And if it is, we're done. If it's not, back to the drawing board. But if it is, we're done.
00:19:37.996 - 00:19:45.520, Speaker A: Myerson's Lemma tells us how to implement step two. In fact, this rule is indeed monotone.
00:19:48.740 - 00:19:49.200, Speaker B: Okay?
00:19:49.270 - 00:20:25.112, Speaker A: It's not hard to prove. I ask you to prove it on exercise set number two. In fact, more generally, any single parameter environment, surplus maximization leads to a monotone allocation rule. It is not just about the Napsack problem. Very generally, surplus maximization gives you monotonicity and therefore by Marison's Lemma, you get DSIC for free. We first saw this with the vicary auction, right? We might have wanted to give the item to the highest bidder, but we didn't know who it was in advance. But we discovered the Vicary auction solved that surplus maximization problem as well as if we knew the data in advance.
00:20:25.112 - 00:20:50.548, Speaker A: We are now seeing a much more general form of that. Any single parameter environment. If you knew the values up front, you might want to do surplus maximization. What we're learning from these two tools first of all, the claim that surplus maximization is monotone. Secondly, Myerson's Lemma, which tells us how to take a monotone rule and make it incentive compatible. Again, it says we can maximize surplus essentially for free. We didn't know the data up front.
00:20:50.548 - 00:21:34.176, Speaker A: It doesn't matter. We still can do it. Giving bidders dominant strategies. So this rule is monotone and therefore Myerson's Lemma gives a payment rule P such that XP is di d sic. Okay? And again, part of what I want to do this lecture is just develop your intuition about what these payment rules look like and kind of make them a little less mysterious.
00:21:34.288 - 00:21:34.950, Speaker B: Okay?
00:21:35.640 - 00:22:12.850, Speaker A: So let me actually digress slightly. So this is just sort of existential, right? So this just says we can make surplus maximization incentive compatible. Let's drill down and look at what these payments actually are, okay? Because they're not so bad. So let's now take it on faith that this allocation rule is monotone. What's the range of this allocation rule? What kind of numbers does it ever spit out? It's either zero or one, right? This is like simpler than sponsored search. You either win or you lose. Your TV ad is shown or it's not.
00:22:12.850 - 00:22:24.062, Speaker A: So what does a monotone zero one function look like? It's pretty simple, right? Zero for a while, then it jumps to one.
00:22:24.196 - 00:22:24.880, Speaker B: Okay?
00:22:28.850 - 00:22:37.838, Speaker A: Remember, when we draw these curves, we're thinking about a fixed I and fixed bids by the other bidders, okay? And we're just varying this one bidder's bid.
00:22:37.934 - 00:22:38.580, Speaker B: Okay?
00:22:39.670 - 00:23:04.906, Speaker A: So there's some point z at which x of z and again, I'm looking just at I's allocation given b minus I, there's some point at which it jumps from zero to one. And so this payment formula is not so hard to write down or understand when you have a zero one monotone function.
00:23:05.088 - 00:23:05.820, Speaker B: Okay.
00:23:07.550 - 00:23:31.794, Speaker A: So it's clear that if a bidder loses, then its payment is going to be zero if a bidder wins. So if this is where Bi is and the bidder wins, what do we do? Well, we look at the breakpoints to the left. There's only one of them. We look at the magnitude of the jump. Well, that's one. And then we look at the position in which that jump happened. Okay, so that's the z.
00:23:31.794 - 00:24:06.000, Speaker A: Okay, so in this picture, the payment of bidder I, when it bids on the winning side, it's just equal to z. That is, the payment of a bidder in one of these zero one monotone rules is just the minimum bid that it could have gotten away with and still won the smallest bid at which it would continue to win. And now think about the vicary auction. This is a totally legit way to interpret the victory auction. What does the winner pay? They pay the smallest bid at which they would have still been the highest bidder I e. The second highest bid. Exact same principle that we're seeing here.
00:24:06.000 - 00:24:36.790, Speaker A: So if bidder I wins, then the payment is what's often called the critical bid, which is what I just said, the minimum bid at which I still wins.
00:24:37.290 - 00:24:38.086, Speaker B: Okay.
00:24:38.268 - 00:24:39.000, Speaker A: Yeah.
00:24:39.450 - 00:24:42.230, Speaker C: What do we do about possibilities like ties?
00:24:44.010 - 00:25:00.800, Speaker A: Yeah, I mean, the theory works fine no matter how you want to handle ties. So, I mean, you know, if if a tie broke in a way that you lost, obviously you should pay zero, and if a tie broken away that you won, then you should use this formula. Okay.
00:25:03.730 - 00:25:04.574, Speaker B: Good.
00:25:04.772 - 00:25:20.214, Speaker A: So, again, I've given you Myerson's Lemma in a pretty general form, and that's because I want to instantiate it in lots of different ways for lots of different applications. But often in a concrete situation, you should not be scared of this formula. It's often something very simple and easy to understand, like this critical bid payment.
00:25:20.332 - 00:25:21.000, Speaker B: Okay.
00:25:22.410 - 00:25:29.720, Speaker A: Yeah. What do you mean?
00:25:34.110 - 00:25:38.330, Speaker C: The pricing function didn't change because we had the master constraint?
00:25:40.670 - 00:26:12.566, Speaker A: No, it does. Right. What do you mean? I mean, the English sentence, your payment is the smallest thing at which you continue to win. That English sentence is the same in both cases. And that English sentence remains true when you have zero one allocation vectors in your feasible set. Okay, but in the Vicory auction, the smallest bit at which you continue to win is the second highest bid overall in a napsack problem, the smallest bit at which you continue to win. It's not easy to explain what that is.
00:26:12.566 - 00:26:56.370, Speaker A: I mean, it is what it is, but that doesn't necessarily admit a simple description. Okay, so I have a question for you then. So surplus maximization, monotone rule payments, DSIC awesome. Or is it is this an awesome? Someone had an opinion. Yeah. So remember there was in addition to surplus Maxation and DSIC, which is what I've been talking about today so far. We also wanted to be computationally efficient.
00:26:56.810 - 00:26:57.560, Speaker B: Okay.
00:26:59.290 - 00:27:28.570, Speaker A: So these were the ingredients and the algorithm that I've described to you, satisfies one, satisfies Two does not satisfy three. In fact, no Auction can satisfy forget about one. No Auction can satisfy two and three unless P equals NP.
00:27:28.650 - 00:27:29.280, Speaker B: Okay.
00:27:35.110 - 00:27:58.246, Speaker A: So answer no. And the reason is that we don't know of a polynomial time algorithm to solve the Napsack problem. Equivalently, we don't know of a polynomial time implementation of this allocation rule. And of course we can say more. It's not that we're just stupid. We haven't found the right algorithm. It's an NP complete problem.
00:27:58.246 - 00:28:50.586, Speaker A: So if P is not equal to NP, there does not exist a polynomial time implementation of this allocation rules. The question, so what kind of auction should we use for this knapsack auction? Right? I mean, just because it's empty complete, the problem doesn't go away. And so we'd still like some theory to guide us about how to approach this problem. So if we can't have all three of these goals simultaneously suggest we should relax at least one of them, one of these conditions. So the question then is which one should we relax? So, like, what about condition one? What if we relax condition one?
00:28:50.608 - 00:28:51.500, Speaker B: Would that help?
00:29:00.270 - 00:29:02.940, Speaker A: It's actually sort of a stupid suggestion. Why?
00:29:11.150 - 00:29:14.514, Speaker C: If they're not really there to evaluation, we don't know what those are.
00:29:14.672 - 00:29:22.690, Speaker A: There's actually an even more fundamental problem than that. You're right. I agree, and that'll come up later. But there's an even more basic problem. Yeah?
00:29:22.760 - 00:29:25.982, Speaker C: Isn't the surplus maximizing what got us the NP?
00:29:26.126 - 00:29:41.500, Speaker A: Exactly. Forget about one. One was never the problem. Two and three are incompatible already. Okay, so we'll access as much as you want, throw it out completely. You still can't get two and three. So relaxing one doesn't help.
00:29:41.500 - 00:30:35.122, Speaker A: You can't have two and three unless P equals NP. Okay, so there will be cases this will more be next quarter where it's interesting to relax one, but that's not going to get us out of our current bind. Okay, so what I want to talk about are relaxing the other things. And so one totally reasonable approach, it's not going to get much air time and lecture, but it's a totally reasonable approach is to relax three, especially in the context of Knapsack. It seems actually maybe not that bad to relax three. Why is that? Do we know any at least nontrivial, non brute force search algorithms for Napsack? Sure. Right.
00:30:35.122 - 00:31:25.690, Speaker A: Certainly, if you took algorithms from me, you do. So there are dynamic programming algorithms for solving the Napsack problem, what's called pseudopolynomial time. But for many instances that you come across, this is much better than, say, two to the N. It's much better than exponential time. So e g solve Napsack in pseudo polynomial. Really? The more general point here is if the Knapsack instances are small and or structured enough, and you have enough time and machine power to solve them in your budget, then by all means, go for it. Don't let MP complete stop you.
00:31:25.690 - 00:31:43.770, Speaker A: If you can solve them exactly for whatever application domain you're working in, go for it. That gives you implementation of the surplus maximizing rule. And again, you can use Meyerson's Lemma. You still have monotonicity, even if you took super polynomial time to solve it. So you can still have monotonicity. You can still apply. Myerson's lemma.
00:31:43.850 - 00:31:44.382, Speaker B: Okay?
00:31:44.516 - 00:31:51.540, Speaker A: So if your Napsack instances are small enough and you have enough time, go ahead and do this totally legitimate way to circumvent the problem.
00:31:54.230 - 00:31:55.060, Speaker B: All right?
00:31:55.590 - 00:32:19.814, Speaker A: But what I want to talk a little bit more about is the case where your knapsack instances are sufficiently big that this doesn't cut it. Maybe you're solving these options in real time. Maybe you don't want to use dynamic programming. It's too slow. You want something which is more like a near linear heuristic for a Napsack algorithm. That's what you have to use to get into your time budget. But differently.
00:32:19.814 - 00:33:17.850, Speaker A: What I want to think about is insisting on one and three and relaxing two. Okay, relaxing two. Hopefully as little as possible. So this brings us to a sub branch of algorithmic game theory called algorithmic mechanism design. I'm actually not going to say all that much about this branch. I'll talk about it in lecture for maybe 30 minutes. You'll have two or three homework problems on it.
00:33:17.850 - 00:33:46.054, Speaker A: That's about what you're going to see about this. Okay, I don't want you to get the wrong impression. I mean, this is one of the earliest concerns on the boundary of game theory of economics and computer science, and it's really been a cottage industry. There's been a lot of work on this over the past 15 years. I'll only have time to give you a taste of it. The chief concern of algorithmic mechanism design is to say, well, problems like knapsack auctions and of course, even harder problems, which you'll see on the homework. You can't get all three of these.
00:33:46.054 - 00:35:01.710, Speaker A: What if we insist on computational efficiency? We insist on the strong incentive guarantee of dominant strategy incentive compatible. How close to maximum surplus can we get? How much can we get away with relaxing surplus optimality and get recover computational tractability? So that's the name of the game in algorithmic mechanism design. Now, an equivalent version of this. What's cool is, so one is this DSIC property, right? But what's cool is we now have Myerson's Lemma, which tells us exactly which allocation rules are implementable says it's exactly the monotone ones. So we can replace one, which is this sort of hard to grok incentive compatibility condition with just the much simpler and much more operational monotonicity condition. So really the way people in this field think about algorithmic mechanism design is you want to get as close as possible to. Optimal surplus to the best possible outcome.
00:35:01.710 - 00:35:49.226, Speaker A: We know we have to relax it because it's empty hard. We want to be polynomial time, and we want to be monotone. From one direction of Myerson's lemma. We know that as long as we're monotone, we'll be able to extend that to the DSIC constraint. The other direction of Myerson's Lemma says, we know we're not throwing out anything interesting by writing monotone here. There's no DSIC auctions that we're missing out on. So what's cool about algorithm mechanism design is it really has a very familiar flavor to people who work in algorithms.
00:35:49.226 - 00:37:23.500, Speaker A: So there's a field called approximation algorithms, which hopefully some of you have seen in your classes what approximation algorithm studies is. Well, for an NP hard problem, let's get as close to optimality as we can subject to polynomial time because of Meyerson's Lemma and rewriting this last constraint. Algorithm mechanism design is almost exactly the same field. Rather than getting as close to optimal as possible subject to polynomial time, you get as close as possible subject to polynomial time and some extra constraint on your algorithm monotonicity. So really, the way I tell people to think about this is algorithmic mechanism design boils down using Myerson's Lemma. It boils down to essentially algorithm design as many of us have lots of experience with in a sort of oddly constrained computational model with this extra monotonicity constraint. So the fact that you care at the end of the day about having a system with good performance guarantees, with strategic participants, that through Myerson's lemma, gets compiled into this very relatively easy to understand extra constraint on the kinds of algorithms that you design, okay? So that's algorithmic mechanism design, and I think the fact that it bears so much resemblance to something that the computer science field knows an awful lot about the design analysis of Heuristics, I really think that's one of the reasons why there's been so much work in progress in algorithm mechanism design over the past 15 years.
00:37:23.500 - 00:37:34.514, Speaker A: Question say it again on board.
00:37:34.552 - 00:37:42.660, Speaker C: Is that monosone allocation rule that should.
00:37:47.590 - 00:38:19.520, Speaker A: It'S a good question. So that's actually on exercise set number two. And in fact, that's the whole reason. I mean, just to give you a hint. Well, I guess it's sort of the hints on the exercise set too. But one of the reasons I digressed into this critical bid discussion so if you think about now that we know that the payments are so simple, it's just about understanding this critical bid. If you think about that for a little while, you realize that it means to compute payments for people, you just have to solve a few extra surplus maximization problems.
00:38:19.520 - 00:38:40.040, Speaker A: So you solve surplus maximization once to figure out the real allocation, and then you do it a few more times to get everybody's payments. But it's not obvious. So it's a good point. So computational tractability extends from that of the allocation rule to the payment rule that Myerson wants you to use, assuming it's, let's say, a zero one environment. So, yeah.
00:38:42.730 - 00:38:48.390, Speaker C: So that we had kind of explicit formula.
00:38:52.350 - 00:39:32.120, Speaker A: Right? So the question is, can you have an algorithm that computes that in polynomial time? Right? So the question is certainly whenever you see a closed form formula, you should be optimistic that there's going to be a polynomial time algorithm for evaluating it. That's usually a good sign, but it's not automatic. Where would what where would the chicken happen? Well, for starters, I didn't promise you there were only polynomial many breakpoints. Okay? But as we said, for zero one, there's only going to be one breakpoint. So again, that's suggestive good.
00:39:32.490 - 00:39:33.240, Speaker B: Okay.
00:39:34.410 - 00:40:07.870, Speaker A: Right. Best case scenario. Okay, so like I said, so approximation algorithms, subject studies, how little do you have to relax optimality to recover polynomial time? And we know a lot about the sort of best possible approximation algorithms for lots of different MB hard problems, really has just been unbelievable progress over the past, let's say, 20 years on that field. We know an awful lot. So here we're saying exact same question. Plus there's one more hoop you have to jump through. You have to be monotone.
00:40:08.030 - 00:40:08.740, Speaker B: Okay?
00:40:09.350 - 00:41:24.262, Speaker A: So the best case scenario, of course, is that you get the same answer for this problem as you do for the easier problem, where I don't force you to be monotone, okay? You can only do better. You can only get closer to optimal if all I insist on is polynomial time than if I also insist on something else, monotonicity. So the best case scenario is to match the best known, or even better, maybe the best possible, assuming P is not equal to NP guarantee, approximation guarantee, without any monotonicity or equivalently incentive compatibility constraint. Okay, so this is obviously the best you could hope for. This would be the Holy Grail, an algorithmic mechanism design. So we already faced some barriers. Just because of properties two and three, there's a limit on how close we can get to optimal in polynomial time, ignoring incentive compatibility constraints.
00:41:24.262 - 00:41:55.780, Speaker A: And the Holy Grail would be to prove that actually you don't lose anything more. You can get incentive compatibility for free. And we're a little spoiled right now, right? Because for exact surplus maximization, that's what we got. We could optimize the thing with these incentive constraints as well, as if we didn't have them. It didn't matter if we knew the values up front or not, we could do just as well in the surplus. So we've been spoiled. We want to just demand exactly the same thing, except for polynomial time heuristics for NP hard problems.
00:41:55.780 - 00:42:54.514, Speaker A: Okay, so that's the high level discussion. Let me make this a little more concrete by returning to Napsack options. One thing you should have learned at some point about the Napsack problem, in addition to it being NP hard, in addition to there being dynamic programming, pseudopolymal time algorithms is that it's not that hard to come up with heuristics that have provable guarantees. In particular, a very simple greedy algorithm, which I'll remind you of always gets within a factor two of the best possible solution. And again, if this is new to you, or if you need a refresher, check out the 161 based videos that I'll put up on the course page later today. So again, to be clear, we're given as instance a napsack problem. Specifically, we're given bids by bidders BIS.
00:42:54.514 - 00:43:16.160, Speaker A: We know their size is the wis, and we have some capacity capital W. We're punting on maximizing surplus completely. I'm again going to follow the two step design approach. I'm going to assume currently that the bids equal the values. We'll worry about justifying it later. And I'm going to try to get an algorithm which is really fast, not optimal, but not too far from optimal. That's the point of what we're going to do now.
00:43:16.160 - 00:43:55.020, Speaker A: All right, so I want a quick and dirty napsack. Heuristic like greedy. So maybe we just want to go through the items in some order, picking the ones that look the best. So what makes an item attractive or a bidder attractive in an absac problem? Well, we want to maximize the total value, so big bids look good. On the other hand, we have this capacity constraint, so small sizes look good. So we're going to sort the bidders according to the bang per buck. Okay, so how much money they get us per unit of capacity they chew up.
00:43:55.020 - 00:44:42.700, Speaker A: So these are the bang per buck ratios. Right now I just do one pass through the bidders bidder. One is the first one that we go ahead and allocate their TV ad. Then we allocate these guys TV ad, then the third one and then so on. At some point we're not going to have room for the next bidder. Okay, maybe we have three units of capacity left and the next bidder has size four. And at that point me just stop, say this is good enough.
00:44:42.700 - 00:45:11.458, Speaker A: It so pick winners in this order until one doesn't fit. I mean, in practice, you would for the analysis, you don't even need to bother to do that.
00:45:11.544 - 00:45:12.180, Speaker B: Okay.
00:45:15.350 - 00:45:54.206, Speaker A: Actually, for the monotheisticity proof, I think it matters how you implement it. So let's focus on this. Okay, so the question was, what if you reject a bidder because it has size four and you have three capacity left, and then later on there's a bidder that only has size two. They're not worth very much, but why not? Why not take them? So for this version of the algorithm, actually, as soon as we have a fail, we just ignore the entire suffix of the bidders. So that's the simpler version of the algorithm. Now this is almost good enough, but actually there's some pathological examples for this two step heuristic, if you have one bidder that's both very big and also very valuable. This can actually do the wrong thing.
00:45:54.206 - 00:47:00.158, Speaker A: So we're going to have a quick post processing hack just to address this special case of one big valuable bidder, which is we return the better of two solutions. And by better I just mean has a higher surplus. So return the better of the solution we just computed. So I'll call it the step two solution or the highest bidder, whichever is better. Okay, so there are cases where the first two steps will give you something that has surplus 17 but is actually just one bidder who bid 22 left, left out. And so then you pick the bidder who alone has surplus 22 over the one you computed that has surplus 17. So that's the heuristic.
00:47:00.158 - 00:47:21.820, Speaker A: I hope you've seen this before, but even if you haven't seen it before, I wanted to remind you what it is. And then what I'm going to state without proof. And again, check the videos if you want to proof or check your favorite algorithms textbook is that this is guaranteed to be close to optimal. In fact, it's guaranteed to be at least 50% of the maximum possible surplus. Questions? Question.
00:47:25.310 - 00:47:31.770, Speaker C: Efficiency without giving any thoughts to the Sic or social service organization.
00:47:33.870 - 00:48:18.210, Speaker A: No, we're definitely we're actually quite focused on surplus maximization. We're trying to get as close to optimal as possible subject to polynomial time. So the next thing I'm going to write down on the board is that this is guaranteed to be close to optimal surplus. Other questions clear on what the algorithm is? All right, so recall.
00:48:25.790 - 00:48:26.540, Speaker B: 50.
00:48:29.390 - 00:48:46.560, Speaker A: Has surplus. This is as usual, assuming that bids equal values, which again we haven't justified, but assuming that the output has surplus at least 50% times the maximum possible.
00:48:48.370 - 00:48:49.120, Speaker B: Okay?
00:48:49.890 - 00:49:18.120, Speaker A: And if you're not impressed by 50%, you can make some extra assumptions which make it better. So for example, if all of the bidders sizes is not too big a fraction of the napsack, like if everyone is at most 10% the size of the napsack, then actually this heuristic is guaranteed to be at least 90% of the maximum surplus. Okay, so this is a well known, very reasonable, super fast, right based, almost linear time. All you have to do is sort heuristic for approximating the knapsack problem.
00:49:18.650 - 00:49:19.400, Speaker B: Okay?
00:49:23.530 - 00:49:28.138, Speaker A: So any questions about that? This I'm stating without proof. This I'm hoping you've seen in the.
00:49:28.144 - 00:49:29.340, Speaker B: Past at some point.
00:49:31.390 - 00:50:13.210, Speaker A: Okay, so again, remember we're in the middle of this two step design approach. First we assume that the bids are truthful without justification and we do something. And now we have to pay the piper. We have to say, can we actually charge suitable payments? And as we know, that boils down to asking, is the allocation rule induced by this heuristic monotone? So again, what is this? This defines an allocation rule as input. You get bids, you run this algorithm, it chooses some winners and then as output you just say who the winners of the algorithm were? That's an allocation rule. It might or might not be monotone. Happily, it is monotone.
00:50:13.210 - 00:51:15.694, Speaker A: It's a little less obvious for this allocation rule than the ones we've been talking about so far, but it is indeed monotone. And that'll be on the exercise set. And so, of course, by Myerson's Lemma, this extends to an incentive compatible option, which we might call an approximately awesome option, okay? So we knew we couldn't get one, two, and three. We didn't relax one at all because it's a monotone rule. We get dominant strategy incentive compatibility. We didn't relax three at all. In fact, it's running in O of n log n time.
00:51:15.694 - 00:51:33.746, Speaker A: So we knew we had to relax two, but at least we relaxed it by a bounded amount. At least we still have a mechanism with provable surplus guarantees. Again, 50% in the worst case, but much closer to 100% under reasonable extra assumptions on the input.
00:51:33.938 - 00:51:34.680, Speaker B: Okay?
00:51:36.170 - 00:52:52.782, Speaker A: Now, I have a feeling I sort of lulled you into a state of complacency, right? So far in this class, I've only mentioned one non monotone rule, and it was a stupid rule, okay? It was the second highest bidder winning in a single item auction, which you'd never want to use anyways. So let me warn you, sometimes for some problems, there are natural heuristics, either the first thing you'd think of and or the state of the art, and they're not monotone. It's not automatic. There are allocation rules you would want to use but that are not monotone. And you'll see a couple on the problem set. In fact, problem four on the problem set is all about knapsack auctions, and a couple of those parts will ask you to verify the non monotonicity of natural rules that you would like to use, okay? And so this is really why there's been so much interesting work in this field of algorithmic mechanism design. If you just ask, how much optimality do we have to give up to get polynomial time? We know an enormous amount about that question.
00:52:52.782 - 00:53:40.170, Speaker A: It's a very sort of mature field at this point, approximation algorithms. So if all of those algorithms just gave us were just monotone anyways by Meyerson's Lemma, we'd be done. We could have technology transfer of the entire field of approximation algorithms en masse over to these approximately awesome auctions. But because so many of them are not monotone, that meant we had to go back and either tweak these heuristics or in some cases, even redesign new heuristics from scratch to accommodate this extra monotonicity property in order to get the incentive compatibility guarantees that we wanted, okay? And so that's a lot of the work that happens in this cottage industry around algorithmic mechanism design. You revisit well known, empty, hard problems. You observe that the standard heuristics are not monotone. You redesign some new ones, which hopefully are just as good as the old ones but are monotone.
00:53:40.170 - 00:53:42.480, Speaker A: In addition question.
00:53:44.290 - 00:53:51.022, Speaker C: We relaxed two to get three, right? Is there ever the idea of relaxing one?
00:53:51.076 - 00:53:52.802, Speaker A: Like have like the sponsored search option.
00:53:52.856 - 00:53:59.860, Speaker C: Isn'T explicitly d sick, but it's close if you find like a good if you're closer to opt.
00:54:02.310 - 00:54:27.786, Speaker A: Away, right? So let me give a two part question. So, about relaxing one. So you need to be clear on the reason why you're relaxing one. So, as we discussed, you should never relax one to try to resolve the friction between two and three. Two is stripless maximization, three is polynomial time. Those are in conflict, independent of what incentive compatibility that you do. So the question is, why are you trying to relax relax one.
00:54:27.786 - 00:54:58.274, Speaker A: And there the answer is yes, there can be good reasons why you might want to drop dominance strategy incentive compatibility. Again, sponsored search auctions don't satisfy that property. It's not clear that there's any extra benefit. It's not clear what they're trading in DSIC, it's not clear what they get in return, except possibly a slightly simpler to describe payment rule. But there are other situations where there is a non trivial trade off. Actually, I'll talk about it in this lecture, so let me wait till then. But the answer is not for resolving two and three, but for other reasons.
00:54:58.274 - 00:55:01.554, Speaker A: Yes, there are well motivated ways to reasons to relax.
00:55:01.602 - 00:55:04.600, Speaker B: It other questions.
00:55:06.090 - 00:57:36.140, Speaker A: All right, so let me just briefly hint at a sort of open research question, which I haven't had a chance to do yet in the class. So I talked about how the best case scenario in algorithmic mechanism design is to match what we know how to accomplish without the monotonicity, without the incentive compatibility constraint. And so obviously a huge question is can you always do that or in what situations can you achieve the Holy Grail where you get approximate surplus maximization for free? So that's a basic question we really do not understand well in these single parameter environments that we've been discussing so largely opening. So are there natural single parameter problems where the best you can do when you insist only on polynomial time is strictly better than the best you can do? If I insist on both polynomial time and monotonicity. So what's largely been happening in this realm of single parameter optimization problems is people observe that the known approximation algorithms are not monotone, work hard and come up with a new one that is monotone and as good as the old ones. For example, for the Knapsack problem, you might have learned that not only can you get within a factor two very quickly, but you can get within a factor of one minus epsilon, where epsilon is a constant of your choosing in polynomial time, okay? Polynomial in the number of items and in one over epsilon. So you want 99%, you can get within 99% in polynomial time.
00:57:36.140 - 00:58:44.240, Speaker A: So this problem, four of the problem set will revisit one of those approximation algorithms where you get one minus epsilon, there'll be an observation that that allocation rule directly is not monotone. But if you have an extra clever idea, you can re implement it in a monotone way. And this is what's been happening in sort of an ad hoc fashion for problem after problem after problem. So what would be super cool would be just some generic black box reduction, some proof that explained why we keep being able to match the best known approximation algorithms with the extra monotonicity constraint. Maybe there's a single generic method that takes some approximation algorithm, not necessarily monotone, for a single parameter problem, and transmutes it into an equally good approximation algorithm, which is monotone. That'd be amazing. Or if such a thing doesn't exist, we need to understand why the best case for a negative result would be a concrete problem where it really explains why you can do better without the monotonistic constraint than with it.
00:58:44.240 - 00:59:33.370, Speaker A: So if you're interested, there's the state of the art. So these so called black box reductions will have more to say about in the winter quarter course for those of you that want to take it. What we know so far for these single parameter problems and these DSIC implementations we've been discussing is a paper. I'll put a link to this up on the website, but this is just from last year, and Stock is one of the two major theory conferences that happens every year. So this is cutting edge stuff that our understanding is still really quite primitive. All right, so there's a lot that we've figured out in algorithmic mechanism design. There's a lot of really nice, approximately awesome auctions that people have designed.
00:59:33.370 - 00:59:47.822, Speaker A: But on a more fundamental level, we really don't understand in some sense why we've had so much success. All right, one more topic I want to discuss this lecture.
00:59:47.886 - 01:00:06.060, Speaker B: Any questions before that's? It.
01:00:30.790 - 01:01:45.670, Speaker A: Sanal topic of the day is called the Revelation Principle. Let me remind you that in addition to the lecture notes which I'm posting, also on the website are links to some reading. So some textbooks either that are out there or in draft form, which give you alternative treatments of many of the topics I'm covering in class. So for example, there's a couple of links to other treatments of the Revelation Principle for those of you that are interested. All right, so what I want to do now is sort of drill down on the question that was recently asked, which is what are we losing by insisting on such strong incentive compatibility constraints? We've focused thus far entirely on these DSIC mechanisms. Now, it was a well motivated goal, right? So again, I don't want to undersell it. Remember, in a DSIC mechanism, it's easy to play as a participant, it's clear what you should do.
01:01:45.670 - 01:02:33.830, Speaker A: And the good news is, from the designer perspective, you have much more confidence in predicting what's actually going to happen, you only need a very weak behavioral model. You just need to assume that bidders play a dominant strategy when they have one. Under that relatively weak assumption, you know exactly what's going to happen in your system. Furthermore, I've shown you a number of examples where we can actually get it, but it's worth taking a step back and saying, is there any motivation for weakening it in various ways. Let me actually tease apart two different assumptions I've been making, which I've been deliberately conflating thus far.
01:02:33.980 - 01:02:34.680, Speaker B: Okay?
01:02:37.130 - 01:02:49.542, Speaker A: So the first requirement has just been that bidders have a dominant strategy. And remember, we haven't talked about this much yet, but in the first lecture, we talked about rock, paper, scissors. You certainly don't have a dominant strategy in rock, paper, scissors.
01:02:49.686 - 01:02:49.994, Speaker B: Right?
01:02:50.032 - 01:03:17.974, Speaker A: We talked about first price auctions. You certainly don't have a dominant strategy in first price auctions. This is unusual. You need to carefully craft a game for there to be dominant strategies. So that's the first assumption. It so every bidder has a dominant strategy no matter what its private valuation is. But I didn't just assume this.
01:03:17.974 - 01:04:03.830, Speaker A: I actually assumed exactly what the form of the dominant strategy is. I assumed that actually reporting your true valuation bidding, your true valuation is a dominant strategy. Conceivably, you could set up some auction format where you had a dominant strategy, which was different. So just to give a very contrived example, you could imagine a single item auction where everybody submits bids, and then I double everybody's bids, and then I run a vicary auction on those doubled bids. Okay, it's a stupid auction, but yeah, I could do it. You have a dominant strategy, but it's not to bid your actual value, it's to bid half your actual value because you know I'm going to double it. Okay, so at least in principle, you could have mechanisms with dominant strategies that are different from what's called direct revelation.
01:04:03.830 - 01:04:51.486, Speaker A: So this dominant strategy is truthful biding. So when you're talking about auction specifically, usually you'll say truthful biding. If you're talking kind of more abstractly, you'll hear this term direct revelation, meaning you have private information and you just reveal it directly to the mechanism design. The reason I've now, and only now teased apart these two different assumptions is because one of them matters and one of them doesn't.
01:04:51.598 - 01:04:52.018, Speaker B: Okay?
01:04:52.104 - 01:04:59.014, Speaker A: And the revelation principle just explains in what way one of them in particular. The second one doesn't matter.
01:04:59.132 - 01:04:59.800, Speaker B: Okay.
01:05:02.250 - 01:05:27.118, Speaker A: But first, let me just talk about the first one. So relaxing one. So what if you set up a system where bidders didn't have dominant strategies? And again, not a hypothetical question. First price auctions. No, dominant strategies. They're not always used in practice, but they're sometimes used in practice. Well, we've talked about some of the cons.
01:05:27.118 - 01:05:56.902, Speaker A: As a participant, it's kind of hard to figure out what to do. So you already experienced this firsthand in your participation in first price auctions and then as a designer, if you want to actually try to predict what's going to happen, you're on much shakier ground. You necessarily have to make some behavioral assumptions stronger than just the bidders play dominant strategies, they don't have them. So you have to make some other assumption about what they're going to do. Generally you make some assumption like players are going to play some kind of equilibrium.
01:05:57.046 - 01:05:57.740, Speaker B: Okay.
01:06:03.710 - 01:06:42.898, Speaker A: So I need to assume players at equilibrium. Definitely a stronger assumption. Equilibrium are not always that easy. It's not always easy to figure out what they are from a bidder's perspective. There can be many equilibria and it's not clear that players are going to be able to figure out how to coordinate on just one of the equilibria. So there are different kinds of equilibria that are used to analyze systems without dominant strategies. The first problem set will give you a taste of a couple of them so rarely.
01:06:42.898 - 01:07:24.626, Speaker A: But in sponsored search auctions, like in problem three, you'll see a situation where you actually analyze Nash equilibria in the exact same sense we were talking about with Rock, Paper, scissors in lecture one. In problem six, you'll get a taste of Bayes Nash equilibria. That's something I'll have much more to say about in the winter. But you make much stronger assumptions as an analyst when you talk about these equilibrium concepts. For example, for Bayesnash equilibria, it's usually discussed with respect to a common prior distribution. And again, see problem six for more details about what that means. All right, so these are unsatisfying things, okay? You can write down models, they make predictions.
01:07:24.626 - 01:08:17.700, Speaker A: You're going to have less confidence in your predictions if you go away from dominant strategies. So why do it? Well, sometimes you can actually have systems that perform better than any DSIC system. This is not always true, but there are systems of interest where you get better equilibrium performance again, assumes that the system is actually at equilibrium, which is a non shriveled assumption, but it is possible if you can actually reach equilibrium play to in some cases perform better than in any DSIC system. Yeah.
01:08:18.310 - 01:08:20.450, Speaker C: Do you mean better maximize?
01:08:22.230 - 01:08:55.282, Speaker A: Yeah, it could mean that or it could mean other objectives as well. Yeah, so it depends on the setting. I mean, next week we'll talk about revenue maximization and in the problems we'll talk about next week, it turns out there's actually no difference. But if you look at more complicated revenue maximization problems, again, there's a difference. So there's no kind of universal rule of thumb I can give you about when it matters and when it doesn't matter, so sometimes it doesn't. Most of the cases we'll talk about in this class are simple enough, there won't be a big difference. But in interesting application domains there can be a difference.
01:08:55.282 - 01:08:58.900, Speaker A: So to full disclosure, I need to tell you this.
01:09:01.190 - 01:09:01.940, Speaker B: Okay?
01:09:03.670 - 01:09:16.940, Speaker A: Yeah. And again so C 364 b, if you're curious about more details there. All right, so now, the revelation principle answers the question of, is it interesting to relax two?
01:09:17.470 - 01:09:18.026, Speaker B: Okay?
01:09:18.128 - 01:09:37.950, Speaker A: And the answer turns out to be no. So there's no need to relax two. If you're focused on systems with dominant strategies, two is for free. It's without loss of generality.
01:09:41.350 - 01:09:42.100, Speaker B: Okay?
01:09:43.110 - 01:11:08.010, Speaker A: So that's the revelation principle. Let me be more precise. It's going to be by a simulation argument, by which I mean you give me a mechanism with dominant strategies that is not necessarily direct revelation, where players don't necessarily just review their true value and I will give you in response. Another mechanism that is equivalent in the sense that the outcomes are always the same and that is direct revelation where all players need to do is report their private information. And the new mechanism will also be DSIC. So for all mechanisms, M with guaranteed dominant strategies. And here, by guaranteed dominant strategies, I just mean no matter which bidder you are and no matter what private your private information happens to be, you have a dominant strategy.
01:11:08.010 - 01:11:18.910, Speaker A: So for every such mechanism, there exists.
01:11:20.770 - 01:11:21.550, Speaker C: Um.
01:11:25.190 - 01:12:14.050, Speaker A: An equivalent direct revelation DSIC mechanism. Yeah. M prime. Okay, so you give me M dominant strategies, not necessarily direct revelation, I'll give you back M Prime, which is direct revelation. So the proof is by a simulation argument. So you give me M. So my assumption is always dominant strategies.
01:12:14.050 - 01:13:08.542, Speaker A: So for a bidder I, when it happens to have the private valuation visa by, it's got to, by definition, have a dominant strategy. Let's call it si of VI. So then we're going to have M Prime, and M Prime is just a front end to M, which is responsible for playing the appropriate dominant strategies in M on behalf of the players.
01:13:08.686 - 01:13:09.380, Speaker B: Okay?
01:13:10.550 - 01:14:04.446, Speaker A: So players show up, they have whatever private valuations they've got V one, V two up to VN. They tell M prime, hey, M Prime, here's my private valuation. M prime says, oh, well, in that case, I if your private value is VI, I know you've got this dominant strategy, si of VI, you should be using an M. Yeah, let me just do that on your behalf. So M Prime takes these as sealed bids, if you like, and then in the guts of M Prime, it just reports the appropriate dominant strategies to M. M is none the wiser. It just gets as input these strategies.
01:14:04.446 - 01:14:17.930, Speaker A: That's one of V one through SN VN, it computes some outcome which M Prime happily refers. So M Prime leaves the outcome unchanged.
01:14:18.910 - 01:14:19.820, Speaker B: All right?
01:14:26.110 - 01:15:13.750, Speaker A: And if you think about it, direct revelation is a dominant strategy always in M prime, right? So if you're a bitter I, your private information is V sub I. By definition, you want to do Si of VI in M. It's never a bad idea, okay? And the only thing you can do by misreporting VI is by confusing the. Mechanism M Prime and getting it to submit the wrong thing to M. Okay, you don't want to do that because SIV has a dominant strategy in M. So that's what's a dominant strategy? Just report VI to M prime. So that's the revelation principle.
01:15:13.750 - 01:15:45.618, Speaker A: Specifically, this is the revelation principle for DSIC mechanisms. Other incentive constraints have their own revelation principles. So in the winter when we'll look at Bayes Nash implementations again, you're making an assumption when you say I'm going to assume this system's at a Bayes Nash equilibrium. But you're not making an important assumption when you say oh, and by the way, I'm going to focus on the equilibrium where bidders report their true value. At least in principle. In practice, there might be reasons to use nondirect revelation mechanisms. I ask you to think about that on the second exercise set.
01:15:45.618 - 01:15:59.400, Speaker A: But at least in principle, it is without loss to ask for a direct revelation mechanism. You lose no power as far as what you can or cannot do. On Monday, we'll start revenue maximizing auctions. Have a good weekend. See you then.
