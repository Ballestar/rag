00:00:00.570 - 00:00:40.234, Speaker A: In our treatment of permissionless consensus. Remember, we're focusing on the two most common approaches to civil resistance, proof of work and proof of stake and the two most common families of consensus protocols, longest chain protocols and BFD type protocols. Now, back when we talked about the proof of work approach to civil resistance, in lecture number nine, we focused only on longest chain consensus. So also known as knock consensus. And we saw why, right in lecture number nine, we saw that if you try to couple BFT type consensus with proof of work civil resistance, you've got problems. Any sort of straightforward way of doing that, you're actually going to lose liveness even in the synchronous setting because of.
00:00:40.272 - 00:00:43.958, Speaker B: The potential fluctuating hash rate with proof.
00:00:43.974 - 00:01:24.322, Speaker A: Of stake civil resistance. Meanwhile, as we've seen in the last three videos, you actually can couple that with BFD type consensus protocols. Indeed, I think that's one of the main reasons we're seeing this migration from proof of work to proof of stake over the last several years. But actually proof of stake civil resistance is more flexible than that. You can also, as we'll see in this video and the next two videos, you can also couple proof of stake civil resistance with longest chain consensus. So in fact, the early generations of proof of stake blockchain protocols, most of them actually did use the longest chain approach to consensus. I think one reason for that is just like in the early days of blockchain protocols, obviously everybody was focused on bitcoin.
00:01:24.322 - 00:02:34.382, Speaker A: So it's very natural to say, okay, can we just have a version of Bitcoin in particular with longest chain consensus, a version of bitcoin where we kind of drop in proof of stake random sampling for proof of work random sampling? The second reason is, frankly, I just think among the sort of blockchain research community BFT type protocols, while known, I don't think they were sort of as deeply understood and widely appreciated as they are now. Of those early generation proof of stake longest chain protocols, cardano is the one that remains the biggest and the most relevant. In 2023, most of the other protocols of that vintage either switched over from longest chain to BFT type consensus or otherwise have faded into our relevance. And for those of you trying to navigate the academic literature there, even now, even in 2023, you'll see a pretty strong skew actually toward longest chain protocols. Amongst the research papers that focus on proof of stake blockchain protocols, I think one reason for that is just the academic literature often lags behind sort of the cutting edge of practice by a few years. So it's just we're sort of waiting for it to catch up. I think another reason is just as we'll see in this video in the next two, getting proof of stake longest chain consensus to work is actually a hard and quite interesting computer science problem.
00:02:34.382 - 00:03:32.880, Speaker A: So it's sort of fertile ground for cool research papers. So for all of these reasons, I think it's worth spending a little time talking about proof of stake longest chain protocols. That's why we're going to have these three videos here in part three of lecture twelve. If nothing else, I think it's instructive to see just how nontrivial it is to try to turn bitcoin into a proof of stake protocol. You really cannot just use proof of stake as sort of a drop in replacement for proof of work and Nakamoto Consensus, as we'll see, lots of other issues come up that have to be addressed. That said, if you're short on time and you find yourself having to choose between either learning about proof of stake BFT type protocols or proof of stake longest chain protocols, I would encourage you to spend your time on the former. On the previous three videos where we talked about proof of stake BFT type protocols, that's because it would appear, at least speaking now in early 2023, that that will be the dominant approach to proof of stake blockchain protocols going forward.
00:03:32.880 - 00:04:25.540, Speaker A: So let's now talk through what it might mean to stitch together proof of stake random sampling with longest chain consensus. Let me repeat here some of the caveats I said when we talked about BFT type protocols. So first of all, as always, the emphasis of this lecture series is on principles, not protocols. So what I write down for you on this slide, it's not going to map literally to any existing proof of stake longest chain protocol. That said, I think it is representative and it's not so far away from how, for example, the cardano protocol works. As with our example implementation of a proof of stake BFT type protocol, the description here on this slide is going to be somewhat under specified. Again, I want to sort of emphasize the key conceptual ideas and lead into a discussion of what I think are the biggest challenges that arise when you try to design a protocol of this type.
00:04:26.150 - 00:04:27.378, Speaker B: So if you wanted to turn the.
00:04:27.384 - 00:05:30.354, Speaker A: High level description on this slide into a concrete protocol that really has provable consistency and liveness well, you'd have to add some additional details, details that I'm not going to discuss further. If you do really want to get out into the weeds, I encourage you to check out one of the research papers on this topic of proof of stake longest chain protocols with provable guarantees. For example, you can look at a detailed research paper that describes Oroboros prowse, which is the consensus protocol that forms the basis of the Cardano protocol. So, as I've said before, in proof of stake protocols, unlike proof of work protocols, one generally assumes a global shared clock or a good approximation of one. And protocols typically proceed in designated time steps. In addition, and unlike in the BFT protocol case, we will be assuming that we're in the synchronous model, not the partially synchronous model. So remember, that means we're going to assume that there's some known bound capital delta and that's the maximum message delay.
00:05:30.354 - 00:06:14.050, Speaker A: So every message that any node ever sends will be received at its destination within delta capital delta time steps. That's a strong assumption. But it shouldn't surprise those of you that remember our discussion of longest chain consensus from lectures eight and nine. Remember, longest chain consensus breaks down quite badly in the partially synchronous setting, right, if you have a network partition. So if you have two groups of nodes that can talk to each other but can talk within groups, but can't talk across groups, each of those groups is going to grow their own chain independently. When the network partition ends and the nodes reunite, those two different chains are going to have to be resolved. And that'll force a bunch of blocks previously thought to be confirmed to get rolled back, which is a consistency violation.
00:06:14.710 - 00:06:16.338, Speaker B: So for concreteness, I don't know, you.
00:06:16.344 - 00:06:24.486, Speaker A: Can think about delta as maybe 3 seconds or something like that and think about a time step as some small, constant multiple of delta. So maybe on the order of ten.
00:06:24.508 - 00:06:27.846, Speaker B: To 15 seconds, these timesteps are going.
00:06:27.868 - 00:07:09.862, Speaker A: To play exactly the same role as the rounds that we were talking about in lecture number eight when we talked about the permissioned version of longest chain consensus. So as usual, we're going to assume that there's some publicly visible Staking contract that includes a list of all of the currently active validators along with those validators stake amounts. When we talked about BFT type protocols, we started with the special case where all the QIS were the same, and then only later did we talk about how to handle the case of general QIS here. Let's just sort of jump in and let's just allow arbitrary stake amounts from the get go. So there are N public keys in the Staking contract, PK one up to PKN. There might be sybils, we don't know. Some of those public keys might be owned by the same person.
00:07:09.862 - 00:07:47.326, Speaker A: And to each of those N public keys, there's some arbitrary associated stake amount. Those are the Q sub eyes. So as usual, what we're trying to do here at a high level is reduce permissionless consensus. The problem we're trying to solve to a problem that we've already solved, namely permissioned consensus, specifically the permissioned longest chain protocol back from lecture number eight. Now, longest chain, you need to somehow select a leader. And in the permission setting, there's any number of ways you can select a leader, like uniformly at random here, because some of these public keys may be owned by the same person, there might be sybils. We definitely don't want to select a public key uniformly at random.
00:07:47.326 - 00:08:31.310, Speaker A: Instead, we want to select one with probability proportional to the stake, proportional to the Q sub I's. So that's the high level idea. Let's just use proof of stake random sampling to, in a sibyl resistant way, pick a leader of each round and then just run permissioned longest chain as it was back in lecture eight. Now, as we know from the part two videos, there's more than one way you can go about proof of stake random sampling. But let's just go ahead and take the same approach we took with BFT type protocols, which is the VRF based approach. So remember what this means. This means that each of the owners of a public key is responsible for evaluating a VRF, a verifiable random function using the private key corresponding to the public key that's visible in the Staking contract.
00:08:31.310 - 00:09:09.994, Speaker A: As in the BFT type videos. I'm going to call this VRF output the Credential. So this Credential is the output of the VRF of the verifiable random function, which of course depends on the input to the verifiable random function, but also on the private key used to evaluate it. So briefly, let's remember the defining properties of a verifiable random function of a VRF. So first of all, it's easy to evaluate if you know the right private key. So if you're in possession of SK sub i, you can easily compute the Vrf's output on any input that you like. If you don't know the private key, you should not be able to guess what that VRF output should be.
00:09:09.994 - 00:09:54.518, Speaker A: On the other hand, it's efficiently verifiable. So if a VRF is computed correctly and then the output is told to somebody, they can verify the correctness of that alleged output, knowing only the corresponding public key. And more concretely, you might just want to think about a verifiable random function as a signature scheme. It should be a signature scheme with unique signatures to avoid the grinding attacks that we talked about earlier. And then optionally maybe, you take that signature and you feed it through a cryptographic hash function to get to the desired randomness properties. In any case, just like how if different people sign the same document using different private keys, they're going to generate different signatures. So too will different people evaluating the same VRF on the same input.
00:09:54.518 - 00:10:48.902, Speaker A: They'll get different outputs because they'll be using different private keys. And indeed, in the protocol here, everybody will be evaluating their VRF on exactly the same input. It'll be the same input we used in our BFT type protocols. The concatenation of the current time step T with a pseudorandom seed R sub T that corresponds to that time step. Now, there's still an underspecified component of this Credential computation, which is what exactly is that pseudorandom seed R sub T associated with a timestep T, as we saw back in part two, as we saw yet again in the first half of part three? That's a quite subtle question. It's quite tricky to define the pseudorandum seed so that you don't mess things up too badly. And even if you're careful, usually there is a little bit of bias ability in it just because it's typically derived in some way from the blockchain state, which of course is manipulable by the nodes running the protocol.
00:10:48.902 - 00:11:35.900, Speaker A: So to isolate the specific issues with longest chain consensus that I want to focus on, let's actually, at least for now, let's just assume we have an ideal randomness beacon. Let's suppose that R sub T is literally just random bits that fall from the sky. You might remember back in part two when we talked about VRF based sampling, at that time we actually were assuming access to an ideal randomness beacon because VRF based sampling already poses a number of challenges. Even in that case. Then we pushed ahead and we said, okay, what further challenges come up if you use a pseudorandom steed instead of a random seed? So we're going to take that exact same sort of sequence here. Let's first think about all the issues that come up even with an ideal randomness beacon. Then at the very end of these videos we'll talk about the different approaches to defining a pseudorandum seed and the sort of pros and cons of each.
00:11:35.900 - 00:12:41.022, Speaker A: As we talk through all the various complications that come up from using VRF based sampling in the next couple of videos, it's worth keeping in mind like why we might want to use VRFs as opposed to some simpler approach to proof of stake symbol resistance, which is the secrecy property that you get from VRFs. For example, if you did something much simpler like weighted round robin, which we talked about at the beginning of part two, then you have this drawback that sort of everybody knows the future block proposers well in advance and so then those proposers might be subject to coercion or bribery or denial of service attacks, et cetera. So you might want to really sort of try to recreate the proof of work property that nobody knows that you're a block proposer until they actually see your block. And so that's the key functionality that VRFs give you. If you don't care about secrecy, you might want to use something simpler. If you do care about secrecy, then this VRF based approach is probably what you want and all the challenges we're going to discuss would seem to be somewhat unavoidable. So those are the private computations everybody's going to be doing every time step.
00:12:41.022 - 00:13:18.394, Speaker A: You're going to be evaluating this verifiable random function with your private key on the input. That's the concatenation of the timestep T with a pseudorandom seed, R sub T for that timestep. What is everybody going to do with those computations with their credentials? Well, as usual, if your credential is sufficiently small, that will grant you privileges in the protocol. Specifically, remember, this is the longest chain consensus. So we're thinking of rounds that have leaders that propose blocks. So if your credential is sufficiently small below a suitable threshold, then you in fact will qualify as a leader of the round, you in fact will have the privilege of proposing a block at this time.
00:13:18.432 - 00:13:21.902, Speaker B: Step T so what exactly, you're probably.
00:13:21.956 - 00:14:11.270, Speaker A: Wondering, is this threshold, exactly how small does your credential have to be before you qualify as a leader of around? So whatever that formula is, you should be expecting it to depend on at least two things. So first of all, you should expect some kind of difficulty parameter, right? All the way back in proof of work, we had our sort of difficulty threshold. Tau we had a difficulty parameter in our proof of stake DFD type protocols. We're going to have that also here. That's going to be Mu in our formula that's going to be tuned to target some number of leaders, a given number of leaders in each time. Step secondly, remember we're trying to do proof of stake random sampling. So we want the probability with which you are chosen as a leader, the probability with which you get to make a block proposal that should be proportional to your stake.
00:14:11.270 - 00:14:46.630, Speaker A: Now you're a leader if and only if your Credential is less than a threshold. Your Credential, if you think about it, is independent of your stake amount. That's going to be the same number no matter what your stake. So if you want it to be more likely for public keys with higher stakes to be selected as leaders, well, then I guess the right hand side, the threshold also better be increasing in the stake amount. The more your stake, the higher your threshold, the easier the more likely it is that your VRF output will be below that threshold. So we should also expect a dependence on Q sub i, the stake amount in the formula.
00:14:47.210 - 00:14:48.998, Speaker B: So specifically the formula is the one.
00:14:49.004 - 00:15:27.614, Speaker A: I wrote down here on this slide. This is actually exactly the same formula we used in part two when we first started talking about VRF based sampling and how to make it sensitive to stake amounts. It's one minus e raised to the minus Q sub I times mu e. Here is the base of the natural logarithm 2.718 dot dot dot q I is the stake amount. Mu is the difficulty parameter, again tuned to target a particular number of leaders per round. Now, when we were using VRF based sampling with the BFT type protocol, we were using it to select an entire committee which we're then going to be responsible for carrying out and voting in a permission consensus protocol like tendermint.
00:15:27.614 - 00:15:40.810, Speaker A: So there we might have been selecting, I don't know, something like 100 public keys in a given time. Step here we're doing longest chain consensus, right? So we don't need 100 people to be voting on things. Ideally we would have exactly one leader in the round to make a block proposal.
00:15:41.230 - 00:15:42.586, Speaker B: So here Mu is going to be.
00:15:42.608 - 00:15:46.474, Speaker A: Tuned to target some small number of leaders per round, maybe, for example, one.
00:15:46.512 - 00:15:49.594, Speaker B: Liter per round if this formula, one.
00:15:49.632 - 00:16:27.378, Speaker A: Minus e to the minus Q I times mu seems a little mysterious. Let me sort of remind you back in part two how we arrived at this formula. It was again this kind of thought experiment where you'd want to treat a public key with state Q sub I as if it was Q sub I sybils with one coin each. So we imagine flipping Q sub I independent coins each with the same bias. Call it tau. And then this is just the formula that arises as the probability that at least one of those Q Subai coin flips comes up heads. As we'll see over the next couple of videos, this is in fact the appropriate model for Longest Chain Consensus.
00:16:27.378 - 00:17:37.482, Speaker A: So unlike back in BFTech consensus protocols, where you actually do care about controlling multiple committee members in the same round, right? That gives you sort of boosted voting power if you're running the tenement protocol with longest chain consensus. Sort of as we'll see, really sort of having three different leaders you control in the same round really isn't particularly different than just having one leader that you control in a given round. The other thing I'll say to sort of demystify this formula is that at least for small stake amounts, for small Q sub I's, this formula is almost the same as the simpler expression stake amount q sub I times the difficulty parameter mu. So for small stake amounts, for example, if you double your stake, you're going to be basically doubling the probability with which you're selected for bigger stake amounts, that's not quite civil resistant. So use the slightly more complicated formula here. So now that we know how the leaders are chosen, the idea is just to pretend as if we're running permissioned Longest Chain Consensus, which means a leader of around someone with a sufficiently small credential they should be able to allow to make a block proposal. Remember, in Longest Chain Consensus when you make a block proposal, you're specifying not just sort of the transactions, but you also get to freely specify the preceding block.
00:17:37.482 - 00:18:05.960, Speaker A: You get to pick which part of the existing blockchain you want your new block to extend. And actually more than that, if you remember from the permissioned version of Longest Chain Consensus we talked about in lecture number eight, the leader can even propose as many blocks as it wants, potentially different blocks extending different parts of the current blockchain. Now, if you're an honest node, of course you're only supposed to propose one block and the block you propose should extend the longest chain that you're aware of.
00:18:06.330 - 00:18:08.466, Speaker B: So this ability of non honest nodes.
00:18:08.498 - 00:18:19.206, Speaker A: To propose multiple blocks in the same time step, that's the same as the version of Longest Chain Consensus we studied in lecture number eight. It's different than the proof of work version from Nakamoto Consensus, which we studied.
00:18:19.238 - 00:18:22.454, Speaker B: In lecture number nine and Nakamoto Consensus.
00:18:22.502 - 00:19:02.214, Speaker A: Remember, a lottery ticket comes with it a fixed set of transactions and some fixed predecessor block, right? That's what you're sort of feeding into a hash. You only learn whether or not you won the lottery after you've committed to a predecessor block and transactions in your own block. Here that is not what's happening. You're learning whether you won the lottery based purely on your credential, independent of what block you might propose. So for that reason, you can propose as many blocks as you want once you have your winning lottery ticket. I don't expect you to remember that long list of assumptions we are working with in lectures eight and nine and assumptions a four and a four prime or whatever. But just in case you do, nakamoto Consensus satisfies.
00:19:02.214 - 00:19:20.954, Speaker A: The stronger assumption, a four prime. A leader, even if they're Byzantine, can only propose one block and there's nothing they can do about it. The weaker assumption, a four. A Byzantine leader can propose any number of blocks. The only constraint is that each block they announce should name as a predecessor some block associated with a previous round.
00:19:21.002 - 00:19:24.686, Speaker B: A previous time step. So that's the gist of proof of.
00:19:24.708 - 00:19:47.154, Speaker A: Stake longest chain consensus. You proceed in these time slots at each time slot. You use VRF based sampling to figure out who were the leaders, who it is, who's eligible to propose blocks at each time step. Anyone who's a leader is allowed to propose any number of blocks that they want. And so this means that some entry of blocks will grow over time. You start with the Genesis block. Each time step, you expect more blocks to be added.
00:19:47.154 - 00:20:25.406, Speaker A: Maybe there'll be forks. At the end of the day, you have this entry, which are the blocks that matter. The blocks that matter are the ones on the longest chain. Okay? But actually, as usual with longest chain consensus, the tip of the longest chain, the last K blocks should always be regarded as tentative and under negotiation. So really the finalized blocks are the blocks that are sufficiently deep at least K blocks deep on the longest chain. You might remember in lecture eight we talked at length about how to set the security parameter K. The trade off you're facing is sort of the bigger K is, the good news is the less likely there's ever going to be a consistency violation.
00:20:25.406 - 00:21:22.386, Speaker A: The bad news is that's just sort of more time that users of your blockchain protocol have to wait before their transaction gets confirmed. And so the right value for K really depends on the assumptions you're willing to make on, for example, the fraction of stake controlled by Byzantine nodes and on the sort of risks that you're willing to tolerate. But for concreteness, you probably want to think of K as in the dozens at least, and then, depending on the parameter choices, possibly even in the hundreds. So hopefully that seems like a reasonably natural way that you might try to stitch together proof of stake random sampling on the one hand, specifically the VRF based approach and longest chain consensus on the other. But you've probably already noticed, as we talked through this video, some things fraying around the edges. So, for example, the fact that with VRF based sampling you can target one liter per round, but you might have zero, you might have many. You might also be bothered by the fact that Byzantine nodes can propose all kinds of crazy blocks extending all different parts of the blockchain.
00:21:22.386 - 00:21:32.050, Speaker A: So there's clearly some more details to discuss, some more challenges to address. So let's start talking about those in the next video. I'll see you there. Bye.
