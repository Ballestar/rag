00:00:00.250 - 00:00:00.798, Speaker A: You.
00:00:00.964 - 00:00:39.640, Speaker B: All right, so I'm going to go ahead and get started. So we've been in the course for about six weeks and most of that six weeks we've, you know, whether we made a big deal of it or not, been talking about equilibria. So the whole time we were discussing mechanisms, we were discussing what are called dominant strategy equilibria. Last week when we were talking about routing games, you know, we talked about equilibrium flows both in Nonatomic and atomic models. But I don't think have even really ever written the definition of an equilibrium on the board. I haven't been treating them as first order objects and today we're going to change that. So today we're really going to talk about equilibria, a bunch of different flavors of them when they exist and so on.
00:00:39.640 - 00:01:11.694, Speaker B: So to begin, let me just remind you where we left off at the end of Wednesday. So last week we talked about the price of anarchy in routing games. And the last result that we gave is we looked at atomic selfish routing. So remember atomic is where you have a finite number of players each of non negligible size. And we proved that when you have affine cost functions of the form ax plus B, the worst case price of anarchy in those networks is exactly 2.5. So I showed you a lower bound that was a bi directed triangle with four players where there was indeed an equilibrium that was 2.5 off from optimal.
00:01:11.694 - 00:02:09.406, Speaker B: And we proved an upper bound that held in general networks. So there can be multiple equilibria. But every Nash equilibrium of every atomic silver shrouding game with afon cost functions is no worse than 2.5 times the cost of optimum. Okay, but if we sort of really scrutinize what we proved, every single equilibrium, and there may be many, is within a small constant factor of optimum, there's still something we should be worried about, which is how do we know that in every instance there's at least one equilibrium? We know there can be more than one. But how can we be sure that sometimes there isn't zero? And if there's no equilibria, then these price of anarchy bounds would be vacuous. And on Wednesday I was focusing on what are called pure or deterministic Nash equilibrium.
00:02:09.406 - 00:02:56.754, Speaker B: That is when we talked about what a player was allowed to do, it had to pick a single path to route one unit of traffic and we looked for a collection of paths so that nobody could deviate and strictly decrease their cost. So that's an equilibrium with no randomization. And we know there were games where there are none of these pure Nash equilibrium. Does anyone remember one? Like maybe from lecture one? Good. Rock Paper, Scissors is a very simple game where there's no pure strategy Nash equilibrium. You have to randomize to be at an equilibrium, right? If you always play scissors, then the other player will always play rock and so on. So atomic selfish routing games are a remarkable class of games in that the existence of these pure equilibria is guaranteed.
00:02:56.754 - 00:03:55.894, Speaker B: So that's not obvious, it's not hard to prove, but it's not obvious. And that's the next result. I want to discuss Rosenthal's Theorem. So this is an old result 40 years ago. So in every atomic selfish routing network, and not just with affine cost functions, with any functions you want, it has at least one equilibrium and we already know there can be more than one.
00:03:56.012 - 00:03:58.950, Speaker C: Okay. Yep.
00:04:00.890 - 00:04:12.970, Speaker D: Like rocket registers where like costs are equal to what, what your outcome?
00:04:15.630 - 00:04:26.740, Speaker B: Yeah, they're pretty, they're different in the sense that in routing games, if more people pick your strategies it's always bad for you, whereas in Rock, Paper Scissors there isn't that property. So you don't have the same kind of.
00:04:30.390 - 00:04:30.706, Speaker A: Mean.
00:04:30.728 - 00:05:38.050, Speaker B: In some sense, just by virtue of Rosenthal's Theorem, we now know that that can't be true. But more directly there's sort of a consistency in people's preferences and routing games which is what gives rise to this result. Correct. So the plan for the proof is I'm going to show that every selfish routing network is what's called the potential game. And potential games always have sure Nash equilibrium. And at a high level, what you do in a potential game is you show, you basically anthropomorphize all of these players and you show that they act as if they are trying to collectively optimize a single function which we call the potential function. And then what we'll see is that at the global optimum of this potential function that people are inadvertently trying to optimize, that has to be an Ash equilibrium.
00:05:38.050 - 00:06:36.566, Speaker B: So there aren't a lot of techniques for proving that games are guaranteed to have pure equilibria in park as many games do not have pure equilibria and this is probably the most useful one. So there's very few tools for proving existence of pure equilibria and this is the number one that you should know. Let me show you what the potential function is. So the potential function assigns a real number to every possible flow. A flow is just a choice of a path by each of the K players in the selfish routing network. And the potential function is the following it looks quite similar to the edge based expression we had for the total travel time, but it's a little different. But we again sum over the edges and on a given edge recall f sub e is the notation for the number of players that choose a path that includes the edgy.
00:06:36.566 - 00:07:23.370, Speaker B: So we're going to sum from I equals one to the number of players using that edge of the cost function of that edge evaluated at i. So there's a little weird. Let me show you a picture. So on an edge where f sub was three, where three players are using it, this sum you just evaluate the cost function at the values one, two, and three, and you would just add up the area under the corresponding rectangles.
00:07:25.630 - 00:07:26.380, Speaker C: Okay?
00:07:28.190 - 00:08:14.138, Speaker B: So on a given edge with three players, that's what you'd get for this sum. Just to help you relate to this, let's compare and contrast it to that edge based expression we had for the total travel time. So, one way to count up the cost of a flow is you sum over the edges and then on an edge, you look at the number of players using that edge f sub times the common cost, they all incur C sub, B times f sub. So instead of this sum, which has f sub right? So if there's five players here, we're adding up five things. It would be five times just the cost when all five players are there. So put differently for the total travel cost function, for the total travel time, rather than this blue staircase, we would be paying attention to its bounding box.
00:08:14.304 - 00:08:15.020, Speaker C: Okay.
00:08:15.470 - 00:08:27.182, Speaker B: To its pink bounding box. So this is what we were concerned with on Wednesday. We wanted to minimize this. The potential function is a bit different. It's the staircase instead.
00:08:27.316 - 00:08:28.000, Speaker C: Okay.
00:08:29.490 - 00:09:30.510, Speaker B: Now, I haven't told you why you should care about this definition. And here's the surprising property, the surprising property of the potential function. There's a sense in which this potential function simultaneously tracks the costs of all of the players. So if a player I deviates, say it was using path P-P-I in the original flow f, and suppose it deviates to a different siti path, let's say p hat i, and let's call the new flow f hat. So f hat is just the old flow f, but with I reassigned.
00:09:34.890 - 00:09:35.640, Speaker A: It.
00:10:08.610 - 00:10:26.310, Speaker B: So the claim is if we look at this deviation by player i, the change in the potential function. So the difference between phi of f hat, the new flow, and phi of f the old hat sorry, the old flow is exactly the change in cost that I itself incurs in these two flows.
00:10:49.890 - 00:10:50.640, Speaker A: I.
00:10:52.610 - 00:11:27.010, Speaker B: So that's the claim. So the claim is this should hold no matter where you start from, no matter what UT is, no matter which player I you're allowing to deviate, and no matter which path p hat i, they're deviating to. So in this sense, this single function fee, which notice is defined independently of any player i. It's just a single global function. It's simultaneously tracking the sort of possible changes in cost faced by all of the players. So that's the key claim. So let me prove the claim for you, and then I'll explain why the claim implies Rosenthal's theorem.
00:11:27.090 - 00:11:27.720, Speaker C: Okay.
00:11:30.910 - 00:12:25.014, Speaker B: So, proof of claim. So once you've actually guessed, once you've pulled this potential function fee, the rabbit out of the hat, it's easy to verify this property. So what is the left hand side? Well, phi is defined as this sum over edges for any edge which is in neither its old path p i, nor its new path p hat i. Of course it doesn't change. This part doesn't change for any edge which is in both the old path and the new path. It doesn't change for any edge which is in the new path and not in the old path. So an edge which player I newly uses, we're going to pick up an extra term in this summand.
00:12:25.014 - 00:13:23.470, Speaker B: So if there used to be five players using it and now player I is the 6th player, once it switches to it, we pick up a 6th summand which is C sub evaluated at six. Similarly, for any edge that player I is abandoning, then we shed the final summand. So if it used to be one of five players, this is going to shed the fifth summand ce of five. So in other words, the change in the potential function value, you just look at all the edges that are in its new path and not its old path and you pick up a ce of Fe plus one. The plus one is because I is now remember, this counts how many players were using at F. This is because I is a new player using it. You look at all the edges that it's abandoning, it used to use and now it doesn't.
00:13:23.470 - 00:14:08.540, Speaker B: And you shed the final summon ce of F sub. So that's expanding the left hand side. And now if you think about it, this is actually exactly the right hand side here too, from player eyes perspective, how does its cost change when it switches paths? Well, edges in neither path don't matter. Edges in both paths, it pays the same before and after any edge which it uses now, and it didn't used to, it has to pay its cost. And again, if there used to be five players, it's the 6th player and it pays like the other five players, the cost when there's six players on the edge and anything it abandons, it used to pay ce of FCB, and now it's not in its path, so it doesn't. So this sum is just the right hand side.
00:14:09.470 - 00:14:10.380, Speaker C: All right.
00:14:14.290 - 00:14:47.670, Speaker B: So that's the proof of the key claim that from any flow for any deviator I and any deviation p hat i, the change in the potential function is exactly the same number as the change in cost that this player I incurs if it switches to the path p had i. So let me explain why the key claim implies the theorem.
00:15:00.370 - 00:15:01.120, Speaker A: It.
00:15:02.050 - 00:15:53.150, Speaker B: So now what the key claim is saying is that these players, little benounce to them, are in effect trying to minimize this global function fee. Okay, so let's consider the outcome which actually has the absolute smallest fee value. So there's only a finite number of possible outcomes in this game. One of them has a smaller fee value than any other. Call it F. Since this has the smallest fee value of them, all, there is of course no deviation by a player that leads you to an outcome with smaller fee. There isn't such an outcome.
00:15:53.150 - 00:16:14.160, Speaker B: Well, by the key claim, the change in your cost when you deviate is exactly the change in the potential. So if every deviation can only make the potential go up, then every deviation can only make the cost of the deviator go up.
00:16:14.610 - 00:16:15.360, Speaker A: And.
00:16:29.790 - 00:16:32.730, Speaker B: But that is exactly the definition of a Nash equilibrium.
00:16:35.630 - 00:16:36.380, Speaker C: Okay.
00:16:38.990 - 00:17:05.720, Speaker B: So why is there a Nash equilibrium? It's because first of all, there exists a potential function. That's the really nontrivial part. There exists a potential function. You can look at the global, minimizer the potential function and that has to be an equilibrium so one exists. All right, so at least there are some classes of games, in particular the ones we were obsessed with last week where pure equilibria are guaranteed rock, paper, scissors. No routing games. Yes.
00:17:05.720 - 00:17:48.450, Speaker B: Questions. Exactly. Yeah, finite number of players. Each has a finite number of paths in this finite network. It could try. So one of them has at least as small a fee value as anything else. All right, so I gave you this argument just for atomic selfish routing games, but it's actually a flexible argument.
00:17:48.450 - 00:18:29.674, Speaker B: So let me just pause and mention some notable extensions which relates to either things we've talked about before or things we'll talk about in the future. So whenever we've talked about routing games, we've made the sort of natural assumption that cost functions only go up. So the more traffic there is on an edge, the higher the cost is for everybody. This proof actually doesn't need that hypothesis. If you look at this proof, the cost functions can be literally anything. Doesn't matter. Okay, so proof still workshop.
00:18:29.674 - 00:19:09.110, Speaker B: If the CES are not nondecreasing. We'll make use of this fact next week when we talk about a model called network cost sharing games. The second thing to notice is this whole theorem and its argument has nothing to do about networks per se. Okay? So these strategies, piece of I, if they were just sort of arbitrary subsets from some ground set rather than passing the network, it wouldn't matter. The exact same proof would work. We never referenced the fact that there was network structure. So in this sort of more abstract setting, these are called congestion games.
00:19:09.110 - 00:20:15.998, Speaker B: And that's a word you see a lot in this part of the woods. It important that e represented the edges of a network and it wasn't important that the PiS that the strategies were pathed in a network. And third, and finally, I want to make a couple remarks about the non atomic model that we discussed last week on Monday and the first part of Wednesday. So remember, in the non atomic model, that's where we had pigu's example embrace's paradox. That's where we had negligible size players like cars in the highway and we looked at fractional flows and back then I asked you to take it on faith that Equilibria exists and are unique. I'm not going to give you formal proofs. You can find formal proofs in the AGT book.
00:20:15.998 - 00:20:24.720, Speaker B: But I'll give you sort of the moral reason why both of those two facts are true. And basically it's because of a potential function like this, there's a question.
00:20:37.850 - 00:20:38.262, Speaker A: And.
00:20:38.316 - 00:20:42.602, Speaker D: Therefore is at any given system like this, you're not going to end up with this cycle of people.
00:20:42.656 - 00:20:43.162, Speaker A: Yes.
00:20:43.296 - 00:20:58.190, Speaker B: The answer is yes, and we'll actually discuss that explicitly in about two weeks. Yes, but you're absolutely right. So the comment was it seems like potential functions should have implications not just for existence, but also for dynamics, and indeed they do.
00:20:58.260 - 00:20:58.494, Speaker A: Okay.
00:20:58.532 - 00:21:21.414, Speaker B: And we'll talk about dynamics at some length a little later in the course question. That's not the case. So it is important that the cost functions are anonymous. Yeah. So the model where cost functions depend on the players is an interesting model, but some of the properties break down.
00:21:21.612 - 00:21:23.080, Speaker C: Okay? Yeah.
00:21:24.090 - 00:22:17.342, Speaker B: Including this one. All right, so for non atomic selfish routing, you use basically the exact same potential function. It doesn't quite type check at the moment because this is for a finite number of players. So for an infinite number of players that are small, you should just replace the sum by an integral. So you just consider the potential function where you sum over the edges and instead of counting up one, two, three, all the way up to F sub B, you just integrate from zero to F sub the cost function. So that's the relevant potential function. Now, when I introduced non atomic selfish routing, we assumed that the cost functions were continuous.
00:22:17.342 - 00:22:45.194, Speaker B: I didn't really ever tell you why that was important, and there was even a question about that. But now we see why it's important. So phi is continuous anyways, so phi is a continuous function and for that reason it has some global minimizer.
00:22:45.242 - 00:22:45.454, Speaker C: Okay?
00:22:45.492 - 00:23:44.046, Speaker B: There is some. It's not, it's no longer true that there's a finite number of outcomes, but because phi is a continuous function and the space of all flows is a compact set, phi does achieve a global minimum on it. And just like the global minimizer of the discrete potential function was a Nash equilibrium, so too, here is the global minimizer of this potential function. An equilibrium flow in a non atomic sense. Okay, that requires proof, but it is true. So that covers the existence in the non atomic model. So what about uniqueness? Well, we also were assuming that the cost functions were nondecreasing.
00:23:44.046 - 00:24:28.366, Speaker B: So if you integrate a nondecreasing function, you get a convex function. Okay, so this potential function, phi, is convex. What that means is that phi, this potential function, has no local minima that are not also global minima. That's a standard property of convex functions. Think about like a parabola defined on convex sets. And since the equilibrium flows turn out to correspond to local minima. And the only local minima are global minima and global minima are essentially unique.
00:24:28.366 - 00:25:02.030, Speaker B: So too are equilibrium flows essentially unique in this non atomic model. Okay, so again the basic reason for uniqueness is convexity of the potential function which just comes from the form of the potential function and the nondecreasing cost functions. Okay, so that's morally why you have uniqueness here's. The global minimizer is the only and equilibrium flow.
00:25:05.570 - 00:25:06.320, Speaker C: Okay.
00:25:13.730 - 00:25:15.258, Speaker B: No, it wouldn't be convex.
00:25:15.434 - 00:25:16.960, Speaker D: Well, all right, but it's not.
00:25:18.950 - 00:25:52.560, Speaker B: So the key point is that the potential function is convex. Was all very good news. This was all saying that the games that we were obsessed with last week have even more nice properties than we thought. Equilibrium are guaranteed to exist. So all of our nice price of anarchy bounds are non vacuous really. They're talking about objects which are there. So that's good.
00:25:52.560 - 00:26:51.434, Speaker B: But as we know, not all games are so nice. So there's still the question looking ahead as we want to reason about other application domains. So what about games with no equilibrium, no pure equilibrium? All right, so as we said, Rock Paper, Scissors is one example, but there's actually games very closely related to the games we've already been analyzing where you also lose the existence of pure equilibrium. So for example, one minor tweak I can make to the atomic selfish routing model is to allow players to have different control, different amounts of flow. On Wednesday, every player controlled a single unit of flow. What if there's like two players? One of them has one unit of flow and the other has two units of flow. Turns out you already lose the guaranteed existence of pure equilibrium.
00:26:51.562 - 00:27:05.640, Speaker A: Even that's it.
00:27:10.410 - 00:27:49.506, Speaker B: So it's not hard to come up with an example, but I'm not going to spend class time on it. I'll just refer you to the AGT book. It's example 18.4 and it's an example that just has two players. One has one weight unit weight, the other has weight two, and the cost functions are quadratic. And there's no pure equilibrium in a very small selfish routing network example. So Rosenstall's theorem, it's great when it holds, but the question remains what do you do when it doesn't hold? So the fact that there's no pure equilibrium, a model like this, that doesn't change the fact that we want to reason about it.
00:27:49.506 - 00:28:14.882, Speaker B: We want to understand the usual questions. When is the price of anarchy small? When is the behavior by strategic players likely to lead to an outcome which is not too far to optimal? But because there's no pure equilibrium, we have to take a somewhat different attack for have a meaningful price of anarchy bound in a model like these, we have to enlarge the set of equilibria to recover guaranteed existence so that we can have meaningful price of anarchy analyses.
00:28:14.946 - 00:28:15.174, Speaker C: Okay?
00:28:15.212 - 00:28:17.320, Speaker B: And so that's the plan from here on.
00:28:18.330 - 00:28:21.120, Speaker A: Question so people.
00:28:25.890 - 00:29:21.486, Speaker B: Is not what, um, I see what you're saying. I don't think it's equivalent. I mean they're not, they're not unrelated but I don't see an equivalence in either direction. I understand your question and yeah, I mean they're not unrelated but I don't see a specific technical connection. Yeah, because in Rosenthal's proof, all the players have the same weight. So when a player moved to an edge we knew it was plus one, it was never plus two. Yeah, so there's really kind of a phase transition between whether all players have exactly the same weight or not.
00:29:21.486 - 00:29:44.710, Speaker B: At least there's a phase transition with respect to the existence of pure equilibrium. What we don't know at the moment is whether there's some phase transition in terms of the price of anarchy. And in fact, once we develop richer equilibrium concepts, we'll see that there isn't. We'll see that exactly the same theory applies to both the unweighted and the weighted case. But to do that we really need to talk about more general equilibrium concepts. And that's the subject for the rest of this lecture.
00:29:47.610 - 00:29:48.360, Speaker C: Okay?
00:29:48.890 - 00:29:49.640, Speaker B: Yeah.
00:29:55.070 - 00:29:58.826, Speaker A: Being global, excuse me, what was the.
00:29:58.848 - 00:30:01.594, Speaker D: Significance earlier of the minimizer of P.
00:30:01.632 - 00:30:06.400, Speaker B: Being a global minimizer that implied it was an ash equilibrium? Okay, yeah.
00:30:08.770 - 00:30:10.670, Speaker A: You can have more than one bubble.
00:30:13.410 - 00:30:24.290, Speaker B: In a convex function. If it's strictly convex, the answer is just no. And if it's weakly convex, you have this flat bit at the bottom which are all optima and all of those will be equilibria and they'll be essentially the same equilibrium.
00:30:32.490 - 00:30:32.758, Speaker C: Yes.
00:30:32.764 - 00:31:02.826, Speaker B: So that was for the non atomic model where we were talking uniqueness. So as we know we do not have uniqueness in the atomic model. So it's an interesting extra feature of the non atomic model that you have uniqueness. And the reason you have it is because of complexity of the potential function. So I hope the motivation of where we are right now is clear. Pure equilibria have gotten us as far as they have. We began with a model Nonatomic selfish routing, which was special in that we had both existence of equilibria and uniqueness.
00:31:02.826 - 00:31:35.258, Speaker B: So it was very clear what the price of anarchy should be. Then we graduated to atomic selfish routing where we still had existence of pure equilibrium, but we had multiple equilibriums. We had to redefine the price of anarchy in terms of the worst pure equilibrium. So now that we're pushing it even further, we lose existence of pure equilibrium and we need to move on to more permissive equilibrium concepts. I'm going to show you three in the rest of this lecture. One, you already know mixed strategy Nash equilibria, but I'm still going to talk a little bit about it. Two are probably new to most of you, correlated equilibria and coarse correlated equilibrium and the focus will be on.
00:31:35.258 - 00:32:24.810, Speaker B: So each of these will be in some sense a strict superset of the previous one will be more general, more permissive. And the focus is going to be on when do we have guaranteed existence, and a subtext will be when do we have computational tractability of these equilibrium concepts. All right, so to discuss these equilibrium concepts, simply, let me just kind of formalize the games we've been talking about in the last week. So a cost minimization game, and just go ahead and think about selfish routing as a canonical example. That's fine. So the ingredients are, you have players, finite set, K players. Each player has its options.
00:32:24.810 - 00:33:07.826, Speaker B: So strategy set, these are also going to be finite a one through AK. So in a routing example, these would correspond to siti pairs. These would just be siti paths in some network. And then for every player, I have to tell you what is the cost. It incurs in a given outcome. And again, an outcome is just a choice of a strategy by each of the players. So for all I, I tell you a cost function CI, where here S, the vector S is called either a strategy profile or an outcome.
00:33:07.826 - 00:33:15.270, Speaker B: Okay, so this is just like a traffic pattern. And this would be the cost that I incurs when it picks a given path in a given traffic pattern.
00:33:15.350 - 00:33:15.980, Speaker C: Okay.
00:33:17.710 - 00:34:14.338, Speaker B: So we already, just for the record, we already know what a pure Nash equilibrium is. But just to compare it to the other three concepts I'm going to tell you about, how would we write it in this notation? Well, so no player can be better off by unilateral deviation. So S is a pure national equilibrium if for every potential deviator, every potential deviation, if I look at its cost after deviating. So I hope you remember this notation from mechanism design. This is just holding the other player's strategies fixed player I deviates to something else, s prime I. And it can only be worse off by deviating. That is the cost should only be higher than in the equilibrium.
00:34:14.338 - 00:35:28.390, Speaker B: This is true simultaneously for all I. And these are great when you got them, but it need not exist. So to track the progress in this lecture, let's use a sort of running diagram to keep track of our four equilibrium concepts, each one more permissive than the previous. So the smallest set is going to be the purest strategy Nash Equilibria. And the first big issue with them is the need not exist. So let's move on to mixed strategy Nash equilibria. We talked about these in Rock, Paper, Scissors in lecture one, how the only way to have a sensible pair of equilibrium strategies in Rock, Paper, Scissors is to allow both of the players to randomize uniformly over the three available strategies.
00:35:28.390 - 00:35:57.994, Speaker B: So in general, the candidates for mixed strategy Nash Equilibria are each player, rather than picking a single action deterministically, it picks a distribution over its actions. The assumption is that then players pick at random a strategy independently, each from the distribution that they've chosen. And then it should be at an equilibrium in the sense that this exact same inequality should hold. But now an expectation where expectation is over the random choices made by all of the players.
00:35:58.122 - 00:35:58.800, Speaker C: Okay.
00:36:06.790 - 00:37:02.670, Speaker B: So a mixed equilibrium. So now instead of a vector of strategies, we look at a vector of distributions over strategies. And these form a mixed Nash equilibrium. If again, for all potential deviators, for all potential deviations, s prime i, the deviation only increases your expected cost. Okay, so add equilibrium. Again, how do we evaluate your cost? All players pick a strategy at random, independently. So I'm going to write sigma for the product distribution.
00:37:04.610 - 00:37:18.140, Speaker A: And it.
00:37:25.310 - 00:38:02.950, Speaker B: And then over here, I look at your expected cost. If you deviate, that's an S prime. So on the left hand side, in general, all K components of this are random because each player is choosing si at random from sigma i. In the right hand side, these K minus one components are again random. They're chosen just as before from those players mixed distributions. This is deterministic. This is a fixed pure strategy s prime I that we're considering as a deviation.
00:38:02.950 - 00:38:30.270, Speaker B: Now perhaps you'd think about an alternative definition. Well, if players are allowed to mix, why not allow them to mix when they deviate? Here, I forced them to deviate to a pure strategy. So you could, you could write down the definition where you could actually deviate to a sigma prime i. You get exactly the same definition. So I'll ask you to work that out in the exercise set. So it doesn't matter whether you check just the pure deviations or the mixed ones. Either way, that's a mixed Nash equilibrium.
00:38:30.270 - 00:39:21.690, Speaker B: All right, so what I hope is obvious is that the pure Nash equilibria are exactly the mixed Nash equilibria. When each sigma I is a point, mass plays a single strategy with 100% probability. Okay, so I hope it's obvious. Pure Nash equilibria are a subset of the mixed Nash equilibria. Rock, Paper, Scissors shows us it can be a strict subset as well. Okay, so the mixed Nash equilibrium contain the pure Nash equilibrium and possibly more. Now, by virtue of being a bigger set, it's conceivable that we have recovered existence.
00:39:21.690 - 00:40:07.360, Speaker B: Okay, we know this might be empty, might be non empty. This can only be bigger. So a highly nonobvious question is whether that set is always non empty, whether a mixed equilibrium is guaranteed to exist. So we're not going to talk about the proof now? We'll talk about the proof in a few weeks. But indeed, Nash's theorem from 1950 says that in every finite game there is indeed at least one mixed Nash equilibrium. Okay, so while the innermost set need not exist, this set is guaranteed to exist. So that's the good news.
00:40:07.360 - 00:40:48.700, Speaker B: The bad news is a much more recent development, really a 21st century development, which is that despite its universal existence. It can be as hard as finding a needle in a haystack. So it can be computationally intractable. We'll discuss at some length, probably in the last week of the course, the sense in which computing a Nash equilibrium is computationally intractable. It's okay if for now you think of it as something like NP hardness, but you should know that the truth is rather more complicated. And again, I'll explain what I mean by that at the end of the course. All right, so that's the bad news.
00:40:48.700 - 00:40:53.886, Speaker B: We know an as equilibrium is out.
00:40:53.908 - 00:40:54.480, Speaker A: There.
00:40:56.770 - 00:41:32.934, Speaker B: But in a precise sense, in general, it's hard to compute. So don't forget our mission. When we started on this strategy of cataloging equilibrium concepts, we were bummed that we're concerned about price of Anarchy analyses that were vacuous. Okay, so when we move to mixed Nash equilibrium, what's happened? Well, because we've recovered guaranteed existence, at least the price of Anarchy is well defined. For the mixed Nash equilibrium of a game, there's at least one. You can just take the worst case over however many there are. Okay, so it makes sense to define the price of Anarchy, given that it's hard to compute one of these equilibria.
00:41:32.934 - 00:42:11.590, Speaker B: Though in general, it's not clear that that bound is meaningful if you prove that every mixed natural equilibrium is within a factor two of an optimal solution. But it's hard to even find one of those equilibria. Maybe I don't care that much about the bound if there's no reason to expect players to have found one of these equilibria, solving this intractable problem, maybe it's not so interesting to have a bound on their quality. So that motivates. Going even beyond the very well known mixed Nash equilibrium concept and looking at still more general equilibrium concepts to recover. We're going to have existence from here on out, but now we want to recover computational tractability. And the flip side of that coin is sort of behavioral plausibility.
00:42:16.570 - 00:42:17.480, Speaker C: All right.
00:42:24.250 - 00:42:43.262, Speaker B: It so here's the third equilibrium concept. This one is the most subtle of the four four, so we'll allow some time for it. It's called a correlated equilibrium. I'm just curious, who's heard of a correlated equilibrium before? Few of you?
00:42:43.316 - 00:42:43.920, Speaker A: Okay.
00:42:48.130 - 00:43:03.540, Speaker B: So I'll give you the definition, then I'll give you some proposed semantics with the definition, which are also kind of the original semantics proposed by Alman. Proposed it back in 74 and.
