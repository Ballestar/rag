00:00:00.330 - 00:00:50.734, Speaker A: Okay, so we've wrapped up the mechanism design segment of the course. You might recall from the first lecture that was part one of three. So we're going to start part two of the course today. And part two is about understanding the inefficiency of equilibrium in games. So this area is motivated by a actually fairly common scenario where you don't have the luxury of designing a game, of designing the rules from scratch. So so far we've assumed that you knew some information about the environment and you got to pick the rules of the game so that the outcome of strategic behavior was what you wanted or as close to what you wanted as possible. So now we're going to look at games in the most basic form, games that just occur in the wild which already exist, where strategic behavior is already there.
00:00:50.734 - 00:01:47.790, Speaker A: We want to know which ones function well and which ones don't. So when the games in the wild, if you will, nevertheless have near optimal equilibrium so sometimes they do, sometimes they don't. Our goal is to have a delineation between the two to really understand which are the good cases and which are the bad cases. Now let me open with just some comments about the difference between this part of the course and the previous one. So on a technical level, our analyses of the inefficiency of Equilibria or the so called price of anarchy, they'll have a different flavor on a couple of levels. So first of all, the games will generally not have dominant strategies. Again, we didn't have the luxury of defining them.
00:01:47.790 - 00:02:19.330, Speaker A: In fact, dominant strategies are pretty rare. So we're actually going to have to analyze non trivial Equilibria. We'll start with Nash Equilibria, but look at a couple of other equilibrium concepts as well. As you might expect, if we don't have the luxury of designing the game, we're typically not going to get full optimality. So there's certainly going to be no analogous result as like the VCG mechanism which says in principle you can get full surplus if you can design the rules of the game. In fact, forget about full optimality, even approximate optimality. In some sense the game has to have fairly special structure.
00:02:19.330 - 00:03:02.902, Speaker A: So the hope is that there are application domains of interest assumptions which on the one hand are strong but are also met in interesting scenarios where we can prove that Equilibria are near optimal. And I'm happy to say we now have about 15 years of experience of different domains where you can actually prove that Equilibria are guaranteed to be close to optimal. One thing that'll be simpler in this part of the course is there won't be private information. So for example, in a traffic network, all players are going to be fully aware that all of the players just want a shortest path. They just want to get to their destination as quickly as possible. By contrast, in the auction setting, I didn't even know what other people wanted. So if you asked me, would this other bidder prefer to win the item at a price of ten or lose? I don't know.
00:03:02.902 - 00:03:33.534, Speaker A: Depends if the valuation is at least ten or not. And I couldn't answer that question in rock, paper, scissors. If you ask me, given that I'm playing rock, would they prefer to play scissors or paper? I know the answer. I know they prefer to play paper. Okay, so it's going to be mostly full information games for those of you who take the SQL course in the winter. There'll be a nice dovetailing of these two areas, and we'll look at things like the inefficiency of Bayesnash Equilibria, which is a way of modeling private valuations in this kind of setup. But for this course, we'll just stick with the full information case, I guess.
00:03:33.534 - 00:04:25.826, Speaker A: One final historical comment. So in mechanism design, I taught you a mixture of classical economic theory, so Meyerson's theory of optimal options being a good example, and the novel contributions coming from computer science have been novel questions or novel extensions on top of this classical economic framework. One thing that's cool about this part of the course is really these questions essentially were never asked, certainly never asked systematically until they were until about 15 years ago, and that came out of the computer science community. So this idea really has this genesis in a paper of Kutsupius and Papdamitrio, two computer scientists back in 1999. The following year, I started working on it myself with my PhD advisor, Ava Tardosh. Okay, so any questions before we get started? Let me quickly remind you of what I mean by a game in the, and this is going to be Braces Paradox. We talked about this in lecture one.
00:04:25.826 - 00:04:50.966, Speaker A: Let me jog your memory. So what you want to think about is you want to think about traffic. And computer scientists who have studied this were motivated more by data networks, communication networks. But the model goes back, as you might expect, to transportation scientists. And you may as well think about morning commuters leaving at 08:00 A.m. From a common origin S to a common destination T. And of course, drivers take whichever route they want.
00:04:50.966 - 00:05:21.106, Speaker A: There's no central authority dictating which route you take from point A to point B. And we're going to assume always that they want to minimize their travel time. And what makes it interesting, the reason you as a driver care about what other drivers do is the congestion on roads goes up, and as it goes up, your travel time increases. So in the basic Brace Paradox network, we have two kinds of roads. We have very simple ones labeled by the cost function C of X equal one. That's a constant cost function. So that says driving on this road takes an hour no matter what.
00:05:21.106 - 00:05:58.110, Speaker A: So think of it as a long road with an infinite number of lanes, but then we have these other roads, c of x equal x. So these are roads that get congested as more and more people use it. So there's one unit of traffic overall. If x units or an x fraction of the traffic takes one of these links, we assume it costs x hours. So if half the traffic is on one of those links, it takes 30 minutes to cross that particular link. So what we did on lecture one is we first asked what kind of equilibrium would they settle into in this basic network? So this already is a game without any dominant strategies. If more people, for whatever reason, are using the top half, you'd prefer the bottom one.
00:05:58.110 - 00:06:32.570, Speaker A: If more people are using the bottom one, you'd prefer to use the top. So your quote unquote best response, your best action depends on what others are doing. So there's no dominant strategies. But by symmetry, we argued that we expect traffic. If these are the same people listening to the traffic report day after day, there's really no reason to prefer one of the paths over the other. So we'd expect a 50 50 split for an average commute time of 90 minutes. The reason it's called Braces Paradox is when you augment the network by a teleportation device.
00:06:32.570 - 00:07:07.974, Speaker A: So zero cost to teleport from the midpoint of the top path to the midpoint of the bottom path, and no congestion. Now, all of a sudden, I've introduced a dominant strategy. So it turns out, no matter what the other drivers do, you always want to use this teleporter. It's always in your best interest. The problem is that when everybody rushes to follow their dominant strategy and 100% of the traffic is on the Zigzag path, the congestion on the upper left and the lower right links have gone up to one, and the commute time has gone up to 2 hours. And because this is the dominant strategy of all the drivers, there's no other equilibrium. This really is what happens.
00:07:07.974 - 00:07:51.150, Speaker A: And people have run lab experiments. If you introduce the teleporter, this is really what happens. People wind up in this equilibrium with a higher commute time than before the introduction of the teleportation device. So the paradox was unlike an optimization, where adding more feasible solutions can only make you better off. Here, you add extra options, and the equilibrium gets worse. So the commute time goes from three halves to two. In particular, in this new network, we're asking, when are equilibrium optimal or near optimal? Well, the equilibrium in this new network is certainly not optimal.
00:07:51.150 - 00:08:46.802, Speaker A: It turns out the optimal thing, even after the teleporter, the best thing to do is just ignore it and stick with the 55th piece split. Okay, so in the new network, the equilibrium has commute time too, but the optimal commute time, if you in principle had dictatorial control of everybody, you could achieve a commute time of 90 minutes. So the price of anarchy is just defined as the ratio between these two quantities. You look at the performance achieved under strategic behavior, the performance you could hypothetically attain if you could dictate actions to everybody, that's going to be a ratio, at least one. In this case, it's four thirds. So POA in the new network after the teleporter equals two divided by three halves or four thirds. And so the price of anarchy in these kinds of networks is just defined as the equilibrium commute time over the optimal commute time.
00:08:46.802 - 00:09:42.870, Speaker A: And again, it turns out in the network with the teleporter, you cannot do better than that 50 50 split that turns out to be optimal. So that, I think, hopefully jogs your memory of what we've already discussed back in lecture one. There's actually an even simpler so called salvage routing network which shows you that the price of anarchy can be four thirds. So that was from 1968. Let's go back even further to 1920, where in his book The Economics of Welfare, AC Pigu discussed at least qualitatively the following example. So he said, what if there's just two parallel roads? Okay? So literally highway 101 and highway 280, connecting Stanford to San Francisco. So just to make the example kind of as stark as possible, let's use these same totally flat and then identity function, cost functions.
00:09:42.870 - 00:10:30.210, Speaker A: So what do we expect to happen at the equilibrium here? Again, assume there's one unit of traffic overall. So what would you do as a driver? Take the top or take the bottom? Yeah. So here we again have a dominant strategy, it turns out, in this particular network. So it's always a good idea to take the top. The worst case scenario on the top is as good as the best case scenario on the bottom. So does it seem like could you do better with respect to the average commute time if I could move some of the people around, if I was a dictator of the system? In fact, anything would be better actually than this equilibrium. Okay, so it turns out the optimal thing to do is a 50 50 split.
00:10:30.210 - 00:11:06.740, Speaker A: It's a simple calculation. So what's the average commute time with a 50 50 split? So half the people take an hour, half take a half an hour. So it's on average it's 45 minutes. So again, price of anarchy is one divided by three quarters or four. Three. We'll discuss to what extent this four thirds is or is not a coincidence later in lecture. All right, but let me come clean.
00:11:06.740 - 00:11:47.920, Speaker A: Turns out, even in these simple routing networks, so if the price of anarchy was always four thirds no matter what, arguably we'd be pretty happy because remember, this is a system where we're exerting zero control at all. We're just letting people do whatever they want. And if they inadvertently wind up getting a pretty good approximation of this hypothetical optimal solution, we're going to define that as a well functioning system. So we'd actually be happy if this was the worst we ever saw. Four thirds. Turns out I don't have to tweak this example too much to show you that in these routing networks the price of anarchy can unfortunately be much larger. So let's look at a non linear version of Pigu's example.
00:11:47.920 - 00:12:34.960, Speaker A: So keep everything the same, except instead of this function, c of X equal x going to make it c of X equal D x to the D. We should think of D as large ten, 101,000, some large number. So how does this affect what happens at equilibrium? Changing D equal one to D equals some large number. No change. Still a dominant strategy. Take the top edge. When everybody does that, you still get a solution in which the average commute time, in fact the common commute time is an hour.
00:12:34.960 - 00:13:23.470, Speaker A: So selfish solution still costs one. What about the optimal solution? So even if you just keep the 50 50 split already, the optimal solution is going to improve as D grows large, right? Because on the bottom you'll still have these half of the people that have an hour travel time on the bottom, but that 50% on the top. Their travel time is going to be X to the D or one half raised to the D. So as D grows large, that's going to zero. So there's people on top of getting there instantaneously. So that already give you a factor two because opt would drop to zero five. But in fact, the situation is even more serious.
00:13:23.470 - 00:14:11.800, Speaker A: The optimal flow can do even better because why bother putting as many as one half on the link of constant cost one? Why not just sacrifice a very small number of martyrs to the link with constant cost? One, you're going to have a one minus epsilon fraction of the traffic on the bottom link. Their common cost will be one minus epsilon raised to the D. One minus epsilon is less than one. So as you keep powering up, it's again just going to zero. So you can find an optimal solution where almost everybody gets to t almost instantaneously. And then there's a few unlucky people who are taking an hour, but they contribute very little to the average. So a little more formally, so the optimal average commute time is epsilon times one.
00:14:11.800 - 00:14:58.222, Speaker A: So what I'm doing here is I'm putting epsilon on bottom, one minus epsilon on top. So the epsilon on the bottom contribute epsilon times one to the average. And then the rest of the average is the one minus epsilon fraction of the people who have travel time one minus epsilon raised to the D. So for any given D, I could solve for the optimal epsilon. But what's going to be true is as I take D larger and larger, the optimal epsilon is going to be smaller and smaller. And then the limit as D goes to infinity and epsilon goes to zero. This optimal cost is actually going to zero, and therefore the ratio between the equilibrium commute time, which is one for every D, and the optimal commute time, which is going to zero with D, this is blowing up to infinity.
00:14:58.222 - 00:16:28.400, Speaker A: Okay? So in conclusion, price of energy goes to infinity as D goes to infinity and epsilon goes to zero. So we're seeing already in these very simple traffic networks, even in just two node toolink examples, sometimes, for whatever reason, the price of energy is good, I it's close to one, sometimes it's not. Okay, so the best we can do as analysts is understand as thoroughly as possible when are these networks? When do they function well and when do they not? So that's the question that we want to answer as thoroughly as possible in this lecture. When that is, under what conditions is the price of anarchy, of selfish routing small, where small means as close to one as possible? Okay, so what might be hope for? Well, for example, I've shown you three different networks. I've shown you one Braces Paradox, where the price of anarchy is four thirds, not too bad. I've shown you another one PICU's example where the price of anarchy is four thirds not too bad. But then I showed you the nonlinear linear variant where it is bad.
00:16:28.400 - 00:17:20.818, Speaker A: And if you're feeling kind of very cavalier, maybe you'd look at these three examples and say, what's the coolest fact I could imagine possibly proving, given what I know is true? And you say, okay, well, obviously an obstruction to having a price of energy close to one is having highly nonlinear cost functions. If you have these x to the DS for super big D, you can't prove anything, right? The nonlinear piggy's example shows that. So if you're feeling very optimistic, you might conjecture that's the only obstruction. So as long as you didn't have very nonlinear cost functions, you're going to be fine. For example, maybe at least if you knew that the cost functions were linear or f fine. So of the form ax plus b, like in Braces Paradox and pigs example, maybe as long as the cost functions are F fine, the price of energy is not too bad. Okay, that's kind of the strongest statement that might be true, given what I've shown you so far.
00:17:20.818 - 00:18:28.002, Speaker A: Turns out it is true. I'll show you a proof in this lecturer let me pin down the model a little bit more before I explain the statement we're going to prove today. So, in general, we have a directed graph with an origin S and a destination T. This is given and you're also told how much traffic there is. So our units of flow or of traffic are to go from S to T in a directed graph G with edge set E, vertex set V. I'm assuming one origin, one destination. Everything I prove to you about these selfish routing networks remains true even if there are multiple origins and multiple destinations.
00:18:28.002 - 00:19:09.570, Speaker A: And I'll ask you to do that extension on exercise set number six. It's really exactly the same proofs, just a little extra notation. So to keep the notation down in lecture, I'm going to assume one origin and one destination and then the only other ingredient in the model. So you have the network and then you have the edge. Cost functions of E. That's a C sub E to denote the cost function of an edge. I want to emphasize this is the cost of the travel time per unit.
00:19:09.570 - 00:19:42.698, Speaker A: So for example, if it's 30 minutes, all traffic on that edge takes 30 minutes. So it's per unit of traffic. And we'll add some extra assumptions as we need to to derive good bounds. But the baseline assumptions are very minimal. No time machines, travel times are non negative. Traffic is only bad. So cost functions are non decreasing.
00:19:42.698 - 00:20:59.286, Speaker A: They can be constant, that's fine, but they can't go down and I'm going to want them to be continuous. Okay, so those are the baseline assumptions. But in your mind as you go through this lecture today, go ahead and if you want think about just the Affine cost function case. I'm fine with you just keeping that as a concrete running example in your mind. So what are we going to prove? Let me explain the results a little bit informally, then I'll develop the definitions that let me state it precisely. But let me just tell you conceptually what we're going to establish today's, an old result of mine. So the main result is going to say that always worst case examples are extremely simple.
00:20:59.286 - 00:21:32.334, Speaker A: Just like that piguz example that you already saw. That's the high level message. So among all networks with cost functions in the set C. So to state this I'm going to going to rise by a set script C. These are the permitted cost functions. So for example, the set C might be the set of Affine functions, all functions of the form ax plus B. Or maybe it's going to be a bigger set.
00:21:32.334 - 00:21:34.460, Speaker A: Okay. And of course the bigger the set.
