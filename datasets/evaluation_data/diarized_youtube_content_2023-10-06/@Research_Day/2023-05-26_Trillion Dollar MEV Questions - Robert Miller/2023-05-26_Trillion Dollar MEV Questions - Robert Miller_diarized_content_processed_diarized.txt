00:00:10.600 - 00:00:45.000, Speaker A: MJ is too kind. He had me go first because he knew that I would show up on time. So originally I was going to give a talk on Suave, but John told me that he had said everything that there is to say about Suave in the public domain already. So we're going to be talking today about trillion dollar mev questions. I'm Robert, I lead product. I'm a steward at Flashbots. We think that these are trillion dollar mev questions because they inform the structure of the market of mev, because we think mev is going to be at the core of cryptocurrency.
00:00:45.000 - 00:01:46.110, Speaker A: So I won't tell you what the trillion dollar questions are. We'll go through them as we get to them to keep a little bit of suspense. But number one, so what is the privacy and efficiency Frontier? These are slightly outdated slides, thus the double. And unfortunately so what do we mean by privacy and Efficiency Frontier? So first place to start here is that privacy is needed to decentralize the mev supply chain. If you think about in proof of stake ethereum, today Validators want to outsource their block construction to specialized entities that are really good at creating the most profitable block possible. But these parties, called builders, aren't willing to share their blocks in clear text with just any Validator, because any Validator might front run them, they might steal their mev, they might unbundle them or do other malicious things. So what this means is that builders, if they were required to send their blocks in clear text to Validators, would only send them to trusted Validators, large ones, ones that have reputation, your lido binance Coinbases of the world.
00:01:46.110 - 00:02:53.964, Speaker A: And in order for small Validators to have access to the same mev as large ones, you need some notion of privacy between builders and Validators. That's one example. And this comes up all throughout the mev supply chain, so users and searchers can't collaborate without privacy. Searchers and searchers decentralized building. Privacy is at the core of the mev supply chain, but it comes at the expense of efficiency. So if you have privacy, how do you optimize your mev extraction? How do you make an ARB with only a limited set of information? How do you merge a block without knowing the entire contents of what you're merging on top of, right? What information can you share to make this more efficient while still enabling these parties to work together? That is the Privacy and efficiency frontier. What information do you share and when and how does it affect the efficiency of the system? So, as a few didactic examples, to get this idea in your head, we'll look at this curve that maps efficiency in the bottom left to sorry, no efficiency on the Y axis, to efficiency, no privacy to full privacy on the X axis.
00:02:53.964 - 00:03:43.488, Speaker A: And we ask the question of what's the shape of this curve? The very naive curve would be as we layer on more privacy, the system becomes linearly, less efficient. So we start with no privacy, full efficiency of extraction or merging or of mev broadly we move to full privacy. Kind of every incremental unit makes the system less efficient, but if we look at an individual example, we find that it's much more nuanced. So for uniswap V two trades, you may not want to share your trade details because if you start at this place with no privacy, your trade is going to get front run by searchers telling everyone what your slippage is, what you're trading on, et cetera. You get worse execution. That's why we start this purple line relatively low, but kind of interestingly, if you hide trade details, you still reveal what you're trading on. So not the direction, not the amount or slippage, but just what the pair is.
00:03:43.488 - 00:04:44.790, Speaker A: You can do these really interesting blind but atomic arbitrages so you can calculate the atomic arbitrage all on chain in a smart contract, only knowing what pair someone is trading on off chain. And this is kind of working live code that if you want, you can go to our GitHub page here, run this bot, see how it works for yourself. So there's this interesting space where actually if you layer on privacy, you get a more efficient system, a system that rebates more value back to users rather than one with no privacy. But there's a point here where this clearly becomes suboptimal because if you hide even what pair someone is trading on with a fully private system, searchers are executing in a totally blind situation. You have to spam the system with every possible trade and you lose some sense of efficiency. So the curve here is non intuitive, the shape we may not be able to just take a naive idea of. Let's look at how it might work in block building too with another didactic example.
00:04:44.790 - 00:06:01.384, Speaker A: So, what I'm putting up on the screen here is the process of building a block. We start with one bundle here and in this example, after every bundle, we share a little bit of information with the rest of the world about the state of the block that is being built. So if you take this example with a single bundle that has been merged into a block and we ask what happens if we share the value of this block and the pools that have been touched? And is this safe to share at this point in the block building process with a single bundle? It's not safe because if you know it's a very valuable block and you know the state of the pools that are touched, you can probably back out what trade or arbitrage to Semi VBOT has done in bundle one front. Run that yourself. So it's probably not safe to share information at this point. But what happens if you layer on more bundles to this process? So if you introduce another bundle that might make a trade on the same pools in a different direction, so there's a little bit of noise in the pools and you do this incrementally over and over at different steps of the process. At what point could it perhaps be safe to share a little bit of information with the external world to help searchers optimize their MUV, to have this feedback process of what the partial block being built is to ongoing extraction by searchers.
00:06:01.384 - 00:06:42.548, Speaker A: And this is one question of when it is safe to share information, at what point. And this is relevant because we're trying to create the most efficient system possible. And this is an example of how privacy and efficiency in the frontier looks within blockbuilding. And to link this back to kind of what we're doing at Flashbots today with Mev Share, we've created this early playground for us to run these privacy experiments in production today. So if you go to Mev Share flashbots. Net, you can see all transactions that are going through Mev Share with information that's being leaked from them. You can search on them if you are an Mev searcher.
00:06:42.548 - 00:07:48.160, Speaker A: And we're interested in other types of experiments with how you share information across the block building process in Mev Share, if anyone here has any ideas for the kind of privacy experiments that we should run. So this is the first large area of the large trillion dollar Mev question is what this frontier of privacy and efficiency looks like when you share information, and how and under what conditions is it safe. The second area is how we escape SGX in the Mev ecosystem. So there's an embedded assumption here, and we'll walk through the assumption as so to move forward within the Mev ecosystem, we being crypto, but also Flashbots need to remove trust from all centralized operators in the Mev supply chain. So the current state of parties like Flashbots, other builders, other operators running centralized infrastructure, probably not long term tenable. We want to make this infrastructure permissionless, lower the barriers to entry, make it more censorship resistant. But how do you do that? It's an extremely difficult problem, many of us are working on it.
00:07:48.160 - 00:08:29.960, Speaker A: Some potential starting points for this one, maybe crypto economics. Two, can you distribute it across a multi SIG or a federation? Three, pure cryptography. Four, trusted hardware. I'm kind of getting ahead of myself in this, but the question is, how do we escape SGX? So just to frame it, we think out of all these potential starting points, SGX is the best path forward in the short term. So the question is how to break out of that in the long term. And that's what this question is about, what we'll talk about for the next five or ten minutes. So why SGX? Why trusted hardware? How does that work? Trusted hardware gives us privacy and verifiable tamper proof execution.
00:08:29.960 - 00:10:02.808, Speaker A: So if you are running code inside of trusted hardware, that means even the party who physically has piece of trusted hardware cannot see what's going on inside of it and they can't tamper with the code that is running inside of it. So, you know, a certain set of rules, a certain binary executable is running inside of that trusted hardware. And this is useful because it allows you to have permissionless mev infrastructure. So instead of an ecosystem where searchers and users need to all decide which builder do you trust? Blocksroute, Flashbots, Rsync, et cetera, you could send to anyone who's running this permissionless SGX infrastructure in Sad, which is the kind of infrastructure that we want to get to, but it comes at the expense of needing to trust the manufacturer of the hardware, in this case with SGX, the most viable short term option that is intel. And oftentimes this is where people like to get pokey on Twitter about it in Flashbot's desire to run infrastructure in sex, asking the question of why are you comfortable putting your infrastructure in this, why are you comfortable trusting intel? And for us at Flashbots, we think this is a reasonable trade off to make because it buys you permissionless. Mev infrastructure anyone in the ideal case running this infrastructure and intel is a relatively disinterested party within the mev supply chain right now. They want to sell hardware and if this is successful, we'll put billions of dollars of value going through their hardware annually and be the first real use case for SGX out there.
00:10:02.808 - 00:11:00.492, Speaker A: They are incentive aligned for this to be secure, they're not a block builder, they don't have an interest in messing around with what is going on in an SGX. So we think it's relatively incentive aligned, gained theoretically aligned in the short term and it is a trade off we're willing to make to get to permissionless. But you know, you might ask, like Robert, I see all of these tweets of SGX attacks. What are you doing? Are you all crazy? And the answer is maybe a little bit, but it's more nuanced than that. So there are many known SGX attacks where you can leak information out of an SGX through side channels or covert channels. The thing is that if you design your applications in a very thoughtful way, you can mitigate most of these, or at least a good class of them. So the challenge is how do you build mev infrastructure in a way that is aware of SCX as an example, making your bundle merging code run in constant time.
00:11:00.492 - 00:12:12.336, Speaker A: So there's no inferences that you can make of how long a bundle took to merge as an example. And we think that the economics of these systems are relatively underlooked. So it's important to ask the question of what is the marginal cost of an attack on SGX and how does that compare in the equilibrium to the marginal benefit that can be gained? And if, say, the marginal cost of an SGX zero day is $100,000. What is the next zero day cost? Is it $200,000? Is it still 100,000? Is it a million? Something like that? And if you take an individual block that someone could break an SGX for, how much value can they extract from the system? And we think the answer to these questions come out very favorable for SGX because the cost of an attack is actually quite high and in the median case the marginal gain is relatively low and it just falls back to the status quo. We think SGX is reasonable for that reason. Briefly a couple future directions for trusted hardware so diversifying to other providers like AMD. In the long run you might even get in the case where if we think this is really important for the community, you're not running Intel SGX, but even like EF SGX or Flashbots SGX.
00:12:12.336 - 00:12:50.012, Speaker A: We'll develop our own hardware on a ten year timeline, something like that. Dan Bennett gave this really interesting presentation where he made the contention that in the same way zero knowledge cryptography was catalyzed by crypto secure enclave, research was going to be catalyzed by mev in the coming years. So we'll see mev specific enclaves too, outside of even the Flashpots SGX idea. So that's enough on SGX. That's broadly my argument to you for why SGX is reasonable in the short term for a choice. Let's talk about crypto economics and how that relates to MEB. So these are a couple images of crypto economic proposals.
00:12:50.012 - 00:13:24.840, Speaker A: The top left and top right are from Vitalik's two slot Proposal Builder Split. The text doesn't really matter for you. It's actually just like crypto economic proposal or proposals that use crypto economics generally. What we mean is some kind of economic incentive to behave honestly through losing revenue or maybe slashing conditions. Top left is that being used in the relay market today. And one of the reasons why crypto economics is challenging in the mev ecosystem is because of graphs like this. So top left shows you the daily mev that was paid to miners in proof of work.
00:13:24.840 - 00:14:04.744, Speaker A: And it's an extremely spiky graph. So you have two large spikes there that get up to 6400 ETH when the average daily ETH paid out to miners is something like 200, right? So in the extreme cases you have 32 times worth of mev going through the system on a day that you do on the average day. And that means that it's very hard to reason about what happens to your crypto economic systems and your guarantees at the limit. And oftentimes you may have incentives to deviate in these exceptional cases that we think are kind of inherent to how mev works. You see this repeatedly happening, this happened this year. The kind of average value of a block going through mev boost is somewhere between 0.1 and 0.2
00:14:04.744 - 00:14:55.892, Speaker A: ETH and there have been 800 ETH value blocks. So thousands of times the value of the average block and this makes it very difficult again to reason about what happens at these limits. We think this is kind of inherent and crypto economics can break down at these limits too. An example of this is from the mev burn proposal that Justin Drake just put out highlighting how sometimes the PBS market structure can break down in the absence of some tweaks that he proposes within mev burn when there's exceptionally large mev spikes. Which isn't to say that crypto economics is useless, but rather that it's nuanced and there are some cases where we can augment it with other things. Another case that I want to share with you is Mev Share. So a very pragmatic sort of short term product roadmap for Flashbots and how we're thinking about crypto economics.
00:14:55.892 - 00:16:12.384, Speaker A: This is the feed for Mev Share transactions, you can look at it yourself on your laptop if you want. And we're thinking about how do you take the transactions and the bundles that are output by this system and allow any builder to permissionlessly use those within a block? Can you use crypto economics within this system? And as we worked through these questions, we found that it is very difficult to falsifiably prove when parties are behaving dishonestly and as a result it's difficult to use crypto economics within the system. So crypto economics in at least the short term kind of product roadmap that we have within Mev share fell short here because of non falsifiability and because we need some level of privacy that just crypto economics itself would not meet. But I think if you look at SGX and economics the system becomes a lot more robust and a lot more interesting. And this is how we think about defense and security at Flashbots. So you have SGX giving you some security properties that are very useful and crypto economics that are giving other properties that are very useful. And to run you through this table, which is from Phil, from Flashbots, the kind of capital that's required to break your design goals within crypto economics systems is inherently very high.
00:16:12.384 - 00:17:20.184, Speaker A: It's like the purpose of using crypto economics right? With SGX it's not so clear, it's not clear what the marginal cost of a new attack on SGX is. But in a crypto economic system you're narrowly kind of reasoning out a set of assumptions and design goals and you don't have security outside of those design goals kind of inherent to the design of crypto economic system. In SGX you by default get some amount of security beyond your design goals because you're restricted to what you can do to the actual code paths that are running inside of an SGX. So it buys you some kind of security outside of your set of assumptions and the code paths that you think people will naturally reach. In SGX you require a great deal of expertise to break a system and attack it sort of inherent to what it takes to find one of these new attacks on SGX, which will take a good deal of people together, maybe ten, maybe a month altogether. But in crypto economics, oftentimes you know exactly kind of the capital limits and how to pull off an attack is just a question of capital within the system. This is a bit high level, a bit of a caricature even.
00:17:20.184 - 00:18:53.168, Speaker A: But this is just to demonstrate how these things are actually complementary instead of and you should use them together in defense and in depth, and how each system has its own limits as well, to briefly talk about multisigs and then pure crypto and then move to our next trillion dollar question. So with a multi SIG, the question is can you take trust in a centralized party today, distribute it across multiple parties, and if you assume that market structure, then you needed to ask a question of who's a part of the multisig and how do you attribute kind of dishonest behavior within that multi SIG. In the salient question for mev, Share and Flashpots today, it's how do we share, order flow with other parties and how do you attribute some sort of front running or unbundling within that system? And the answer is generally you can't attribute faults within that system and that gives a privilege to these multisig members that allows them to extract a little bit more rent. So we're very not bullish on these multisig or federation kind of designs at Flashpots for this non attributable reason and the rent that the members can get. And briefly on pure crypto, there's not that much to say on the subject. You could use things like multiparty computations, EKPS, fully homophobic encryption for the same purposes that we do in SGX. But the challenge is that we are not at a place where these technologies are production grade, at least for mev, use cases in kind of the unique settings of mev.
00:18:53.168 - 00:19:42.996, Speaker A: And the natural questions are how soon can you get there and how performant can it be relative to centralized alternatives? There is a good deal of interesting progress on this. So top right, you see a screenshot from back running private transactions using multiparty computation. It's a researcher at Flashbots who is able to use multiparty computation to actually backrun private transactions on uniswap without any information preserving the privacy of the searcher and the user. So we are getting there, it will just take some time to do so on the order of yours and we're not ready just yet. So to review here, crypto economics, it's good, it has its limits. You probably want to layer in SGX multisig, in my humble opinion, probably strictly worse than sex. Pure crypto, we're not ready for production, we want to get there.
00:19:42.996 - 00:20:38.020, Speaker A: A couple years trusted hardware, SGX, it's nuanced, it doesn't feel great, but in the short term it might be the best option that we have. Diversifying like AMD, other providers is helpful. Mev specific hardware also probably helpful, and that's where we're at. But really what I want you to take away from this know SGX alone, not a silver bullet crypto economics alone, not a silver bullet. Defense in depth of all these things together is probably the right approach. And pure crypto is not ready yet, but I hope you can accelerate it. Okay, so our final trillion dollar mev question for the day how do we minimize and address latency advantages within the Mev ecosystem? So why are we talking about latency? Why does that matter for mev? If you look at the top left, this is a graph of the ultrasound relay as they enabled optimistic relaying at their relay.
00:20:38.020 - 00:21:37.524, Speaker A: What this means is that normally in the Mevboost workflow, builders are sending blocks that are being simulated by relays in order to tell how much profit they make, whether they're valid keeping builders honest. But within optimistic relaying, builders post collateral and they then do not have their blocks simulated, they're just instantly passed on to validators. The result being that there is collateral to take from the builder and pay to the proposer if they've acted dishonestly. And the net benefit being you miss this simulation period. And that gives builders more time to optimize for mev so they can do more computation, they can update their blocks based off of what's happening in the external world. And it's something like 100 to 250 milliseconds, which is not that much time, but here it led to a 10% increase in the inclusion rate just straight up from the optimistic relay. So it's a pretty significant advantage.
00:21:37.524 - 00:22:26.484, Speaker A: There's 150 milliseconds already. On the bottom right is a screenshot of the top builders yesterday in 24 hours. Beaver build and Rsync with 25 and 22% respectively, are two statistical arbitrage bots. They used to be searchers that they vertically integrated into builders now. And the hypothesis is for the reason why they are winning so many blocks is that they're able to gain an edge from updating their blocks at the last second based off of sexx arps, basically. So you want to wait until the absolute last moment seeing what the binance API tells you the price is, and that gives you the ability to take more risk and make more higher bids within this system. So latency is already playing a significant role within the mev marketplace.
00:22:26.484 - 00:23:56.336, Speaker A: And why do we care about that? Well, because if latency is the dominant strategy within the mev marketplace where it really matters, you're able to make more profit from being low latency, then there's a natural incentive for parties to colocate together into one place. So if you're trying to optimize for every single millisecond, you're going to want to be in the same place as the rest of the players within the system that you're playing this game in. The net result being that in ecosystems where latency really matters, you might see geographic centralization into a single geography. And if you have all of the mev supply chain within a single geography, then the mev supply chain is subject to the rules of that single geography and you might get censorship or other kind of ways that the state might come and undermine the properties of public blockchains like we want. So we want our protocols to be not latency sensitive and we want geographic distribution within our systems. And that's why latency matters. Here the other thing that I want to call out briefly before decentralized building is it matters not just for centralized exchanges, but for other domains as well, right? So if your roll up as an example has first come through Serve, and if it incentivizes people to have super low latency connections to capture mev, that may then put a centralizing pressure on other domains.
00:23:56.336 - 00:24:54.730, Speaker A: Because if the dominant strategy is to colocate with a sequencer for a roll up on one domain, cross domain mev might mean that builders are going to co locate on that domain as well to extract that cross domain mev and put a centralizing pressure on the mev supply chain within Ethereum or another domain as well. So this is a problem not just for kind of centralized exchanges in finance, but for all rollups and all domains as well. And the choices that other domains make affect Ethereum is one of the findings from cross domain mev. And I want to call out that this matters a lot. Latency matters a lot within decentralized building because inherently, if we're trying to distribute this building role, you're going to be passing messages around sort of inherent to a distributed system. You're going to introduce some new type of latency. And so it's important that we learn how to make these systems address kind of the latency needs of its participants, like statistical arbitrage bots, and we minimize the impact of latency on the overall system.
00:24:54.730 - 00:25:49.716, Speaker A: At Flashbots, we're really interested in kind of how you can allow someone to define a smart transaction or a strategy that is evaluated at mev time instead of using individual transactions, right? So instead of statistical arbitrage bot sending a single transaction, maybe they send you an array of transactions and we choose the optimal one or something like that at the time of building a block as a way to kind of address latency. So this isn't to say that this is a lost cause or something like that, but to say that we need to be very mindful of latency when designing a decentralized builder network. And this is like a primary consideration to address. And if we don't, the future of block production might end up looking something like this. So this is an actual thing. So the Binance API, for whatever reason, historically is in Japan. So it's in like the AWS Japan server somewhere.
00:25:49.716 - 00:26:39.652, Speaker A: And if we're not mindful of latency in the mev supply chain, you get into a place where beaver build, Jump, Arsync, Citadel, Goldman, et cetera, are all kind of colocated in Japan. And it's all subject to the whims of Japan as a state. That's why it matters. That's why we're talking about Latency and our third kind of large mev trillion dollar question. So, to review, we talked about the privacy efficiency frontier, what this looks like, how to share information, at what point when it is safe, how we escape SGX, why SGX we think is a viable short term option, and how it fits within crypto economics as well. And finally, how we minimize and address Latency advantages. So these are things that are salient on our minds both in the short term of flashpots and long term, and would love it if every single one of you came and worked with us today.
00:26:39.652 - 00:26:42.060, Speaker A: So thank you so much for listening. Really. Shit.
