00:00:06.170 - 00:00:14.990, Speaker A: Next up is Marius, and Marius going to be talking about the merge, but the perspective from the execution layer. So, without further ado, let's welcome Marius.
00:00:17.010 - 00:01:06.770, Speaker B: Hello everyone. What a nice discussion. I didn't really prepare that good, so I hope that I can deliver something after this. From my perspective, I think it's very important to have this client diversity, especially on the execution layer. And we're always trying to promote it, always trying to build tools and at least get the other execution clients on the same amount of testing that we do in yeah, I'm hopeful about the future. All right, let's start. My name is Marius.
00:01:06.770 - 00:02:29.980, Speaker B: I joined the Ethereum Foundation one and a half years ago working on the Gas client, which is right now the biggest client on Ethereum. And so today I'm going to talk about the merge from the execution layer perspective. First of all, what's an execution layer client? I already said it. It's Gas or Nethermind biso Aragorn, and well, it used to be open Ethereum, not anymore. So those are the clients that currently run the network and they have mining consensus module built in, which basically does the verification of the proof of work and during the merge and afterwards, we're going to take out this module and replace it with a consensus layer client. So the consensus layer client is going to follow the beacon chain and the execution layer client is going to follow the ETH One network. Yeah, and so we have an API between those two.
00:02:29.980 - 00:04:02.890, Speaker B: So the consensus layer client basically has to tell the execution layer client what to do. And some of the responsibilities of the execution layer client is to maintain the state of the network. This is all the accounts, all the balances for everyone, all the smart contract, smart contract code, all the states in the smart contract. So, I don't know, if you store your NFT, then the data that you need for your NFT is stored in this state and the state tri, which is basically used to prove that all the nodes have the same state. And we also need to maintain the historical blocks and we need to provide access for both of them to nodes that just joined the network. So if you join the network and you don't have any state, you will get the historical blocks from all the other nodes. They send it to you and then you can either execute them one by one, but this takes a long time, or you just download the state and then only verify that the state corresponds to the newest block that you downloaded from your peers.
00:04:02.890 - 00:04:54.410, Speaker B: And this is also going to be something that we will still maintain after the merge. So this sending and receiving of the state and the historical data is still the responsibility of the execution layer. We also store and distribute the transactions. So if you send a transaction, typically as a user, you use MetaMask. And MetaMask then talks to a node, either your own node or a node run by infura. And they will then send the transaction, distribute the transactions throughout the network. It will create and execute the payloads.
00:04:54.410 - 00:06:30.140, Speaker B: So basically, once the beacon chain says that we are the ones responsible to create a new block, the consensus layer asks us, hey, execution layer, we want a new block. So you take all the transactions that you currently have, you sort them and then you pick out the best 200 transactions, execute those, put it in a block, and then return this block to the consensus layer. The consensus layer will then take this block, send it throughout the network, first seal it so like sign that this is the block that is valid and send it throughout the network. Yeah. As I previously said, we have to provide an API for the consensus layer clients to do this interaction with us. And we also provide the JSON RPC API endpoints. So those are basically things like ETH underscore Send Transaction or ETH call ETH Estimate Gas, all these things that are used by wallets MetaMask or applications to basically interact with ethereum in the larger sense.
00:06:30.140 - 00:07:02.226, Speaker B: And this functionality will still be retained by the execution layer. So this will be provided by us. Yeah. So a bit about the design of the JSON RPC API. This is specifically the engine API. So in the top right, we have the consensus layer client which basically tells the execution layer client what to do. And this arrow is basically this API that I'm going to describe right now.
00:07:02.226 - 00:08:26.910, Speaker B: We have the prepare payload method that starts the payload preparation process. So basically give me a new block, take the transactions that you have in your node and execute them and return me a valid block and the get payload. The reason that those are two different methods is because you want to give the execution layer a longer time to prepare payload. For example, if you want to do reshuffling of transactions looking for mev rewards, whatever, you have two calls, two different calls and then you have the execute payload call. Whenever a consensus layer client gets a new block from the other nodes in the consensus layer network, that is like one of the things that's different between now and after the merge. Now the execution layer clients will distribute the blocks. So if a new block is mined, then this node will send the newly mined block throughout the network.
00:08:26.910 - 00:09:26.674, Speaker B: This is not going to be the case anymore. Now it will be that the consensus layer client will distribute the block and the execution layer client will only distribute historical states, historical blocks. And so once the consensus layer client receives a block from the network, it will call execute payload with the payload within the beakj block and that returns valid if the payload was executed correctly. And then we have another method called consensus validated. This is a method that might not be. So this engine API is pretty new and it's still under development. It might change a bit in the future.
00:09:26.674 - 00:10:33.830, Speaker B: And one thing that we might delete is the consensus validated RPC call because that is not really used by the execution layer. Basically it just tells you that a block was valid. Regarding the beacon chain specification, the idea behind it was that once the consensus layer got a block, it will call execute payload. And while the execution layer is executing the payload, the consensus layer will verify the signatures. And once the signature on it is verified, it will call consensus validated. Might be something that we won't do in the future. And the last method is forkjace updated, which basically just notifies the execution layer client of the current head and the last finalized head, last finalized block.
00:10:33.830 - 00:11:45.550, Speaker B: So with the execute payload, you just execute the payload but basically you don't move the chain to that head. With Fog choice updated, you will set the chain head. And this means this is now the current head, the most recent block. And if we don't have this block and you say, hey, this is the block that you need now, then we're going to start synchronizing from the other nodes in the network. Yeah, so a bit about the merge itself. So right now we are in this part left here we have the proof of work chain which is chugging along and we have the beacon chain which is also chugging along. And the condition for the merge is the total difficulty, the total terminal difficulty.
00:11:45.550 - 00:12:55.970, Speaker B: So every block has a difficulty which is derived from the amount of work that you have to do for this block. In proof of work. If you sum all of these difficulties up from the blocks, you arrive at the total difficulty. And the total terminal difficulty is basically a parameter in the consensus in the execution layer clients that says once this total difficulty, total terminal difficulty is exceeded, we will stop the proof of work chain and go into the proof of stake chain. After this is the merge point. After that the blocks are embedded into the beacon chain blocks. So the execution layer blocks are embedded into the beacon chain blocks.
00:12:55.970 - 00:13:52.210, Speaker B: Yeah, a bit about the switch. Our clients of course need to stay in sync with the proof of work network up until the point of the merge. And we also already need to provide all the payload calls. So execute payload, create payload, get payload because we don't know if we might be the one client that gets to propose the first beacon chain block. And on the first Foxjoice updated call, we check if the total terminal difficulty is reached and if the head block hash is valid. And if so, we switch to proof of stake mode. And this means we also disable block propagation.
00:13:52.210 - 00:15:11.098, Speaker B: As I said before, we don't send out the new blocks anymore, only the historical blocks and we set the chain head to the new proof of stake block. One thing that I wanted to talk about is the reverse header sync. This is something that's new with the merge and basically it's about the way that we synchronize the network. So if you join the network you only have the genesis block. So it used to be that you will just ask your peers about all the blocks that they have and you will start from the genesis block and then synchronize to the next block. There are sibling blocks or can happen that there are sibling blocks that are on the same block height, different blocks on the same block height and you will always take the one with the higher total difficulty. So you will always take the chain with the highest total difficulty.
00:15:11.098 - 00:16:21.186, Speaker B: And so basically you start at the genesis. You go forward in time now with the proof of stake chain. Creating these sibling blocks requires solving the proof of work and this is something that's hard and in proof of stake. Creating this sibling blocks is pretty easy if you don't finalize them. But yeah, the idea is we need someone to tell us what's the actual hat and this is done by the beacon chain. So basically the beacon chain synchronizes and then after the merge tells us hey, this is the new head here, find the way back to the genesis and we can look up this. We have this header and we know, okay, in the header is the parent hash.
00:16:21.186 - 00:17:27.020, Speaker B: So we look up in the network which header has this parent hash and then we find this header and in this one we look up the parent hash and so on and so on until the genesis block. So basically we synchronize the network from the news block back to genesis and this is the reverse header sync. So a bit about the interrupt. This is a picture photoshopped by Depline from the previous panel by the way. Yeah we started implementing an initial version of all of this. It's built on Guillaume's catalyst. Guillaume is going to give the talk after me and he worked a lot on all of this during the Rayanism hackathon and laid the foundation for basically what I'm talking about today.
00:17:27.020 - 00:18:39.870, Speaker B: Peter also worked on the reverse header sync and we already managed to test all of this with four out of the five consensus layer clients. Yeah, one small project that I wanted to show regarding the execution layer is merge fuzz. It's a new project that I started on the last day of the interop because I was so bored and it basically creates random inputs to the merge API and it can be used for differential fuzzing between different implementations. So again we're always trying to build tools that can not only be used by gas but also can be used by other clients. To make sure that they receive a comparable level of testing to us. It does things like execute Payload and Foxchise updated and verify the current head. So like in random operations.
00:18:39.870 - 00:19:26.610, Speaker B: And you can find the code at my GitHub. Some next steps. We have to clean up all the changes we did during the interop. Of course, all of them are a bit hacky right now. We have to refactor the downloader to allow for this reverse header sync. We have to work a bit on the minor and the block production and also refactor some of the existing JSON RPC APIs because they might not work with the way that POS is done. After the merge and then more testnets, testing, testing, testing.
00:19:26.610 - 00:20:22.258, Speaker B: For us, it's really important. We don't want to start the merge procedure when we finish the code, but we need enough time to test it because Ethereum grew so big. It's a billion dollar network and we don't want to crash it. So we want to be as conservative as possible with this even if it takes a bit longer. And yeah, you can also join like we have a long running testnet. There was one started in Greece at the interop. We deprecated this now and we started a new one or Paritor started a new one.
00:20:22.258 - 00:20:43.282, Speaker B: And yeah, that's basically some I collected some Q as from Twitter already. But Kartik, if you have other questions from the audience we can also absolutely.
00:20:43.356 - 00:21:00.414, Speaker A: I think I saw that tweet and the thread and there were so many awesome questions that came in so I think you should definitely answer a lot of them. One question I'll add to this list is a question from Danny Ryan, which is what are you most concerned about from an el client perspective? As in what keeps you up at night?
00:21:00.452 - 00:21:01.040, Speaker B: There.
00:21:05.750 - 00:21:06.820, Speaker A: Easy stuff.
00:21:07.510 - 00:22:00.820, Speaker B: It's not much keeps me up at night anymore. After like one and a half years in the Gas team, I think I've seen a lot. We had issues in Gas, we had issues in Go, in the language itself, in the Standard library. I'm pretty confident in our ability to adapt. If there's an issue, we can find it and fix it rather quickly. The last few consensus issues were found in a matter of like half an hour to an hour or something. We have a cool, great suit of tools for testing the EVM stuff.
00:22:00.820 - 00:22:49.860, Speaker B: The only thing that I would say what keeps me up at night is that we might finalize something that is objectively wrong and that we might have to break finalization. And I think that would be really bad. It would be bad for Ethereum. It would be really bad. And this is the only thing that I really worry about. And I hope things like Proxies to run a validator of multiple execution layer clients is something that could help there.
00:22:51.430 - 00:23:03.654, Speaker A: That makes a lot of sense. There's another question that came in just now from Trent. The question is, can you tell us more about the minority project Peter teased about earlier? Just give us a little context and you can jump right into your Q.
00:23:03.692 - 00:23:53.320, Speaker B: A. Yeah, I'm not sure if I should talk about it too much. Basically, I think the idea was born in Greece that you can run multiple execution, layer clients for one consensus, layer client for one Beacon Chain client, or maybe even run multiple Beacon Chain clients with multiple consensus layer clients with multiple execution, layer clients and multiplex between them, and then take, like, a two out of three majority vote. And this is something that he's very interested in working on.
00:23:54.890 - 00:24:01.420, Speaker A: Well, Trent is a little bit disappointed, but we can maybe have you quickly on some of your questions.
00:24:04.190 - 00:25:06.634, Speaker B: Yeah, so I think Hudson asked whether it was more difficult to fork the code after the merge. It's a bit more difficult, I think, but shortly after the merge, we will still have to retain all the functionality from pre merge. And so yeah, there's not a big difference. Once we are comfortable in post merge land, we should really find a name for that. I don't want to say ETH two, but in proof of stake land, then we might start deprecating some of the features. In Gath. The ETH balances will be maintained on the execution layer.
00:25:06.634 - 00:25:59.310, Speaker B: So the execution layer holds all the information of the current state. Will execution layer and consensus layer share the same process and storage? They won't. They will, at least for the merge and probably a long time afterwards. They will reside in separate processes that talk to each other via the standardized engine API. They will have different storages, they will have different storage formats. And I don't think it makes sense to unify those. Which layer will propagate the blocks? The consensus layer will now propagate the blocks, the beacon chain blocks which contain in them the execution payload.
00:25:59.310 - 00:27:23.740, Speaker B: How is the transition triggered? As I said, it's the terminal total difficulty. If this is exceeded, the block that first exceeds the total terminal difficulty will be the last proof of work block. What's changing for users? Do you need to upgrade your nodes? Hopefully for the average user that just holds ETH, there's not much impact. You don't need to upgrade your wallet or whatever. You will need to upgrade your node, your guest node. And you will also need to run a consensus layer node or maybe in the future a consensus layer lite client that will feed all the blocks to your execution layer node. How does the block proposer collect the transaction fees, the the execution payload or the assemble parameters in the create payload has a field called fee recipient, which basically is the same thing as we used to have with the coinbase address.
00:27:23.740 - 00:28:29.454, Speaker B: So the block proposer sends the that's how it is right now. It might change with the proposal separation in the future. But the way it is right now, the block proposer can specify where the fees should go and those will be paid out instantaneously once the block is mined. And the last one is something that's still up for debate. Just really quickly, we have a testnet up and running. If you go to Pithos minus Explorer East DevOps IO and you can see that there's a lot of client combinations currently, all with Gats. The other have some problems apparently, to run this test network, and you can join it from home to test all of this out, which is really cool.
00:28:29.454 - 00:28:32.126, Speaker B: So go do that. Thank you very much.
00:28:32.308 - 00:28:43.070, Speaker A: Awesome. Thank you so much, Marius. This is a great overview on what's happening with the execution layer. And if you have more questions, I'm sure Marius will pull back on the chat and answer them directly.
