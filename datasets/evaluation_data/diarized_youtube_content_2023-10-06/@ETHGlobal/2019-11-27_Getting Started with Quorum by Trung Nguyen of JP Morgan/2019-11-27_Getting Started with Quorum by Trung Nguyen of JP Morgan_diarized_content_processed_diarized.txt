00:00:08.840 - 00:01:26.592, Speaker A: How to spin up Quorum network. Yeah, so basically so you have you heard about Quorum already? Yeah, I think workshop. Okay, so you don't quorum is actually a fork of ethereum. So we modify the upstream and add some more stuff in there like this. Enterprise ready, so we got a lot of features, but I'm going through that with you later on. Now myself I'm a quorum engineer Initially I worked as an infrastructure installation engineer for Hoppy Cloud AWS Jpmollet because we use a lot of TerraForm internally, contributors to the TerraForm pool and TerraForm providers. You heard of TerraForm before? Yeah, basically that's right.
00:01:26.592 - 00:02:12.288, Speaker A: It's the infrastructure as a post kind of tooling for DevOps. It's pretty cool because we use telephone a lot in interference, so we contribute back to the community in terms of calling the providers. So I'm from Vietnam, I did my graduated EC in Australia, I worked in Singapore and I'm fulfilling my blockchain dreams in US. That's a very short introduction. So you can find me on Slack and GitHub, not using Twitter, but if you have hopped into the Slack channel for Quorum, then you can find me easily. Right? So, very simple. Going to showcase how we're going to deploy Quorum nodes.
00:02:12.288 - 00:02:44.584, Speaker A: Actually a lot of tooling available to make it happen and in the demo and focus on one tool that we'd like to bring it forward further. And what's the next one for the deploying the Quorum network. Now for Quorum network, everyone play with Quorum. They start with example, there's a link to pick up over here. It's an example. So it's kind of kitchen sink for blame core. Start up the seven nodes.
00:02:44.584 - 00:03:09.936, Speaker A: Example, you can send private transactions between nodes and we support a various way of starting up them. Vagrant is the first option. Later on we add docker compose based on the official docker images that we publish to docker hub. So you can play around with that. It's very simple. It's running on a single machine. If you bought like a laptop or a VM somewhere require four, eight to eight gig Ram.
00:03:09.936 - 00:03:59.380, Speaker A: You can start up with a simple script and play around with the network. That's one way of doing it. The second way is that's a photo maker tool that is developed by our partner and it is very similar to Pocket. Pocket, it's a wizard like you write shell script and then it asks you start network joining the network. It's a very step by step manual interactive console that you can create the network for the network easily. We have current cloud, which is the one that I'm going to present today for the demo. And the idea coroncloud is we would like to have the ability to bring up forum network in many cloud providers.
00:03:59.380 - 00:04:51.074, Speaker A: AWS Azure, there's an Arduino blockchain service that they just announced this year which powered by Quorum. So by default you use that service, it's Quorum underneath it with example. And also hopefully we can do something called Cloud to support Azure as a band Aid VMs as well and GCP or Google Cloud platform waiting for your contribution. And we have another project, just Open source, recently called Kubernetes. Libby is the author of it. Any questions? Right here. So basically the idea is generate a bunch of meta file for Kubernetes clusters.
00:04:51.074 - 00:05:38.902, Speaker A: You can bring that metadata file, then you can a lot of Kubernetes platform, you should check it out. All of them are open source and putting over here. Play around with it and give us some feedback from such issues if you find anything interesting. The idea is using TerraForm as a tool to consistently provide the workflow to deploy quorum on the different cloud providers. So you can deploy AWS Cloud or any other cloud platforms. TerraForm code. So the good thing about TerraForm is the ability to mix and match.
00:05:38.902 - 00:06:39.980, Speaker A: So you can really start two notes in AWS and three notes in Azure if you want to. That's possible because TerraForm gives you the very nice abstraction layers that communicate with all the providers using the API. And on top of that, it has something called the HCL, the hashico configuration language. So you can describe what you want to do with your infrastructure or software. So when you describe it, different runtime is going through that configuration file and then perform API calls to all the cloud providers and form accomplishments provisioning. Yeah, so the first version code cloud that we have at the moment is mainly focused on AWS. It's actually the very first project that I did when I first joined Forum because back then we had only seven example and that's it.
00:06:39.980 - 00:07:37.370, Speaker A: And there was an issue about memory leak in Forum. So I really wanted to see how do I run it for a long time to observe the memory and the new usage and stuff like that. First I run on my laptop. I just leave my laptop in the office and then come back the next day. I need the letter for something else so I can't run like that. So what I did was I created the core cloud on AWS using AWS elastic container service because we already produce couple containers images. So we can use that to create a coral network in ECS easily some S three and I have the EC two instance to act as a jump box to our core network.
00:07:37.370 - 00:08:30.270, Speaker A: So the architecture is like this very simple. So it's all native environment. So we've got a public subnet. There are two subnets that segregate the parts, you know, and the actual core network. So the actual port network is in private subnet, so it makes it easy for you to scale as many as you want. The public subnet is only the bunch of node, which is the jump off that can help you to tunnel to the coral network. So your coral network doesn't expose all the node to the public inside private subnet and all the traffic will go through the basic node and go network I showed you on the demo on how to connect to the coron network via the basic node.
00:08:30.270 - 00:09:27.150, Speaker A: So this Corn cloud project is TerraForm zero point eleven. So because there's a major change in the HCL language in I haven't upgraded yet. So when I will be compatible with zero point eleven. Now the TerraForm gives you a very consistent workflow. So once you describe the infrastructure, the workflow to provision the infrastructure or the software and that is very consistent. You init, you plan, you apply to destroy consistently throughout AWS or Google or Azure, you run the same command in it plan, apply and destroy. So that is very powerful in terms of the experience and the consistency in terms of how I can change, I can provision my structure.
00:09:27.150 - 00:10:34.450, Speaker A: Now, Chrome cloud AWS here is doing bootstrapping the whole network from scratch, which means that it doesn't depend on any existing information on your local key for you create some defaults, create some data directory. Normally you run it by get in it, you collect all the IPS and be the study notification. Now, one of the challenges in the cloud is like the IP chain all the time, right? So it's going to be hard to fix the IP. If you want to fix the IP on the cloud then you have to pay money for it. And that's why we don't want to go for that problem. And there's some workarounds make sure that only when the node comes up to collect IPS and then I build a static node JSON, and then I distribute that into the network before I actually start the network up. Question for any new nodes that get spin up, you'll actually address the updated Wilder nodes.
00:10:34.450 - 00:11:17.038, Speaker A: Very good point. So here we are talking about the day one operation for the network. It means that I only care about whether bring up the network. This tool doesn't give you a day two plus feature. It means that if you want to change the network, if you want to add new node in, what if nodes down and stuff like that, it doesn't give that feature yet. It's a little bit tricky but it's doable. Just like we need to spend some time and get it up and running because all the features about remove a node, update the node or add a node in, there are APIs available already as well.
00:11:17.038 - 00:12:09.138, Speaker A: We just need to make sure that we can collaborate them and then make it happen. And that's a good point because I'm going to go at the end of the slide and show you what is our plan to do all these things. Google cloud can support the A two plus in a certain level. I'm not saying 100% like being a network management type of tool, but it can give you some level of management that is good for testing and development. So we use it actually we use it to run our test suite on a daily basis. So we've got the test suite running on Travis. It's open source swap every day it runs for a cloud provision the forum network on AWS, run a bunch of tests and then shut it down, destroy everything.
00:12:09.138 - 00:12:48.880, Speaker A: It's very clean. Save money for the firm. Sure. And give us an output of whether output having any issue, broken existing features or not. It's very useful for us. And the second thing that we use for is to keep track of long running network because we really care about the memory usage, the city usage, to see how the blockbot generated any error from the log is going to be present. That way you can see how the networks perform in a very long period of time.
00:12:48.880 - 00:13:25.210, Speaker A: Later on I'll show you the log monitoring available with AWS. It's pretty cool actually, and pretty simple. There's not much work to do with everything is integrated nicely in AWS. Yeah. So give you a demo. Now I pre recorded it because I don't trust the wireless over here. A little bit slow, but it's exactly what this happened.
00:13:25.210 - 00:14:07.302, Speaker A: So I have bunch of videos here. I'm going to skip a bunch of things because it's not very necessary because for TerraForm there's one thing that we have to keep in mind is TerraForm managing the state. For us, the state means the infrastructure state. So it has its own view of joint infrastructure and that's actual state of joint infrastructure. So when it runs it try to compare those two together to decide whether it should delete, remove updates, anything in infrastructure. So the state management is crucial in TerraForm. So there are two options.
00:14:07.302 - 00:15:19.982, Speaker A: One is you can start a state locally as a file and second option is you can start state is a remote operation like S Three. So the prepared environment here then it is state management is about to make sure that the TerraForm has a place to store your state. So TerraForm recently, I think a couple of months ago they opened for public something called TerraForm Cloud which allows you to remotely manage your state, which is pretty cool because right now it's very troublesome and manual work to make the state managed remotely. Now TerraForm Cloud is the online service, it's a SaaS service from TerraForm Ashico. They make it very easy. So you should check out TerraForm Cloud to manage your state model instead of using something like S Three like I did right now go through. So yeah, TerraForm Cloud is just another service from Hashico and your TerraForm runtime or your telephone operation is sitting in your local.
00:15:19.982 - 00:16:35.420, Speaker A: So when you run it, it just store the state of your infrastructure in that TerraForm Cloud. So it's a separate service altogether, doesn't do anything with your infrastructure. So you have a bunch of HCL configuration here on your local when you run TerraForm, it is plan apply what it is, it goes your cloud provider of choice, provision everything. Remember the state of it and upload it to a different class going through your actual network and then no so telephone class only to store the state of your infrastructure like your VMs, your S three bucket, your EC two information and stuff like that. It's nothing to do with the coral network. Yeah, so it's just a state of your infrastructure, not the state of the core backlog the coral network is installed in AWS. So here's how things I start.
00:16:35.420 - 00:17:48.410, Speaker A: When you start the quorum network, I leave it the security group very strict so no one can access to my quorum network. So do the curl config call and give me the current IP of it and then I can fit into my TerraForm script, say that okay thread for me the security group that allows me this IP to access my network. So basically what I do here so the next thing is I just copy the file and there's a file called TerraForm TFR which is only input to my TerraForm configuration. So here a bunch of input. As you can see there's a subnet ID information, there's public subnet ID information and there's access bastion either blocks that's where I'm going to put my IP in so that from my local I can access to the Bastion node because of the security group restriction that I want to put on. There are some other things like contested mechanism that we can configure the number of nodes we want to spin up. There's a docker image tag, the version that we can use to spin up the network.
00:17:48.410 - 00:18:54.620, Speaker A: There are more inputs that can put onto the network. What I've merged is in the modify for the variable stuff here that will describe for you all the input that you can do to customize the network. Just copy it there, set that file and then simple I edit make sure that I'm using S three to store my telephone state for my network. It's going to download a bunch of providers. Providers are the one that managing all the API call, all the resource creation that is defined in my telephone configuration. When I say telephone configuration is like a template or a script. So it describes infrastructure in SCM.
00:18:54.620 - 00:20:18.920, Speaker A: So when you say telephone plan, it's going to tell you that what are the resources to be created, what are the things that going to be destroyed and stuff like that. But because now we generate a brand new network so everything is so when you plan it show you all the resources that we create. Over 32 resources to be created. Just imagine that you can create it by hand when you do the pipeline to give you a preview of what it's going to do as well. And when you say yes, it's doing a bunch of things it's going to call a bunch of API provision the Iron Policy Provision Security Group creating the ECS Task Services EC two instances wide, themed up together, make it nice and neat and in a few seconds takes about five minutes, but I cut it short. So Bastion here created and then it provisioned. Sebastian, copy the information to the bastion and then do the start of the network.
00:20:18.920 - 00:21:14.124, Speaker A: So what is done, you can see the output coming out of it is giving some information about the network. That it. Just provisioned the image version and name that you get from the Cloud Watch log group where you can see all the logs of all the nodes that you have, the batch DNS and IP, that's for you to access to the batch node so that you can jump to the Internet network and the bucket name and stuff like that. So one of the things is it generates for you the private key as well. With this private key, you can use it to access to your Bashi node after you got the network. That's good, right? How do you connect? So here's another video that captured how to connect to that network. So here the information about the network got printed out.
00:21:14.124 - 00:21:47.990, Speaker A: After I run TerraForm apply. I copied the bastion node, right? Go to the EC. Two. Now this is interesting. Now the Bastion node acting as a jump off to the private network or core network. But also we deploy the E stats on the Bashi node as well so that it can give you the information about the whole forum network. So let me jump out over here quickly and give you the view of that.
00:21:47.990 - 00:22:36.240, Speaker A: So this is Russian nodes information. That the network that I already provisioned. And this is start from puppet listing our own denotes in the network and some useful information like I let this network run very long times, like 2 million plus blocks generated just now within Istanbul. Yeah, some information like version and stuff like that. So it is exactly the same as the UI that you're going to get for running the Heater stats and publish the metrics to heater stats. So here got some information about. Now go back here.
00:22:36.240 - 00:24:01.820, Speaker A: If I list out the current directory, that's a Bam file, right? Which is the private key file that I'm using to access to my dash node user and buchananode bump, I jump into the jumpers from my local, right? And then if I want to get attached to any node, I just say node one or node two and node four, node five, so on and so forth. It means that now I SSH to the jungle and then from there I access my network, which is cool, but it's not very useful, right? What you want, you want to access your network from your local machine. So how do I do that? It's a get attach command because I have all the information about what IP for the Node One and Node Two and so on, right? So I just create a share split. But Frank speaking, it's a bit useful, but it's not super useful. This one is more useful because most of the time what we want is we want to access the network from outside, right? Not from inside seven and stuff. Just give some get attach information which is similar to what you can get, but it's from the jump box. Here you go.
00:24:01.820 - 00:24:57.464, Speaker A: So you can always run the telephone output command to display the existing information of your current network. Okay? And that's it. Now, if you want to connect from outside, that's how it goes. Same thing. They're from output to get information now, because you can SSH to the port or to the vaccine node, you can do the SSH tunnel to that as well, right? But we need to know some information about the network. You don't know the IP of every node. You don't know what are the public key of the privacy address or public key decision.
00:24:57.464 - 00:26:40.824, Speaker A: So there's information available in the Buckshit node and the Q data for a metadata and other the information you have like node One, URL a bit, privacy address a bit, and so on, so forth. Seven, we add it, we put it in the provisioning script, and after you got displayed some information here, we know that, okay, here's my network. The next thing is we're going to start an SSH tunnel via Bashi node. So this command already dies. Very standard command, establish an SSH tunnel to the Bashi node and make it ready, right? So the next thing is, okay, I got it ready. All I need to do is I export a HTP proxy using Sox Five to the SSH tunnel that I created over here, say port 5000, right? So it means that all the HTP requests going through this proxy, when hit through the jump host to the private network, so it's go all the way in and it brings the SQL as well, because you only want to get a private key here, right? So you look at a little bit. So after you export the HP proxy as a Sox 545 thousand, which is the SSH tunnel that we just started right there in the left hand side, then you can take attach to the private IP inside the IWS.
00:26:40.824 - 00:27:21.498, Speaker A: Because now you've got a tunnel via Jumpboss, go into the private network, which is private subnet and you can run kind of data loads with public contract and private contract and stuff like that. So easily do exactly the same way that we can do it. Like you have a local core network. Now I'll show you quickly about very interesting things about the network. So this is my cluster. Click on the cluster. These are my seven node examples.
00:27:21.498 - 00:28:11.390, Speaker A: Using ECS, I click on say node seven task. There's only one task because I start only quorum. I click on task, go down there and there's a bunch of very interesting information. So here are different containers that I started and most notably there's only Tessera run and quorum run, right, designing the bootstrap container which died right away after it did its jobs. And in the quorum run, it's actually running the quorum and punch up shell script pretty early. Some labels for your network and you can view ropes, cloud Watch to click on here. It's going to direct you to a Cloud watch for row seven.
00:28:11.390 - 00:28:57.082, Speaker A: And from here you can filter, you can search, you can set the alerts for certain information from your network, send your emails, send text, blah blah, whatever fancy notification services that AWS provide you, you can use it here as well. So this is all information, it's all the locks with verbal five pockets going to be listed here. This one is more interesting. In the Cloud Watch, I click on the metrics. I'm searching for my quorum network because I'm using ECS. I click on ECS. Here are the memory and CPU utilization for individual node in my network.
00:28:57.082 - 00:29:32.780, Speaker A: If I search for memory, show you the memory on the node, right? I click everything. Here's a memory utilization for all seven nodes that I started. I can do a kind of field link and display. You can see that it's very consistent. Got some swipe which is okay, like block generation and then catch fill up and then it do some GC and blah, blah blah. But for the last one, which is pretty consistent, so we know that oh, okay, looks good. There's no memory leak over here.
00:29:32.780 - 00:30:16.502, Speaker A: In the first issue that I encountered there was a memory leak. You can see clearly that's going up somewhere and then died. So that's how we can monitor and detect whether there's anything wrong with the gap. Yeah, so yeah, what's next? Okay, now it's very interesting. Right now the bootstrapping is like coupled inside the ECS container. So I have to run like multiple containers to get information. Like I have to run get container to do the get.
00:30:16.502 - 00:31:28.074, Speaker A: I have to run tessera container to do the key generation with tessera, which is crazy. Now we need to do the whole app to make sure that we have the bootstrapping and core network on your local. You've got the infrastructure ready, you just merge them together. In order to do that, we have to do something called we have to write our own TerraForm provider plugin, which is very easy to write as well. And we're planning to work with hashifot to open source that and make it happen. So everyone can use the TerraForm plugin to bootstrap the quorum network using TerraForm and then they can write all kind of TerraForm configuration that fits their needs to deploy the quorum network into their structure easily. And the second thing that we want to do is we want to use two instead of container because a lot of question is okay, you start up container and stuff and how do I access to the lock, how do I access to the box? Because they want really to see the instance running so we need to make it happen.
00:31:28.074 - 00:31:32.880, Speaker A: But that is in the pipeline right now and I UNCP farm first.
