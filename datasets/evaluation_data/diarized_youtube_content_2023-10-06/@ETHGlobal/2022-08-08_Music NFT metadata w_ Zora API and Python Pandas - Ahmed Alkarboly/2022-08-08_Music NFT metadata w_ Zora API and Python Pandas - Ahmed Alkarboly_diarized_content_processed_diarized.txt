00:00:06.410 - 00:00:15.022, Speaker A: All right. Good morning. Good evening. Good afternoon. Depending on where you're from. We have Ahmed here from the underground. Violet Rave, citizen developer group.
00:00:15.022 - 00:00:28.390, Speaker A: Doing a workshop on music NFT metadata with Zora API in Python Pandas. If you have any questions, they can go in the zoom chat and Ahmed would be more than happy to answer them. Otherwise, feel free to take the floor. Ahmed.
00:00:29.370 - 00:01:03.130, Speaker B: Thank you, Anna. Yeah. My name is Ahmed. I'm a part of the underground Violet Rape citizen Developer Group. We are an organization that just makes artists or tools for artists and tries to leverage the blockchain as much as we can. So today I just wanted to quickly go over the Zora API and then do a code walkthrough where we're integrating the Zora API with Python Pandas. And then I want to talk a little bit about the possibilities with aggregation.
00:01:03.130 - 00:01:38.874, Speaker B: And then hopefully, if we have time at the end, open the floor for questions. But you can always hit me on Twitter and I'd be happy to answer questions there as well. So, right off the bat, the Zora API, so the link up top, if you visit, it will take you to a GraphQL interface. And so I'll just go ahead and for us, this is an interface for the Zora API. On the left, we have the Explorer panel. What the Explorer Panel does is it lets you dynamically build queries with just a couple clicks. It's very cool.
00:01:38.874 - 00:02:17.698, Speaker B: In the middle, you can actually see your query get built in real time as you go and select the options. And then on the right side, when you execute your query, you can actually see what data is being returned quickly. To talk about key fields, we have the collection address. This is how you tell the API what information, where to go to retrieve information. We also have a field called Limit, and this is how many nodes are going to be returned per page. A node in the context of Music NFTs is just going to be a song in a collection. And then there's the page navigation.
00:02:17.698 - 00:03:07.990, Speaker B: So I think the limit on the Zora API, last time I checked, was 50 nodes or songs per page. So if we have a collection that's multiple pages, when we're trying to go to the second page, we have to provide it with a page navigation value. And then looking at the actual data, we have your standard metadata from a smart contract. And then we also have some navigation information from the API that's really important for later. It has a boolean which says, hey, yes, there is a next page in this collection, or no, there's not a next page. That's the has next page field. And then the end cursor attribute is what would go into the after field in the actual query.
00:03:07.990 - 00:04:03.242, Speaker B: So if there is an X page, you give it the end cursor value and it'll go to the end cursor page, which is the next page. So key takeaways, we can use the API to return all the semi structured JSON data for a particular publishing platform. Think mint songs, catalog sound, XYZ even the Chaos Collective releases or any independent artists like Jaden Violet or Twinnie Twin or Aero Mist or Nexus. Music spread out across different collections is not scalable. There's a conversation of building a data set, a registration data set that you could go and reference, but that's a different conversation. So if we want to collect metadata in a single place, we probably want to do it in a single collection repository to make our life on the back end a little bit easier. And then I also linked here the Music NFT metadata standard.
00:04:03.242 - 00:05:12.320, Speaker B: It's currently adopted by Minsongs and catalog. And I think that adoption of any standard is good, especially in the Music NFT space. It makes creating a microservices ecosystem easier, and data aggregation is needed to make these microservices possible. So what's our desired end state using the Zora API? It is to build a simple data set with multiple platforms with our desired metadata that we can push to a storage endpoint of choice like Google Sheets or SQL or something in AWS. And the way that this came about was the Zora hackathon, I believe in June I made a project where I used the Zora API to query in Mint Songs metadata, mint Songs V, two metadata, independent metadata, excuse me, metadata from independent artists, and then catalog metadata as well. And there was even an integration from a third party data source from Future Tape. And I was able to make a music aggregator, which I'll talk about later.
00:05:12.320 - 00:06:03.514, Speaker B: So if we look at the Music NFT metadata landscape, we have a graphic on the right made by Laura Wynn. And so you can see that as far as adoption metadata standard goes, min, Songs and Catalog are the only people. But you'll notice that in the user interface that those publishing platforms provide, they don't actually give the option to update this metadata. They only have a couple of limited things like title and artist metadata standard is adopted, and if you talk to those devs, they'll tell you that it is. So let's talk about the actual code. To pull this information in, you're going to need a couple of things. A code editor, you're going to need Python and the libraries below installed.
00:06:03.514 - 00:06:44.160, Speaker B: And then there's a Google Cloud API component to this. If you're interested, I can talk about it later in the DMs or something like that. But it's how you would push your data to a cloud storage endpoint. So what you want to do is you're going to import your libraries, you're going to want to connect to the Zora API and establish a client. You're going to define a Pandas data frame, what a data frame is, think about it like a data set. You're just saying I want to define these columns in the data set. And then you're going to later push rows into that data set.
00:06:44.160 - 00:07:33.440, Speaker B: And then what I'm doing next in this code is initiating variables for an API loop. And I'll get into the actual building out the dynamic query. You'll notice that it's a while loop that checks for a value of has next page. So this piece of code is going to execute until we get to the last page in the collection. If it's the first page, it's just going to execute a simple query. And here what we're doing is we're just looking at Mint Songs collection. If you wanted to aggregate catalog and Mint Songs and any other ETH based platform through the Zora API, you would just provide that collection address up top.
00:07:33.440 - 00:08:22.910, Speaker B: For pages that are not the first page, the counter gets incremented. And if the counter is greater than one, that means that we're no longer on the first page. So like I was mentioning earlier, what we do is we pass along the end cursor value to the query and then the next page is brought in. That's how you build a Pagination feature using Python to navigate through an API. And then so now actually executing the query that we just built, we're going to initiate the query. We're going to execute the query to return the JSON node page that we saw earlier on the GraphQL interface. We're going to load the result from that query onto a data frame.
00:08:22.910 - 00:09:35.380, Speaker B: And then we're going to have what's called a node page. The idea of a node page is pretty important because like I was mentioning earlier, I think the Zora API is limited to 50 right now. But that means that when we go query a collection, for example, this Mint song collection, I think there's 123 songs or something like that, it's only going to return the top 50. And so that node page, when I go say, run a function that says, hey, return the length of this node page, it's going to return 50. If I set the limit to be 50, or if I set the limit in the query to be hey, return ten nodes per page, ten songs per page, it's going to return ten for the length of that object. And so like I was saying before, we use that node page to basically iterate through every single object or every single song on that node page for analysis. So we run a for loop that starts from the first song on the node page to the last song on each node page.
00:09:35.380 - 00:10:30.866, Speaker B: And it's going to assign a variable by navigating the JSON that's returned to populate a specific variable. What does that actually look like? So let's say, for example, we wanted to get the JSON structure return in the API to get the song title for a specific song. So what we would do is we would navigate the data frame that's returned from the Zora API. And we would tell Python to say, hey, go look at Mints. Once you go look at Mints, we have to tell Python what is the next thing that I should be looking at? Where should I navigate to next? In this case, we have to index it because this specific JSON structure doesn't have a key value. So I can't navigate to it by using a word. So I have to use an index.
00:10:30.866 - 00:10:59.950, Speaker B: That's why it's zero. And then I is actually the song on the node page. So because this is in a loop, I runs from zero to whatever the length is of the node page. So if I'm looking at the first song, I would be zero. If I'm looking at the last song, I would be 49. So I'm looking at the first token. I am going to go navigate to the metadata and then return the song title.
00:10:59.950 - 00:11:52.682, Speaker B: And so if we look at that code again, that's pretty much how it works, right? I go return a collection of all the songs on a specific publishing platform. I then use hopefully, there's a Music NFT metadata standard that makes my life on the back end easier. And then I go and pull those tags and populate a data frame to my liking to do whatever I want to do. And then here, just real quick, we define an array with the data we just scraped off of that API. We load that array onto a temporary data frame. And then we append that temporary data frame to a master data frame, which is actually holding all of our Music NFT data. And then one of the last pieces of code is checking to see if I need to run the code again to bring in more songs from the next page.
00:11:52.682 - 00:12:28.112, Speaker B: So right here, those are those values updating. This is the last part of the code. There is a Google Sheets integration. I'm not going to talk about it too much, but essentially you set yourself up with a Google cloud account. There's some sort of authentication file that is a JSON file. You drop it somewhere on your desktop, and then you link that JSON file with file path like here. And then you go into Google Sheets.
00:12:28.112 - 00:13:28.356, Speaker B: And then you would create a Google Sheets page. And then using this code, you would be able to push your data frame into Google Sheets. And that's exactly how I built the integration tool, which got third place in the Zora hackathon. I went through and got each collection address for the listed platforms. I used whatever metadata they had to fill out a standardized data frame. I had to do a little bit of integration to get some additional data from catalog and sound, specifically BPM and Tag from Future Tape, shout out Anthony from Future Tape, and then used Python to orchestrate all this, pushed it to Google, and then I had a repository with BPM and tag data and artist name, artist profile. And so what can we do with metadata aggregation? We can do things like music charting.
00:13:28.356 - 00:13:55.372, Speaker B: We can do things like playlisting music discovery, think things like, I want to dig for music on bandcamp. I'm a DJ. I love digging for music on bandcamp. Right now there's not really a good way for me to do that. I can't go find Techno or House or UK Garage or something like that. There's no way for me to easily do that. There's also a lot of implication with intellectual property and music rights automation.
00:13:55.372 - 00:14:51.170, Speaker B: When we think about integrating things like BMI or different pros, it's really important. The metadata conversation is really important because that's where that information would go. And it's just an additional metadata field that we could bring into our repository to run any different number of microservices. Another thing that you'd be able to do is ecosystem analysis. So let's say that I wanted, as an artist wanted to go and see what my music ecosystem was using some sort of data set like this, you would be able to do something like that. And then, of course, like music players. One of the biggest needs in the space right now, I think, is having a way to have music that is published on the blockchain readily accessible, whether that's through a mobile app or a website, something resembling Apple Music or Spotify or SoundCloud or Bandcamp for that matter.
00:14:51.170 - 00:15:31.330, Speaker B: What I did with my integration was I curated and Djed a set using NFT metadata. So that Zora Hackathon project produced a data set. I used that data set to build a front end application right here. And you can see that it's just a basic table with a bunch of different filtering tools. And so what I did was I searched the data set for songs that were tagged as electronic, and then I curated a set and Djed it and then put it on SoundCloud. That's all I have. And so I guess we have like 15 minutes or so.
00:15:31.330 - 00:15:35.570, Speaker B: We can open the floor to any questions if there are any. Thank you all.
00:15:45.810 - 00:15:48.880, Speaker A: Feel free to come off mute if you want to ask your question live.
00:15:55.670 - 00:16:22.890, Speaker C: Hey, everyone. I make music as infanati part of the hackathon, I recently deployed my own smart contract with Sweetman Todd S. This is right up my alley as far as metadata and future of blockchain. Not sure what to say because I am driving. I'm at red light, so just keeping the loop.
00:16:25.470 - 00:16:30.590, Speaker B: I appreciate you coming through. And you said it was Sweetman e correct.
00:16:30.660 - 00:16:32.510, Speaker C: And it's in the chat as well.
00:16:32.660 - 00:16:43.540, Speaker B: Yeah, he's one of the pioneers in the space for sure. I think he sees a lot of the problems and he's building tools to fix them. I think you're right where you need to be, sweet man.
00:16:46.330 - 00:16:59.930, Speaker A: All right. I guess if there aren't any other questions? I'm going to give another minute or so for questions. We can maybe end the workshop here so we can give a couple more seconds, see if anyone's typing in the chat.
00:17:03.310 - 00:17:27.330, Speaker C: It's sergio Infinati. Again, just wondering how I can help. Sorry for not showing my face right now I'm driving, but I am doc and full real life person. I'll just leave it at that, see how I can help. Obviously I make music, but I'm a bigger part of the spectrum.
00:17:30.410 - 00:18:29.240, Speaker B: One of the most important things is education, especially with the idea of metadata, especially in the music space where we have a lot of artists who are not comfortable with defining themselves. And so when we have something like a metadata standard, that can be pretty scary. And so I think one of the biggest helps is supporting the developers who are solving the problems. And then number two is continuing to have conversations around metadata and just learning as much as you can and maybe debunking some of the rumors around metadata and what metadata is specifically around artificial intelligence, because it's a real fear. And I think that the most important thing we can do is just to get educated about the topic and just talk about it.
00:18:34.210 - 00:18:47.460, Speaker C: I agree. Are you talking about AI as far as like, artificial intelligence music? Because I know if you ask, just push the button music and I don't like that.
00:18:49.430 - 00:19:51.080, Speaker B: Yeah, and I see another question in the chat. But I think in the music NFT space I have conversations with artists and they say, well, I don't want to put music in a genre. I don't want to be classified as this or that. And what I would always say to that is, well, okay, if you make techno and I like to DJ techno and you don't put techno in the genre, it's harder for me to find your music. So having conversations about that because that is how metadata works, right? If the data is there, awesome. I can use it to find your music, for example, or get you paid on a secondary streaming platform or something like that. But like I said, just going out and learning as much as we can about artificial intelligence and information data systems, I think you're doing everything you got to do to help.
00:19:51.080 - 00:19:54.390, Speaker B: I see we have another question in the chat.
00:19:55.370 - 00:20:19.360, Speaker D: Hey, Ahmed, thanks for the overview. That was super dope. I'm also a data scientist and DJ, so it's great to see what you were able to build at your hackathon. I have two questions. So my first question was with the Mint songs, you use the Zora API to query data like metadata from Mint songs or how was that incorporated in your project?
00:20:19.810 - 00:20:47.830, Speaker B: Yeah, so specific. The Mint Songs factory was not through the Zora API. I should have clarified that that was through started integrating things just like weren't built on Zora as well. And so I should have clarified that. But the Minsongs V Two is through the Zora API and yeah, that's actually the example that we use today in the Code Walkthrough.
00:20:48.970 - 00:21:23.234, Speaker D: Awesome. And my last kind of tidbit is I definitely agree with you with the AI aspect of the space. Like helping DJs, helping artists kind of sift through songs. Because I had a specific issue with franchise record pool where I would go through these songs and sometimes they would be wrongfully put in different genres. For example, they'll have a Latin song and they will have it as, like, Afrobeats. Right? Even though some of the songs could be like the same cadence or same tune, they would have it wrongly classified. So I think it's super.
00:21:23.234 - 00:21:26.340, Speaker D: Dope what you were able to do and we should definitely connect.
00:21:27.670 - 00:21:36.760, Speaker B: No, I'm super down love. I my data scientists and my DJs. Yeah. If you follow me on Twitter or whatever, I think that's probably the best way to tap in.
00:21:39.270 - 00:21:40.660, Speaker D: For sure. Thanks, man.
00:21:41.350 - 00:21:51.760, Speaker B: Yeah, of course. Thank you. Yeah. Any other questions? If not, we'd be happy to give everyone back seven minutes.
