00:00:03.290 - 00:00:35.010, Speaker A: Cool. Looks like there's a solid turnout. I hope people brought their questions. Go ahead, Andrew. Okay, yeah, so I was just saying that I'll do a little recap of the week and then we could just jump into questions and feedback and everything. And so I guess recap on the week we launched the hosted Powergate for teams to use. So this is a Powergate connected to currently testnet.
00:00:35.010 - 00:01:21.538, Speaker A: I know that there's another kind of parallel network to testnet that Hack FS users are able to use, and it syncs a bit faster and deals clear a bit faster. But right now we're going to leave this Powergate connected to the full testnet. We could always switch it if there's strong demand for some reason to move over to the other one. The reason we'll keep it on this one, though, is then you can make use of other resources that are connected to testnet. So things like the Block Explorers and things that are online. But anyway, if you've missed any of that, just look at our Slack channel and we can get you instructions on joining that. The other thing that we launched this week was our experimental version of the Hub APIs.
00:01:21.538 - 00:02:36.910, Speaker A: And so this is a version just for hackfs participants, but it gives you an extended API set so you can use all the same things for API key generation threads, users, buckets, all of that stuff is in there. Everything that's in our production docs is available to be used, but it additionally has the ability to run bucket archive commands, which will push bucket snapshots to deals on filecoin and get those stored with miners on testnet and provide you back the deal information so that you can do things with deals on filecoin, in your app or on the command line. So that's super cool. Sander just pushed a big release to Buckets late last night. We'll work on getting some of that stuff into the production APIs shortly, but if you missed that, that's over on our Slack channel. We just announced our releases, but lots of cool things coming there for making use of Buckets in your hacks, if that's what you're doing. And then I think just a recap on some issues that we're seeing that maybe are worth discussing.
00:02:36.910 - 00:03:19.100, Speaker A: I think that there's going to be a bunch of Powergate questions, it seems, from our support. Just a lot of people using the Powergate JavaScript library and interested in talking through that. And then I had a little thread on our support channel about identities. Right now, our APIs just use a very simple key pair based identity. But I'm just trying to explore where we should expand to. And so I have some ideas now on what might be coming next, but if anybody's interested in talking through that stuff, and then Carson Aaron, do you think there's anything I missed there? Maybe we just jump into any questions people have.
00:03:21.250 - 00:03:23.150, Speaker B: Yeah, I think that's a pretty good summary.
00:03:25.010 - 00:03:26.058, Speaker A: Carson's inventory.
00:03:26.074 - 00:03:34.500, Speaker B: I didn't know about either. Oh, yeah, I'm here. Yeah, I think let's just jump into.
00:03:38.630 - 00:03:54.200, Speaker A: Do the I mean, there's not so many people we can do hand raising or people can just jump in, right? Yeah, I think that's fine. I believe people should be able to unmute. If you can't we'll change that setting? Yeah, go ahead, John.
00:03:57.610 - 00:05:42.390, Speaker C: Guys, can I just share my screen for a moment so that we all know what I'm talking about? Would that be okay? All right, can you guys see that? Okay, so this is the basic idea. It's a Python financial data app. Ideally, what we want to do is add a UI onto it so that the end user can get a quote and an associated chart with it. Ultimately, what we want to do is have it so that it would be a financial data store where end users could get historical quotes. Let's say you wanted to see a quote on Apple or a chart from Apple, say from 1980 till the present. In traditional databases, there really aren't any products that do that, but it would be very useful. My question is, the way we have the app now, it's plugged into a Postgres database where customers can kind of well, the end user can kind of go get their quote, goes into Postgres, pulls out the information and creates the chart.
00:05:42.390 - 00:06:44.190, Speaker C: Also could create a CSV file with those historical quotes. How would this app be able to plug into Powergate, then into Filecoin so that the data would be stored there, and then the end user could pull it out? Is there an ability to do that? That anytime the end user requests that data, that it can go into filecoin, pull it out? That's question one. Question two is, since because it's a Python app, would we be better off using pygate for it, or does one have nothing to do with the other? And we could just use that suite of what Andrew did in his video two weeks ago where you have Lotus, Power Gate and IPFS all in one package.
00:06:45.730 - 00:07:14.120, Speaker A: Maybe to answer the second question, mean, definitely the pygate stuff could move you along quickly. Aaron also just started publishing the Python packages for the gRPC API directly. So you can also use that if you just want to be calling Powergate functions from Python. Aaron, anything maybe to add there about that?
00:07:15.450 - 00:08:41.970, Speaker D: Yeah, maybe. Let me just explain kind of how those pieces fit together a little. So pygate, at least my understanding of it, is just a wrapper around the gRPC bindings that communicate with the Powergate gRPC service. And that Powergate gRPC service is just one service kind of exposed by that system of Powergate, Lotus and IPFS that are running, choosing not choosing pygate or really, you know, one is an extension of the other or client of the other. So I think if you have an application written in Python using. If work continues on pygate and it ends up being a nice client that's easy to use to communicate with Powergate, I think it would be really good option. If you find it isn't really to your liking and you still want to use Python, then like Andrew mentioned, we're publishing the gRPC generated Python bindings as a Python library in the PyPy package index.
00:08:41.970 - 00:08:51.590, Speaker D: It's called powergate client. So you could build your own client on top of those gRPC bindings.
00:08:52.730 - 00:08:53.142, Speaker E: Okay.
00:08:53.196 - 00:08:58.280, Speaker C: And then not even have to really use pygate. I could go directly to that.
00:08:58.750 - 00:09:15.600, Speaker D: Yeah, but I mean, you might end up writing a lot of the same kind of wrapper code that they are writing for pygate because the gRPC binding like using gRPC bindings directly, it's kind of a lower level API. It's not as nice.
00:09:16.930 - 00:09:20.160, Speaker A: You have to wrap protobuff calls a.
00:09:20.770 - 00:09:35.330, Speaker D: Yeah, so so usually when you write like a client library on top of some gRPC bindings, you do the work that it takes to kind of turn that lower level ugly API into kind of a prettier, easy to use API.
00:09:38.650 - 00:09:43.974, Speaker C: So a combo of both seems like it might be the best.
00:09:44.172 - 00:09:53.260, Speaker D: Yeah, I mean, definitely if pygate is a good library that you like and it's complete and usable, I think that'll be the way to go.
00:09:56.830 - 00:10:39.334, Speaker A: The reason we did the little motivation there, the reason we did the Python releases is because without those they were having to manual in pygate. They're manually basically wrapping our APIs and the protobuff definitions of our APIs. But now we automatically generate these bindings every release, so they can just pull in the latest release and get those sort of bindings automatically. So it was just to help them kind of keep that up to date faster. And Aaron had some big API releases or API stuff coming out anyway, so got that in. Yeah. Anyway, so then the first question is well, does that answer the second question? Sounds like it does, yeah.
00:10:39.372 - 00:10:51.834, Speaker C: That the end user can just get the data dip into filecoin, get what they need. I guess it would be in cold storage, let's say, if it's something that nobody really gets a quote on that often. Yeah, I think that did it.
00:10:51.952 - 00:10:53.982, Speaker A: Okay, cool. Yeah, super.
00:10:54.116 - 00:10:54.894, Speaker D: Thank you very much.
00:10:54.932 - 00:10:55.920, Speaker C: Appreciate it.
00:10:57.810 - 00:10:58.750, Speaker A: Aaron.
00:11:02.870 - 00:11:25.320, Speaker D: Yeah, I mean, we can talk more about this in Slack if you want, but I think depending on how users are interacting with this data, like how dynamic it needs to be as far as querying for only certain fields in the data or only certain time.
00:11:27.850 - 00:11:28.166, Speaker A: Mean.
00:11:28.188 - 00:11:31.474, Speaker D: That kind of stuff is really typical with a database like Postgres.
00:11:31.522 - 00:11:32.082, Speaker F: Right.
00:11:32.236 - 00:12:23.738, Speaker D: But if you're talking about pulling data out of filecoin, it's a little bit of a different thing where you're just going to be pulling out a chunk of very static data. So that's one concern that I had when you mentioned that. So I think however you use Filecoin, you just need to understand kind of the nature of how data is stored and retrieved in Filecoin. It's kind of slow. You're pulling out chunks of data. It's not a very dynamic kind of like database query, kind of like API. And also, depending on how frequent any data set needs to be retrieved by your user, I think you definitely want to consider using in Powergate the hot storage or IPFS layer to kind of make that data more available.
00:12:23.738 - 00:12:27.260, Speaker D: So you don't actually have to retrieve it from filecoin every time.
00:12:31.550 - 00:12:31.994, Speaker E: Or else.
00:12:32.032 - 00:12:35.600, Speaker D: The user is going to have to pay to retrieve it from file point every time. And you don't want that.
00:12:36.130 - 00:12:37.120, Speaker E: Got you.
00:12:37.570 - 00:12:41.006, Speaker C: Well, actually there would be kind of.
00:12:41.028 - 00:12:42.414, Speaker E: Two uses for it.
00:12:42.532 - 00:13:18.010, Speaker C: It would be that static long term data storage just for somebody doing technical analysis of stock, when's a good time to buy it? When's a good time to sell it? But then somebody using hot storage might be somebody who's trying to write an algorithm for a trading bot, which that would have to be very dynamic data. So I guess kind of have to pick and choose which bucket it goes into, hot or cold or depending upon.
00:13:18.910 - 00:13:45.010, Speaker D: And you might want to consider also like textile Threads database as a more dynamic way to interact with the data. Maybe periodically, when the whole data set is pulled from cold storage, maybe you parse it on your application server and load it in a more dynamic way into a textile like a thread database.
00:13:45.910 - 00:13:56.760, Speaker A: One question about that. Go ahead, querying one question about that. Who's creating that index of data? Are you doing that kind of as a service right now?
00:13:59.070 - 00:14:53.914, Speaker C: Actually, the feed would come from through Pandas data reader. Actually, the new data would come through Pandas data reader from Hookup to New York Stock Exchange or Nasdaq or an exchange such as that. That's where it would come from. But they only go back a certain period of time. Like you can only get three years of data where if you're going to do real thorough technical analysis of any kind of trading instrument, you'd have to have a much bigger sample space. So I'm also thinking, like, where would that data feed come from? That's something I haven't figured out yet. And that's where the integration into this whole setup with Filecoin and IPFS, I kind of have to figure that out later.
00:14:53.914 - 00:15:03.322, Speaker C: But for hackathon purposes, just for the next, whatever it is, three weeks, the information that you guys are giving me is kind of what I need.
00:15:03.456 - 00:15:23.620, Speaker A: Okay, but just like a clarification there. So what happens is a user will come and they'll actually generate their own feed from one of these APIs the first time. And then what they'll do is they'll take that CSV or whatever, and they'll put it in powergate. So the next time they need it, it's just there, and they can add more on top of it or whatever.
00:15:25.430 - 00:15:48.410, Speaker C: That might be. Some users and some users might need it to be dynamic. So, for example, let's say somebody were trading the stock of Apple or Google, and it trades like water. It trades all day long. So you would not have that kind of data going to cold storage. You want it to be always accessible in hot storage so that they could get kind of like that up to the minute quote.
00:15:49.310 - 00:16:20.566, Speaker A: But it's them creating that data from API calls to the original feedback. So that's cool. That's a good clarification because that means it's them that will actually put it in hot storage and them that will pull it back out the next time they need it. Or they're kind of a closed loop of their own use. So that's cool. So, Aaron, that sounds like they don't actually need anything super dynamic because they're the ones that will create it. So they could just expire old powergate CID configs and create new ones for the updated content.
00:16:20.566 - 00:16:30.860, Speaker A: Or have, like, an append system where new content points at the old content. So you can have a series of deals in the CID, something like that. Sounds doable, though.
00:16:31.390 - 00:16:32.140, Speaker D: Okay.
00:16:32.510 - 00:16:37.340, Speaker C: And they could get in and out and do what they need to do. And it would be quick.
00:16:37.870 - 00:16:48.846, Speaker A: You hit if you hit issues there, there's a good chance. I don't quite understand the setup. So we should just chat more. Like Aaron said, we can jump on Slack. Okay, cool. Nice.
00:16:48.948 - 00:16:49.630, Speaker C: That's great.
00:16:49.700 - 00:16:50.960, Speaker D: Thanks so much, guys.
00:16:51.330 - 00:16:52.400, Speaker A: Anyone else?
00:17:01.490 - 00:17:06.230, Speaker E: I got a question. I think I'm hand raising. I don't know, like these confused.
00:17:09.530 - 00:17:10.966, Speaker A: You'Re clapping right now.
00:17:11.068 - 00:17:27.178, Speaker E: Clapping? Yeah. For me, of course, knowing me, that perfect sense. It was either that or give myself a thumbs up. So although your beard's growing in pretty good there, Andrew. It's looking pretty you scruffified. It looks like you've been doing that. So I have a simple question.
00:17:27.178 - 00:18:07.442, Speaker E: Like, nationally, in my development process, you get down in the basement. I'm still in the basement, but I have an old saying, if you have it, tear it tore down. If you're replacing the plumbing, you might as well get the electrical. So the issue that I have is that I've designed my subscription blog such that we're going to have an archive folder and a current folder. That's it. Because whenever you subscribe to a month of Galvan Karate's awesome blog, you get all the archives. So whenever they use the Smart contract, it's going to populate the array with their address and the date timestamp, and then it's going to actually push them into both arrays.
00:18:07.442 - 00:18:16.374, Speaker E: So we're going to have two keys. We're going to have two buckets. One encrypted bucket that's archived, and whenever someone pays, once, they automatically get added to the group for the Textile bucket.
00:18:16.422 - 00:18:17.286, Speaker G: Or the hub bucket.
00:18:17.318 - 00:18:18.566, Speaker E: What do we call this? Just the bucket.
00:18:18.598 - 00:18:18.890, Speaker A: Right.
00:18:18.960 - 00:18:28.894, Speaker E: They're added to the group that has access to that, so when they get the session token, they can read it. The issue I have is the current bucket. So I'm trying to think about this in such a way.
00:18:28.932 - 00:18:29.278, Speaker A: Right.
00:18:29.364 - 00:18:37.060, Speaker E: When you pay, you get access to the current bucket, and then I need to rotate that key in that bucket somehow for each month. Like, what do I do?
00:18:37.830 - 00:18:40.050, Speaker A: Why don't I just create a new bucket for each month?
00:18:40.120 - 00:18:54.774, Speaker E: That's what I'm thinking. Well, I don't want one for every because I don't want the web page to get filled up with like month and month and month. I just want it to be current and archive. Right? Current and archive. Go ahead and listen.
00:18:54.892 - 00:19:01.482, Speaker B: There's also the possibility what's going in the bucket. It's like the blog post itself.
00:19:01.536 - 00:19:02.700, Speaker E: Blog post, yeah.
00:19:03.070 - 00:19:25.854, Speaker B: So there's also the option to individually encrypt on a per file basis what goes into the bucket with a password. So basically, you just give them a new password every month in their well, you'd give them a link that contains the password, probably, so that when they click on it, they would get the latest blog.
00:19:25.982 - 00:19:27.460, Speaker A: That'd be awesome. Yeah.
00:19:28.950 - 00:19:32.660, Speaker E: So what you're saying is that I encrypt the post itself.
00:19:33.270 - 00:20:25.266, Speaker B: Yeah, that is an option. In the Buck command line thing, there's like an encrypt one. So by default, if you have a private bucket, it does all of the encryption stuff transparently and those keys are the so once you're part of that bucket, that's it, you're in. But there is an additional layer where you can actually individually password protect a single file. So if you do that for each month's blog post with a different file, you get a different password and then you could just in your email. However the subscription system works, they would just get the new password each month, or a link that embeds the password and you're good to go.
00:20:25.368 - 00:21:03.406, Speaker E: That's 219 95. I appreciate that. And I still may end up doing that, so I probably shouldn't make fun of it now because I'll probably end up doing that, but I want it to be that they go to. So I wrote that down. This may not be the time for this, but I want them to be able to go, like I said, current archive, so that they click the link. I love the functionality that is already built in to where when they go, it says type in your email, they click it, they get the link, it logs, it, gives them the session token, it opens the URL, and then they're good. And then I haven't worked out the usability here, but when it comes up, they would just click that.
00:21:03.406 - 00:21:18.514, Speaker E: You have the archive bucket in the other bucket. So I guess I'll keep that in mind. But if I could just create a new bucket for every current month, right, which was kind of this is a hybrid between what Andrew said. What you're saying? Right. I could just create a new bucket every month and that would be the new one?
00:21:18.632 - 00:21:20.690, Speaker B: Yeah, that would work. Yep.
00:21:21.370 - 00:21:33.180, Speaker E: That's what I'll probably do. How's that URL going to work? Right. I get a new URL to the new bucket, though, right? A new IPFS. Sorry, we're not calling a URL. We call it a CID. What are we calling that? Is that a CID? What is that path called?
00:21:33.790 - 00:21:39.810, Speaker B: You would get a new IPNs CID for every bucket.
00:21:39.990 - 00:21:44.190, Speaker E: Yeah. So I'm going to have to work out my naming convention.
00:21:48.210 - 00:22:16.310, Speaker A: I was just thinking there's actually something pretty interesting there. Maybe it's a hybrid of this, where you could I don't know if this is is this possible? Carson, can you change the password on a bucket? I guess not. I was just thinking you could actually delete I was just thinking you could actually use the same bucket, delete the old document, move it to the archive and create the add the new document.
00:22:16.650 - 00:22:18.198, Speaker B: But you could definitely do that.
00:22:18.284 - 00:22:20.630, Speaker A: You just need to change the encryption of the new document.
00:22:21.230 - 00:22:25.702, Speaker E: Or I could change the key. Can I change the key? I can change the key for a bucket.
00:22:25.846 - 00:22:27.420, Speaker B: I don't know that you can.
00:22:28.190 - 00:22:29.434, Speaker E: Sounded good, though, right?
00:22:29.552 - 00:23:04.680, Speaker B: It sounded like an awesome idea. Yeah, that's a great feature request. That was kind of what I was trying to get at with the individually encrypting the files is like, each month you encrypt the file, move it, like decrypt it, move it to archive, encrypt it with the new one. You do still have to get the password for it somehow, but I'm sure you could also have a thread, like a subscription thread for the user when they subscribe that just gives them the latest passwords, something like that.
00:23:06.330 - 00:23:07.590, Speaker E: User friction.
00:23:08.250 - 00:23:21.210, Speaker B: Well, I mean sorry. So they wouldn't actually do anything with the password. Like, the password would just be there and would be used when they access it so they wouldn't have to type in the password. The system would unlock it for them automatically.
00:23:24.710 - 00:23:35.666, Speaker E: I might have to do some research there. I get the idea. So you're saying would it be part of the URL string that I'm giving them, or would it be built into basically their identity that's on their machine somehow, or their mobile?
00:23:35.778 - 00:23:57.630, Speaker B: Well, you could do it either way. You could do it so that they've got, like a thread that just syncs in the background that just syncs the passwords there, and then your system would or your app or whatever would go, oh, look, here's the password. Great, you can see this. Or yeah, I mean, the easier way to do it is just to embed it in the links that they get each time and be done with it.
00:23:57.780 - 00:24:41.482, Speaker A: Related here is actually the thinking about when that needs to change because basically you could create the same password so like in your subscribers list, you have one subscriber. You're going to create a password anytime you add a new subscriber. You can just keep using the same password for every month for all the users. It's actually only when a subscriber leaves that you need to generate a new password. So you could just have a trigger that if subscribers leave, you could generate a new password for everyone and start the next month using that password instead. So there's not so many passwords you'd have to. So actually you could make it so that you just generate a new bucket only when subscribers leave, if that makes sense.
00:24:41.616 - 00:25:10.166, Speaker E: So this is designed to be like, we haven't gone this far yet and I'll just give you a window. So we're going to have basically going to be able to parameterize the different types of subscriptions. And ideally, the design is that you pay one dollars a read per article, but then you can get it monthly for 999 or something. People just want to read one. There's so many I have to subscribe to and I want to get away from merchant services, evil addiction, like just slavery. And so this is the beginning. We're starting very simple, okay.
00:25:10.166 - 00:25:49.250, Speaker E: Trying to get encrypted content that people can read and click through that actually works, that somebody can like a normal person, like not one of us can actually use this blog functionality. And so I think we have a good answer. I'm going to go with probably the new bucket, and then I'm going to have to mess with the CID and the URL mapping or something because that is clean. Because then when they use the smart contract, it's going to populate those arrays and it'll be totally transparent to them and they'll click and they'll get all the archives and then they just won't be able to see the new ones. And then that involves the least amount of steps, but I may end up with some mixture of these. Let's just see if I can get this thing running. Right now I'm learning Hugo, which is my new web platform.
00:25:49.250 - 00:25:52.722, Speaker E: I started with Jekyll, which didn't do the job. Hugo is much better.
00:25:52.856 - 00:25:53.298, Speaker A: Awesome.
00:25:53.384 - 00:26:10.860, Speaker E: Yeah, it's way better. But now it's a long story. I downloaded like the biggest theme ever and now I have to customize it. So I'm now becoming developer on side. Thank you though, very much for this. And eventually we'll get into React. This whole thing is going to go great.
00:26:14.510 - 00:26:23.200, Speaker B: I'm just looking to see in our bucket documentation if there's a way to change the password, but I think not right now.
00:26:27.650 - 00:26:49.490, Speaker E: How do you mask the bucket names in your React app, Andrew? How do you mask those? Yeah, because I've read that app, but I haven't been able to get it to start. So just thinking, what am I doing? The Photos, you have a React native Photos app and those buckets completely transparent to the user, they subscribe to the threat. Right, those buckets.
00:26:49.650 - 00:27:33.358, Speaker A: So basically that's like single writer buckets. So the user creates the bucket, but they're not encrypted, so then I can share the IPNs address with anybody who wants to view it. Okay, yeah, let me explain it because it's actually pretty neat. So you as the owner of the bucket, you know the structure of the bucket, so the app can just do anything in the bucket. It knows the schema and everything. But when you share that IPNs address, you imagine that you're just sharing some dag with people and they have no clue what's inside of it. But most gateways on the IPFS network will look to see if it's an HTML folder.
00:27:33.358 - 00:28:10.138, Speaker A: And so if there's an index HTML in the root, it will just render that. And so what I do in the app is the user creates a bucket that they own and then the app drops an HTML file into the root, an index HTML file into that root that just has some really simple JavaScript to parse all the photos that they're adding to that bucket and render them in a gallery. And so what's really cool there is that then the owner can update those images, add a delete, whatever, and they can share that IPNs address, which just renders them as a gallery. So they get this public gallery on their images.
00:28:10.234 - 00:28:12.558, Speaker E: Did you just say it wasn't encrypted, though?
00:28:12.724 - 00:28:14.418, Speaker A: This one is a public bucket. Yeah.
00:28:14.504 - 00:28:20.242, Speaker E: Sneaky. So even though they subscribe to the thread, that means someone else, if they found it, they can still see it then.
00:28:20.376 - 00:28:25.800, Speaker A: Yeah. Well, the whole idea is to share the gallery. So this is for creating public galleries? Yeah.
00:28:28.250 - 00:28:28.950, Speaker E: Interesting.
00:28:29.100 - 00:28:35.846, Speaker A: So it was kind of like if you wanted to build like a Flickr clone, this would be the basic start of that.
00:28:35.868 - 00:28:45.420, Speaker E: I was thinking of it as like a Facebook thing. Sorry for the entire sorry for the dirty word. I did. I said Facebook. I did it again. But that's what I was thinking of.
00:28:47.330 - 00:28:49.214, Speaker A: My computer bleeps those out.
00:28:49.332 - 00:28:59.142, Speaker E: It does, it's just like when Cake had that. What do you have on there? Dropbox? I was terrible.
00:28:59.306 - 00:28:59.874, Speaker A: Cool.
00:28:59.992 - 00:29:01.250, Speaker E: All right, thanks, man.
00:29:01.400 - 00:29:04.450, Speaker A: I see another hand. Tyrone.
00:29:07.350 - 00:29:09.118, Speaker G: Yeah. Hi Andrew.
00:29:09.294 - 00:29:11.460, Speaker A: Hi there. Hi.
00:29:11.990 - 00:30:25.210, Speaker G: Yeah, I wanted to discuss something regarding we have some update. So I've been in continuous discussion with Aaron from past few days and we were looking to have this offline signing for our architecture, but coincidentally yesterday we had a one on one call with Filecoin and with the Filecoin team, and I discussed the architecture with them. So they were saying it does completely make sense. But right now their team has just started doing work around offline signing stuff, maybe for this hackathon, and for next month we can just go with the Powergate and whatever the current architecture looks like. We can just run the Powergate node ourselves or maybe like the hosted provided by you guys and just store our data on our file coin addresses for now and users have full control on it because we are using end to end encryption so we are not going to do anything with the data. Right? Yeah. So I just wanted to update.
00:30:25.790 - 00:30:46.434, Speaker A: I mean that makes a ton of sense actually because well good on the update about the offline signing but also just make a lot of sense because it'll reduce what you have to develop for the next couple of weeks and kind of MVP status. Plus it's all in testnet so not so much that can go wrong right now.
00:30:46.552 - 00:31:01.074, Speaker G: Yeah, it sounds and like they have also shared me the links where I can just see all the RPC methods. So basically everything is like end of the day it is calling that RPC method.
00:31:01.122 - 00:31:01.430, Speaker A: Right.
00:31:01.500 - 00:31:16.006, Speaker G: So they need to just support that but they are just asking for the time right now. They are majorly focusing on other things. So yeah, we can just wait and just go for the testnet. Does it make sense? Like I'm asking it again but verify?
00:31:16.198 - 00:31:18.480, Speaker A: Yeah, I think it sounds awesome.
00:31:19.250 - 00:31:19.902, Speaker G: Nice.
00:31:20.036 - 00:31:20.382, Speaker A: Yeah.
00:31:20.436 - 00:31:37.140, Speaker D: Thanks for the update there. You're definitely like where you were going with that idea is kind of like on the bleeding edge of filecoin and therefore kind of already on the bleeding edge of powergate. So we are literally figuring this stuff out at the same time you are.
00:31:37.670 - 00:31:48.742, Speaker G: Yeah. Thanks a lot guys. You are helping us a lot. So it's like I was very new to learning this stuff but you guys are really helpful. So thanks for that.
00:31:48.876 - 00:31:50.440, Speaker A: Cool. Keep it up man.
00:31:51.770 - 00:31:52.760, Speaker G: Thank you.
00:31:56.010 - 00:32:00.486, Speaker E: Yeah, totally fine.
00:32:00.588 - 00:32:13.918, Speaker A: Yeah. Who else? Anybody else with a question? If we don't have any questions, I'm going to put Carson on Spot for some dad jokes. We'll do that for 30 minutes and.
00:32:13.924 - 00:32:20.770, Speaker B: Then I'm always ready with judge dad jokes. It's not a problem. Puns are my specialty.
00:32:22.070 - 00:32:27.140, Speaker E: A horse walks into a bar, the bartender says why the long face?
00:32:27.750 - 00:32:31.540, Speaker A: Classic. Classic. Still good.
00:32:33.130 - 00:32:51.578, Speaker G: Just a question. Yeah, I'm just curious. As buckets and thread, DB really is going to change the user experience for the developer also. So developers can easily integrate same kind of stuff what we are used to in web two.
00:32:51.664 - 00:32:52.010, Speaker A: Right.
00:32:52.080 - 00:32:57.900, Speaker G: And then when you are really planning to attach that service to file kind of also.
00:32:58.830 - 00:33:36.982, Speaker A: Yeah, a lot of that we're just trying like filecoin so early. We're just trying to figure out and this hackathon is going to be awesome for us. We're just trying to figure out how people want to use these APIs. And so that's why for us, it makes a lot of sense to have the power gate be kind of raw and open so that people that want to use that stuff can just go use it. And we can get some feedback about how you're imagining organizing. Deals and who you want to be in control and manage those things. And then on the Hub side of things, our host APIs, we're just slipping them in in some simple ways at first.
00:33:36.982 - 00:34:26.950, Speaker A: So the first example, that is with Buckets, like this experimental version of the Hub, you can do all the archiving that get you on filecoin and that really rides on this architecture of the filecoin, the idea that things can live in the hot layer and be available on the network. And then you can archive them, which is in Bucket terminology. But on Powergate, that's just moving it to the cold layer. And so that's sort of our nice and most straightforward integration there. But we're also exploring kind of two other concrete things. One is we're exploring the idea of if you're any developers that have already dug into the Powergate, there's the FFS API, which is more or less the primary API. You get an FFS token.
00:34:26.950 - 00:35:14.838, Speaker A: You can map that to a service or a so we're looking at every user of the Hub would get a new FFS token so that they could have sort of the full FFS API available per user. And that's pretty cool because that means that every developer would get an address on filecoin. They'd get the full FFS API. It would have all the API security stuff that's built in the Hub for them to use it. But then the next question is, do we mirror that down into developers users themselves? So then your app user could have their own FFS instance and their own API. That's something we're exploring. And then the next thing kind of more deep integration is in the threads database.
00:35:14.838 - 00:36:07.146, Speaker A: So there's a few big chunks of the Threads database that are missing still. One is more advanced ACLs and the other is snapshotting. And so snapshotting is super important for threads because they let you wrap up the current state of the thread into one item. But when we implement that in threads, it opens the door to do a lot of other really cool things. So one of them is that we can allow the developer to this isn't concrete exactly how it work, but you can allow the developer to set the thread for how much verification you want on that snapshot. So for example, all thread participants maybe sign the snapshot and say, yeah, for sure, that is the current state of the database. And then they can move to basically building off that.
00:36:07.146 - 00:36:25.294, Speaker A: They can all collectively move to that being the root of the next updates. And so what's really cool about that is then you can have mutable ACL in your database because you can create a snapshot, use that as the root of a new thread with more people in it or less people.
00:36:25.412 - 00:36:30.426, Speaker G: Yeah, just like Distillation has this concept of snapshotting, right?
00:36:30.548 - 00:36:31.086, Speaker A: Totally.
00:36:31.198 - 00:36:40.146, Speaker G: You can just totally have a snapshot of the server. And after that you could just spawn it into another group or maybe somewhere totally exactly.
00:36:40.248 - 00:37:05.610, Speaker A: But the next door that opens up for us is because Filecoin is really great at this sort of cold storage archiving that is a great place to put your snapshot. And so you would have thread commands to archive a thread, which would be take the snapshot, put it on Filecoin and start storing it long term. So that's just in our heads. We know that that's the direction that that will go, but it's just about time. And human resources.
00:37:08.210 - 00:37:25.890, Speaker G: Anything you guys are doing related to providing some Caching service like Redis? Maybe it's like something on the fastening of the things. Or we can just directly use Redis on top of our infrastructure when we integrate textiles.
00:37:26.550 - 00:37:31.140, Speaker A: So I don't know. Carson, does that trigger any thoughts for you?
00:37:31.670 - 00:37:33.140, Speaker B: Can you repeat the question?
00:37:33.830 - 00:38:20.530, Speaker G: It's like something are you guys also planning for this caching layer also? So I'm just asking. It's not like I'm also clear. So it's like when, let's say we are using Powergate and we want to fasten up some experience so that we can just cache some data and just include Redis for that. For that, we need to build something out for that. And I'm just saying, are you guys also building something related to caching also for some library around that, so that we can just integrate Redis like service very easily with textile?
00:38:22.790 - 00:39:15.590, Speaker B: I don't know, just a think that's well, so you may see Ignacio just posted in here. We could think of a hot storage implementation that uses a different data store for storing data. So you could have a Redis or Mongo or something like that as a local database or even potentially like browser or something, if it's a JavaScript, our threadsdb JavaScript implementation, the database implementation that does basically have a local cache in the browser or on the desktop if you're running it in Node. So all the queries actually go to the local one and then updates are synced to and from the network. So you can imagine something very similar to that, I think, for the Powergate.
00:39:16.090 - 00:39:16.598, Speaker A: Yeah.
00:39:16.684 - 00:39:28.958, Speaker B: And one thing we have discussed actually as a team before is so Ignacio mentioned we can think of a hot storage implementation that uses another data store, but you could think of also, like parallel hot storage.
00:39:29.154 - 00:39:45.630, Speaker G: Yeah, I was asking something around that if we have a distributed system around like a cluster of powergate nodes running and if we have some cool library around it. But yeah, it's something very later on things cool.
00:39:45.700 - 00:39:46.394, Speaker B: Totally.
00:39:46.522 - 00:39:56.030, Speaker G: So for sure we are totally in process of integrating Powergate in our application. So I'll update if I have any doubt.
00:39:56.190 - 00:39:57.362, Speaker B: Yeah, please do.
00:39:57.496 - 00:40:00.338, Speaker G: Super excited. That's awesome.
00:40:00.424 - 00:40:05.400, Speaker A: Yeah. All right.
00:40:08.970 - 00:40:23.382, Speaker B: We're still at that magic stage with a lot of this stuff. So when it works, you're like I mean, I know it was supposed to work, but like damn, it worked. That's pretty cool. A lot of that stuff. I mean, of course it works.
00:40:23.516 - 00:40:26.960, Speaker A: We won't tell them about the number of times we cried when it didn't work.
00:40:30.370 - 00:40:41.360, Speaker F: Hi, so my friend is not here today. He tried to connect to work with Buckets example and it failed with.
00:40:44.230 - 00:41:08.698, Speaker A: I saw this issue, I wrote back in a thread to him to see if I could take a look, because it rings a bell that something like this happened when I was building some react examples. But it was pretty quick to get around and so I just wanted to see if I could try his code or take a look at it. I'm not sure.
00:41:08.864 - 00:41:18.990, Speaker F: Try to launch a bucket example and then on a yarn start he has this course issue because he's on local host. He's running a local host?
00:41:23.410 - 00:41:24.160, Speaker B: Yeah.
00:41:24.690 - 00:41:26.078, Speaker A: Well, first of all, I thought we.
00:41:26.084 - 00:41:29.360, Speaker B: Had cores enabled on those APIs, but maybe not.
00:41:30.290 - 00:41:35.218, Speaker A: We do. I think it's something to do with the react app launching, I think.
00:41:35.384 - 00:42:02.186, Speaker B: Yeah, the other thing you could try is you could try accessing it over, like loopback versus localhost versus whatever, to see if that makes a difference. Because some browsers treat localhost and like 127 one differently. So you could try that as well. But yeah, the best thing is maybe just if you can get a reproducible example. What was that?
00:42:02.288 - 00:42:04.150, Speaker F: It could be related to browser.
00:42:04.310 - 00:42:06.170, Speaker B: It could be related to the browser.
00:42:06.770 - 00:42:18.240, Speaker A: Well, my question for him was is the react app running just a static react website or does it have like, an exprs server in the example?
00:42:19.350 - 00:42:25.140, Speaker F: So you just pressed yarn start on bucket example.
00:42:27.430 - 00:42:37.174, Speaker A: On bucket example in the JS examples repo, you mean?
00:42:37.372 - 00:42:38.520, Speaker F: I think so.
00:42:39.930 - 00:43:01.440, Speaker A: In which example, though? Oh, the bucket. Photo gallery. So there isn't a yarn start there. That might be one problem. I haven't tested this with yarn. I can't imagine that leading to the problem. But definitely just try the default NPM run start, NPM install and NPM run start.
00:43:01.440 - 00:43:14.420, Speaker A: And then the other question is yeah, there's no server involved here. Yeah, let's take this one over chat because I don't have a good answer for you right now.
00:43:22.870 - 00:43:36.554, Speaker E: Yeah, that photo app works. If you drop the key in, then you run NPM like you do. That one works. Your react app sucks. Yeah, it works great. When you demo, it looks awesome. But on my shitty machine, it doesn't work.
00:43:36.554 - 00:44:04.594, Speaker E: So I assumed it's me. I have other problems, like actually developing something that someone wants to look at that's taking up far more my time. We can add react native later in our leisure. I did follow all of your instructions too. Like with the whole Xcode and everything else for iOS run start or whatever. Run start iOS. It didn't work.
00:44:04.594 - 00:44:05.860, Speaker E: I think it's me.
00:44:08.470 - 00:44:13.700, Speaker A: I find the mobile stack to always have weird issues that sneak in there.
00:44:14.390 - 00:44:16.758, Speaker E: That's why I didn't want to waste your time.
00:44:16.924 - 00:44:22.134, Speaker A: Well, we're happy to try because we can always add it to the README or whatever if we can figure it out.
00:44:22.172 - 00:44:52.558, Speaker E: So neither Android nor iOS worked on it and I had the simulator already started and I've used it for a different react app, but mine uses Expo, so I used it on my expo. I've never used it with just react native. I use Expo normally and that works fine, but I have not been able to get react native to work with the I cloned it. Basically you have like four steps that you do, and I did all the steps. I blew it out like three times and tried it all different ways. And when it starts, it gets a crash. It's actually a crash from Xcode.
00:44:52.558 - 00:45:11.560, Speaker E: It's error 65 where it's a build error. It's a well known error because Xcode build produces weird errors and that's a well known weird error has to do with it doesn't have a path to config, blah, blah, blah. So I think it has something to do with the Xcode configuration setting of some sort.
00:45:13.530 - 00:45:38.158, Speaker A: Okay, actually, go ahead. Still chat that one to me because when I put that example together, I definitely hit issues, but then you think that they're you and you think that stack confuses you, so you're not sure. And so I might not have documented them and I might just not remember. So if you share that, maybe it'll ring some bells for me and I.
00:45:38.164 - 00:45:50.690, Speaker E: Can I'll bump it in chat? Yeah, I'll bump it. Like I said, I figure that's further down the road. Let's get this subscribe blog first work, then we'll worry about native.
00:45:51.290 - 00:46:08.540, Speaker A: Cool. What else we got? Any questions? Carson, what coffee are you drinking today?
00:46:13.550 - 00:46:25.498, Speaker B: So, I am drinking a medium roast from the Fernwood Coffee Roaster, which is like roasted about 50ft from my house. Lovely.
00:46:25.674 - 00:46:26.446, Speaker A: Nice.
00:46:26.628 - 00:46:28.480, Speaker B: Already polished it off. Actually.
00:46:30.950 - 00:47:11.040, Speaker F: I would like to ask question related to that example with blog and secret keys or secret phrases for every subscriber. So basically more about maybe details how it's implemented, how this secret keys is stored. I mean, is it encoded per every public address of every subscriber? So if there are like thousands of subscribers, there will be thousands of encoded secrets to the content.
00:47:16.290 - 00:47:20.834, Speaker B: Maybe you didn't catch the first. Is this a question about did you say blog or log?
00:47:21.032 - 00:47:22.260, Speaker A: Blog. Log.
00:47:23.990 - 00:47:25.650, Speaker B: Is this a question for karate?
00:47:26.470 - 00:48:14.930, Speaker F: I think yes, it's related. I mean question. So you have this bucket and said that there is option to go with password and you can specify who can access this, right? So there is only one password and it's up to bucket owner to send this password via email or something to anybody else. Or there is option to encrypt this password per address like this asymmetric key. So you encrypt the public address of everyone like Bob Ellis, et cetera, and then they can decrypt it with their private key. How is it organized?
00:48:20.470 - 00:48:22.050, Speaker B: I think you're on mute.
00:48:23.030 - 00:48:32.920, Speaker E: You were glad I was on mute, but unfortunately I unmuted. So you're saying that's another option I can use, correct? That's what he was saying, right?
00:48:34.910 - 00:49:21.510, Speaker B: I think he was asking but I think it is another option. I mean, it it doesn't I mean, it depends just on what channel. I think you want to like what channel you want to use to get that password to the users. If it's an insecure channel, then doing something like encryption per user identity, sending them that and then having them decrypt it locally, obviously all seamlessly, they're not doing this directly, then that is a great idea. But ultimately they're all going to end up with the same password. So if you're worried about someone leaking the password, they could leak it whether you encrypt it for them directly or you don't.
00:49:22.250 - 00:49:40.830, Speaker E: Yeah, this is the Internet where that's good news. If your content is good enough, someone's pirating it. Dude, you did a great job on your blog. Honestly, you're getting huge hits. If someone wants I mean, that's the right way. Sorry I asked you to the right way, but I find that the Internet that's a good idea. People are linking your blog.
00:49:40.830 - 00:49:55.630, Speaker E: You have some hot content and you can monetize it in different ways. But I just want it to be seamless. It's not my favorite thing, but I like the way it's clicked. You get a session token, I watch the whole process. The session token gets loaded in the cookie.
00:49:55.710 - 00:49:56.194, Speaker A: I'm good.
00:49:56.232 - 00:50:19.526, Speaker E: I can use that with Hugo. I'm in good shape, I think. We'll see. I'm not going to get into this fancy encryption or fancy, like encrypting with people's public key and allowing them to decrypt it. It sounds awesome, but I'm not awesome. I want something really simple so that a regular, like the example I use for my use case is The Defiant by Camilla Russo. I hate subscribing on substack.
00:50:19.526 - 00:50:25.274, Speaker E: Is that that new one they have out there? Substack? I can't stand that site. So that's my reason is to make.
00:50:25.312 - 00:50:28.880, Speaker A: Something better so I can subscribe anyway.
00:50:29.890 - 00:50:31.200, Speaker E: I'll look at it.
00:50:32.770 - 00:50:48.660, Speaker B: Well, yeah, I mean, the TLDR there I think is Alex. Yeah. That is a reasonable thing to do. And I think it depends a lot on how you want to structure your user network and identities and things like that.
00:50:50.070 - 00:50:50.386, Speaker A: Yeah.
00:50:50.408 - 00:51:46.040, Speaker F: So I was thinking about this approach. So as you mentioned before, you encode every article individually with different password. I mean, the writer of this blog post or author, and then you encrypt this password per every subscriber. So you can, for example, create additional file that will be, for example, JSON array of encrypted passwords per every subscriber. So there could be post content and accompanying file with encoded passwords to this content per every subscriber. And you can do this for every article but the big problem here is when somebody joins or leaves this.
00:51:51.610 - 00:51:56.860, Speaker B: You. But I think the other part of it, and karate, you're probably going to agree with me on this, is.
00:51:59.550 - 00:51:59.914, Speaker A: The.
00:51:59.952 - 00:52:31.790, Speaker B: Leaving thing is less of an issue. I think once you've given someone a password for any content at some point in the past, you just have to assume that is effectively compromised. They have that now, they could leak it. And so it's really just like I don't even think it's worth mitigating against that threat, really. But you obviously don't want someone who has left to get future posts. So you want sort of forward secrecy, but you don't really care so much about backward secrecy.
00:52:31.950 - 00:52:41.960, Speaker E: Yeah, that's why they get all the archives. And not only that, like, sharing passwords would spawn the creation of the Ganu operating system. So let's hope that I'm 110 thousand as successful as that.
00:52:42.410 - 00:53:11.040, Speaker A: I always think that email is the perfect design to always think about these things. You can't delete an email from somebody else's inbox. Once it's gone, it's gone. I always think that delete is also a user interface. It's not data. Data doesn't know delete at all. So removing access to other people of data is just UI and that's not very secure ever.
00:53:12.210 - 00:53:12.766, Speaker G: Right?
00:53:12.868 - 00:53:17.246, Speaker E: It's like that video of you drinking in Cancun when you're like 19 or whatever.
00:53:17.428 - 00:53:18.558, Speaker A: Oh, you saw that?
00:53:18.644 - 00:53:20.506, Speaker E: Yeah. Just kidding.
00:53:20.538 - 00:53:23.570, Speaker A: I never have. I've never drank in Cancun.
00:53:23.650 - 00:53:58.880, Speaker E: I don't drink. Yeah, so but that's the idea, like, you know, give them all content to all archives and it's honestly, I did think about this. So a lot of people want to resell content that they've already done the work for. But why do you get paid more than once for the same work? Really think about that. So there's a lot of moral and ethical things that IPFS and the new decentralized Internet we're building is solving. This is a really big deal. What we're doing in case people don't realize, and I think everyone does, but it's as big of a deal in government and policy that's been made in at least the last 6000 years.
00:53:58.880 - 00:54:20.326, Speaker E: That's why originally I didn't want to share my idea. I was like, dude, you're on IPFS. These guys are giving away everything for free. You're going to share your stupid idea, you're going to tell them exactly how you're building it. And I was like, man, I want to share my idea, but whatever. Looks like I'm done. So I've already talked too much.
00:54:20.326 - 00:54:24.418, Speaker E: If I don't leave, I'll just keep rambling. So I want to help me out.
00:54:24.524 - 00:54:31.020, Speaker A: Yeah. Thank you. Thank you as always for your questions. Any last questions for today?
00:54:33.230 - 00:54:35.130, Speaker H: Hey, this is Samikshan.
00:54:36.030 - 00:54:36.970, Speaker A: Hi guys.
00:54:37.120 - 00:55:35.034, Speaker H: Hi, Nick. So if you remember that I had this idea of working on a collaborative music platform and initially I had thought of a design. I know it's towards the end of the discussion, so I'll try to make it quick. So initially I had this design around Pargate and FFS and then recently I've tried to relook at the design and tried to use Buckets and the Threads API. And while doing that, I started looking at the authentication part of the documentation. I came across some issues while using trying to document, while trying to authenticate through the Go backend. And I raised an issue on the GitHub on GitHub for Go threads.
00:55:35.034 - 00:57:07.310, Speaker H: So while in that discussion itself, I spoke with Sandapic and that was when I kind of thought about the idea a little bit and maybe thought about totally scrapping the back end out of my application. Totally. Because when you think of it in an application like this, you probably don't need to have any kind of private data because I want to have maximum collaboration on any audio that has been posted. So basically the idea is that a user will submit a publish a track and any other user could, based on the search that he or she makes, would be able to jam on that particular track and republish new track. So probably I don't actually need a database, like a centralized database that would, for example, block views for particular tracks for particular users, things like that. So I was thinking of absolutely going like serverless and have just a front end client to client communication approach while having the Threads API and Threads database to store all of this information and have Buckets as a store for the audio tracks. So I just wanted to run it by you to maybe if there would be any more challenges that I could be facing with this particular approach.
00:57:09.250 - 00:57:34.370, Speaker A: Yeah, I see Carson thinking the only thing I see that maybe so right now I think our user authentication model is pretty thin. So right now when you create your API keys, you can authenticate based on key pairs.
00:57:34.710 - 00:57:35.362, Speaker F: Right.
00:57:35.496 - 00:58:22.600, Speaker A: We're in discussions right now about what the right way to go forward is, but I don't think we'll have anything significantly different before the end of the hackathon. So just be aware of that Aaron put together. So one thing you might want to do is just have like a really thin you might want to still have a really thin server that just will allow you to do more authentication types. So like allow people to log in with any provider so that you don't have to force them to be like a private key holder. Right, okay. So that would just be like nice UX, maybe in the short term. And then you could remove that do or like you're proposing, leave it sort of light and don't do that.
00:58:22.600 - 00:58:54.142, Speaker A: But Aaron has a nice example called the Node Starter in our repos and also in Jay's examples, there's like the Hub browser example. Both of those ones would just give a really simple back end that then you could map things like allow people to sign in with their GitHub or with their spotify and get a key pair that then they use for all the rest of the APIs. And next time they log in, they would get that same key pair. That just might be nice. UX. But up to you, right? Yeah.
00:58:54.196 - 00:58:59.360, Speaker H: So this is the Hub browser repo that you were talking about, right?
00:58:59.990 - 00:59:28.650, Speaker A: Yeah, there's another one. Let me share, actually. I think I need to merge pull request real quick in there while I'm in there. Right. This doesn't really involve anything Textile, except for it currently has the latest libraries as dependencies, so you can just start using them, but it just gives a simple framework for having an authentication endpoint.
00:59:30.030 - 00:59:34.140, Speaker H: Right, yeah. Makes sense.
00:59:35.230 - 00:59:35.978, Speaker A: Thanks.
00:59:36.144 - 01:00:10.280, Speaker H: And yeah, I'm actually thinking of running a very thin server. For example, like, when a user would make a search for a particular track based on for example, a user would need to particularly need just guitar tracks because that person wants to add some drums on top of that. So for those kind of searches, I was thinking of writing a thin server anyway. But for the authentication part.
01:00:12.570 - 01:00:13.218, Speaker A: The discussion.
01:00:13.234 - 01:00:40.350, Speaker H: With Sandabic was like, why don't you just have the client directly authenticate with Textile to basically get those tokens to be able to make push buckets and add files to those buckets and things like that. All right, I'll actually think about this a little bit more, and then we'll get back to you guys regarding whatever changes I've thought about.
01:00:40.500 - 01:00:59.880, Speaker A: Cool. Yeah, I think all those make sense. Like, you could go super light and do it that way. You could add a little layer here, but like you said, if you add the little layer, that gives you another place to add indices or, like, search endpoints and things too, which could be nice. Totally. Right. Thanks.
01:00:59.880 - 01:01:17.840, Speaker A: It anyone else? Are we at the end of office hours? We're technically at the end, but it's a final question.
01:01:20.210 - 01:01:21.600, Speaker B: I think we're good.
01:01:23.810 - 01:01:44.760, Speaker A: Cool. Well, awesome as always. Really excited to see everybody and hear about some of the progress and hopefully any of the issues we're able to unblock quickly or unblock some of them are today. But we're trying to be as active as possible in Slack. So just keep the questions coming, and we'll try to keep you unblocked. So keep up the good work.
01:01:46.730 - 01:01:47.654, Speaker D: See you guys.
01:01:47.772 - 01:01:48.438, Speaker E: Thank you.
01:01:48.524 - 01:01:50.740, Speaker A: Thank you. Thank you. Thanks, everyone.
