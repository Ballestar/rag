00:00:11.930 - 00:00:13.120, Speaker A: And we're good.
00:00:13.490 - 00:00:14.240, Speaker B: Cool.
00:00:14.610 - 00:00:43.114, Speaker A: All right, I already said this, but just for anybody who's on the stream, this is the Textile office hours part of Hackfs. We've got Andrew starting off session with us and then a little bit later, a few Textile team members will join as well. So I'll let Andrew start it, give a little intro and then we can have people talk about their projects, any tough issues they're having and likewise, go ahead.
00:00:43.152 - 00:01:06.126, Speaker C: Cool. Yeah. So thanks, everybody, for joining us again. Maybe it'd probably just helpful. Kind of like kick off with a little lay of the land, remind everybody all the things that we're offering, and then point down a couple of people. On my team that are already on the call and will join the call, that are just like great resources in all the weeks going forward. And then we can just jump into some common problems.
00:01:06.126 - 00:01:53.130, Speaker C: Maybe it would be useful right now while I'm just kind of giving the lay of the land. If you want to already kind of mention topics or even specific questions in the chat and then if there's any kind of consensus around ones, we can surface those more quickly and then just try to get to all of. So let's see, so quick lay of the land, all the things that textile is trying to offer for this hackathon. First one is all the powergate stack. So if you're here for talking about powergate, you're in the right place. We're offering powergate in a few different ways. Obviously, the open source stack, run it your own there's no closed source stack, but the run it your own stack from GitHub and on docker in docker images.
00:01:53.130 - 00:02:37.102, Speaker C: So anything you want to ask about that, feel free. We're also trying to offer powergate as hosted instances, synced to testnet. And so for those of you that are building teams and need things from testnet and you're having issues syncing yourself or worried about resources to do that, we're going to be offering help there. So if you want to talk about that, totally open to chat about that and what our game plan is there. And timelines, we have a number of teams that have already signed up to get access to that. So if that's you, let's talk about that today. So then on the Textile side of things, we have threads and buckets which we gave a workshop on two days ago.
00:02:37.102 - 00:03:29.550, Speaker C: And so if you want to talk about those, happy to jump into that. We have the Textile Hub, which offers hosted APIs for pushing threads and buckets and things like that to IPFS for persistence. So if you have questions there, happy to talk about that. And then that brings me to the last kind of piece of the offering, which is we have a future version of the hub that we're giving everybody at Hackfs access to early, which is purely experimental, beta stage connected to a power Gate. So you can push buckets to this experimental hub, do everything you would do on the normal hub, but also be able to store those buckets on filecoin and get deal information about those buckets being stored. And we'll add more features over time to that. So that kind of opens up everything.
00:03:29.550 - 00:04:24.266, Speaker C: Just one note about the hosted Powergate. We're in kind of the warm up stage for that, getting a node connected to the testnet and testing everything out. It looks like everything's green lights this morning. So I'll be sending emails to people that signed up with details to help you get connected to that this weekend if you're going to be working. And then for the alternative Hub, this futuristic hub, we haven't shared the details to connect to that yet, but we will be sharing those either later today or early tomorrow morning. So basically everything that you do with the Hub CLI or the Hub JavaScript libraries, buckets or threads, you'll be able to do against this future beta version by just changing an API endpoint. And so you can already start using the existing APIs and Hubs and then convert over to this once we give you those details.
00:04:24.266 - 00:04:56.794, Speaker C: There's a bunch of strong warnings with that one. Just because it is very beta and it is running on testnet that don't do anything that you need for production, don't store any sensitive data, important data, data that's not yours, data that's illegal. Let's just have fun with it. And same thing with the hosted Power Gate instances. Let's have fun with those. If we find people not having fun with them, then we'll just have to lock it down more and be specific about who we're working with on those things. So that all said, let's open it up to some questions.
00:04:56.794 - 00:05:30.630, Speaker C: I see one already from you, from karate about design. Oh, and then I see one about is allowed to talk. Totally allowed to talk. This is in a presentation mode. I was just kind of giving the lay the land so we all knew where we could jump in. But about the design patterns, do you want to say something more about that? Karate, you're muted. You can't unmute.
00:05:32.010 - 00:06:00.154, Speaker D: Yeah, you definitely don't want to give me the power to unmute decision. You guys all know me now, so I really appreciate you having me default mute. Yeah, seriously, Mike, my series of ex girlfriends can vouch for that. They would love to have that. I'm going to type in there what I put. I'm not expecting you to answer all these, but I typed them up so I could paste it and make it easy. But I have workflows, user workflows for the app and I'm also happy to contribute to your docs if you want me to write a blog.
00:06:00.154 - 00:06:30.102, Speaker D: If you guys, whatever, I'm happy to contribute. But these are the common things I'm running into. I made some questions around business continuity planning, how we're going to host this in the long run. Not because I love decentralization, right? But we're going to need to have aggregators. So we need to know how I'm backing this up and how I can support my users. So I'm sure when I deploy this app that this platform I'm deploying that I can support it. Then the next one was I have a whole bunch of user sign up workflows, right? Most of them are pretty basic right now, which is click the link, user puts their address into my react app.
00:06:30.102 - 00:07:05.246, Speaker D: They get the link from Hub, right? And then they basically click it. And then what happens if their machine gets wiped out? Their iPhone Android gets wiped out. Then the next one is grouping content by bucket by so that the encryption keys like you designed it so I could do my monthly, right? Each month I get a new bucket. And then when they pay, they get access to it, which is, as you know, my hack. And then the final thing is smart contract ethereum interaction. So I'm leaving this open for the next four weeks anytime anybody wants to talk to me about it, and I will be happy to write it up and publish it and make a pull request to your docs.
00:07:05.358 - 00:07:37.626, Speaker C: Yeah, super. So I can kind of answer two of those pretty quickly. And then two of them are obviously complicated and probably nuanced based on what you're imagining. So maybe we can just set up some time to chat through those specifically and then figure out your use case. Because a lot of this stuff is just early testing, so it'll be based on what do you need and then we can plan to build it too. Let's start with the number four. So, smart contract ethereum interaction.
00:07:37.626 - 00:08:29.150, Speaker C: We haven't done a lot there, but because all this stuff is based on IPFS, there's a lot of good documentation about how to use IPFS content, addresses, hashes in smart contracts. So anything that you do there should be compatible with the things that you're doing in textile, especially like bucket. IPNs addresses I think are pretty interesting and useful there so that you can point to dynamic data sets that are signed and have this address that you can reference in smart contracts. But you'll be kind of on the forefront there. So we'd love to know what you need there and what's tricky. And we can try to build documentation around it and then just share with other people how you're doing it, what solutions are. I know a ton of stuff is possible there, but yeah, you'll be kind of on the frontier.
00:08:29.150 - 00:09:06.246, Speaker C: So then number two, user sign ups and workflows. Yeah, that one's really interesting. So a lot of our documentation we built around just the on demand key pair, public private key pair that you create in the browser and your user can have. And then you hit the APIs with those identities. That's just because we're really identity agnostic. We haven't tried to solve any identity things. At Textile specifically, we say, like, whatever your app is using for an identity should just be able to use that against the APIs.
00:09:06.246 - 00:09:45.254, Speaker C: And so we have some basic examples of how to use, say, identities in, like, a three box profile. We're talking right now about trying to get a MetaMask. Basically, you could let somebody use their MetaMask public key, and you like, that one? Okay, cool. So there's just one little hang up there, I think, about basically our TypeScript. Types make it tricky, I think, but we'll try to solve that pretty quickly. Otherwise, that one should just work out of the box. So what you would do is I don't think that in MetaMask, it's, like, straightforward how to get the public key.
00:09:45.254 - 00:10:13.040, Speaker C: But I've seen that it's possible to get the public key just by kind of parsing one of the other outputs from one of the APIs. You get the public key, and then it already has a built in signing endpoint. And that's all you need to hit the user group key API or the API with the user group key. So you say, like, this is a new user with a new public key, and then you provide that with the signing challenge, and they should be good to go. Are you unmuted? No, we need karate back.
00:10:16.290 - 00:10:17.206, Speaker A: I muted.
00:10:17.338 - 00:10:33.846, Speaker D: I talked to myself, and I don't want you guys hearing me saying, yeah. And stuff like that. So do you guys work with Ethers? I saw your library. Does it work with ethers? So I could use Ethers in my React app to pull the address from the person's browsers. Does your library work with that?
00:10:33.948 - 00:11:07.354, Speaker C: Yeah, I started working on an example to do that, like, just two days ago, and that's where I learned about this type mismatch. And so I think I opened a ticket on one of our JS repos to fix it. So we'll look into doing that pretty quickly before the end of this hackathon. For sure. We're going to have an example of that, but hopefully pretty quickly of how to do that. So just stay tuned and I'll share it in our Slack channel for sure once we have a MetaMask example up there. So then the other two, the business continuity planning.
00:11:07.354 - 00:11:15.170, Speaker C: I'll just need to learn more about what you're thinking there and what you need from us documentation wise and everything, and we can build it for sure. Happy to work with you.
00:11:15.320 - 00:11:57.498, Speaker D: My user loses their phone or basically changes accounts or wants to give it to their girlfriend, boyfriend, dog cat, wants to be able to read the subscription. How do I manage and track those keys for them? Because that friction. I've lost like, everybody on here has lost wallets before. There's tokens lost in the world of crypto out there for every on this call and so I want to make it easier because I'm trying to onboard people onto the decentralized web and they don't understand. Man, it took me years to really get the so this is me signing and all that, so that I need to have a good story now for beta. Sure, I can throw something out and it could be this horrific experience we're all used to, but I'm not really completing the hackathon if that stays. I mean, not personally finishing, I'm missing the goal.
00:11:57.594 - 00:12:37.774, Speaker C: Yeah, okay, let's keep talking about that because I think there's some neat solutions out there that other teams are working on and so just figuring out how to pull them into the workflow should be cool. And then number three, we already have that at the developer level, the level you can invite other developers to buckets and even to threads and they'll have complete access to the ones you create at the developer level. But then users that you onboard with, the user group key, we don't have an.org level automation. And so it sounds like, yeah, that's what you want. And so let's just talk about that because I think that's a pretty common want. We just haven't gotten there.
00:12:37.774 - 00:13:37.410, Speaker C: So cool. Let's bring those two to continue conversation. So next one implementing a simple blogging platform. Yeah. So this one's just an app architecture question, and I don't have a good answer for you about I haven't architected blogs and posts and likes and follows with threads or actually any technology before. I think it should all be possible. But one thing that we could do there is if you have a sense of what that architecture already looks like in your head without threads, without IPFS, what are the connections and what are the kind of models that you need? We could easily kind of work through that and say what would be possible and what we could move to threads or buckets or other just pure IPFS or pure lip p to P to make that possible.
00:13:37.410 - 00:13:56.454, Speaker C: But it's hard because it's a pretty I mean, a content management system with a kind of social network on top that has likes and follows and personal feeds and things. It's pretty complicated. So any more information you can give us there, happy to dig in and help. Anything else to say about that one?
00:13:56.492 - 00:13:58.314, Speaker E: I can't can I add those?
00:13:58.432 - 00:13:59.900, Speaker C: Alex? Yeah, you're on.
00:14:01.870 - 00:15:11.786, Speaker E: So I implemented sort of social network protocol on substrate blockchain and destroy content on APFS, but all the structures on blockchain and the linkage on blockchain. So authorship, who created what blog and where the post was posted. And here is the comment for this post and here is the list of posts for this post. Everything is on chain, and I'm thinking about improving performance by maybe not linking posts and comments and likes on chain, but just having the blog registered on chain, who owns it and permissions, and then everything is until we have the need to save it on chain. So the question is how to okay, cool recreate the same structure but in threadsdb. So we need a way to follow a blog. Then we need to link post to a blog.
00:15:11.786 - 00:15:28.230, Speaker E: There should be link from post to blog and optionally to another parent post. In this way we will get three like structure of comments and then likes should be linked to posts and shares should be linked to post and to blog.
00:15:29.130 - 00:16:25.298, Speaker C: Okay, I have an idea for you at least to get started. The likes and the shares, those kind of like that derivative model, that's trickier, but as sort of like the first step. I could actually build that with buckets easier if I were you. So what I would do is something more like in the on chain piece, I would point to the IPNs address of the blog and that IPNs address could be the IPNs address of a bucket which is living in a thread. And so then the author of that blog can push new posts to that bucket and it will update automatically people who resolve that IPNs address. So I did an example of this. You could do it in threads as well, but you don't have to, you could just do pure buckets.
00:16:25.298 - 00:17:26.762, Speaker C: And so I did an example that has a data model kind of along the lines of what you could do and it's in our docs, it's this photo gallery example. And in order to give a user a kind of nice photo gallery publishing experience, they actually just write a JSON file to the root of their bucket that keeps an index of all the photos that they upload to the gallery. And so they have control of new photos they're adding to the bucket. But then they can publish the IPNs address of the bucket and the HTML page can just look at that index and selectively load photos. So you could imagine an alternative way where the blog, they just keep an index of their blog posts in the same bucket. They're putting the content of each blog post maybe that's just marked down or whatever. And then when somebody goes to look at it at the IPNs address, the HTML can render based on that index so that that HTML file could grab the time ordered ones.
00:17:26.762 - 00:18:13.130, Speaker C: I mean, you could be building when the author is writing a new blog post. They could be updating search indexes and all those sorts of common you see in Jekyll and Gatsby and Hugo kind of generate the content, put it in the bucket, update that index and then people can go look at it. And since buckets are user already authored by the user and owned by the user, that could be the verification step itself. So that could be a really interesting thing to look in into. If you go pure threads, you'd kind of be doing similar things but you wouldn't get some of the nice automated gateway rendering and things by having the buckets which are fundamentally the Unix FS folder structure.
00:18:14.270 - 00:18:47.400, Speaker E: Can I ask additional question to this? If we're thinking about lists, so like with follows and with likes they need similar structure. So there should be a map where the blog is a key and there is a list of followers and then post has another map. Post ID is a key and there is a list of uploads and then the same for download. So upload download could be the same thing but just true false. So what was the best way to handle this?
00:18:48.090 - 00:18:54.178, Speaker C: Something about yeah, go ahead, sorry, what's.
00:18:54.194 - 00:19:06.246, Speaker E: The best way to model this? Maps key is a blog ID or post ID and the value is list of followers or list of likes dislikes.
00:19:06.438 - 00:20:26.360, Speaker C: So every post that they put so if you do it with the bucket structure, you're thinking basically inside the bucket you might have a folder just like any kind of web folder architecture, you might have a folder that has all the posts in it. Well every post is going to be a leaf in your merkel tree so it will have its own IPFS address as well and that's immutable that will always be there and so that should be the ID for the map. What's really cool is then you can reference it on the blockchain as well. And so anytime that there's this social piece where people are saying I liked this post, to me that feels a little bit like that should be something on chain because that's going to handle kind of who has sort of the permission to be saying I did whatever or this is really my like. And so that could basically be they could have a hash that exists in some blog ID and they could say I liked this one and then you could just look at that map. Anytime somebody goes and they look at that blog post, they could also look at that current map and you could figure out all the people that have liked or followed or whatever that specific blog post.
00:20:27.290 - 00:21:26.920, Speaker E: Yeah, but it sounds a little bit not optimal because if you look at social networks there are more likes and comments rather than root posts. So in this way we will optimize just root posts. That is let's say 5% of all the content and like is put like on blockchain. It's quite expensive thing and I was hoping to make it less expensive by putting it to IPFS and I was thinking is it possible to think in this way? Like there is every person bucket or something and then he collects what he liked, what he disliked and then through some sort of hub or whatever, I still don't know, some third party just aggregates all the likes from all the users that this service can find for this post.
00:21:27.930 - 00:22:09.080, Speaker C: So that seems doable too. Yeah. So you'd have every user is emitting their own feed of likes. But I feel like, yeah, I mean, that would totally work, but then you just have this inverse scalability problem that every user needs to go look at every other user's feed of likes in order to figure out if the one post they're looking at has been liked by all the users. We don't have anything at Textile that makes that easy, that you could roll those all up, some sort of MapReduce at the network layer. I think it's a really interesting idea. I just don't have a good, easy solution for you.
00:22:10.250 - 00:22:40.480, Speaker E: It could be some sort of centralization in this way. But at the same time, as Carson presented recently, it could be a problem of end user application. So End User Application knows who are the users of this network, a blogging platform, and then he pulls all the data from them and then do MapReduce. And here you can see the whole likes on this post. Does it sound good?
00:22:41.650 - 00:22:51.300, Speaker C: Yeah. I mean, it seems like a good starting point, for sure. And then we'll probably have to see how it scales on the different angles of it.
00:22:53.030 - 00:22:53.780, Speaker E: Thanks.
00:22:57.110 - 00:23:01.720, Speaker C: Philip. Trent, I see you say Jay can go next.
00:23:02.730 - 00:23:08.570, Speaker A: Yeah, I was just trying to get an order going. Yeah, Jay, go ahead. I think you're unmuted.
00:23:11.550 - 00:23:13.820, Speaker B: Yeah. Are you hearing me?
00:23:14.270 - 00:23:15.130, Speaker A: Yep.
00:23:17.310 - 00:23:21.838, Speaker B: Hey, Andrew, I just have a sort of high level quick question, actually.
00:23:22.004 - 00:23:22.526, Speaker C: Cool.
00:23:22.628 - 00:24:09.370, Speaker B: So first I'm reading about, of course, Filecoin and IPFS, and I'm reading about Textile, and I'm reading about fleek. And I just noticed today that Truffle announced that they're going to be using Textile under the covers in what they do. And I'm just wondering, this is kind of like a stack emerging on top of IPFS, and I'm a little confused as to where an application developer would sit in that stack. Should I be looking at Truffle or should I be looking at Textile or IPFS? Can you just help me get a sort of understanding there?
00:24:09.520 - 00:25:09.760, Speaker C: Yeah, so obviously, I just know kind of what well, I know a lot of where IPFS fits and where Textile fits because we build entirely on top of IPFS. Truffle. I know probably about as much as you do, but let me kind of break that one off real quick, because I think that one's easy is basically Truffle. The only thing that they're doing with the Textile stack is they're using some pieces of the powergate to make it easy for people that are doing smart contract development and have been building on Ethereum and building DApps already can use some of the nice services and APIs that the powergate delivers. So I think it's like if you're an experienced sort of Ethereum DAP developer, you're probably going to go to Truffle because you've probably already been using it. And I think that's a great way to go. They don't have threads or Buckets or any of the IPFS abstractions that we've been building.
00:25:09.760 - 00:26:14.370, Speaker C: And so then that comes to textile, what we're building. So we think that we've been kind of thinking of what are some of the common patterns that developers need when they're building applications? And two really common ones are you need to synchronize data, whether that's metadata, application, state messages, all those kinds of information, the light information that usually you move around in a database. It gets tricky on IPFS, because the first thing you have to figure out is how to manage a lot of content addresses. So you're moving around a lot of addresses, and if you're adding encryption, you're moving around a lot of addresses and keys. And so threads sort of simplifies that and just gives you a useful API to not have to think so deeply about that. But under the hood, it's all IPFS, and so if you don't need it the way that we've kind of formulated that opinion, you should go right to IPFS. Oh, threads also bakes in some Lib P to P things to help with the communication between peers.
00:26:14.370 - 00:26:48.160, Speaker C: Lib P to P is an amazing library, so if you just want to have peers sending messages back and forth, that's obviously a place to go. You don't probably need full baked threads. When we built threads, we also realized that people quickly wanted to move around larger binary files or they wanted to attach things. Yeah. And so that's where we built Buckets. We were like, okay, there needs to be an easier way for people to create folders as they're used to them of files and have those synced to different nodes. And so that's what Buckets does.
00:26:51.250 - 00:27:18.354, Speaker B: I'm sorry. My application is maybe a little bit different because I hear you guys talk about the ability to change this data over time, but my data is frozen solid as a rock, and it never changes once it's created. So I think maybe some of your features are maybe not applicable to my data because it doesn't change quite so much. It doesn't change ever once it's created.
00:27:18.482 - 00:28:12.710, Speaker C: Yeah. Okay, so if you were using data that you never want to change in Buckets, the only feature that it has, the couple of features that are really nice for you, is that it's meant to help you push your data to remote nodes. So if you need to do persistence of that data, so, like, if that data is being created in the browser where that session might go away, but you want to push it to a remote node, that it's going to be persisted as the same thing with the same hashes. Buckets can help out there, but so can pinion services like Pinata. So if you want to go straight to IPFS and just create those hashes and push it to a service like Pinata, you can get the same thing. You're just not going to get that folder organization and Buckets also has the IPNs addresses out of the box and HTP addresses out of the box. So they're just kind of like nice, helpful features.
00:28:12.710 - 00:28:30.430, Speaker C: But if you don't need those things, then you can go straight to IPFS and you can get hashes for the files you're creating. You can push those hashes if you need to get them off device. You can push those hashes to other services as well. So, like, any pinning service like Pinata, I understand completely.
00:28:30.500 - 00:28:44.034, Speaker B: Thank you. One very quick question and I'll be done. Is there a JavaScript library for using your stuff? I imagine there must be, yes.
00:28:44.232 - 00:28:45.090, Speaker C: Totally.
00:28:46.170 - 00:28:52.022, Speaker B: Pretty straightforward how to use it. It's basically put get and list or something like that.
00:28:52.156 - 00:28:54.280, Speaker C: Yeah, push, pull, and list. Yeah, exactly.
00:28:55.210 - 00:28:59.418, Speaker B: I got you. All right, thanks. I have to get off the call, but thank you so much.
00:28:59.504 - 00:29:02.490, Speaker C: Yeah, absolutely. Who's next? Trent.
00:29:06.030 - 00:29:08.300, Speaker A: I don't think anybody else has raised their hand.
00:29:09.150 - 00:29:11.274, Speaker C: I see. Phil, questions.
00:29:11.392 - 00:29:40.520, Speaker A: Okay, so just for reference, if I have ever suggested people raise their hand, there's a little thing underneath the participant tab. It's not immediately obvious, and it might be different for non hosts, but it should be somewhere in that area. And you can raise your hand through that? Yeah, in previous sessions, we've had people literally waving, but when I say raise hand, that's kind of what I meant. Oh, wait, Phil. Phil, was that you? Okay, there we go.
00:29:42.650 - 00:30:18.420, Speaker F: Hi. I'm trying to build a lyric sharing application. And so the idea is that users connect, they see the same lyrics at the same time. You'd have a controller. There's essentially three sort of different apps. One would be a database for storing lyrics in which could be shared between a group of people who can edit it. Another one would be a controller application, which is a group of people who could decide which song is shown next and which verse of that song is shown next, and then a consumer application which only just shows, like, the verse which a song is on at the same time.
00:30:18.420 - 00:31:17.000, Speaker F: I've been sort of playing around with Lib, P to P and IPFS building it, just rolling my own pub sub stuff with it. And so I think I'm doing okay on that, though. The nice thing that I'd see within Textile is the ability to get the as soon as somebody logs on, they could get the current verse without having to get the pub sub message. I've got a bunch of questions around basically how Textile is doing things. So am I right in thinking textile's database is a log of data, basically, and when somebody the database is based on a log, so when somebody comes in, it reduces that log to get the current state. So they essentially have to get all previous messages to get to the current state. Is that right or is that not right?
00:31:17.770 - 00:31:37.820, Speaker C: Yeah, there's some minor details there that. Are slightly different just because it sounds like you're interested in the deep down. The way that threads work is every peer actually is its own log. So every peer is a single writer log. And then that reduced step pulls all the logs from all the peers to bring up the latest state.
00:31:38.190 - 00:31:44.906, Speaker F: If a song consumer was getting that, they'd then have to pull in the whole history. They wouldn't just get the current song current verse.
00:31:45.018 - 00:31:57.090, Speaker C: Yeah, we have some work outstanding to do snapshotting. And so that's one of the coming features where a peer would be able to jump in and just pull the latest snapshot to just ramp right to the newest.
00:31:57.590 - 00:32:19.046, Speaker F: And could I get a feel for sort of what the latency is? It's probably the wrong word using Textile versus doing raw P to P, lib P to P stuff. I'm kind of looking for about a second of delay. It needs to be less than a second, basically. Probably about half a second.
00:32:19.228 - 00:32:31.050, Speaker C: Well, yeah, I think lib p to p, probably. I mean, depends what you need exactly. Lib P to P is what threads use behind the scenes.
00:32:31.390 - 00:32:35.086, Speaker F: Is there much overhead on top of that? Threads is adding to lib P to.
00:32:35.108 - 00:32:53.554, Speaker C: P. Well, the biggest overhead might be the encryption step. So like, everything over threads is going to be encrypted. So you're going to have the speed of encrypting in and speed of encrypting out. So that could cause some latency if you're using threads with the hub. I see your question. First question too.
00:32:53.554 - 00:33:11.938, Speaker C: Can I use threadstv without the hub? You totally can. You can use the Go implementation to run your own daemons. You can connect other Go instances to daemons, have them run their own embedded. The JavaScript version, it runs best against you can host daemons.
00:33:12.034 - 00:33:21.260, Speaker F: So there's an embedded one I could run in the browser because I'm wanting most of the application to run in a browser on a phone and really not have hosting services or things like that.
00:33:21.950 - 00:33:55.234, Speaker C: So we've been implementing it in phases with Go being the first and most complete. So everything is possible in the Go side. With the JavaScript side, we've split it into two parts. There's the database and then there's the networking side. And for most networking in the JavaScript library, it pushes that to a remote node. The reason that is is because expecting peers to be able to connect and find each other and stay persistent in the browser is really tricky. And so what we said is like, let's not tackle that right away in our implementation.
00:33:55.234 - 00:34:06.854, Speaker C: Instead, connect to other nodes and ask them to do networking for the browser. And so for that, you can use a godaemon, you can use the hub, and then we'll be backfilling that as we go and adding more and more of the networking directly.
00:34:06.902 - 00:34:17.678, Speaker F: So if I were using Textile for the viewing songs, part of it it would all be routed via central via servers, basically.
00:34:17.844 - 00:34:21.146, Speaker C: Yeah, but I don't know how rather than WebRTC.
00:34:21.338 - 00:34:32.290, Speaker F: Yeah, I don't mean centralized, it's more like there's going to be a cost in it if I'm using somebody's servers or I'm going to have to host something myself, I'm really trying to do something that I can scale at absolutely zero.
00:34:32.360 - 00:34:57.914, Speaker C: Totally. Yeah. No, so I think that's true, but I think there might be networking already. Some networking already in the JavaScript library. Carson hasn't joined the call yet, but let's come back to that question and ask in a little while what the state of the networking is in the browser, because you might be able to get away with some of it. I know that he was planning to put the Lip P to push based. Okay, let me actually explain this really quick because it's pretty nice.
00:34:57.914 - 00:35:40.006, Speaker C: So in threads, one of the things when we were experimenting, building apps in IPFS and using Lip P to P, one of the things that we found with a database that's really important is you want peers to be able to not only have to push and this is what you mentioned before. Like, you come online and you have to wait for somebody to push the state to you. That's great. But it's really hard in mobile networks and in browser networks where peers are ephemeral and coming on and off a lot. So what you actually want is you want peers to be able to also pull. And so with threads, every peer also becomes a pull endpoint, but you can also designate remote nodes to be that pull endpoint. That's one of the things here.
00:35:40.006 - 00:36:00.798, Speaker C: And so with the network inside of JavaScript, I think it might already have the push based built in, so it would already do what you're doing, which is other peers can push their updates to other peers they know about, but it doesn't have the pull because that's tricky in browser still. And so we're kind of solving that one, but I might be misspeaking, so let's revisit that one when Carson comes back online.
00:36:00.884 - 00:36:39.980, Speaker F: And so I'm thinking where textile might fit most for me is in the song database. And I'm wondering if that would lean most towards being buckets or towards being thread DB. And the kind of thing I want here is I want a pool of people to be able to edit a group of songs. And that database should essentially be private between that group of people. You can have some people who can read it and edit it, others who can just read it, and then the general public who can't see it at all.
00:36:41.170 - 00:37:28.602, Speaker C: So that's exactly what we're building in threads. But that's another piece that is sort of a more complete ACL, which has those different roles, and we haven't been able to implement that yet. It's this piece that we keep backlogging and keep backlogging for other features every sprint it comes up that it will be the sprint, we do it and then we don't get around to it. So it's coming soon to be able to have read, write, just read private. But so right now buckets can get you two of those really easily, which are you can have the people that are able to read and write the buckets and then you have the people that can just read it. So if you publish it and it's open, you could publish the IPNs address, for example.
00:37:28.656 - 00:37:43.594, Speaker F: So presumably if you encrypt the data that you're writing, then that gives you if you just encrypt each piece, then you can have some key which is only known to the totally read write totally.
00:37:43.642 - 00:38:03.798, Speaker C: But so one of the things, once we implement ACLs in threads, that will also trickle into buckets because they run on threads and so you'll actually be able to have buckets that are encrypted, but you can actually provide read endpoints for those buckets for the public. But that's coming. Yeah.
00:38:03.964 - 00:38:22.906, Speaker F: And your trajectory is towards something that could just run in the browser in the future and there's no dependency on yeah. With the API key thing, is that centralized completely?
00:38:23.008 - 00:38:28.110, Speaker C: The API key for the Hub. Yeah, the Hub is a centralized yeah, yeah.
00:38:28.180 - 00:38:33.466, Speaker F: And I can't do anything without Hub, really. Or I can use threaddb without Hub.
00:38:33.498 - 00:39:16.106, Speaker C: Can't yeah. So our goal is to make all of this this is probably just useful to restate for the people here. Our goal is to make all this very open, very interoperable, very run it yourself. But a couple of things I kind of think strongly that services like the Hub aren't going to go away, but the lock in behind them, your motivations to use them, who's paying for them, those will change. And so we really want to build the Hub as a resource to help applications be able to onboard to these things quickly without, say, having to force all application users to have to run their own IPFS nodes. That's a really good example. We did a lot of mobile development where maybe that's tricky.
00:39:16.106 - 00:40:08.510, Speaker C: You don't want to have an IPFS node that has to do the full networking and all that, but you just want to push that to remote services. So the Hub is a good resource there. But we have open protocols like threads that are built on IPFS and lip P to P. And the idea is that other services should be able to implement those things too, or you should be able to stand up your own services to do those. At the same time, we want to backfill a lot of these protocols so that they can run in a more and more decentralized way as we move forward. But if we try to engineer them in the purely decentralized way, right away they're going to be broken and we're going to have a very hard time getting apps to actually implement them. And what we want are we want all the web two apps in the world to come build on this stuff, right? We want everybody to say, oh, actually giving users control of their data using encryption, having open protocols, those are all really good things we want in our app, but we want them to be performant and work today.
00:40:08.510 - 00:40:16.420, Speaker C: So we're starting with getting things performant and working, building on the right sort of mission and vision and ideas that we can spread it out more.
00:40:18.150 - 00:40:23.730, Speaker F: And if I've got questions, if I'm building stuff out, is there a good person I can contact during the hackathon?
00:40:24.470 - 00:40:25.282, Speaker C: Yeah, we're all there.
00:40:25.336 - 00:40:29.574, Speaker F: Link and what's the best channel to reach you? Is it the Slack or the yeah.
00:40:29.612 - 00:40:44.362, Speaker C: The Slack support textile team is awesome place. All of us are there listening. The team is Ignacio, Sander, Aaron and Carson and myself. And we're all there all the time. So, yeah, just ask away.
00:40:44.496 - 00:40:45.500, Speaker F: Thanks a lot.
00:40:48.270 - 00:40:56.190, Speaker C: So, just a quick note. Trent said to raise your hand using if you go to participants and click raise your hand, you can get next.
00:40:56.340 - 00:41:22.934, Speaker A: Austin yeah, I mean, it's mostly useful for when you have a ton of people, and it's just a way to kind of sort out who's going to talk next. But with a group this small, shouldn't be an issue. Austin go ahead. Looks like you're unmuted, but we still can't hear you. It might be a permissions thing for audio. Good.
00:41:23.052 - 00:41:23.670, Speaker G: Better.
00:41:23.820 - 00:41:24.966, Speaker A: There you go.
00:41:25.148 - 00:41:25.974, Speaker C: Okay.
00:41:26.172 - 00:41:52.080, Speaker H: Yeah, I wrote up big part, but I think most of it was answered there. As far as what's going to be available just in the browser without having anything installed. The key feature I'm curious about whether or not it'll ever be doable in the browser is large scale encrypting of buckets. Because if you have, like, a folder with even just a few movies of a few hundred megabytes each, will a browser be capable of encrypting a bucket of that size?
00:41:53.330 - 00:42:25.866, Speaker C: It's a really good question. One thing that I'm not probably the right person to answer this, I'm guessing. Don't know if I've seen Sander pop in here. So there's a really good thread. Let me reshare it, actually. Just ask your question in the sponsor channel, and I'm sure Sandra will jump in and get you some thoughts there. We were talking about that recently, but not browser specific, but how you would handle, say, like, large scale encryption of a video.
00:42:25.866 - 00:43:02.396, Speaker C: And one thing that we want to do is add, like, streaming bucket support. And I think some things like that could help within the browser. You'd just be having to encrypt smaller chunks of it at a time. But I'm not sure. I'm just not the expert to answer that one. Do you need to get unmuted again? Austin yeah. Trent can we unmute him? Yeah.
00:43:02.498 - 00:43:47.064, Speaker H: Thank you. And then the other part, because I'm going to be encrypting the buckets. I'm trying to decide between your guys'hub tool and then the space daemon from Fleek as to which one to use. They seem to have a very well defined API. And then I think your command is the Hub Buck init key and then there'd be further things to do on that when the basically which one do you think is the most well developed as far as like single access tools for just defining this as which is the cleanest API to use? And I know that you work for Textile and all of I mean, we.
00:43:47.102 - 00:44:35.880, Speaker C: Work really closely with Fleek. So you're talking about their space tool that they've been talking about. Yeah. So I think the biggest difference there is that space is intended to work locally. So if you want to build a desktop app or you want to build a system that people can install on their computer, the space node essentially will give you access to buckets and things directly. We've been talking with them too, so that when you do that, you could give it a flag that would let the user push those updates to the Hub, for example, for archiving and persistence as well. I don't know the status of their development there, but if you want to build browser applications or even if you just want to use the Buck instance itself, you should definitely just use Textile.
00:44:35.880 - 00:44:45.790, Speaker C: So it's just kind of depends on what you're building and where your app should be installed and things like that. Cool.
00:44:52.160 - 00:45:14.356, Speaker A: Anybody else can also just have open discussion. It doesn't have to be a specific technical question. Andrew, I know you said you were expecting other team members to join. Do you know if they're still going to join or they may not.
00:45:14.378 - 00:45:26.550, Speaker C: The reason they weren't joining is because they were on another call, so I'm guessing they're just still chatting away over there. I see Aaron's here. Aaron is one of our powergate experts. Any powergate questions in here?
00:45:39.760 - 00:46:35.570, Speaker H: Yeah, actually, it's not so much a question, but it was a thought I had while I think it was Phil was talking about making this as scalable as possible with zero cost and my hack being similar to karate's, where check for something on ethereum for a purchase and then share an encrypted bucket with the key after the check succeeds. But then that all depends on whether or not the Hub is there or other users. So on the topic of powergate, once you push something to filecoin that way, that might be the best way to do it because then it's there. It's behind a bit of a paywall because then you need to do the retrieval cost, but at least it's there. And then if you want another further layer, I don't think it's doable yet, but it could be another whole hack project as a crowd store or store together. That way you would have a contract where all of the users pull money together to maintain that one bucket or whatever on Filecoin or through Powergate at all times. But I think a couple more layers need to be developed for that.
00:46:36.100 - 00:47:12.364, Speaker C: Yeah, that's awesome, actually. So that's related to this future Hub version that we're sharing with you all. I don't know if everybody caught that idea, but you can take buckets and you can push them to new deals on the testnet. Once you do that, you can take the deal away from the Hub, you can take all that information away and you're not locked into the Hub at all. Like you said, there's some cost to go retrieve it from the Filecoin network, but it's yours. There's nothing we can do ever that would stop you from getting that data back. So that's really cool.
00:47:12.364 - 00:47:54.328, Speaker C: And so that will be the Buck Archive commands. So you can do that through the CLI, you can do that through the JavaScript library. So you can build this, create buckets for users or do that as a developer, push them to the Hub, call this archive command and get the Filecoin information back. I see a question here from Karate. Are you going to offer hosted Powergate as a service long term? We're not sure yet. We're definitely doing it in the near term. So throughout the rest of testnet, we're going to be spinning up Powergate instances for teams and offering help.
00:47:54.328 - 00:48:38.520, Speaker C: The idea there is to work with you all that are part of the hackathon, as well as teams that have received grants from Filecoin already that sort of have the momentum and will to actually build interesting things on Powergate. And we just want to help get more people onboarded to the ecosystem and try things out. And if some teams just don't have the resources to stand up nodes on Filecoin yet and maintain syncing and that's something that we do all the time on our team now. And so we're going to offer hosted powergate just to help those teams get APIs and start building faster. But long term plans? We're not sure yet. We'll probably use that as a test to see how well it goes and see what kind of demand it drives and see what's oh, and I see. Carson.
00:48:39.340 - 00:48:42.792, Speaker G: Hi everybody. Double booked myself this morning.
00:48:42.846 - 00:48:52.460, Speaker C: But Carson, I already have a question for you. It was from before because I wasn't sure. The current state of networking in JavaScript threads.
00:48:53.440 - 00:48:57.000, Speaker G: The current state of networking in JavaScript threads?
00:48:57.080 - 00:49:01.920, Speaker C: Yeah, the thoughts behind doing any lib P to P push based networking in threads.
00:49:02.420 - 00:50:09.408, Speaker G: Yeah, we really want to get to that. There's a couple of things that have to happen in order to do that. And I think what we're going to do is roll out a sort of like staged upgrade of that. So to get a full blown pure JavaScript threads daemon essentially is like quite a lot of work because threads supports both push and pull. And pulling from a browser peer to another browser peer is effectively like you'd have to run a server in the browser, which is not a thing that happens. So we have to come up with ways to essentially proxy those polls. But what we're going to start with is basically like a pub sub based layer that then will allow us to still do pushes and pulls through remote network and then we'll start to upgrade to full IPFS or full Lib PDP based pushes and pulls.
00:50:09.408 - 00:50:28.888, Speaker G: But it'll take a little bit of effort and then at that stage you'd have like browser to browser pushes and pulls, which is pretty magical. And we have prototypes for that working now and it's just a matter of kind of rolling it out in a sustainable and scalable way. Cool.
00:50:28.974 - 00:50:30.670, Speaker C: Okay, thank you very much.
00:50:32.800 - 00:51:35.360, Speaker I: This is Jay, I've got a question. So our team is running me in AWS and we're also running Hub in AWS and I've got Hub running on a Raspberry Pi. I'm trying to get Powergate running on a Raspberry Pi and I'm having some trouble with probably the Go path, but I'm not up to speed enough on GOPATH to really troubleshoot it at this point without probably some time. So anyway, I just wanted to throw it out there that we're building a lot of things on Raspberry Pi and if people see someone else who's running Powergate on Raspberry Pi, if they could connect them with me, I would really appreciate that. Or throw it into the chat session, some sort of link to posts and so forth, tutorials that would be most helpful.
00:51:38.420 - 00:51:41.184, Speaker G: That's magical. That's crazy.
00:51:41.382 - 00:51:42.130, Speaker A: Yeah.
00:51:43.080 - 00:52:07.690, Speaker I: I'm also interested in anything else that can be stood up on a Raspberry Pi. Like somebody posted that they connected a Terabyte drive to a Raspberry Pi and they're supposedly mining filecoin, but I thought it took like 128 gig of Ram to run to mine filecoin, but anything like that is really of interest to our team.
00:52:09.660 - 00:52:31.424, Speaker C: Yeah, super cool. I think that's really interesting. I can't wait to see how you do it. We'd love to add any of the instructions for successfully running stuff on Raspberry Pi to Docs or at least link to it. If you have write ups on that stuff, that would be awesome. So I think that's really cool. I see a question here.
00:52:31.424 - 00:53:02.620, Speaker C: Can we push custom objects to buckets? I've only seen images into buckets in workshops and documentation. That's just because images are cool. But no, the documentation has an example where we push images in folders, but we're also pushing JSON files that track metadata about those images. It can push anything, they're just Unix FS file folder structures. So anything that you save on your desktop you should be able to push to buckets.
00:53:05.040 - 00:53:19.052, Speaker G: But also Aaron just posted something in the chat there which is very relevant, which know it's totally fine to mix data types in a thread bucket as well. So you might have binary stuff in a bucket and structured data in threaddb.
00:53:19.116 - 00:53:19.730, Speaker A: And.
00:53:21.940 - 00:53:31.590, Speaker G: All that cool stuff. The neat thing about buckets is that it's also on a thread. So it's really easy to mix data structures and types in a thread like that.
00:53:42.380 - 00:53:54.590, Speaker C: Thanks Karate, nice seeing you as always. That was just goodbye to him. We don't have to leave. He said goodbye on the more I see Alex is raising a hand.
00:53:54.960 - 00:54:24.260, Speaker E: I was thinking about this post and we can use seed of a post file for postbody identification, but I think it's not optimal because then we cannot have updates and if you need to change char then everything will broke. So what if we have a folder for each post and there could be something like body and images, arbitrary number of images.
00:54:27.080 - 00:54:42.856, Speaker C: Just a quick clarification there already. Yeah, you don't have to do the hash of the post directly. You could actually do the path address under the IPNs address itself. And since it's IPNs, the content that is in that path could be changed by the owner.
00:54:43.048 - 00:54:50.060, Speaker E: So post could be just one, two, three and just increment number within that folder.
00:54:52.260 - 00:54:55.056, Speaker C: Yeah, I think a model would work like that.
00:54:55.238 - 00:54:59.760, Speaker E: For example, you can have a subfolder in post folder.
00:55:03.000 - 00:55:05.764, Speaker C: Yeah, I think that would work. Yeah, for sure.
00:55:05.962 - 00:55:13.590, Speaker E: And what about resolution time of IPNs? I heard that it's quite slow. How long is it?
00:55:15.340 - 00:55:51.744, Speaker C: I've been seeing something for any examples that I've been doing, I haven't seen more than 20 seconds or so, but I have heard worse. I think a lot of that improved quite a lot with the zero point 50 release and beyond in IPFS. So just a quick FYI. I have to jump off here in two minutes. If people want to stick around, maybe carson, could you take over and just follow up? Just answer any more questions?
00:55:51.942 - 00:55:53.796, Speaker G: Yep, I can hang around for a little bit here.
00:55:53.898 - 00:55:59.670, Speaker C: Super. Or I don't know if to we need to stop here.
00:56:01.240 - 00:56:05.604, Speaker A: We've got a little bit of buffer after this. If people still have questions, we keep going.
00:56:05.802 - 00:56:10.008, Speaker C: Alex, I don't know if you wanted to keep asking though, I didn't mean to cut you off.
00:56:10.094 - 00:56:36.620, Speaker E: I would like to ask one more question about threadsdb. Sorry, I still don't very big expert in this, but threadsdb is it running on every user's side? So every user has its own threads DB. If we're talking about the dub that uses threads DB, what is the architecture here? For example, we have 1000 users, 1000 threads DBS.
00:56:37.840 - 00:57:28.496, Speaker G: Yeah, it depends on how you want to architect your app and what they're using threads DB for. So you can use local first offline, first thread database, which is the database like import database from threads. And effectively what they have is like a local database that's like in their browser cache. Or if it's a node app. It's on disk and any reads and writes are happening local first and then flushed to the network. And so in that case, you basically have like N replicas of that database. And that's how that would work.
00:57:28.496 - 00:58:25.920, Speaker G: Alternatively, you could use the Hub, Textile Hub to create a developer account. And then in that situation, instead of having N replicas, you basically have one replica on the Hub scoped to different users. So it really depends on sort of what you're using it for and how you're using it. And the Hub is designed to be pretty flexible, so you could have N databases scoped to each one database per user effectively. Or it also supports like a multi writer scenario or sorry, like multitenant scenario. So single writer multi users in that situation, that might be an app where you've got like public comments. So you'd have a single database with a comment collection and you might have multiple users, but they're all effectively being written.
00:58:25.920 - 00:59:01.490, Speaker G: They're proxying their rights through a single developer user. So it really depends. It's designed to be pretty flexible and to match actual database use patterns that different developers have. So the answer is it depends. Which is an annoying answer, I know, but it depends on how you want to structure your application. One of the coolest things I think about decentralized tech is when you start to get the N replicas scenarios, which is pretty powerful, but it depends what's realistic for your app.
00:59:05.700 - 00:59:16.980, Speaker E: There are issues with concurrency. If you're using this central bucket of SDB and people are starting to write comments.
00:59:19.400 - 01:00:34.236, Speaker G: You can run into, well, so we do have support for different types of conflict resolution. If you're using the Hub, we have like a default codec that is used to manage concurrent writes and it uses basically like an arbitrary but deterministic ordering for updates. But in that scenario, you could have multiple users mutating the same object. So the application would have to be like any database, the application has to be designed to avoid writing to the same object at the same time. But if you have the sort of like single writer multiple database scenario, then that concurrency issue kind of is handled because you can take advantage of the codec to actually do the conflict resolution. So again, if you use a centralized database, you're using a centralized database and so you've got to deal with that. And if you're using end databases, then you have end databases that can sync and then you have to deal with that.
01:00:34.236 - 01:00:51.730, Speaker G: So it depends on what end of the spectrum do you want to deal with things? Do you want immediate write or do you want eventual consistency? It depends on your application and what works best.
01:00:53.540 - 01:01:04.150, Speaker E: By databases and synchronization. You mean if you have 1000 users, then 1000 databases. And there is one instance that synchronize as a state between all of them.
01:01:06.120 - 01:01:30.350, Speaker G: If you set it up. So that you have a single thread that end users are writing to, then those end users will be eventually consistent and they will sync yes, depending on network connections and things like that. It could take some time for them to all sync to the same state, but eventually they should sync to the same state.
01:01:35.460 - 01:02:13.196, Speaker E: Is there an example of how to for example, every user has its own database and she modifies something and is there an example on how to send notification to some arbitrary service that I modified on my side? This and please pull this data and aggregate it on your side in order to implement something like MapReduce service for every user service that aggregates data from all the users databases by notifying when every user notifies that I made this change. I made this change.
01:02:13.378 - 01:03:35.200, Speaker G: Well, the way you might do that is that whatever you want, the service that you want to do the MapReduce would itself be a peer in that network. And so when that peer syncs because all the peers like if they're sharing and they are like known peers, they will notify each other when an update happens. So you could just have that reducer peer, let's call it that, be a known peer in the network. And then when any other peer makes an edit, they will push their edit over to that peer. And then we have some notification APIs so that as soon as an update from the network layer is detected, it's pushed, then you could kick off that MapReduce, step on that particular peer and you can also set it up so that that peer basically also pulls. So that if you don't want to rely on pushes, you can also pull from known peers. So a common scenario for that would be like you might have a set of peers that are all writing environmental data to a given thread and then you have one peer that's actually responsible for aggregating those results.
01:03:35.200 - 01:04:00.350, Speaker G: That peer would be an additional peer in that network and then on every update that peer may kick off some particular job that could be a MapReduce step or something like that. But just to be clear, all the peers are synchronizing the full database state. So like queries and things like that are not fully distributed. The queries are based on what the peer knows about.
01:04:01.780 - 01:04:17.220, Speaker E: So you're saying if, for example, every user has, let's say, 1GB of data on each site, then this MapReduce will synchronize all these gigabytes even if one byte changed?
01:04:18.760 - 01:04:46.110, Speaker G: Well, no, the peers will only notify the well, I mean, I don't know, it depends on how you set it up. But the peers only notify each other of changes and only diffs get sent across. So the diffs would be applied locally. So it's very small. Like the updates tend to be fairly small. Sorry, when I say the full state, I mean they're just like arriving at the. Same full state locally, but they're not transmitting the full state.
01:04:48.400 - 01:04:56.928, Speaker E: Okay, so better to look at something like this. Say that again, is there an example of something like this?
01:04:57.094 - 01:05:25.400, Speaker G: We don't have an example of that particular scenario of a single MapReduce situation like that, but we do have some great tests in our Go implementation that shows like, spinning up multiple peers and synchronizing across those peers. Are you more of a Go person or a JavaScript?
01:05:25.900 - 01:05:27.290, Speaker E: JavaScript trust?
01:05:28.540 - 01:05:50.160, Speaker G: Okay, yeah, we don't have a specific canned example of something like that, but probably for spinning a test of N peers synchronizing. I can point you to the Go examples.
01:05:50.980 - 01:05:53.090, Speaker E: Not possible in JavaScript yet.
01:05:53.940 - 01:05:56.788, Speaker G: Well, it is possible, I just don't have any examples of that.
01:05:56.954 - 01:06:06.052, Speaker E: Maybe you just point me to set of methods so API endpoints so then I can assemble it on my side.
01:06:06.186 - 01:06:55.992, Speaker G: Yeah, so the best place to go there is just well, our docs honestly have been updated pretty recently, so docs textile IO. And then if you go down to like on the left hand side there's building an app. I think there's a pretty good getting started framework. But then if you want to dig into the repos, the JavaScript repos, then it's GitHub.com. Oh, hold on, I'll just type it in here. JS threads is the place to go. And just for reference, there's the Go threads one.
01:06:55.992 - 01:07:23.900, Speaker G: So Go is always our reference implementation and then JavaScript is ahead on some things and behind on some things, but in general the reference implementation is Go and the JavaScript implementation is the nicer API. I mean, that's coming from someone who likes to write JavaScript.
01:07:27.060 - 01:07:30.320, Speaker E: Do you have any plans on Flutter integration?
01:07:30.900 - 01:08:18.610, Speaker G: We do get that question a fair bit and the answer is we would love to, but we just don't really have the human resources to devote any time to that right now. But if it's something that you're interested in, I would love to see a ticket or something like that in either Go or the JS threads repos that would help us to prioritize that kind of work. So that's the real answer to that question and I want to highlight that. Anyone else? I mean, I'm happy to keep taking Alex's questions here, but also if anyone else has questions, don't be shy. These are good questions.
01:08:26.840 - 01:08:28.100, Speaker A: Don't be shy.
01:08:29.640 - 01:08:31.060, Speaker G: Any other ones, Alex?
01:08:31.480 - 01:09:04.000, Speaker E: I can continue. So are there any examples of real or almost real world applications? You have just a couple of examples in that folder and that's it. Maybe, I don't know, something like audios or something like what? There is audios or this sort of I don't remember exactly the name for sharing audio files with IPFS and Ethereum.
01:09:04.740 - 01:09:54.210, Speaker G: Oh, I don't have an example like that. I mean, we have examples of non blockchain apps. So like if you're familiar with any type, which is a sort of like notion type framework tool that's built on threads. DB Fleeks product launch just recently. Spaces is built on threads. And do I know there are some examples of other teams like Sapien is building things with threads that's like a blockchain rating framework. I think that's more of a bitcoin thing, though.
01:09:54.210 - 01:10:25.880, Speaker G: And sorry, there's people in the background here and I don't know, I'm blanking on other examples off the top of my head, but in the Ethereum space I'm not well, I'll try to come up with a list. We should have a list, but I'm just blanking right now off the top of my head.
01:10:25.950 - 01:10:39.496, Speaker E: Yeah, it would help to have this list. I mean, not just Ethereum, just something that is working and we can click, we can understand that it works, and then it's easier to see how it's implemented in sources.
01:10:39.688 - 01:11:07.800, Speaker G: Right. The other one of our own products that is a useful one to look at is Buckets, which is implemented on threads. So you could see one like how we think you might want to architect an application. So that's GitHub.com textileiotextile. That's our hub buckets implementation. So that's an application that was built on top of threads.
01:11:14.620 - 01:11:31.170, Speaker A: I think we may have surfaced all the questions that people have for this session. Go ahead. There is hand from Phil Holden in oh, sorry. I thought we had enabled the unmute function.
01:11:32.500 - 01:11:56.570, Speaker F: Yeah, so I just wanted to find out what happened. So for user creation and group creation and things, is that always free, basically. And where are the users kind of stored? So if Textile disappears, do our apps keep running or do they stop running?
01:11:57.980 - 01:12:22.576, Speaker G: Great question. So Textile everything textile build is designed to assume textile will one day not exist. And I think that's kind of everybody's goal in this space. Right. So we have a pretty agnostic identity, agnostic treatment of as and it depends on what you're doing. Right.
01:12:22.598 - 01:12:35.116, Speaker F: So if you're thinking about the API keys here that I'm generating, basically so when I'm using the CLI and I'm getting group keys and these things, that stuff is used in the output that's.
01:12:35.148 - 01:12:38.336, Speaker G: To use the Textiles Hub infrastructure.
01:12:38.448 - 01:12:38.724, Speaker C: Yeah.
01:12:38.762 - 01:12:48.090, Speaker G: So it's like if you want to use the Hub, then we need some way to track usage and all that stuff. So that's how you are.
01:12:49.980 - 01:13:08.430, Speaker F: Think about here is like if I've got my decentralized app and my users are trying to create groups and things like that for themselves to communicate with each other, are they somehow having to interface with the Hub in order to create these groups? Is that how they do that?
01:13:10.240 - 01:13:39.144, Speaker G: If you want them to use the Hub, which is basically like you're always on cloud based infrastructure, then they'll have to go through the Hub. But everything that runs on the Hub also runs, like on a desktop or on your own threads. Damon, if you're the developer and so if you would rather your users use like a local oh, no, I think I lost you. I hope I didn't. Are you still there? Oh, good. Okay.
01:13:39.182 - 01:13:40.490, Speaker F: Yeah, I'm still there.
01:13:41.260 - 01:14:25.110, Speaker G: So if you'd rather your users be connecting to a local desktop peer where they have full control over everything, then that is also a possibility. So it's designed to be a hybrid network, so if the hub doesn't exist, they'll still be able to access their data, create groups and share data, et cetera, with other peers. It just works better when the hub is there because you've got that always on peer. Just like, why with IPFS it's useful to have a pinning service because, you know, at least someone out there is pinning and storing data and Is.
01:14:27.960 - 01:15:09.220, Speaker F: Is like, this is not a textile question. This just might be something, you know, can you subscribe to an IPS name update? So I think IPNs is using IPFS pub. Sub or Lib PTP in order to do its kind of it's sending updates to transparently update these records. Is there any way you can hack into that and actually be informed when a name is updating? Because I couldn't see anything in IPFS JS that enabled you to actually listen to those updates. So it's almost like if I wanted to do that, I have to poll locally to say, has this changed?
01:15:09.560 - 01:15:48.704, Speaker G: Yeah, well, that's a good so IPNs recently added support for propagation over pub sub, which means it's using pub sub, which means but right now that's handled sort of like seamlessly, like if you have the pub sub flag on, but since it is using pub sub, it must be publishing on a particular topic. So by looking at the source code, we should be able to figure out what the structure of that topic is. And then you could subscribe to that topic over pub sub and then yes, exactly.
01:15:48.822 - 01:15:50.032, Speaker C: Cool. Yeah.
01:15:50.086 - 01:15:54.310, Speaker G: So the answer is I'm not totally sure off the top of my head, but for sure it's possible.
01:15:55.160 - 01:15:55.910, Speaker C: Yeah.
01:15:56.280 - 01:15:57.270, Speaker F: Thank you.
01:15:59.800 - 01:16:27.788, Speaker G: And then just to self promote, if you're using threads, it also does all of the notification of changes over pub sub, so you can also subscribe it may I don't know, does the JS IPFS, does it also do IPNs over pub sub? I don't know.
01:16:27.874 - 01:16:40.690, Speaker F: It sort of mentions it. So it's got things like you can see something, you can get some stats on what's happening without actually having something to subscribe to, which seemed to me to be the useful thing. Right.
01:16:43.860 - 01:16:49.908, Speaker G: You'd probably have to figure out what the structure of the topic is and then do it that way.
01:16:49.994 - 01:16:50.580, Speaker C: Yeah.
01:16:50.730 - 01:16:53.856, Speaker F: And can you view that? Is wireshark the way? No, it wouldn't.
01:16:53.968 - 01:17:01.960, Speaker G: Would it be wireshark? Well, I mean, honestly, you could just look at the code. Yeah, you could just look at the code. I'm sure it's like a structured.
01:17:05.420 - 01:17:05.736, Speaker C: It.
01:17:05.758 - 01:17:12.430, Speaker G: Might just be the IPNs address. I mean, that would make sense to me. Yeah.
01:17:17.280 - 01:17:18.220, Speaker F: Thank you.
01:17:18.370 - 01:17:20.700, Speaker G: No problem. Yeah, my pleasure.
01:17:22.740 - 01:17:43.910, Speaker A: Anybody else? All right. Going to make sure I'm not missing any other raised hands. Think they're all clear. This has been great. A lot of really good questions. Glad we were able to have Carson stick around for a little bit extra. Yeah.
01:17:43.910 - 01:17:54.468, Speaker A: Oh, Phil, he's back. He's gone. He's clapping. Oh, he's clapping. Okay. Thanks, Kudos. Kudos to the team.
01:17:54.634 - 01:18:01.324, Speaker G: Thanks, everybody. We'll see you. Same bad time, same Pat Channel next week, definitely, right?
01:18:01.522 - 01:18:03.208, Speaker A: Yes, I think that's planned.
01:18:03.384 - 01:18:04.108, Speaker G: Cool.
01:18:04.274 - 01:18:06.840, Speaker A: All right. See everybody in slack.
