00:00:06.810 - 00:00:40.810, Speaker A: Okay, great. We're going to jump into our next chat here, which is going to be reviewing another ecosystem. If I get the slides to work, here another product in the kind of Protocol Labs ecosystem. So I'm going to bring up Kareem and Alvin from the Estuary team. There we go. They're going to chat about Estuary and how it's being used. Entrusted by 150, I believe this is pronounced tetabytes of data clients.
00:00:40.810 - 00:01:01.886, Speaker A: So, yeah, I'll just jump it over to them. Another awesome chat with another ecosystem or another product within the Protocol Apps ecosystem. So I'll let you kind of show your cameras and then I'll get my screen share out of the way and then feel free to jump into it. Nice to have you here with us.
00:01:01.988 - 00:01:26.770, Speaker B: Yeah, thank you so much. Let me just share my screen. 1 second. Perfect. All right, so hey, everyone, I'm Kareem. I'm a product manager here at Protocol Labs, and I'm working on Estuary. And Estuary is a reliable way to upload public data onto Filecoin and pin it to IPFS.
00:01:26.770 - 00:02:03.714, Speaker B: And you can find it at Estuary Tech. So the outline for today's presentation is as follows. The problem of centralized storage, why Estuary? How Estuary works, 1000 foot view. How do developers use Estuary, estuary's performance, and the future of Estuary. So firstly, the problem of centralized storage. So first, centralized storage is storage that is owned by a singular entity or organization. And this causes many problems because if you store data with this one entity and that entity decides to go down for the day, then you're not able to access it.
00:02:03.714 - 00:02:44.654, Speaker B: And this also has other problems such as accessibility. Worldwide, there are a limited amount of data centers, so that also causes problems. And there's also monopoly over storage because there's only a few different storage and cloud companies. So this allows them to dictate prices, allowing them to put them sky high, determine who can access this data and where it can be accessed worldwide. Now, a solution to this is actually the decentralized storage model that Filecoin is based off of. So this allows for an open market for storage and a peer to peer network of storage providers. And this peer to peer network is between a client and a storage provider.
00:02:44.654 - 00:03:55.590, Speaker B: So a client is an individual who wants to upload their data, and a storage provider is an individual or an organization that's able to facilitate this. Now, the great thing about filecoin, again, is that storage providers are able to set their own prices, hence it's an open market. So in comparison to the centralized storage systems, where you only have a few different cloud companies to choose from, in a decentralized model, you actually have multiple cloud companies. Yeah, so they're able to set their own prices and the clients themselves are able to shop through and see a whole different array of storage providers out there. And how this works is that storage providers actually, to prove that they're having the storage, they have to provide cryptographic proofs. And this cryptographic proof means that they're storing the data of the client correctly. And that proof is put on a block to the network and the deal between the client and the storage provider is actually replicated six times to ensure that the data is available worldwide.
00:03:55.590 - 00:04:30.766, Speaker B: So. Why estuary now? Estuary actually solves a lot of the issues with file claim because it's actually a little bit difficult to use it. It requires you to spin up your own IPFS node. And to do this, you need to know how to do so first of all, and the computational power necessary. So Estuary itself is its own specialized IPFS node that Protocol Labs runs. And basically what it is, it's a brokerage between the client and the storage provider. So let's say you yourself are the client and you want to store data on filecoin.
00:04:30.766 - 00:05:15.950, Speaker B: All you would have to do is just ask estuary, hey, can you make storage deals for me? And Estuary will automatically start to do this. So how this works is that you have a piece of data and this data has an associated CID. And the CID, once the deal is made, is put onto the filecoin network. So that's really important for retrieval later on. And again, this deal, the deal between the client, the storage fryer is replicated six times. Also, while the deal is in progress, your data is still retrievable off of the Estuary node because it is pinned there for hot retrieval. And once the deal is made, then it's available for cold retrieval.
00:05:15.950 - 00:05:49.770, Speaker B: And here's a little bit more of an in depth visual of the architecture here. So on the left we have the clients, and then in the middle you can see the Estuary main node. And then we also have shuttles. So you can send the deal request through the shuttles, which eventually goes to the main node and then makes deal with the storage providers. And these storage providers later on can apply to become miners. And that's just an additional incentive layer for them. So, as you can see, the S ray node is actually quite complex and it's using two protocols, filecoin and IPFS.
00:05:49.770 - 00:06:29.716, Speaker B: So, yeah, many things that go into it. And if you want, you can look at the code base yourself. But if you're just a developer looking for something a little bit easier, you probably just need this. This is S ray tech, this is our web UI and it's super easy to use. All you have to do is drag and drop your files and Estuary automatically starts making deals on your behalf. And you can even check out your deals at estray Tech on the deals tab. So here you can see your minor ID, the proposal receipt, the filecoin deal receipt, and the status of the deal.
00:06:29.716 - 00:06:54.152, Speaker B: And the minor ID usually starts with an S. And that's important because it tells you who exactly is storing your data. And in the fellow Coin deal receipt, you can see this minor ID along with your CID. Now, as I mentioned before, the CID is super important for retrieving your data. So let's say this was a traditional pinning service. If you have your pin, you can retrieve your data, no problem. But let's say that pin is somehow lost.
00:06:54.152 - 00:07:37.164, Speaker B: Well, that's a big issue because now you can't retrieve your data anymore. But what's so great about SRA and Filecoin is that even if you lose your pin, you're still able to get your data back because of that CID. So since Filecoin is also a peer to peer network, you're able to ask any storage provider, hey, I need the CID, can you go ask your peers of other storage providers to retrieve it for me? So it will find someone that eventually has that CID and it will come back to you. Even though this is slower, you will still have your data back for sure. And Estuary makes uploading data to Filecoin and replicating that data around the world. A five minute problem. So as I said before, the deal between the client and storage provider is replicated six times.
00:07:37.164 - 00:08:05.104, Speaker B: What's so great about this is because if a storage provider decides, hey, I don't really feel like being on the network anymore. Well, you still have five other storage providers that have your data. And as well, you're able to access it all around the world. And here's a good representation, a visual representation of that. So this is us right now. This is the world. Here are the Filecoin storage providers, here is the Estuary nodes that are able to talk to these storage providers.
00:08:05.104 - 00:08:18.010, Speaker B: And here are the deals. And as we get more and more deals, the data that we have keeps replicating across the world more and more and more. So now Alvin is going to talk about how do developers use.
00:08:19.900 - 00:08:34.430, Speaker C: Thanks for that. Thanks for that. I'm not sure if I can share my screen. Maybe you need to unshare first and then I'll share mine. Yeah, thanks for that. Okay, hold on. There we go.
00:08:34.430 - 00:09:34.272, Speaker C: Right, slideshow. Okay. All right, my name is Alvin so I'm the software engineer here at PL, and I'm one of the software engineers maintaining and supporting Estuary. And, yeah, I'm here to give you an overview on how developers can use like for their development, for building their apps. So I think Corrine has mentioned earlier about the benefits of using Estuary, being able to upload data and sort of replicate that data six times over on the FICO network and then make it sort of reliable and retrievable. So there's a lot of mission critical applications that anyone can use or can build on top of Sri. So it's easy to say that, yeah, you can build sort of an app that relies that an app that has data centric data centric that handles a lot of data.
00:09:34.272 - 00:10:49.080, Speaker C: And Sri is one of the perfect platforms to do that, right? But before we even go to the examples and how developers can use it, or how UK developers can use it, it's important to understand the architecture. So Sri has three main components, the main node, the shuttle and front end application. So the main node is sort of like the main broker node that sort of acts a broker between the clients and the file coin network. So when you upload a file on the front end, it pins onto the main node and then it facilitates and manages the creation of those six deals, six filecoin deals, six replications, meaning and then it persists that onto the filecoin network to the storage providers. And the shuttles is basically the way for this main node to scale. So if you need more storage, if you need more processing power, if you need to process more data, you can actually scale the main node and add more shuttles to it, right? So actually, currently, the main suary production environment currently has six shuttle nodes. So we have managed to scale, we managed to support a lot of files by scaling our main network main node.
00:10:49.080 - 00:12:10.384, Speaker C: And the lastly is the front end, which is basically the user interface for any users or for any consumers to upload their files onto Esuary. So I think this is one of the demonstration that Corinne showed earlier, wherein any users can easily drag and drop files onto the front end. And then all of these replications, all of these facilitation of files to the filecoin network is done on the back end. What's good about Estuary is that when this was built, it was built with an API centric mindset, meaning all of the core features or the core functions of it are accessible via API endpoints. So meaning if you upload a file, a car file, or even if you're retrieving a list of CIDs, all you need to do is, all you need to do as developers is that you just need to call a specific endpoint, passing a token, an API key, and then you can retrieve that to your application. So technically, any platform that understands Http and can also sort of parse that Http response can literally use SQR. So here are some of the examples, right? So example one, file upload.
00:12:10.384 - 00:12:49.420, Speaker C: So all you need to do is really just call the endpoint content add and then pass the better token authorization. So this is a key that you can actually retrieve and they can request the invite for. And then you just need to pass the data and then you're good to go. So just file upload, just pass that data in there and you're all set. Now, of course, you wanted to have a way to access those files, right? So there's also an endpoint for that. So just call this endpoint, pass the better token, then it will retrieve you back all of the files that you uploaded. CIDs.
00:12:49.420 - 00:13:30.328, Speaker C: So similar thing with Car file. So if you're uploading a content archive file onto the network. So just need to call the endpoint, passing the better token and then passing the Car file as part of that data body and then you're good to go. So everything is endpoints, even the collections. So collections is one of these features, sri features, wherein you can tag a specific file and then sort of aggregate and collect them. Sort of creates a group for each file. So it's like a hashtag that you can tag a specific file so that you can collect them or you can group them and then sort of just use that tag to identify the specific files.
00:13:30.328 - 00:14:41.616, Speaker C: So again, for creating collections, all you need to do is call an endpoint, pass the better token key, right? And then you're all set. I think here's a demonstration, a quick demonstration of how it works. I'm not sure if I can play it, but I don't think I can play it, sorry, hold on, let me just check if I can sort of okay, all right, let me play that. Okay, so again, as I mentioned earlier, all you need to do is just call this endpoint. So this entire demonstration, this entire page is a way for anyone to just test out the endpoint. Then we choose a file and then we upload the file. Everything happens on the back, so it calls that endpoint.
00:14:41.616 - 00:15:49.508, Speaker C: So API, S, UI, tech here, contentad here and here, we're now listing our files, right? So all we need to do is just replace that header token with a legitimate with an authentication token that anyone can get if you request an invite and everything is going to be retrievable, right? Okay, let me just go back to my slideshow now. It plays. Hold on. Okay, so now once you're done with uploading your file, you can actually verify your CID. So we do have a front end, as I mentioned earlier, a front end that allows anyone to just upload their files. But there's also a way for you to verify the CIDs that you uploaded through Sri. So you can verify your CID using this tool and then it will look up onto this DNS endpoints here, the weblat link and IPFS IO.
00:15:49.508 - 00:16:46.236, Speaker C: So of course there are a few more APIs that you can take advantage of as developers. So Collections API, as I mentioned earlier, you can use it to group files together and sort of tag them so that you can retrieve them as a group. There's also a Deals API to access all of the existing deals, any deals that was created for your CIDs, the storage provider and minor APIs. So it's sort of like an admin endpoint to grab or to get all of the storage providers registered on the system. And of course admin and system APIs, sort of like maintenance and support APIs to maintain the Sri load. So of course, all of these are since these are accessible by Http API endpoints, right? So it just makes sense to build tools around them. So that's what we actually did.
00:16:46.236 - 00:17:19.828, Speaker C: So we created SDKs and libraries that sort of wrap all of these API endpoints. And the beauty about it is that it's written in Java. JavaScript rust. Python c sharp. So all of these are mainstream programming language. So if you're working, for example, in an application that's written in Java, you can just import that module onto your Java application and then call these APIs through the Java library. So all of these are available in our GitHub.
00:17:19.828 - 00:18:00.868, Speaker C: So everything is open source. Anyone can access it. Anyone can just grab it and then just use it for their own. Of course, since we also documented all of the API endpoints using Swagger. So Swagger is an API documentation tool, but the great thing about it is that you can actually use that documentation to build stubs. So client SDK stubs and server side stubs. So, for example, if you have a specific use case for, let's say, Flutter app, right, let's say you're building a mobile application in Flutter and you need a Dart SDK, you can actually use a Swagger docs to generate the Dart SDK for you.
00:18:00.868 - 00:18:46.960, Speaker C: So here's sort of like some of the key examples. Using the code generator, you can generate Android SDKs, apex closure. There's even C sharp dart flash, right? And then Groovy and Java. So everything is compatible with Swagger code generator, right? So the API key is only by invite. So you would need to request access from the development team. So if you scan your QR code, if you scan this QR code right now, it will redirect you to the request invite page wherein you can register. And then we as a team will check and we'll assign you an API key so that you can use these API endpoints.
00:18:46.960 - 00:19:45.428, Speaker C: Estuary is open source. So every source code, the node, the SDKs, the Swagger docs libraries, even the complementary tools that it has are all open source. If you go to Application Research GitHub page, you will see all of the projects here and anyone is free. If you have sort of like an idea how to extend it, you can just clone and sort of create a PR against the, against the repository, against a project. So if you're sort of trying to build an innovation on top of filecoin and you want to use to have your own use case or to build your own project, you can definitely do that. Just clone, extend, and then you're good to go. All of the developer documentations API docs are available in our documentation website.
00:19:45.428 - 00:20:20.172, Speaker C: So that's docs sui tech, you can scan this QR code to visit that webpage as well. And of course, if you have any questions about the tech. Our tech team is on Slack. We have a Slack group which is open to anyone, it's ecosystem dev, and if you have any questions about or anything that you need assistance, we will be happy to assist you. Yeah, that's yeah, I'll give the floor back to Corrine for the next few slides.
00:20:20.316 - 00:20:40.544, Speaker B: Thank you, Alvin. You can just click for me. Okay, sure. I'll share my screen. Okay, cool, we're back. So s three performance. We have over 18 million total files uploaded by all users using the primary S three node.
00:20:40.544 - 00:21:14.036, Speaker B: 165.93 terabytes of total pinned IPFS storage for hot retrieval from the IPFS gateway, over 100,000 active storage deals on the filecoin network, 971.59 terabytes of total sealed storage on filecoin, including replication. And lastly, we have 176 total storage providers receiving deals from our S ray node. So, some really good stats. And then as you can see, the trend is looking good for the amount of data that's been uploaded onboarded onto the filecoin network. And this data is since April 2021.
00:21:14.036 - 00:21:45.116, Speaker B: And as you can see here, there's a really great upward trend. So the network is definitely growing. And now to talk a little bit about the future of Estuary, here are a few of our goals that we want to accomplish. We want to make it easier to onboard data to filecoin. And what this means to us right now is that we want to improve our web UI for other users as well. We want to make it very easy to use. And Sri right now is actually going through a little bit of a redesign, so that's very soon to come.
00:21:45.116 - 00:22:27.940, Speaker B: We want to be able to onboard more data and users. So some examples of our users are listed below, and we want to be able to accommodate larger upload sizes. Right now in a singular upload, SRA can only accommodate up to 32GB. So we really want to stress test that and see if we can break that barrier. We also want to expand the amount of projects using Estuary, broaden our network of storage providers, and we want to have more online deals like on the network. And then our biggest goal I'd say right now would actually be Auto retrieve. So this is kind of completing the picture of data retrieval.
00:22:27.940 - 00:22:51.612, Speaker B: So if you were to lose a pin on Estuary, it would be really great to be able to retrieve your data. So that's basically what Autoretrieve is doing. It is about 95% of the way there. It's almost completed and I'd say would be done within the next month or two. So that has been the major push as of now. So, yeah, thank you so much for listening to our talk today. And as Alvin mentioned earlier, we're all open source.
00:22:51.612 - 00:23:11.050, Speaker B: You can find us at ecosystem dev on filecoin Slack. Please check out our GitHub. If you want to contribute, you can find that application research slash Estuary and again, if you want to use Estuary, go to Estuary Tech and please request for an API key. So thank you so much everyone and we can take some questions now.
00:23:13.900 - 00:23:48.100, Speaker A: Awesome, thanks so much folks. Just loading up the channel to see if there were any questions. Maybe in the meantime, if you could highlight maybe some of the you mentioned some of the big companies that are using asui, but maybe just kind of some of the cool ideas that come to mind for ways in which people can leverage this kind of bridge to build some cool projects during their next two and a half weeks. I don't know if you have any good ideas or any alpha you want to leak for things that people can build, but yeah, I would love to hear any ideas you have for a bunch of hungry hackers.
00:23:52.040 - 00:24:36.916, Speaker C: Yeah, one of the key benefits, right, of using Estuary is the replication. Right. Whenever you upload a file on Estuary, it replicates on the filecoin network. So if you're building sort of an AI machine learning app that uses a data model that you don't want to be tampered with, that's actually a good use case. Because when you have a reliable storage like filecoin network, for example, using the Sri as a broker, you can sort of ensure yourself that that data is there. It's replicated, it's retrievable, and it's also Verifiable. Right? Just because we have the Content Addressable storage technology there.
00:24:36.916 - 00:25:03.450, Speaker C: So, yeah, if you're sort of building an application, I would look at building an application that relies on aggregation of a lot of data, like Geolocation, and then use Sri to store that, or use Sri to us Sri to store all of those information. And that's virtually any application. Right. Like any application that collects data. Really?
00:25:04.380 - 00:25:06.330, Speaker A: That makes sense. How about.
00:25:08.140 - 00:25:20.050, Speaker B: Mean? Yeah, basically what Alvin said, like anything that's really that you need to onboard a lot of data, s three is definitely the best bet for that. Yeah, Alvin really hit it on the head there.
00:25:21.780 - 00:26:38.840, Speaker C: Yeah, machine learning. It's just because in the AI machine learning space, there's a lot of data sets that you can take advantage of. And I think one of the key things really in this data set, because I work for a company that does this, it's the reliability of that data set before you feed that onto the machine itself. It's sort of like a supervised learning data model. So you create this whole bunch of data, you source it from different sources, like different channels, you aggregate it and then you store it somewhere and then you use that later on to create data sets or data models that will then be fed to chat bots. Chat bots that responds to customer requests, customer inquiries, or to maybe an application similar to Amazon, an e commerce website, where it tries to predict what your trends are. What are the trends or what are the things that you buy or a person buys during this season.
00:26:38.840 - 00:26:51.964, Speaker C: Those are the things that I would look at. Those are the solutions that I think that's very impactful, very good. And it's great to have those solutions, I think.
00:26:52.002 - 00:27:25.620, Speaker A: Yeah, awesome. Well, yeah, it's been amazing. Thank you so much for the whole overview of just how far Sway has come over the last little bit. Been amazing to see, sorry and yeah, really appreciate having both of you here to give us that quick overview and looking forward to seeing many projects built using Estuary and the world that you can have when you have this persistent data. So thank you so much folks and I think we're probably going to move on to the next talk.
00:27:25.770 - 00:27:29.200, Speaker C: Thank you. Thanks. Thank you so much. Bye.
