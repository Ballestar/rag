00:00:00.890 - 00:00:40.610, Speaker A: So some of that is going to be a little bit redundant, but it's going to be mostly new stuff. So kind of the quick outline of the talk. So the first I want to discuss Arithmetization, what it is specifically. So we have a lot of this potential with the zero knowledge proof technologies and they're really wonderful. But the question is how do we translate the programs that we kind of use in the daily basis into those type of things that can be used to generate proofs for those programs. And this is what Arithmetization is about. Then I'm going to talk about a little bit about how Starks work very quickly just to show an overview where the Arithmetization fits.
00:00:40.610 - 00:01:30.678, Speaker A: And lastly, if there is enough time, I'll show the quick example of how you can write a program in airscript that can be verified or for which you can generate the proof using Starks. So let's jump in. So the first thing to kind of think about is how we can think about computations. And there are really two ways to think about computations in general and those are circuit computations and machine computations. And the difference between the two is that kind of the first one can be represented as an arithmetic circuit. We can think about it almost like an electronic circuit as well, where you have some inputs, you have gates and the inputs propagate through those gates and then you get an output. This is different from the machine computation approach where you have kind of a state of a computation and you apply transition function to the computation and you apply it many times and every time you apply the transition function, your state changes and that kind of defines your computation.
00:01:30.678 - 00:02:09.462, Speaker A: So those are the two approaches and there are different ways to arithmetize those two approaches. The first one is R One CS. So that's a very well defined constraint system that you can translate computation into. And for machine computation that's called Air or algebraic intermediate representation. Now, there are different benefits and trade offs associated with them. I've listed a couple here, but for R One CS it's fairly easy to take a general computation, translate it into R One CS. It's fairly easy to compose different computations for machine computations because they can be represented using a succinct transition function.
00:02:09.462 - 00:03:02.114, Speaker A: Usually you can get them much more efficient for specific time of computation both in terms of generating proofs and verifying proofs. And there are different types of languages used to write for those constraint systems. So like, first you write in a given language and then you translate into like, let's say R one CSO, Air. And there are quite a few languages for circuit computations, those Narcissists, Circum, Socrates, the new one recently came out as Zinc. And for machine computations there is really Air Script and Air assembly and they're kind of languages that are tied together and this is what I've been working on primarily and air assembly translates into or airscript can get compiled into air assembly and that gets executed to generate a proof and then just to say where they're used. So most of the Snark constructs, constructs that people usually talk about use R one CS constraints. Starks are one of the exceptions that use air constraints.
00:03:02.114 - 00:03:46.926, Speaker A: In theory it is possible to use air constraints with other proving system, but nobody really does that in practice. So this is kind of the lay of the land and let's dive into what exactly is air and what are the concepts behind it, because I think there are basically five concepts that once you understand them, it's fairly easy to understand what's going on. So the first concept is the computation state. You can think about this as a set of registers that have a value at a given point in time. It's in a way similar to how like, let's say CPU has a set of registers that have different values stored in them and this is kind of a state of a computation at a given point in time. The next concept is execution trace. So if we take those states and record them at every point in time, we'll get an execution trace.
00:03:46.926 - 00:04:25.822, Speaker A: So you can think about it as a two dimensional matrix where a row in a matrix represent a point in time of a computation and the column represents a given register. So the next concept is a transition function. So a transition function takes a state and outputs the next state of the computation. And kind of for this to work to be efficient, you have to apply the same function from one state to another. So it's the same function that gets applied every time and you get the execution trace. And the next concept is transition constraints. This is also a function that gets applied to two consecutive states.
00:04:25.822 - 00:05:05.774, Speaker A: So you basically fit in two states and you get a set of values out of it. And the computation is considered to be valid if all of those values are zero. And the last concept is boundary constraints that basically allow you to specify what is the value of a computation or a given register at a given point in time. In reality, transition constraints and boundary constraints are really the same thing. Just I think it makes logical sense to separate them and think about them differently. Okay, to dive into the execution trace a bit more. So this is kind of how the execution trace would look like, or at least how I described it, but I actually kind of simplified it a little bit.
00:05:05.774 - 00:05:43.958, Speaker A: So there is actually two parts to the execution traces that you can kind of conceptually separate. There is the set of dynamic registers that get built up by the transition function, but there is also a set of static registers that you can define using some simple representation. As an example you can think of like let's say a cyclic register that gets a set of values repeated over and over again. You don't really need a transition function to describe it. You can describe it using a simple polynomial, for example. Another example is kind of this holy register where the values get inserted at a given point in time and you don't really care about what the values in between are. Those are also very easy to describe using polynomials.
00:05:43.958 - 00:06:27.666, Speaker A: Now, these are two concepts and if you start combining them in different ways, they're actually pretty powerful allow you to do a lot of different things and there are some kind of considerations. So first thing we need to have our traces, execution traces for efficiency reasons have to be a power of two. You can make your registers public or private and fields have to have high orders rule of unit. It's like special type of fields, a lot of fields have that property but not all fields. So it's something to be aware of. Now, transition function now to update based on our kind of separation between static and dynamic registers. Now, previously, I only used dynamic registers.
00:06:27.666 - 00:07:28.554, Speaker A: So in this case, a transition function takes a set of dynamic registers and a set of static registers and outputs the next state of the static or dynamic registers. Actually, and it might have seemed like it's, a very limited transition function is a very limited way to describe a computation, because it's the same function that gets applied over and over again. But you can actually use a concept of arithmetic switching where you can define kind of two separate functions and when let's say one of the registers is zero, this function will get executed. But when let's say this k zero register is one, this function gets executed. So you can actually kind of extend this and have many different functions executed and they get switched based on values of other registers that's actually very powerful and we can describe pretty much any computation using this approach and some considerations. So you can use all arithmetic operations like divisions, multiplications and so forth within a transition function. You have to keep in mind what the degree of the function is because it's important for efficiency reason.
00:07:28.554 - 00:08:31.882, Speaker A: The higher the degree, the longer it will take to ingenuate a proof and the bigger the proof size would be. And the way you can keep your eye on degree is that you want to minimize the number of multiplications or reduce the number of multiplications between registers or raising a given register to some power. And the other thing I kind of skipped over the counter with, the transition function can actually be even more powerful where you don't have to take two consecutive or one state. You can take multiple states for example, and Fibonacci sequence is a good example of that, where next state of the sequence depends on a two previous state, not only on one previous state and just to dive a bit more into the transition constraints. Now again, it takes the two states of the dynamic trace and state of the static trace and then outputs this transition constraints frequently. Transition constraints could be just something as simple as you take the current state, apply transition function to it, and subtract it from the next state and that would give you all zeros for certain type of transitions. But you can actually make it much more complicated.
00:08:31.882 - 00:09:11.846, Speaker A: You can apply different constraints based of what kind of information you want to fit into them. And this is a way to kind of sometimes reduce the degree or get a bit more sophisticated. And some of the considerations for constraints is that you can't really use division very easily, but it's very easy to emulate it. The degree of the transition constraints could be different from a degree of transition function. You don't have to have the same degree and actually the degree of the transition constraints is what is important. The degree of the transition function doesn't matter as much as actually does matter at all. What matters for the computational efficiency or proof generation efficiency and so forth is the degree of the transition constraints.
00:09:11.846 - 00:09:54.502, Speaker A: And again, the concept of long range constraints where you can take more than just two consecutive states. I'm kind of skipping over for the sake of simplicity here. Okay? So with this, let's kind of get into the stark specifically and talk about a bit how Stark proof generation process works. So every computation starts with a set of inputs. You run those inputs through a transition function and you get your execution trace. The next step is to apply the transition constraints to this execution trace and you get your constraint evaluations. And then once you get them, you do something called you compose those constraints into a single polynomial using random linear combination.
00:09:54.502 - 00:10:39.910, Speaker A: And lastly, you use the Fry protocol to kind of prove the low degree of that polynomial. And I'm skipping over a bunch of different steps here, but this is kind of the high level process of how things work out. And the way to think about these steps as well is that the first two steps are computation specific, meaning they depend on the specific computation that you are trying to generate a proof for. But the last two steps are computation agnostic, meaning it doesn't really matter what computation you're running. The last two steps are always kind of the same and within kind of the work that I'm doing. The first two steps are handled by this airscript language. And the last two steps there is a genstark library that allows you to give an airscript that allows you to generate proofs and verify those proofs for the computations.
00:10:39.910 - 00:11:36.294, Speaker A: And the purpose of airscript languages, there are really three main goals. The first one is it describes the logic of how you generate the execution trace. It describes the logic of how to evaluate transition constraints and it also provides the logic of how you interpret different inputs that fit into it. And kind of the actual tool chain model of how this works is that you have your erascript source, it gets compiled into error assembly, and then this genstark prover and verifier can interpret error assembly to generate proofs and verify proofs. In the future, I hope that more people will kind of try to build other languages that I can think of to compile into error assembly and then build other provers and verifiers that can run off of Air assembly to verify and generate proofs. Now let's dive into an example of how you could use Air script. So we're going to do it on an example of a very simple computation.
00:11:36.294 - 00:12:23.018, Speaker A: It's called MIMC computation. How many people have heard of MIMC before? Okay, so MIMC is basically nearly trivial computation, but it could be used to kind of generate a hash, or it could be used as a simple hash function because if you repeat many times, it's very difficult to kind of roll it back and figure out what's going on. So the computation itself is described by this simple formula. So we have kind of a value we qubit and we add some constant to it and we repeat this over and over again. So in a context of Arithmetization, like, we can say this is our current state, this is some constant that we're going to be adding to the current state. And that could change from one step to another, but it changes in a predictable way and this is going to be our next state. So fairly simple.
00:12:23.018 - 00:12:45.242, Speaker A: So we really have just one dynamic register. That the single value that changes. Like, you can think about it as an execution trace with a single column. And we have one static register that's actually going to be another column within the execution trace. Now, how would this work out? So let's generate an execution trace for this. So let's say we start with a value three. That's going to be our input.
00:12:45.242 - 00:13:19.100, Speaker A: We're going to have a single static register that's going to repeat this simple cycle, 1234 over and over in the execution trace. We're going to run the computation for 64 steps and we're going to use a field in which we do computations. One thing I probably should have mentioned is all the arithmetic operations for Starks happen in a finite field. So in this case, the finite field has this modulus. Basically, it's kind of like modular arithmetic. You basically do arithmetic and reduce by the modulus or divide by the modulus. So this is how the execution trace is going to look like.
00:13:19.100 - 00:13:53.718, Speaker A: You can see we have our static register k zero here and it just repeats the sequence of 1234-1234 for 64 steps. And then you see our dynamic register over there. So because our input is three. It starts with a value three. And you can see like the first time we apply the transition function, what it does is it cubes three and adds one to it. So we get 28. The second time it cubes 28 and adds two to it and you get 21, nine, five, four, and it runs until then, until it gets that 4012 and so forth number as a very last step.
00:13:53.718 - 00:14:39.794, Speaker A: So this is our execution trace and this is the computation that we generated the trace for. So in the context of Genstark library or well, first of all, let's talk about airscript. So how would you describe this using airscript and this is the entire code that you need to describe this computation using airscript and I'll explain what it does. So the first thing that we do is that we declare our stark and we say that it's going to work over this field. The second thing that we do is we define our static register. So we say this round constant is going to be the name of our static register and just going to repeat the cycle of 1234 over and over again. The next thing we say is that we're going to have a single input which is going to be a single field element.
00:14:39.794 - 00:15:25.102, Speaker A: So because our computation just takes one input at a time, that's what it's going to be. And then we define our transition function. So here's a bit more kind of things to explain here. So the first thing we say that our transition function is going to work with only one dynamic register and we're going to repeat this cycle or this loop for every start value that gets passed in. So we could pass in just the three or we could pass in like an array of values and for each of those it will run this computation. The first thing it will do is initialize the execution trace, put the three like if you think about the trace that I showed before, it would put the three as the first value in the execution trace and then it's going to repeat this, run this formula for 63 more times. So 64 total calculations.
00:15:25.102 - 00:16:04.754, Speaker A: And in this case, like r zero is actually an implicit variable that refers to the first register in the trace. We only have one register, so it's going to just have a single column. So we basically take our current state qubit add round constant and that's going to be the output of the computation. And then the last thing is our transition constraints, they're very simple. In this case, you just take the current state of the computation, apply a transition function to it and compare it to the next state. And in this case, dollar sign n is kind of implicit variable that refers to the next state of the computation. So we basically say if we take the current state, which is dollar sign r zero, apply transition to it, it should equal to the next state.
00:16:04.754 - 00:16:37.942, Speaker A: And if that holds, that means that our constraints have been satisfied. All right, so how do you run this example? Let's say using JavaScript. So this is the code, the entire code that you need to run this example and generate and verify proof for it. So the first thing we do is let's assume that the script variable here has that script that I showed on the previous slides. So we say instantiate script and it generates a stark object. This stark object then can be used to generate and verify proofs. So the next thing that we need to do before we can generate a proof, we need to define some assertions.
00:16:37.942 - 00:17:50.714, Speaker A: What statements do we make about the computation? So in this case, we're saying that register zero at step zero should be equal to three and register zero at step 64 should be equal to that value. So computation would be valid if those two registers have those values or those two steps has those values. And then the next thing that we do is we just generate proof and we pass this three as our initial value. So basically what it says, if you execute this MIMC computation for 64 steps and you start with a value three, you should generate an execution trace that will align, will satisfy these two assertions and then we can verify this assertions against the proof that gets generated in the previous state. And of course, in this case the proof will pass because we have generated verified exactly the same proof. But you can think about serializing this proof and sending it to somebody else and they can verify that you run that computation and done it correctly. Now, of course this is a trivial computation, it doesn't do a lot of things, but you can think about different types of computations that they can prove in the same way, like a pre image of a hash function or that you verify the digital signature or something even much more complex.
00:17:50.714 - 00:18:07.620, Speaker A: So you can write air scripts. So like for example, there are air scripts that verify membership in the merkel tree or verify digital signature like schnorr signature and things like that. And this is my talk, so any questions?
