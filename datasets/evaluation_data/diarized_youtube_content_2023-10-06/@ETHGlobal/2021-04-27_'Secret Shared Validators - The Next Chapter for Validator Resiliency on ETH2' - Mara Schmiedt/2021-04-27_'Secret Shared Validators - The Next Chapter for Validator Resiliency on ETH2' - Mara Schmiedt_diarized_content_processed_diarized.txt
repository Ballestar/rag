00:00:00.330 - 00:00:00.880, Speaker A: You.
00:00:01.810 - 00:00:20.320, Speaker B: Next up, we have Mara from Coinbase who will be chatting about Secret Chat validators, the next chapter for validator resiliency on East Two, which is an exciting effort in collaboration with the Ethereum Foundation that just rolled into the testnet. Mara, welcome.
00:00:22.530 - 00:00:56.240, Speaker A: Hello, everyone. Let me know if this works and if you guys can hear me. All right, awesome. Cool. Let's get it kicked off. Incredibly happy that Superfiz actually preceded this conversation because it sets a lot of the context around what we're actually going to be talking about as part of this presentation. So secret shared validators, as just discussed, is an effort that's kind of been underway for almost a year now to address certain parts of validator resiliency improvements for East Two.
00:00:56.240 - 00:01:41.374, Speaker A: So without further ado, let's just jump in. Awesome. So you guys have probably heard a little bit about this throughout the summit today, but just, like a quick recap on what the duties of a Validator are on e two. So validators, in short, are responsible for participating in consensus activities on the network, so producing blocks and attestations. In order to participate, each Validator has to put up a 32 e security deposit and much serves as, like, a form of collateral to ensure that participants are incentivized to behave honestly and truthfully in the network. For doing that, validators receive rewards. The current annual reward rate is around 7.8%
00:01:41.374 - 00:02:31.306, Speaker A: for fulfilling those duties, but a failure to perform in line with those duties result in punitive measures. So there's two types superficial just kind of ran through them with you, but penalties are incurred when you're offline. So when your validator is requested to attest or propose a block and you're offline, basically you're missing out on rewards that your validator would have earned if you would have been online. The second mechanism is slashing. And slashing is really there to disincentivize malicious behavior. So in the later phases of ECU, there's going to be different types of punitive measures. But for today and as part of phase zero, the two major ways in which a validator can get slashed is either through double voting or surround voting.
00:02:31.306 - 00:03:38.846, Speaker A: And then in later phases of ETH Two, there will be an introduction of other types of punitive measures around validators not storing available chart data or not making that available. So that's really to prevent and disincentivize the withholding of information and making sure that validators are behaving as they're supposed to. So there are a few possible scenarios in which a slashing event can be incurred, and not all of them are necessarily a malicious attack, even though the network doesn't really make that distinction. So a really good example of that, and we talked about it in the previous talk, is there can be misconfigurations that happen at the topology level in which validators are operated. And in many cases, that actually happens because multiple validators are run on identical instances. The identical key for the validators are operated on multiple instances. So to date, there's been a few major slashing events where these types of issues have actually occurred.
00:03:38.846 - 00:04:24.782, Speaker A: And I think the community is in agreement that this is definitely something that needs to be avoided, but is not uncommon for early rollouts and infrastructure configurations. So that's definitely one of the areas that we've observed and taken learnings from over the last few months. So, just to summarize a little bit around, really what validator duties look like on e two. So in order to really provide a resilient public good for the ethereum Mainet, and also to make sure that your validators are actually performant and rewarded for what they're doing, there's really two categories that are important to keep in mind. So the first one is liveliness. So making sure that you're online don't be offline. The second one is safety.
00:04:24.782 - 00:05:04.254, Speaker A: And safety can really be bucketed into two things. So ensuring you're not producing any slashable offenses and making sure that you don't run multiple instances with the exact same validator key. The other one really is like protect your keys. So your validator keys, they need to be safe, make sure that there is no compromise that can occur to avoid malicious attacks or behavior on your validator. So preventing validator failures, this is really where we get into the nitty gritties. Like, how do you actually make sure that those failure modes are addressed. So let's talk about the first one.
00:05:04.254 - 00:06:09.714, Speaker A: So liveliness failures, they can occur both at your beacon node or the validator client level. So they can result as misconfigurations or issues with your hardware, the software network level, or if you're leveraging a cloud provider, potential cloud provider outages, or general or localized power outages. So really, the main form of mitigation for this type of validator failure mode is redundancy. So making sure that you're running your node across different instances that have diversification across different components. So validator clients, different cloud providers on prem versus on cloud, and making sure that that redundancy is built into your node topology to prevent against single points of failure for your node operations. So the second one is safety failures. So Byzantine faults and Byzantine faults really occur when operating nodes in a distributed network have a conflicting view on what reality looks like.
00:06:09.714 - 00:07:25.862, Speaker A: And this can happen as a result of a software bug or a network attack that happens at a broader level. So this really can be mitigated through fault tolerant consensus mechanisms where the consensus on what is the truth is achieved across a number of different node instances. So really, Byzantine fault tolerance is a feature that is part of E two at the network level, but it's not something that's been implemented necessarily at the individual node level to ensure that there's fault tolerance and some type of consensus mechanism at the validator level to make sure that there is no Byzantine failure that relates to that. And then last but not least, safety failures relating to key compromise. So this happens when your key gets compromised, when it's not safely and securely stored, but in many ways also when your key is in its compromised form and susceptible to attack. So, mitigation measures for that, including protecting for key compromise through something that is called threshold signatures. So validator keys can actually be split and a threshold signing mechanism can be introduced to ensure that signatures can be combined to produce a complete signature.
00:07:25.862 - 00:08:39.246, Speaker A: So BLS, signatures on Ethio are additive which make them really friendly to aggregation. And there's different ways in which, e. Two validator keys can be split. So either through a distributed key generation mechanism or sham your secret sharing amongst a group of network operators with a corresponding threshold and then making sure that different share signatures and that threshold is required to command the validator. So, if you split an initial validator key into four individual shares, setting a threshold and Byzantine fault tolerant threshold at around three validator signatures required to command the validator, then that would be a good failure mode to protect against keep compromise from that perspective. So really, to sum up what optimally resistant yeast to infrastructure looks like, really can be comprised of just three components that are key to that. So to protect against various node failure modes that can exist, the three key things are having and leveraging threshold signatures, ensuring that there is redundancy and a consensus layer to coordinate your validator.
00:08:39.246 - 00:09:24.270, Speaker A: And that really introduces secret shared validators. So we kind of ran through it. Secret shared validators are really comprised of all of these key elements. You can think of it as open source middleware for improving validator configurations, or in a more simple term, it really acts like a large multisig for distributed consensus finding duties on the ethereum blockchain for individual validators. So, the first step in an SSV setup is to split an existing key. Again, as mentioned, there's two ways to do that. You can use shamir secret sharing for an existing key, or you can jointly generate a secret key amongst different parties, leveraging distributed key generation schemes.
00:09:24.270 - 00:10:20.910, Speaker A: So the second part of this is a coordination mechanism. So, SSV requires a coordination mechanism with a consensus algorithm that is used to coordinate the beacon nodes that utilize the special signatures that are set. So the consensus algorithm that is utilized to achieve fault tolerance, as we mentioned earlier in this example and the way that it's been constructed today is leveraging Istanbul BFT. So this is a deterministic leader based consensus algorithm, so it can tolerate up to one third of the nodes failing in the setup. So really key splitting and IBFT. So the consensus layer that coordinate different SSVs are the foundation of every single SSV node. So first nodes decide on what to sign, and then after that sign the data and then reconstruct in line with the threshold signature scheme.
00:10:20.910 - 00:11:25.126, Speaker A: What is to be broadcasted. So what you can see here is full redundancy components across your beacon notes, your validator clients, and then a consensus layer that basically coordinates a threshold signing scheme between these different components of the validator instance. So this doesn't only provide superior safety configurations, but it eliminates single points of failures and it enables a variety of redundancy capabilities at all different types and layers across the topology of your validator. So what can this really be used for? And really that's kind of the brunt of what I want to focus on for this conversation because SSVs are really a middleware that almost serve as a primitive. They enable a lot of use cases and all of those use cases are really intended to drive better infrastructure resiliency for the entire ECU network. So let's talk about three main components. I'm expecting there to be a variety of applications and we're already seeing some of these develop today.
00:11:25.126 - 00:12:41.070, Speaker A: So let's talk about what this means for infrastructure providers. So, as an infrastructure provider, and this is offering infrastructure services to other stakers, one of the main benefits of an SSV configuration is the fact that you can achieve active active cluster redundancy across all the subcomponents that your clusters comprise. So you can have different validator clients within the same instance talking to each other through the SSV API. You can deploy them across different cloud providers, different regions, and your validator still acts in unison through that consensus mechanism to ensure that you really have minimal service disruptions and really enhance the resiliency to protect against node failure. So there are also interestingly and potential dynamic deployments that can be leveraged through this for this particular use case. So for example, you could imagine a world in which different providers are making up an SSV node and offering those services to the market. You could also imagine a customer having an in house setup and leveraging a provider as part of the SSV configuration to stake their ETH in a distributed voting power type of manner.
00:12:41.070 - 00:13:49.442, Speaker A: So the second one is at home Validators that operate their own infrastructure. In many cases, at home Validators don't necessarily have access to or the technical capabilities to implement this multilevel redundancy into their existing infrastructure and introducing additional security measures to their existing configuration. So SSV middleware for At Home Validators really serves to support the validator in distributing their signing power to dramatically decrease the risk of failures and downtime penalties. And what I would envision and really hope for is that one day this can really just be deployed through something like Dapnode. It's like a package that helps you simplify the setup and the deployment process if you're an at home validator in a way that you can opt into choosing an infrastructure setup that is significantly more secure and resilient. The last one is staking pools. So today the most prominent decentralized staking pools are operated through single validator architectures.
00:13:49.442 - 00:15:02.010, Speaker A: So what that means is usually what happens is there's a pooling of stakers ETH that basically gets bundled up into 32 ETH chunks and then that 32 ETH gets assigned to a Robin Hood type selected validator within the pool. So again, that validator serves as a potential single source of failure. And in many ways there can exist scenarios in which if different validators inside of the pool are operating the similar infrastructure component. So call that all of them using the Prism client or some of them, and the majority of them being deployed on the same cloud provider, then you really run into the risk of introducing more severe risk measures into the decentralized taking pool. So as a result of leveraging this type of configuration, you introduce fault tolerance, which fault tolerance on the pool level and single validator pool setups doesn't really exist yet. So that really significantly improves network uptime and security. And we're already seeing Blocksu is one of the partners on this program with us leveraging this implementation to build trustless staking pools for their stakers.
00:15:02.010 - 00:16:15.646, Speaker A: So super excited to already see that part coming into fruition and on to the next one. So give everyone a little bit of context on how we got here. So the research group for this effort was actually formed back in July 2020, which is crazy to think. And throughout the process incredible efforts and help has been provided from the EF on the research front. So John, Crad, Aditya and Carl have been doing tremendous work on pushing forward a lot of the components that today have actually turned into a functioning testnet. So we've been supported by a grant from the EF back in February and really with the core purpose of bringing something to the community that is an open source SSV middleware solution that can be leveraged and implemented across different use cases that is applicable to. So we rolled out the SSV testnet on April 20, so actually just a few days ago and we have a group of twelve experienced node operators, both at home validators client teams and staking providers currently testing the implementation.
00:16:15.646 - 00:17:18.380, Speaker A: We're very likely to roll out a second testnet to a broader group of participants later in the quarter and this really serves to ensure that we've conducted sufficient testing before getting the initial implementation out for an audit and then making sure that it gets released to the community for further work. So there's always ways to get involved. We'd love for you to get involved. So you can connect on the discord in the official Ethernd channel. If you scroll down, secret Trader validators has a little thread, you can also scan the QR code and that's where most of the conversation is happening at the moment. You can also check out the GitHub loads of information on there, including information around the testnet. So if you want to participate in that as it comes up again, we'd love to have you and if you want to just ping some questions, you want to connect, feel free to hit me up on Twitter just under my name and yeah, would love to have you there.
00:17:20.990 - 00:17:38.080, Speaker B: So much for introducing secret chat validators. We have lots of questions for you, so I'm just going to go ahead and relay them to you. First up, during secret sharing, we need full consensus. And during signature generation, IBFP is used.
00:17:39.330 - 00:18:24.320, Speaker A: So IBFP is used as the consensus layer. So this is more to ensure that there is like a threshold signature mechanism at the consensus layer that coordinates the different SSB nodes. So for the current testnet implementation, we're leveraging Shamra's secret sharing. We're not leveraging a DKG, although it's currently in research mode. And in the future, we're really trying to add more advanced functions that currently some of the teams that have been supported through DF are working on. So as we look into future phases of the rollouts, we have a team called Playton working on multiparty computation for a proof of custody scheme that could be leveraged for this as well.
00:18:27.810 - 00:18:33.150, Speaker B: Are the parameters for the IBFT the same as the threshold for signing?
00:18:33.590 - 00:18:37.426, Speaker A: Sorry, could you repeat that for the.
00:18:37.448 - 00:18:40.850, Speaker B: IBFT the same as the threshold for signing?
00:18:41.510 - 00:19:06.170, Speaker A: Yeah. So basically, the way that the recommended threshold signature scheme would be set up is ensuring that you use a three out of four scheme. It can be changed and altered. For example, if you were optimizing for things that were not necessarily designed to be fault tolerant. If you are, for example, an individual validator, but in the reference implementation that is the recommended specification.
00:19:09.230 - 00:19:19.390, Speaker B: Then the next question for home validators, I guess, Mara, what are the risk factors if we have set up our validator keys on a separate offline throwaway machine?
00:19:20.450 - 00:19:23.470, Speaker A: If you've set up your validator keys on a separate.
00:19:25.730 - 00:19:28.050, Speaker B: Line throwaway machine?
00:19:29.590 - 00:20:17.810, Speaker A: So I can't answer that in terms of as it relates to the comparison of this configuration. If you're an at home validator and you have adequate validator private key protection mechanisms, as came up in the last talk, we haven't observed a massive amount of punitive measures on at home validators really oftentimes that we've observed slashings on Mainet has really been a consequence of misconfigurations on validator pools and staking providers. So I would say just in terms of configurations, obviously you would continue being able to operate that, but with this mechanism, you'd be able to operate a node that just has some degree of fault tolerance on being able to coordinate across redundant components.
00:20:20.700 - 00:20:31.580, Speaker B: Then we have a question connected to our talk that we listened to earlier today. Is there a plan to integrate this with Vouch? I'm not sure if you're familiar with Vouch.
00:20:32.240 - 00:20:40.850, Speaker A: I am not. Probably I should be, but whoever's involved, please let me know. Would love to take a look.
00:20:43.300 - 00:20:49.516, Speaker B: We had this talk just three talks ago. It's an open source cross validator it's.
00:20:49.548 - 00:20:57.830, Speaker A: A test in teams Jim is working on, right? Yeah. Yeah. I love Jim. Their team's great.
00:21:01.720 - 00:21:28.216, Speaker B: Okay, are there any more questions that I can relate to, Mara? Let's check the chat. Does not look like it. Keep them coming, guys. We have a few more minutes, and if there are no further questions, I'd say let's move on to the next speaker. Thank you so much, Mara.
00:21:28.328 - 00:21:30.680, Speaker A: Thank you, everyone. Happy Friday.
