00:00:01.210 - 00:00:55.854, Speaker A: Everybody who's been here in the earlier session that I had today. Okay, not everybody, but who's familiar with proof systems. Okay, so this talk now starts with an introduction to proof systems, something that I did this morning as well, and then continues story. I'll just and then continues with diving into the Stark protocol. It would be a bit less engineering like and there would be some mathematical stuff here. But before that, I will just tell you that you should concentrate because there might be some tricky ideas that it's not trivial to conceive. Okay? So shortly I start I introduced us in the morning.
00:00:55.854 - 00:01:48.110, Speaker A: We are starkware. We are building an exchange with diversify ASOFT custodial exchange allowing high throughput of transactions. Cryptographic proof system in high level is something that its input can be a predicate. A predicate described with any program, for example, a Python program, a C or whatever that given an input returns true or false. And it can be compiled using systems like Stark to approver and a Verifier such that the prover can receive an input that satisfies the predicate. It can generate a proof to show that this predicate, it knows a valid predicate. And the verifier can read this proof and be sure that the prover indeed knew such a predicate.
00:01:48.110 - 00:02:50.338, Speaker A: I'll do a general cynical example for those who don't really have the intuition to what can be done with that. So computational integrity is one example. For this, we can think about the following scenario. We usually send benchmarks on work to the cloud and we hope the cloud will reply honestly with results. Technically, the cloud provider has the ability to do anything they want to tamper with the result that they return to us. Using computational integrity, we can think about the predicate as just something that can verify that when executing the program I want to render with the input I give, I get the result I really want, the cloud provider really suggests is the result of the execution. So I'll dive to describe the features of the ZK Stark proof system.
00:02:50.338 - 00:04:16.910, Speaker A: So ZK stands for zero knowledge, which means that when someone sees the proof, they cannot know anything about the witness, the satisfying witness. Scalability it means that verifying such a proof scales logarithmically with the time that it takes to compute to execute the predicate. For example, in the case of the cloud provider, it could be the case I actually offload big workload to this cloud provider, something that would take them a lot of time to compute, something that I would not be able to compute in reasonable time on my laptop. But the verification of the proof would take me milliseconds and I can be sure that they cannot lie to me or give any false result. Transparent means that there is no need in any trusted setup that reading this proof is sufficient, like a mathematical proof, to make sure that everything is okay and you don't have to trust any other party argument of knowledge. It means that looking at the fact that the approver can generate a proof, says that the proof actually knows a witness satisfying this predicate. What I will focus mostly on this talk is about the scalability feature, which is the main feature that Stark provides.
00:04:16.910 - 00:04:49.106, Speaker A: Okay, so the Stark protocol, just like any other protocols, it's kind of an agreement between two parties. In this case the prover and the Verifier. And many times it's very comfortable to think about protocols like protocol stacks, like the Tcpap stack. Are you familiar with the TCP stack? Yes. Okay, so that's good. So we will see something which is similar to the TCP stack. So there is the application layer.
00:04:49.106 - 00:05:47.930, Speaker A: In the application layer we have a statement on the side of the Verifier and we have a statement in the witness on the side of the prover. The prover has to know some special witness. Not in all cases. For example, in execution it's not in all cases, but it could be the case that I provide the proverb a program and they prove to me that they know something that I don't know of how to satisfy this program. An example for such an interesting predicate, a program that takes two inputs, verifies, they too are different, hashes them with chateau and then Verifies the outputs are the same. Technically satisfying this predicate means knowledge of collision of chateau. So somebody could generate a proof of knowledge for satisfaction of such predicate put there on the website and if it's a zero knowledge proof, then everybody would know.
00:05:47.930 - 00:06:23.714, Speaker A: They know a collision to chateau but nobody would get any information about the data itself. It would not leak. So this is the statement something very easy to talk about, something very standard in computer science. What we do when we want to construct a struct proof, we move from a statement to some kind of a localized format of the statement. In high level, you can think of it as executing. The prover can execute the predicate. And what the Verifier does, it can locally verify the trace.
00:06:23.714 - 00:07:38.730, Speaker A: It can just access two consecutive lines of the trace and verify they are consistent. Assuming for example, we run on a specific architecture, the intel architecture, then it's very easy to look at all the state of all the registers and to see that when we are in one state, we move correctly to the other state. Another thing is the arithmetization. Arithmetization is just taking all the things that we had before the trace and the way to verify two consecutive lives in the trace and to make it algebraic. There is not much intuition now of why would we want to do something like that. But hopefully by the end of this presentation you'll get intuition of why would we want to arithmetize this localized language. And after that what we do, we do low degree testing again, not much of intuition right now, but hopefully we will get some by the end of this language and we do a realization of the entire model using Merkel commitment.
00:07:38.730 - 00:08:28.398, Speaker A: Trees. Are everybody here familiar with Merkel trees? Is anybody not familiar with Merkel trees? Okay, so in a way, the Stark Protocol is actually a very simple protocol. It's not something complex. What it does is just it's based on two pretty complex ideas. One of them is very computer science like idea of programs, execution traces that programmers usually feel comfortable with, but not most of the people in the world feel comfortable with them. The other set of ideas are more algebraic ideas talking about polynomials and load agreeness. This is something that mathematician might feel comfortable with and most of the people in the world don't feel comfortable with.
00:08:28.398 - 00:09:12.960, Speaker A: And what we do in Stark we just merge the two ideas and build on top of them to provide a proof system. Okay, we will just now scan all the reductions in the protocols, but not in the consecutive order of what's going on here. We will start with going from an application to a localized statement to a localized test. We will see what is the issue there and there. In order to find a solution, we will jump to the end to something that intuitively can find a solution. And we will do this man in the middle technique. Finally understanding what the Stark protocol is.
00:09:12.960 - 00:10:20.450, Speaker A: So in localization the predicate is compiled to approver and the Verifier, the prover given a witness, can generate an execution trace. And now the Verifier can choose randomly two consecutive lines from the trace and verify if there are consistent, given the architecture executing this program. But the issue is assuming the prover is malicious, assuming the proverb is the Amazon and I'm running some program that they really want to cheat on, they really want me to think the result in something else. For example, I want to know if I want to invest in Azure or Amazon and they want me to invest in Amazon. So what would be their probability of cheating? How hard it would be for them to cheat me in this case? Anybody? Something interactive here. Somebody wants to guess. Does it depend on the length of the program? It depends on the length of the program.
00:10:20.450 - 00:10:46.140, Speaker A: So assume the program is very long million of lines, million of lines in the trace. They only have to cheat once. Exactly. They only have to cheat once. It is sufficient to find a single line and to make it completely independent from the previous line. In the case of a trace of length, a million. The probability of me choosing this line would be one from a million.
00:10:46.140 - 00:11:35.210, Speaker A: It's not very sound, so I wouldn't use this system. So we have here an issue that what we want to do is to verify for all constraints for all pair of consecutive lines, something is satisfied and in the standard way, it's not very sound. So this is the reason why we're going to the algebraic world. And now we will get the intuition of how algebra can help us. In this case, if somebody is familiar, I can say it's related to error correction, error correction codes. Okay, so we are jumping down to the last layer of low degree testing and the realization. And we will start with a story.
00:11:35.210 - 00:11:57.570, Speaker A: In the story we have Alice. Alice is the manager. We have Bob, who is very busy. And we have Charlie, who is a coder. So Alice asked Bob to do some computation. Alice provides Bob with a list of numbers. And she wants Bob to compute their square root.
00:11:57.570 - 00:12:50.126, Speaker A: The issue is that there are many numbers there two to the 50 numbers. It's a lot of work. And Bob is very busy. So Bob calls and Bob Watalis gives Bob she doesn't give him two to the 50 numbers, she just gives him a merkel root of those numbers that Bob can use to download them from bitorrent. You familiar with BitTorrent? Do you know how when you get a slice of a file, how you verify that this is indeed consistent with what you want to download? It's actually merkel trees. You verify that the things that are consistent with the merkel root, this is the hash that you use when you want to download something in BitTorrent. So Bob can download the file in BitTorrent.
00:12:50.126 - 00:13:16.390, Speaker A: But Bob is very busy, doesn't even have time to download it from BitTorrent. What Bob does, Bob asks Charlie to help him. Charlie is a great coder and he can solve this issue. Charlie can write a script to solve this issue. The issue is that Charlie sometimes does mistakes. And it could be the case that Charlie has a bug. And Bob really want this job to be done correctly.
00:13:16.390 - 00:13:53.880, Speaker A: He doesn't want any issues with the result. So Bob has to verify Charlie's work. The naive solution for Bob to verify Charlie's work is just to go over to two to the 50 result that Charlie would provide him and to compute their squares. But it's a lot of work and Bob is very busy, as you can see his name. Okay, so now, Bob thought about an idea. And I apologize. There is not much intuition to what is going to happen now, but please try to follow.
00:13:53.880 - 00:14:50.918, Speaker A: It would be this kind of mathematical argument that it's pretty easy to follow it line after line. But in the end there is something that one have to just rub the head around. There are some interesting ideas that just you need to think about them. So I really suggest to concentrate on it now. So Bob thinks intuitively that maybe those numbers are values of a polynomial. Every set of numbers are values of polynomial. You can always do interpolation over values, right? So Bob tells to charlie, the file that Alice gave of numbers, think of them as the values of a polynomial, that the polynomial on I is actually the ith number in the file.
00:14:50.918 - 00:15:17.794, Speaker A: Now you can do interpolation and get the coefficients of this polynomial. You have now a formal function, a polynomial. And the degree of this polynomial is at most two to the 50. It's limited by two to the 50. This is how interpolation works. And what Bob asked Charlie as well is don't give me explicitly the list of result. Do the same for the result as well.
00:15:17.794 - 00:16:17.874, Speaker A: Once you have the result, the square roots of the numbers, then think of them as values of a polynomial over the same X's over the same domain. And just give those coefficients not explicitly to me. We will see exactly what will happen with them. But think about the coefficients of this polynomial. Those are his values on this domain. And this polynomial is again of degree at most two to the 50 because it's an interpolation of two to the 50 numbers. So the observation in this case, the important observation is that if we think of the polynomial Q, which is G minus P square, it has to vanish over the domain both polynomials were interpolated on, right? It has to be zero for any X under two to the 50.
00:16:17.874 - 00:16:42.080, Speaker A: Starting of zero. Right? Is it? Okay. And what is the degree of this polynomial? So this polynomial is a linear combination of two polynomials. One of them is of degree, two to the 50. The other one is the degree twice two to the 50. So two to the 51. Okay, so there are some is a polynomial of degree at most two to the 51.
00:16:42.080 - 00:17:32.640, Speaker A: Is this okay? Are there any questions? Meanwhile, okay, so we have an algebraic fact. Algebraic fact. A polynomial vanishes on some point only if we can factor it. We can factor this root out. So if R is the root of Q, then we can think of Q as a multiplication of a polynomial B by the polynomial, the simple polynomial with the root R x minus R and the degree of B is smaller by one from the degree of Q. Does it make sense? Anything? No, doesn't make sense. It's okay.
00:17:32.640 - 00:18:47.430, Speaker A: Okay. And by induction, because we know that Q should vanish in case Charlie did the work correctly, q should vanish over this entire domain. Then by induction, we can see that Q can be factored as the product of some polynomial B of small enough degree, and the minimal polynomial vanishes over this domain. Okay? This is the important idea that we will use. So those are the facts, and this is the construction that we have. And now we see what is the test Bob will apply on Charlie's result. Bob will simply draw a random number from the domain zero to two to the 60, and we'll ask Charlie to evaluate the polynomials charlie computed over the point R and verify that G in R minus P in R square equals B in R, which Charlie should compute as well multiplied by this polynomial vanishing on the domain.
00:18:47.430 - 00:19:50.998, Speaker A: Okay, so because of our construction in case Charlie did a good job, bob is always satisfied, right? But what if Charlie failed? What if Charlie had some kind of a bug, something didn't work, right? In this case, when we look at this equation, on both sides of this equation, we have polynomials of degree at most two to the 51. Right? And if this is not exactly the same polynomial, then they can agree on at most two to the 51 points. Because think about their difference. If we subtract the two sides, we have here a polynomial of degree at most two to the 51. Here polynomial of degree, at most two to the 51. They're differently, the polynomial of degree at most two to the 51. And if it's not zero, it can have at most two to the 51 roots.
00:19:50.998 - 00:20:31.638, Speaker A: So they can agree on at most two to the 51 points. But Charlie chooses R from a much bigger domain. He has two to the 60 options. So the probability of Charlie choosing by mistake a value that satisfies this equation in case this is not always satisfied, is at most one over 500. Okay, which is okay to catch a bug with probability one over 500. Sorry to be cheated. Not to catch a bug with probability one over 500 is great.
00:20:31.638 - 00:21:28.490, Speaker A: It means that you catch a bug with probability 499 over 500. This is really good. And if Bob wants to be more sure about this test, bob can choose another R and to do it again. And the probability of Bob not finding the error will go down exponentially. Okay, till now we talked about the case that Charlie is trustworthy, but he might do a mistake. So it was a way to verify Charlie did everything correctly. But what if Charlie is malicious? What if Charlie is actually kind of lazy and it tries just to cheat us that it really did the job? In this case, we will use the miracle trees.
00:21:28.490 - 00:22:49.000, Speaker A: So we will ask Charlie to commit on both the real values that we know, the merkel tree of them and the low degree extension with some commitment and to do the same for all the polynomials, for all the polynomials evaluating them on the domain zero to two, to the 60, the domain that Bob will be asking on. And after Charlie does this commitment with merkel trees only then Bob will decide on what value he wants to query and will query all those polynomials and verify they are consistent with the route Charlie provided ahead. So using Merkel trees just eliminates the ability of Charlie being adaptive, because without them, if Charlie is malicious, it's very easy to give values of GP and B satisfying this equation. You just give some random numbers and set the last one to be whatever. It's an equation that is easy to satisfy if you don't really commit to polynomials. But this requires Charlie to commit to polynomials. But there is another problem here.
00:22:49.000 - 00:23:57.130, Speaker A: What if the polynomials, the evaluation Charlie committed here are not low degree? All of our soundness here was based on the fact they must be low degree. So this is where low degree testing comes to. Low degree testing allows a succinct verifier to look at some enormous evaluation, not to read all of it, but to sample parts of it and to engage in a protocol with approver that eventually the verifier can be satisfied and know that this evaluation describes a polynomial of low degree. This is what we actually need here. I think this was the hardest part. Any questions before I go on to the rest of the construction? Are you aware of anything besides low degree testing to solve this problem? Maybe there's other types of protocol. Yeah, so it seems that all the computational integrity and proof system are somehow eventually reduced to low degree testing.
00:23:57.130 - 00:24:53.338, Speaker A: So, I don't know, it seems that initially in the late 80s they started with this approach and it seems to be going well. And I'm not aware of something that took a completely different direction. Okay, so we looked at the reduction from application to localization and we look at reduction from low degree testing to realization. And now we will just continue to do meet in the middle until we get into Stark. So remember in localization we said that the prover generates a trace, an execution trace and the verifier just verifies two consecutive lines in this trace. And you can think of the way the verifier does it using some validation circuit. An example of a validation circuit.
00:24:53.338 - 00:26:46.210, Speaker A: If we'll talk in here about the intel architecture, the validation circuit could be just the circuit of the CPU verifying that the next line is consistent with the execution of the CPU on the current line. This is an example, but in the end those are all circuits. So Arithmetization is actually taking this circuit that verifies consistency between two consecutive lines and making a polynomial out of it. Okay, this is a very simple example of assuming polynomial that receives bit because we start from a circuit that is Boolean circuit, but actually a lot of more interesting constructions do stuff that are above this and look at full field elements and some more complex encoding, which Bobbin will be talking about it in 430. So why do we want to make this circuit into a polynomial? Because of Bob's idea that we seen a few minutes ago. This circuit, the Q circuit, is very similar to Bob's idea of defining Q polynomial, having some constraint and checking that it is satisfied on all parts of the trace, on all numbers. So here we are making this cup polynomial and we are using it to verify that every two consecutive lines of the trace satisfy this polynomial, meaning it satisfied the circuit or the CPU architecture.
00:26:46.210 - 00:28:00.538, Speaker A: And as I said, this is a very naive technique. Bobin will be talking about more interesting techniques to do this Arithmetization. Okay, so we covered all the parts, and we will just rub them all together to see what Stark is. So, in order to get into Stark protocol, both sides need to agree on some arithmetization of the constraints of the circuit of the architecture they want to execute. The prover should compute the execution trace and encoded in an algebraic way that can be verified with this Arithmetization of the circuit with the polynomial. And in the end, we are just using the technique that Bob used with Charlie to verify that every two consecutive lines in this execution trace indeed satisfy this constraint polynomial or the circuit. So now we covered everything, and I hope it provided you more intuition to what Stark is.
00:28:00.538 - 00:28:01.000, Speaker A: Thank you.
