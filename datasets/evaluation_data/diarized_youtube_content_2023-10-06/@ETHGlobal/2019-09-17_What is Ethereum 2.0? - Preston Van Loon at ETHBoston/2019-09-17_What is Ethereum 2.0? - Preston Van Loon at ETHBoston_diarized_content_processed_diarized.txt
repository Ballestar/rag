00:00:05.190 - 00:00:32.900, Speaker A: You. Hi, everybody. Thanks for taking a break from hacking to learn a little bit about E 2.0. This is something that myself and a lot of other people are working on. There's dozens, almost 100 people working on this project. So something really cool and exciting and I'm really thankful you guys are out to listen. So let's go ahead and get started.
00:00:32.900 - 00:01:01.770, Speaker A: My clicker is not going to work. There's a new computer, so let's see. Okay, there we go. This is my team, Prismatic Labs. A couple of people here today. We started this as a project just for fun to do on the side. We started it in January 2018 and ever since then it's just been getting more and more momentum.
00:01:01.770 - 00:02:02.478, Speaker A: We've been able to get 50 open source contributors on our project. On GitHub, we've received grants from the Ethereum Foundation, ethereum Community Fund, and other projects within the community to help us build Ethereum 2.0. So what we're doing is we're building a production ready client. This is a Sharding proof of Stake client that you can use at home, on your laptop, or in more complex configurations where you want to have a highly available, high uptime guarantees with Ethereum 2.0. So let's dive right into what is Ethereum 2.0? Let's take a look at this quote from Vitalik, the founder of Ethereum. According to Vitalik, this is a big multi year upgrade to massively increase the blockchain scalability through Sharding, increase security to proof of stake, and increase the programmatic ability of the blockchain through improving a bunch of things we got on the first time.
00:02:02.478 - 00:02:47.210, Speaker A: So this is really a big effort. It's multi year effort across 100 people or more. So why are we going to do this? If we already have blockchain that allows for decentralized applications, why bother? Well, it's actually not very fast, right? We can only do on average about twelve transactions per second, and we have 14 2nd block time. So that's on average, the minimum amount of time you need to wait for your transaction to be included. But also, the Proof of Work consensus Mechanism is very energy expensive. Today. It's using enough power to power small countries or even medium sized countries.
00:02:47.210 - 00:03:21.538, Speaker A: It's very wasteful, but it's actually really good at what it does. But we think we can do better with something like proof of Stake. So with this, Ethereum has the ability and the momentum and the capacity to bring a truly decentralized future on a global scale. Twelve transactions per second is not a global scale, but we'll get there. So let's take a look at how are we going to do this. As Vitalik said, this is a really huge project that we're working on over many years, over dozens of teams. How are we going to do it? But we're going to roll it out in different phases.
00:03:21.538 - 00:03:53.374, Speaker A: So in the bottom here, we have what's called the beacon chain for phase zero. And this is going to be your base layer that we're building everything upon the foundation, that we build everything else. It's proof of stake. It's the beginning of sharding. But the extra shards don't come until phase one. So this is phase one is really just building upon the Vegan chain layer to actually add the shards. And then finally to complete this pyramid, we'll actually then include state execution.
00:03:53.374 - 00:04:41.262, Speaker A: So having your smart contracts, town abstraction, other things coming in phase two. So let's take a look at each of these. Phase zero is by far the most complex of all these phases so far. It has four major responsibilities which are to deal with the actual Validators themselves. So getting people to join the Validator set through a one way deposit. So if you're wanting to be a Validator and you have 32 E is the minimum at the moment. And that's what we're thinking is going to be for main net, you will take that 32 E and send a proof deposit to smart contract on the Ethereum one chain.
00:04:41.262 - 00:05:11.562, Speaker A: And then you'll be set up to become a Validator in the Beacon chain. This also is responsible for doing injections, exits, withdraws, basically keeping the list of Validators, managing that. So that's the validator registry. Next, we have rewards and penalties. So acting as a Validator is not passive income. You're actually doing work. You have to validate blocks and attest to the head of the state.
00:05:11.562 - 00:05:47.686, Speaker A: So you should be rewarded for that. Likewise, if you're offline not participating, you should be penalized for that or if you're acting maliciously. So the beacon chain is responsible for rewards and penalties. In essence. Another key part here is to deal with randomness and shuffling randomness is really hard on a blockchain. It's really hard to do it in a way that's unbiaseable. So if you're thinking like, I'll just use the previous block hash to see my random data, well, you can have an actor choose not to participate based on that random value because they know what it's going to be.
00:05:47.686 - 00:06:28.574, Speaker A: They could wait until the right opportunity. So even though that is random, like you can't predict what the next block hash is going to be, it's not unbiaseable. So we can still decide. So we solved that problem using what's called Randao. And that's where you have a large group of people, the Validators, in the sense producing a random number which is all mixed together. And then that mixed number is then revealed at the end to generate a random number. So it's not perfect yet because the last actor in that Randale model can still choose whether or not to reveal their number and still bias the outcome.
00:06:28.574 - 00:07:26.422, Speaker A: So we're working on something called Verifiable delay function, which is a type of proof of work where you have this complex operation that takes a long time to compute but easy to verify. That way it can be used for random numbers. So that's a really big part of the beacon chain. And the last part that we need is the proof of stake finalization. So that's having finalized checkpoints where we have more than two thirds of the state agreeing on certain blocks to be finalized, and then nothing can be reverted before that. So that's part of Casper and we can actually use that to finalize the ETH One chain. Taking a look at Casper real quick, this is the proof of stake mechanism to replace proof of work.
00:07:26.422 - 00:08:27.462, Speaker A: So it is much more energy efficient, where we don't have to calculate this really expensive, this really expensive puzzle, cryptographic puzzle. We're really just putting up some value at stake and saying I can be held accountable because if I'm malicious and you can prove it, then you can take my stake away and be rewarded for keeping the system in check. So I'm disincentivized to attack the network because it literally costs money, where proof of work to attack would cost compute. And that's really hard to get this, you have to have more than a third of the network to value, to burn, to attack. So it's very expensive to attack and works really well for chronic checkpoints. It also has a lower barrier to entry. So if you wanted to be a block producer today in Ethereum, you need, I don't know, entire server farm of GPUs because the cost to produce one block is extremely expensive.
00:08:27.462 - 00:09:03.510, Speaker A: But here you only need a fixed number, 32 E and you will be selected to produce a block. And it's very cheap. So that makes it more accessible to more people and therefore more decentralized. So this is good. Okay, so let's take a look at how exactly you can become a validator. I briefly mentioned that you would send 32 E to deposit contract through this process. So let's imagine that we're this emoji guy and we have a little bit of extra capital that we want to put up and be a participant in E Two because it's very exciting.
00:09:03.510 - 00:09:54.678, Speaker A: So we'll send that to the deposit contract on the ETH One chain and then we'll wait until the beacon chain has seen that log because it's also monitoring ETH One deposit logs for this contract. And then it goes through voting period, which consists of 1024 slots. A slot is a new block time, which is 6 seconds. And so this is a really long time, it's about 2 hours. And that's to prevent any sort of quick reorgs to make it more expensive to undo that deposit. We have this longish delay. So once that's been voted on, people have seen your ETH deposit and they agree this happened, all the votes are in.
00:09:54.678 - 00:10:31.102, Speaker A: You wait for finality for Casper mechanism, the proof stake mechanism, to come to a finalized defot where nothing can be reverted. Then that's finalized in the state, finalized in time, you're put into an activation queue. So we have a rate limiter so we don't have like surging of people joining and exiting. We have a rate limiter called the activation queue, which is also the exit queue. They share the same rate. Usually this should be no line at all, no queue at all. But if a lot of people are joining at once, you might have to wait a little while.
00:10:31.102 - 00:11:21.754, Speaker A: The minimum activation time, assuming that there's no queue at all, is just over 2 hours. So once you do your deposit, get ready to start doing work because it's only going to be 2 hours. So what does it mean to do work as a valuator? What do you have to do? You actually have two major roles. You can either be a proposer, this is somebody who is selected to propose a new vegan block in phase zero, or you could be an Attestor, which is someone who is part of a committee that is going to select. They're going to essentially vote on what they think the head of the chain is. And then we come to consensus on that. To reach finality committee is just a subset of Validators, randomly selected every epoch, which is 64 slots.
00:11:21.754 - 00:11:57.180, Speaker A: You'll be selected to be a, you may be selected to be a proposer and you will definitely be selected to be an Attester. So like I said, it's not passive income. You need to be online, you need to be available, you need to be listing for your assignments. You're going to have something to do all the time. Okay, so what does it mean to produce a beacon block? If you're familiar with E one, you might be familiar with blocks and how they're assembled. So you have a header and a body essentially. And these look much different than ETH one.
00:11:57.180 - 00:12:24.574, Speaker A: One important thing you'll notice there's no transactions. That doesn't come until phase two. So we're just still talking about phase zero, the beacon chain. These are beacon blocks are a little bit different than phase zero blocks. So the first thing you're going to want to do is collect all this data. So we have the Randall reveal that I mentioned earlier to do randomness. We have Attestations that we've seen that are ready to include from other Validators.
00:12:24.574 - 00:12:50.182, Speaker A: We'll include that here any deposits that are ready. People who have deposits in each one contract and we made it through the voting period ready to include those deposits here. And then we have some operations. So we have voluntary exits. People who want to withdraw, they don't want to Validate anymore. We have slashing. So people who we can prove did something wrong.
00:12:50.182 - 00:13:22.840, Speaker A: So maybe they're proposing a block on two conflicting chains or testing two blocks on conflicting chains. That's not a good idea. So we're going to penalize them for that. Then we also have transfers which are not enabled in phase one yet, but they exist. So when we're ready, we're going to turn on transfers and that's to send balances between validators. We also have our E Four data boat. So what we think the head of the EF One chain is where we're listening for that data to.
00:13:22.840 - 00:14:01.246, Speaker A: So we build all this, put it all together, we then execute the state transition. So what happens after we get this block? And we take the root of that, just like we would do with these today. And then we sign this whole thing and broadcast it to the network. So this is really quick. You're just fetching data from disk or memory and then finding it. At least compared to proof of work, this is really easy to do. Okay, so talking about what happens to the block next, so we broadcast to the network.
00:14:01.246 - 00:14:21.210, Speaker A: Everybody in the network is going to run this process. So we verify the slot is within the appropriate time. We verify that the parent route exists. So the block that came before that exists. We verify the signature ran out. We verify the Rand out is correct. We have been mixed it in for randomness.
00:14:21.210 - 00:15:01.990, Speaker A: We process the equal data, updating it to the state if the voting period has ended and we want to update it. And then we process all of the objects and the operations in the block. So that's like I said, the flashings any deposits attestations transfer exits, things like that. Cool. So that's block processing. Let's move on to what it's like to do attestations. So Attestation means to attest to what you think the head of the chain is.
00:15:01.990 - 00:15:30.754, Speaker A: So very similar to a beacon block. We're going to assemble some information. There's a little bit less here, but we're going to vote on literally what we think the best block is. So we have it's called an LNG ghost boat. That's part of resolving the fork choice and deciding the head of the chain. Then we also have our Casper finality book. So the target root and epoch, that's what we're currently in.
00:15:30.754 - 00:16:13.198, Speaker A: And then the source would be what we're aiming to finalize or justify. Then we have some other things like a custody bit field, which is proof of custody and aggregation bid field. So the aggregation bit field is actually really interesting because ideally a lot of validators going to be attesting the exact same data. If there's no conflicting information, there's no forks in the network, everyone should be saying the same thing. So instead of having N number of objects, we'll actually aggregate them together. And using our BLS cryptography library, we can aggregate signatures together. So we can see that 128 people signed this exact same data.
00:16:13.198 - 00:17:13.790, Speaker A: And this bit field represents the index of the people in the committee who actually signed it. So we can verify their signatures. So we'll collect all this data, aggregate any similar Attestations we've already seen, and then sign it and broadcast it to the network. Just like we did with the block going on to rewards and penalties, you're rewarded for both actions. So when you propose a block that's rewarded higher than attestations because it's less frequent, the rewards and penalties are applied at EPOD. So whenever we have Epot, we'll adjust the balances. And then one interesting thing about Casper is that when there has been a long period of time since finality, meaning that we're having a hard time to agree on something, the penalties start to increase exponentially.
00:17:13.790 - 00:18:26.246, Speaker A: So if it's been more than four epochs, four times 64 slots, then we're going to start exponentially increasing those penalties. So if you are offline during that time, or if one third of the network is offline during that time, we're going to increase fees until they either come back online or they're forcibly ejected for their don't be too low. Here's a table of what you can expect in terms of the issuance and rate of return on the 32 E. So the minimum to start the chain is just over 2 million. So somewhere between one and 3 million, I probably should have put that on here, but let's just say it's like 12% maybe. This is sort of what we can expect over as the validator set grows, as the communities get bigger, as the registry gets bigger, the rewards are decreased in terms of rate of return. But even when you have 100 million, ether, which is getting pretty close to the maximum in circulation, is still getting 1.8%,
00:18:26.246 - 00:18:57.790, Speaker A: it's not too bad. It okay. Moving on to shard chain. So this is when we want to actually introduce the idea of sharding. Phase zero was just proof of stake, validators randomness rewards and penalties. But now we're going to add some data to the whole operation list. So here we have the beating chain in the middle and then we have 1024 shards.
00:18:57.790 - 00:19:27.886, Speaker A: They wouldn't all fit here, but I just put a couple for the diagram. But that's the idea is that we have all these shards in sort of like a hub and spoke model where they're linked to the beacon chain through what's called cross links. But they're not tightly coupled with that. So they're not actually connected. They're only connected through the cross links at phase zero. Sorry. At phase one, the shards are just data only.
00:19:27.886 - 00:20:01.638, Speaker A: So there's still no state execution, there's still no accounts or anything like that. But you have this data availability, guarantees of sharding and approved of stake. So there's actually some benefit to that. We expect to come to consensus on ten megabytes of data per second. So that's pretty good if you're wanting to utilize this. So let's take a look at some use cases. Some things you can do are what's called a zero knowledge roll up.
00:20:01.638 - 00:20:34.066, Speaker A: So rolling up a set of transactions into 10 knowledge proof, you can roll those roll ups into a roll up. You can run like a decentralized Twitter because Twitter is really write once and read many times. So this is perfect for phase one. Same thing with pretty good key servers for privacy keys, maybe web hosting. You can put your JavaScript and HTML here. That's something else. That's right.
00:20:34.066 - 00:21:31.490, Speaker A: Once read many times and even using this for private blockchains enterprise solutions, where you can store encrypted data and then read it back, really anything that you would do, small or medium sized pieces of data would be great for Phase One. And that's cool because the really interesting stuff comes when we have state execution. So let's take a look at what that's going to be. So the plan for Phase Two of state execution is to take the Ethereum virtual machine and completely rewrite it in WebAssembly or a flavor of WebAssembly called eWASM. This has some things taken out or added for Ethereum specifically, but it includes things like cross shard transactions. So we're sending from an account in the space of Shard One to Shard Five. We're going to need some support for that functionality.
00:21:31.490 - 00:22:41.814, Speaker A: Also migrating between shards. If you have contract in Shard Five and it's getting really crowded for some reason, maybe there's a really popular app there and you just want to send a birthday card to your friend, you'll deploy that contract somewhere else or move it somewhere else using a concept called contract yanking. And this is exactly when the blockchain becomes very useful to the average developer. So when we get to Phase Two, you'll have everything, just about everything that we had in Ethereum One, but on a much scalabler fashion because we have this parallel throughput capacity of 1024 times. So we should get a huge 1024 times throughput increase. It's currently in still in research phases, but we're getting close. Some people are actually experimenting already with some proof concepts and running local discovery type ideas to look at state execution.
00:22:41.814 - 00:23:25.190, Speaker A: So it's getting really close. It's not tied to Phase Zero or Phase One, so they don't have to wait until we're done with either of those phases to start researching, designing and building it. So hopefully that'll be likely to start on production development at the beginning of next year. Okay, so that's sort of how things work. Let's talk about how actually we build this thing. Going from a research idea to implementation is quite a long process. So we have researchers from the Ethereum Foundation, independent researchers, other implementation teams who are researching as well.
00:23:25.190 - 00:24:11.320, Speaker A: They come up with ideas, experiment, collaborate, talk to each other and then propose these changes to the specifications. So we have a spec repo on GitHub that sort of defines everything supposed to work. Everyone reviews it who wants to, and then we merge that in and we tag a release. So if you're familiar with software development, that should be pretty straightforward. Once we have a release, we can all start building it. We can agree and say, okay, there's version one, we're going to start building. So we'll take a look at all of the features that we need to implement and write out our own implementation designs and how we're going to do that.
00:24:11.320 - 00:25:14.870, Speaker A: So in Prism prism is the name of our client at Prismatic Labs. What we do to get from a research idea to production code that you can hardly see here, but it looks great from really close up, just believe me. So we start with a design document. So when we have non trivial code, so really complex logic like how are we going to architect this entire system? We don't just start writing code, we actually write it out on paper or on a Google Doc or something like that and then get it reviewed by the entire team. Usually these kinds of issues need to be broken up into smaller pieces for these tasks, go into smaller pieces so we can work in parallel. So what we'll do is we'll come up with what we call a tracking issue, which is sort of like an outline of everything we're going to do broken up into bullet points that can be done in granular tasks. Then we implement it, we do code review, then we run through some testing and finally we can tag our own release of this implementation.
00:25:14.870 - 00:25:51.858, Speaker A: So let's dive into more of that. Prism we use a client server architecture. So your Validator, the thing that holds your keys, is a separate process from the beacon chain node, the thing that's actually talking to the network. And this is really important because you can really lock down your validator. You can put it in a secure environment, just make sure your keys never leak out. They don't have direct access to the network. We also use top class tooling, so we use a tool called Bazel for really reproducible builds.
00:25:51.858 - 00:26:36.262, Speaker A: So it doesn't matter what dependencies you have installed in your system, bazel will ignore those and use what's defined within the repository. That's really great when we're working on Mac or Linux and everyone's environment is a little bit different, this really enforces those rules. We use gRPC framework for interprocess communication, lip PDP By protocol apps for networking, and then Vault TP for our database. Our client is written in Go and we really like Go. It has excellent documentation for the CoreLogic. A lot of standard libraries that make it really easy to use. It's a typesafe language, so you're not running into the typical pain.
00:26:36.262 - 00:27:01.070, Speaker A: With JavaScript, where you don't know if it's a number or a string, it's really helpful to know exactly what you're handling. It has built in garbage collection so it can be fast without having to think about cleaning up after yourself. Of course you should be conscious of the space you use, but you don't have to worry about it too much. Standard library is great. It's got built in concurrency patterns. It's just really easy to use. It's also really easy to learn.
00:27:01.070 - 00:27:34.978, Speaker A: So if you're looking for something new to learn new language to learn. Go is really great candidate for that. Like I said, tracking issues. So here you can see we have one where there's a new spec version tagged and we created a tracking issue being 19 tasks. This one at the bottom was 75. And of course that's too much for one person to do, so we'll split it up into small pieces. We have to do a lot of monitoring in production.
00:27:34.978 - 00:27:51.630, Speaker A: So we're running the client. We're not always looking at it right. It's running remotely, so we want to know what's going on. You can query things. So like how many peers are connected. In this case, I thought that the peer count was correlated with the number of reorgs. It turns out it wasn't.
00:27:51.630 - 00:28:20.150, Speaker A: This looks pretty normal and that is crazy. So it's been really helpful for debugging like that, especially when things go really horribly wrong. So this chart in the top left is the slot count, and that should just be a linear, nice linear slope. And you can see it like falling off. And the CPU is maxing out and the number of concurrent routines is getting up to a quarter million of processes are dying. Rios are going crazy. Everyone's not agreeing on anything.
00:28:20.150 - 00:28:40.618, Speaker A: So the alarms are going off here and we need to know visually what is going on. So it's super helpful. Other things you can do. So, instrumentation. So how long is each operation taking? Here we have assignments being updated. This person is proposing a block. It took 300 milliseconds.
00:28:40.618 - 00:29:15.718, Speaker A: We think that's slow. We can sort of look into each operation, what took the longest. We can dive into errors with instrumentation. This is really, really great. When you have a remote distributed system that's not on your laptop, that's running in the cloud or something like that, locally when you wanted to see why is my method really slow. You can do something called plane graph, which is you take a profile of your code and then this will measure how long each thing takes. And you can actually click on them and drill down.
00:29:15.718 - 00:29:40.110, Speaker A: And you can see all the way until you click on one of these and see exactly what that was. So that's also been really helpful. Something that came from C plus plus we inherited in Go. So it's a really great tool. Documentation is really important, especially if there's something expensive. We put a big warning here. We also reference the Python pseudocode from the specification.
00:29:40.110 - 00:30:20.506, Speaker A: We run what's called a Canary analysis, which whenever we have a new binary that we want to put into production, we will put it into production, but only give it a subset of the production traffic. So if we had put this out here and we had ten nodes, and we put one more with this one and we give it 10% traffic and it starts to behave crazy. We can see against the baseline what's going on. So this one is using way more memory, it has less peers. Blocks are failing. We don't like this one, we're going to have to dive into it. It's not going to get sent out for a release.
00:30:20.506 - 00:31:00.170, Speaker A: So that's been something really helpful too. Testing is really important. It's not just unit tests. So we do unit testing which is testing core small piece of logic spec tests which are these data driven tests that everyone runs and we all agree on. We do something called mutation testing which goes through and tweaks your code a little bit. And if something doesn't fail, it means that you're not really testing that. So if you had some boolean logic where if this guy's active, give him a million dollars and you inverted that, so you give him a million dollars anyway.
00:31:00.170 - 00:31:27.250, Speaker A: So that's something you want to make sure you're testing because that could be a big deal. Fuz testing. So pumping random data into something and seeing if it blows up. Intuitive test, it's really great. They're hard to do, so they're really just a smoke test which can I start the operation? Can it do a simple thing and then that's it. Then we do the pre production soap. So like I said, canary testing will run up for 3 hours.
00:31:27.250 - 00:32:01.598, Speaker A: If it doesn't blow up in 3 hours, the canary the thing is, when the coal miners were in a cave, they had a canary bird down at the bottom of the cave. And if the bird died it's because there's like a gas leak or something. So same thing here. If our canary dies, we don't, we want to get out of there, we don't want to move forward with that. And all this gives you the peace of mind that your code is going to work and you have all this proof that it works. So you feel good, you sleep at night. Another important thing is that everyone participates in code review.
00:32:01.598 - 00:32:29.302, Speaker A: If you're on GitHub, this is how your chart should look. It shouldn't be all commits and zero code review. Everyone should be participating, everyone should know what's going on and giving their feedback. Everybody has a different perspective. So coming together you can learn from reading other people's code and they can learn from you. So it's really important. What can you do on E two today? So we just have phase zero at the moment.
00:32:29.302 - 00:33:12.354, Speaker A: So some really cool ideas if you're looking to hack and not already hack on something, is to build a primitive block explorer analytics for validators or just any kind of visualizations on what's going on in the network. We have what's called the Ethereum API, so open source repository that shows the API schema and metrics for the service design on how you can get involved with that. This works with TRPC and also JSON. The URL is down here in GitHub.com. Prismatic Laboreemapis. Just to recap. Ethereum 2.0
00:33:12.354 - 00:33:55.646, Speaker A: introduces proof of stake. And blockchain charting. It's an entirely new blockchain. It's not a hard fork. So this will run in parallel to ethereum one for some time while we migrate over designing the specification is hard, the research is hard, but implementing is even harder. As you saw, we have all this tooling and all this stuff and all these processes just so that we don't screwed up. And then phase zero, we have these clients and this code, but we don't have the data analysis and the visualizations and the tooling that we're going to need to really understand what's going on in the blockchain.
00:33:55.646 - 00:34:14.162, Speaker A: So if you're looking for something fun to do, azure really needs some tooling there and that's it. If we have time for questions yes, do we have time? We're kind of drifting.
00:34:14.226 - 00:34:15.334, Speaker B: I know you get started ten minutes.
00:34:15.372 - 00:34:25.100, Speaker A: Late, but we're drifting back like we're 15 minutes behind schedule. Could we do like two quick ones? Two. Okay, two questions. Yes.
00:34:25.870 - 00:34:45.614, Speaker B: So you put 32 E to be automatic, but you said that you penalize or you maybe want to go out. How's that decision made? How you kick somebody out, or if I decide I no longer want to be, can I get my 32 back? Or what would I have to do? And how would that be decided?
00:34:45.742 - 00:35:11.100, Speaker A: Yeah, exactly. So there's two types of penalties. There's aliveness penalty, so if you're just not doing anything, you're going to be penalized for that. It's about the same rate as what you would get rewarded. And there's also the slashing condition. So if you're acting completely crazy, you're proposing conflicting information, that's going to be a big slash on your stake. So it could be all or half of it or something like that.
00:35:11.100 - 00:36:09.002, Speaker A: In order to get your initial deposit back, plus all the money you made, you would do a voluntary exit and that will be included into a block. Then you'll get put into there's a long delay on that. It's about 27 hours. So once you signaled you want to exit, and that's been included, you still have to do work for just over a day. And then you go into that rate limited queue and then you'll be released from your duties and you can withdraw your funds after that. If I'm creating a new smart contract, do I have to signal the Shard that I want it to go to or is that sorted? Yeah, so you should signal the Shard you want it to go into because you'll probably want to choose one that's colocated with other contracts, so you're not doing as many cross contract calls. Or you want to choose one that's not very populated, depending on your needs.
00:36:09.002 - 00:36:12.220, Speaker A: So you will be able to choose what Shard you want.
