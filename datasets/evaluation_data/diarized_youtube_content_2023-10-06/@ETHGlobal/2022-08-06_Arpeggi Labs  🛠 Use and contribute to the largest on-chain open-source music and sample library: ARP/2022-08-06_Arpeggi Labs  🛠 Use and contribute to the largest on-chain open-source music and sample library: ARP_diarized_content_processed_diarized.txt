00:00:06.170 - 00:00:32.920, Speaker A: Well, I'm excited to kick this talk off with Kyle. So yeah, so we're going to be chatting about a lot of cool stuff here. In particular how to use and contribute to the largest on chain sound library. I know there's like a huge topic right now is NFT music. So a lot of people are excited to build with that. Excited to do a ton of stuff with music. So I'll get out of the way, I'll let Kyle take over and yeah, excited to learn more about art.
00:00:33.370 - 00:00:44.890, Speaker B: Excellent. Awesome. All right. Thanks, Andrew. And Jacob. All right, so my name is Kyle. I am the CTO co founder at Arpeggi Labs.
00:00:44.890 - 00:01:22.950, Speaker B: Really excited to talk to you guys about this. I love hackathons. I've been a part of many hackathons in the I mean, I think music and crypto are probably the coolest two things that you can work on right now, either as a hackathon or as your full time gig. So as a software engineer myself, this is kind of a really cool opportunity to talk to you guys about what I think is some of the technology that's going to really revolutionize the way music is made in the future. So I'll jump in quickly. I'll just talk about Arpeggi. Arpeggi labs aka arpeggi.
00:01:22.950 - 00:02:11.640, Speaker B: We've put out a platform and a protocol, but the summary is we're a transparent, open source and collaborative music creation platform. And that's basically a combination of a platform which is our website, our Peggy Studio, our homepage, our Explore page which I'll show you in a moment, plus an underlying on chain protocol. And this protocol is what allows us to enable permissionless remixing of sounds. It tracks attribution of sounds. It can enable royalty payments and splits payments out to contributors of sounds. So everyone who makes a sample that gets used in the song can receive credit and payment for that song. And I'll get into that in a moment.
00:02:11.640 - 00:02:57.480, Speaker B: This is what I'll be focusing on primarily is the Art protocol, because it's something that we've intentionally designed to be open source collaborative, so that developers can build tools, music creation tools or registration systems on top of it. So that this sort of collaborative music ecosystem can grow and grow and musicians will have access to the best tools and the most sounds possible. So it'll be helpful, I think, to just quickly go to the Arpeggio website and show you guys a little bit of kind of in practice. What does this look like, what does this mean? So you can find it at Arpeggio. IO. I actually encourage you guys to follow along, check out the site yourself. So let's just take a look at what that looks like.
00:02:57.480 - 00:03:47.174, Speaker B: So our homepage has some marketing information at the top to kind of explain the concept. You can see here, this is a screenshot of our Peggy Studio, which is kind of our primary platform product. This is an in browser digital audio workstation that's free to use, that people can, the musicians can use to basically take sounds that are registered to this protocol and create songs that then get re registered back into this protocol so that every component of your song is reusable for other artists to use. Slide ahead a little bit. I'll show you how you can browse the actual sounds that are currently inside the protocol. And these are sounds that you all have access to. These are all CC Zero sounds, which means that you can use them for literally anything you want to right now.
00:03:47.174 - 00:04:28.178, Speaker B: And I'll explain that in a little bit. Every item currently that is in our platform, on the platform side of the site, is actually tokenized and turned into an NFT. But to be honest, this isn't actually required. This is just sort of a choice that we made just as a way to visualize and to easily represent each sound. But if you guys are building on top of ARP, you don't actually have to use this. You don't have to tokenize things if you don't want to. And then this is kind of the most interesting part of the platform, which is the fact that we track the ARP protocol tracks the usage of a sound as it gets.
00:04:28.178 - 00:04:51.930, Speaker B: Say you have a sample, like a short sound of a guitar being played. You can take that sound, use it in a loop. That loop can be used in the song. That loop can be used in multiple songs, right? That sample can be used in multiple loops. Someone could take a clip, a snippet of that loop and use it in a new sample. And then that sample can be used in new songs. And this is kind of the thesis behind the Audio Relationship Protocol.
00:04:51.930 - 00:05:29.686, Speaker B: All right, so with that said, let's take a look at what kind of content we actually have in ARP. You can find this by going to Arpeggio IO Explore, or you can go to our Arpeggio IO and click the Explore tab on the left. This will open up sort of an explorer of all of our sounds that are in ARP. You'll see it's grouped right now into songs, loops, and samples. These are the primary types of media that are stored in ARP. So you can listen to a few of these sounds. If I just click Play here and it'll start previewing it on the right.
00:05:29.686 - 00:05:58.014, Speaker B: This is a full song. So this song is CC zero. It's available for you to use and remix however you'd like, and I'll talk about that a little bit later. Here you can see loops. These are more discrete components of songs, and these are also available to be used and remixed. And then finally, samples. These are short one shot samples, which are just little sounds.
00:05:58.014 - 00:06:49.440, Speaker B: They're usually less than a few seconds long. And if you are a producer, if you make digital music, you're probably familiar with downloading a pack of these samples from say, a site where you pay for them, or maybe a site like Splice where you pay a subscription and you download as many of these as you'd like. Or a site like Reddit, where you can download these for free illegally. You can pirate them, essentially, which is actually really common in music production because of the restrictions that have been placed around usage of sounds. I'll just actually quickly show you our pregu studio because I think it's quite cool. Again, this is a free to use app. You can go to Arpeggio IO studio to kind of get a hands on experience with what this kind of ecosystem looks like.
00:06:49.440 - 00:07:27.722, Speaker B: Let me just clear this track here. But basically you can see on the left you have access to all these samples and you can drag them into your studio here and create loops. I'll just play you can hear kind of how that sounds. When you're done, you click Mint song. The resulting song and its individual tracks will get registered back into the protocol. So the reason I'm talking about our platform is because it's a good example of the kind of thing that you can build on top of ARP. But by no means do you have to use anything that we've built on the site.
00:07:27.722 - 00:08:03.830, Speaker B: What I really want to talk about today is the actual on chain code that I think you will find a lot more interesting there's, a lot more easy to use. This is where we get into the ARP protocol. What does that actually look like? And now this is actually inspired by Zora. So I'm sure the people who are participating in the Zora hackathon, you all probably familiar with Zora. Zora is a protocol for selling and buying NFTs. We were inspired by that model. Basically, they have smart contracts that are deployed to different blockchains that can empower NFTs to be bought and sold easily.
00:08:03.830 - 00:08:59.050, Speaker B: We took that idea and we said, what if we made a protocol that was deployed to different blockchains that allowed media to be reused permissionlessly? And that's kind of where the origin of ARP came from. So essentially it's an open source on chain media library that's on polygon. It's comprised of one smart contract, which I'll show you guys the actual code for, if you're curious. It tracks attribution usage of sounds and the actual audio data. So the actual wave files for all the sounds that you all heard is stored on Rweave, which is, if you don't know about Rweave, it's a really fantastic product. They've created a it's called a Weave, which is like a it's kind of like a blockchain, but it's designed for decentralized file storage. And the advantage over IPFS, for example, is that it's guaranteed to be permanent.
00:08:59.050 - 00:09:38.546, Speaker B: You can also use IPFS actually. You can actually also use S Three or some other data store. Whatever place you want to store your wave files on. We just prefer Rweave because it has those guarantees of permanence and persistence. And we want the media that's registered to the ARP Protocol to be around forever. So you can always track it and go see it and find it and listen to it. All right, so let's actually get into what does ARP look like and how does it work? So here I've linked our docs docs rpeggy IO.
00:09:38.546 - 00:10:11.086, Speaker B: If you want to follow along, this is where I recommend going. If you go to Docs arpeggi IO, you'll see we have our FAQ page here, which explains what Arpeggi is. On the left, click Build on Arpeggi and this will give you information about ARP. All right, I discussed ARP is a composable on chain registry for music primitives. It's decentralized, it's transparent, it's trustless. Again, very similar to Inspired by Zora. So let's scroll down.
00:10:11.086 - 00:10:48.966, Speaker B: So again, if you build on ARP, it makes your media trackable attributable usable and remixable, and it can potentially even add utility to NFTs, which I'll talk about a little bit later. Again, the license for all this media is CC Zero. Right? Now, that means that you can use this media for whatever you want. Okay, now the fun part, the actual code. So we've open sourced the code. You can find it in the GitHub repo. If you click this, you should have access to our Public Contracts repository, where you will find the smart contract code for V One of ARP.
00:10:48.966 - 00:11:45.600, Speaker B: So just click V One, go to Contracts Audio Relationship Protocol, and you'll be able to actually look at the code. This is deployed to Polygon right now, and it's also deployed to Mumbai, which is the polygon testnet. So if you guys have written code to interact with smart contracts before, then this should be pretty straightforward. Essentially, you'll use a tool like, say you want to do this in a browser. You want to build a browser app, like a web app. To interact with this contract, you will use a library like Ethers JS or Web Three JS, one of these JavaScript libraries. You'll create a new instance of this contract object, and you can call one of the two methods that are on this contract that really matter, which are either Get Media or Register Media.
00:11:45.600 - 00:12:20.300, Speaker B: It's really simple. It's just a read or write. Essentially, let's say you want to build something that uses media from ARP. You'll primarily use Get Media, and I don't want to go over all the details of the API. If you guys are interested, you can find all that information here. That's the beautiful thing about blockchain programming, is that all the code is pretty much open source by default. But I've specked out a little bit more of the information about the parameters and kind of why they're used and what you should set them to be.
00:12:20.300 - 00:13:30.880, Speaker B: If you'd like to register media, that means taking a sound or a sample that you have and make it available for use in Arpeggio Studio and on all the other platforms that are built on ARP. All you have to do is call Register Media and pass in the artist address, which is the person who created the media, pass in the data Uri, metadata Uri, which is explained below here, and these other parameters, and it'll become available instantly. All right, if you all have questions or want to use ARP, please follow up with me. I'd love to answer questions about this and improve the documentation here, but I just wanted to give you a link to this so that you have a place to start if you really want to get nitty gritty and get into the blockchain side. All right, now I'm just going to quickly go over some of the cool things that you could build with ARP for this hackathon. For example, this is stuff that I find super exciting because it's a mix of music and crypto. Here's an example.
00:13:30.880 - 00:14:18.490, Speaker B: You could create an automated DJ mixer that makes an infinite mix, like just a permanent mix of essentially an infinite DJ set using on chain stems. Like I mentioned earlier, every single stem in Arpeggi is registered or every we call them loops. Every loop or stem is registered onto the blockchain, along with some metadata about that stem. You'll be able to read from these stems and then potentially mix them together in interesting ways and make a song player. We have the BPM, we have the key, all of that provided. So this would be really a really cool project. Another option would be to make an in browser step sequencer that takes samples from ARP.
00:14:18.490 - 00:15:26.006, Speaker B: So again, all these one shot samples that we have, we have a really high quality number. We have something like over a thousand sounds registered to ARP right now, and a lot of them are very high quality submitted by the community. You could take these and create a step sequencer that would let you program, say, drum patterns. You could make a synth sequencer and then at the end, if you would like, you could register those loops back into ARP for people to reuse in Arpeggi studio or in other tools. I'll say one shot samples here because I think, just to be clear what that means, another option is an in browser sample editor. So if you really wanted to get your hands dirty with signal processing and use filters, you could create a simple web app that reads any sample from ARP, processes it in the browser, allows the user to modify it, to pitch it, to reverse it, do whatever, and then re register the resulting sample back into ARP with a reference to the original. Right.
00:15:26.006 - 00:16:25.718, Speaker B: So you can have this kind of like chain of attribution that carries through where samples are just getting modified and chopped and screwed as much as you'd like. I'll have some suggestions at the end of this talk for how to actually edit audio because it's really quite powerful in the browser nowadays. Next is you could build a desktop application, if you really wanted to that allows dragging samples from ARP into your favorite digital audio workstation like Ableton Logic Fruity Loops. This would be if you really wanted to start using samples that are on chain in your favorite daw that would be really powerful. This one is if you wanted to get more into the marketplace side and integrate with Zora. You could build a split distribution smart contract on top of ARP that automatically rewards sample and SIM contributors of a song. For example, by using the Zora Asks 1.1
00:16:25.718 - 00:16:56.298, Speaker B: contract, which I can link to this as well. This is actually available on Zora's website if you'd like to find the Ask 1.1 contract plus Arpeggi's art protocol. So this would kind of look like this diagram that we have on our homepage. Let me find it. So imagine you have a graph of audio that looks like this. So a sample was used in a loop and then it was used in a song.
00:16:56.298 - 00:17:57.090, Speaker B: You could write a smart contract that would let you potentially say, give a tip to somebody who made a song or sorry, to all of the creators of a song and it would basically funnel back through all of the contributors at each step of the way. So you might give 50% of the tip to the artist who made that song and then split 50% of the tip to the contributors of loops to that song. And then for those loops, you could also distribute some percentage of that to the people who made the samples that went into those loops. So you could use this Ox Splits hyperstructure to do this. Ox Splits is a really great open source system for splitting on chain income. I'll put a link for that here. You can kind of start to see how this is one of those things where this wouldn't really be possible in web two, right layering these different protocols on top of each other in this totally native way.
00:17:57.090 - 00:18:41.380, Speaker B: And this is the kind of thing that we've always wanted to design around and it's one of the reasons that, again, Zoro is so influential in kind of our protocol design. Last, and this would be the most intense, but really quite powerful, is you could make a VSD type plugin, which is like a synth or say a filter or equalizer that could be tokenized. The actual code of it could be tokenized. And then you could actually integrate that plugin into Rpeggy studio. This would require you to work closely with the Rpeggy team, but it's something that we're really interested in doing. And if you want to make a plugin, if you want to make the first tokenized plugin, talk to me. That's pretty much it for everything that I wanted to cover right here.
00:18:41.380 - 00:19:16.160, Speaker B: Actually I'm going to link a couple of sites for folks to use to work on if you want to work on browser based web audio processing apps. I have some experience now doing that in different ways with both Web Audio API and with a new framework called elementary, which I highly recommend, but both of them are totally valid. I can talk about the pros and cons if people are curious. That's it. I want to open the floor for Q and A.
00:19:18.210 - 00:19:32.740, Speaker A: Awesome. It looks like there's a question in the chat already, which is, has anyone harped on audiovisual creation with Arpeggio or maybe hopped? Like just visualizer and outside stuff, like spore stuff?
00:19:33.830 - 00:20:35.158, Speaker B: Yes, it's a really good idea, and because everything's open source, you could totally do that right now. You could take any of the wave files and make a visualizer wrapper on top of it. If you're interested in making visualizers, we would actually love to talk to you and we could potentially work together to integrate them into our native Token. We've talked about literally just expanding our you can see kind of our song token has this sort of technical breakdown view that shows the composition, but we have plans to essentially upgrade this to support like a variety of visualizers that you can just flip through. So if you're interested in doing that, I'd love to talk. It'd be a great hackathon project and I can give you a few example stems if you'd like to work on something like that. This is all using React and you could literally use whatever you wanted to for that.
00:20:35.158 - 00:20:49.290, Speaker B: You could use like Pixie or I think something called Three JS, different tools for three D or two D visualizer rendering. Cool. Awesome.
00:20:49.360 - 00:20:58.174, Speaker A: It seems like they might want to so if you want to get connected with Kyle, I can just email thread after this. You can just DM me your email or you can DM Kyle your email or something.
00:20:58.292 - 00:20:59.920, Speaker B: Yeah, I'll paste my email in here.
00:21:00.450 - 00:21:12.722, Speaker A: Okay, perfect. And then another question. Yeah, same. Know what? If you interpret music from the blockchain, something like sheet music, is that something that's possible? I guess. Are they Midi files or what's possible?
00:21:12.856 - 00:21:46.362, Speaker B: It's a great question. Right now there's sort of like an Arpeggio format that we use to represent the composition. So that's sort of the sheet music composition. It's very similar to Midi, but it was developed, it's kind of like a way that was designed to be ultra lightweight for storage on the Ethereum blockchain originally, and we've upgraded it now to support a lot more features. In other words, we could open source this format. And we're planning to open source the format right now. It's not open source, unfortunately.
00:21:46.362 - 00:22:14.418, Speaker B: It's quite a complex, I would say. You can imagine any audio format has a lot of little edge cases in it, but one option is open source that format. Another option is we could actually build a Midi converter that takes that format and converts it to the best possible Midi approximation. So, unfortunately not available right now, but a good question. And in the future it'll come. Obviously. That would be really useful for your visualizers.
00:22:14.418 - 00:22:29.020, Speaker B: By the way, I just wanted to add, I think the fact that most visualizers only depend on having access to the waveform of audio. Imagine if you had access to the actual sheet music, how powerful that could be. Yeah, really good question.
00:22:30.350 - 00:22:39.200, Speaker A: Sweet. And I think you mentioned this a little bit, but it'd be cool to drill down and how you guys are handling licenses. Just ownership in general and all that stuff.
00:22:39.570 - 00:23:13.740, Speaker B: Yeah, cool. Yeah. Thanks for the compliment. Everything is CC Zero right now in ARP, and we're kind of keeping it that way. We'd like to move towards CC Buy, which is the same as CC Zero, but you need to give attribution to artists. We feel like that really fits our ethos at Arpudgy, which is essentially make your things available for use, but trust that the people who are going to use them are going to give you credit for the stuff that you made that will bring value to you the more your stuff is remixed. And it'll bring value to them because they'll have access to more things to work with.
00:23:13.740 - 00:23:59.420, Speaker B: And right now, if you think about the traditional music industry, you can download all these royalty free samples from different platforms. You have to pay for them or you have to do it illegally. But once you've downloaded them and use them, there's no connection between the sounds that you're using and the artist who had created them originally. There's literally no reference there at all. That's something that we want to challenge that because we think Blockchain Tech is the perfect place to have a permanent attributable ledger of even fine grained things like that, like who used what sample and what song. That stuff is a perfect use case for Blockchain. So let's say CC Zero is where we're at right now for everything because it simplifies things massively for us.
00:23:59.420 - 00:24:27.540, Speaker B: But we're considering potentially, eventually, how do we take some of these concepts that we've figured out with this very simple CC Zero licensing system and move them towards more traditional music licensing systems where each song has a number of rights holders. It might be the producer, it might be the record label, it might be the artist, it might be the singer, it might be the guitarist and kind of expand from that from there, but currently CC Zero.
00:24:30.710 - 00:24:37.926, Speaker A: Cool. All right, well, if there's no other questions, we're actually basically at Time.
00:24:38.108 - 00:24:46.520, Speaker B: Perfect. Cool. Yeah. You'll find all this information at Apeggi IO. Yeah, that's pretty much it.
00:24:47.210 - 00:25:10.640, Speaker A: Great. Well, thank you so much for being here, Kyle. I really appreciate you taking the time. And again, this talk is going to be uploaded, so if anybody here wants to review it or anybody is watching this later from home. You're already watching it on the live stream, but yeah, of course. Get a resource there and you can just go to the global YouTube page and then yeah. Thanks again, Kyle, for being a part of this and excited to have you be part of metabolism with us.
00:25:11.090 - 00:25:14.302, Speaker B: Awesome. Thank you so much for having me. Thanks for watching, everybody.
00:25:14.356 - 00:25:14.940, Speaker A: Take care. Take care.
