00:00:00.250 - 00:00:20.080, Speaker A: We have a chat going there if you want to get involved. Our next speaker I would like to introduce is Paul Dorzanski. He is having some slight technical difficulties so he won't have camera on. But Paul will be giving a talk titled EVM three, four, eight, doing Fast, Crypto and EVM. So Paul, take it away when you're ready.
00:00:23.090 - 00:00:42.440, Speaker B: I hope you can hear me, I'm in the process of sharing slides right now. I hope you can see the slides. Can someone confirm that you can hear me and see the slides?
00:00:42.520 - 00:00:44.260, Speaker A: You are all good to go, Paul.
00:00:44.440 - 00:01:17.016, Speaker B: Thank you. So today the topic is EVM 384 for this talk. It's a project and the title is also doing Fast Crypto in EVM. I should explain the title, what I mean by crypto. So there are three sort of interesting things. The word fast, the word crypto and know doing in EVM. What I mean by crypto is not all crypto, just a certain class of crypto that's in demand right now.
00:01:17.016 - 00:02:02.680, Speaker B: Don't worry, this talk isn't crypto heavy. By fast I mean pretty fast, but not speed record fast, but still pretty fast. Fast enough for our purposes. And by saying in EVM, I mean user deployed, user written in EVM. So that's the topic this work is a lot of work went into this from Alex Casey, I'm Paul and Jared and the rest of the eWASM team was very helpful as well. So the goals, this is an engineering project, so we should have some sort of goals and scope. So I have a goal slide.
00:02:02.680 - 00:03:01.320, Speaker B: We want user deployed crypto. Like I said, we want EVM to be generic enough to support any crypto for the purposes of this talk. And this isn't very generic, but there's a certain class of crypto that we're targeting for this talk in this project and that's any crypto with a bottleneck of modular 384 bit or less arithmetic. And for example, BLS twelve 381 operations are very popular now for F two especially, and other projects as well. But not only, there are other things and we want our project, our EVM 384 project to support any crypto, any crypto. This is a strong statement with this bottleneck, not some specific use case, any, it's generic, so I'm putting emphasis on the genericity and we want it to be fast. What I mean by fast, I said not speed record fast, but very fast.
00:03:01.320 - 00:03:40.516, Speaker B: So approaching speed records, there are optimizations that we want users to deploy it. We're in this EVM role, so we accept it. There is some tension between how generic we are and how fast we are. So we want it to still be generic, but we want it to be very fast, more than fast enough for use cases and the generic. And then there's a whole interaction of the speed and why. If we're generic, then users can optimize for speed and as optimizations come along, people can implement the new optimizations and the new crypto systems. So there's some interplay with this as well.
00:03:40.516 - 00:04:46.168, Speaker B: So who's to say? Today it might be a little slower, but as the optimizations come in, it will improve with time. And the whole idea is we want to have a renaissance of permissionless crypto innovation. And we know with what we have, with permissionless innovation, with things like DeFi and earlier CryptoKitties, things like this. And if we allow users to deploy it themselves to design the whole crypto system themselves, then we're hoping that there will be a whole renaissance and a whole blossoming of this whole ecosystem just based on adding this sort of EVM 384 project. So as engineers, there are trends that we have to be aware of, we want to design, looking forward to the future, we don't want to be obsolete. So the big trends in cryptography hardware and blockchain, this is very loose, this is a very high level. I'm not being very specific about anything, and maybe some of these things are controversial.
00:04:46.168 - 00:05:16.324, Speaker B: But one interesting thing I want to emphasize on this is that cryptography hardware and blockchain all interact with each other. They drive each. So I'll explain that as I go along. The first bullet point, fast crypto is designed with hardware in mind. There are examples, I'll give an example. The Blake hash function was based on some cryptography, some stream cipher that was designed with hardware in mind. The author of it said I designed this with hardware in mind.
00:05:16.324 - 00:05:39.864, Speaker B: And that's why it was fast, because they knew that they knew how the hardware works. They knew if they design it like this, it will be fast. And if it's fast, it's used slow. Crypto is unused. Fast crypto is good for everybody because people use it. And the most popular crypto in the world, the most used, I mean crypto in the world is the fast crypto. And of course there's some mathematical beauty to cryptography.
00:05:39.864 - 00:06:26.652, Speaker B: We can do this, this is possible, but it's so slow that nobody uses it. Maybe they will in the future when computers get faster. Another trend, the second bullet point is there are breakthroughs in zero knowledge. Snarks and Starks and others to point out a few, but we are in some sort of renaissance as well in zero knowledge and cryptography in general. And so there are interactions with these breakthroughs and with hardware as well in the third bullet point that is making these breakthroughs possible, because we can support hardware improvements, allow more expensive crypto. 30 years ago it would be too slow, ten years ago even it would be too slow. But now it's usable because hardware is fast enough.
00:06:26.652 - 00:07:28.672, Speaker B: And looking forward, as engineers, we don't want to be obsolete, so we want it to be reasonably generic. And another one is there's a growing need for cryptography on chain ZK roll ups is one example, but there are others. So these are all trends and the ethereum client complexity is growing. So this might be controversial to say diversity is shrinking and some people have gone as far as to say stop, freeze all proposals until we fix the diversity problem. The reason that they say that the reason diversity is shrinking is because client complexity is increasing and it's getting more and more difficult to implement the clients. So there are interactions with crypto and the demands and there's a tension between the demand of new crypto and ethereum stability. The diversity is important for the stability and the robustness of the system.
00:07:28.672 - 00:08:20.736, Speaker B: If one client goes down, it should be okay because there are other clients. But now there's a major tension and we have to be forward looking as well. New crypto systems, it seems like they're coming out every year or know there are breakthroughs and we anticipate more in hardware, there are co processors, FPGAs, quantum computers. Recently in the news, Was AMD buying Is in discussions to buy Z Links, which is an FPGA producer. As you know, intel already owns Altera, which is another FPGA producer. And maybe they want to have Know in computing we see GPUs as coprocessors for high performance computing or for machine learning. So there's a trend in this direction and that we're aware of.
00:08:20.736 - 00:09:16.720, Speaker B: And of course, quantum computers we have to mention for cryptography they're very relevant, but they're not here yet, at least at any useful calculations. And also WASM plays a story as well. It gives us nice guarantees and we'll talk about WASM soon. So at this point I want to give a history as well. We want to be forward looking with trends, but we also want to be backwards looking with history. There are lessons learned along the way and we wrote a nice history in our first EVM 384 post, in our first EVM 384 update, which is linked on this slide. But I just want to mention the high points and there are more details, there are more stories to be told that are very interesting, but I just want to touch on a few things that are especially relevant.
00:09:16.720 - 00:10:14.736, Speaker B: Some high points, some historical high points and some lessons learned. 2015 early Pre Compiles for EC Recover Chat Two Six Ripe MD ID so this was the mechanism, the pre compile was a mechanism for doing crypto that users can call on chain with their contracts. And you can talk about how they first came out in 2014 in a blog post by Vitalik and how EVM came about as well. We talk about that. And something interesting happened in 2016 sha one pre compile was proposed and then someone said well, do we need it? Is it possible to implement it in pure EVM? By impure EVM, I mean user deployed, just EVM opcodes contract and in the contract code it does this Shawan calculation. It implements the Shawan function, in other words. And it turns out, surprisingly, yes, we can do it in pure EVM.
00:10:14.736 - 00:10:34.992, Speaker B: So this is a success story. We don't need pre compiles for everything. We can do some things in pure EVM. It's not speed record, but it's fast. It's reasonably fast. It's more than fast enough for our purposes. As the years went on, we added more pre compiles, ECAD, EC Mall, EC pairing, Modixp.
00:10:34.992 - 00:11:25.580, Speaker B: These each have stories behind them, which you can read about. Modi XP has an interesting story that started with a proposal for RSA that got broken into five precompiles for Primitives for RSA, and then it ended up that only one was especially needed, which is Mari SP, the EC at ECMO. EC pairing is an interesting story about how this pairing, this BN 128 curve operations were needed and there was demand for it. And in 2019 something interesting happened. Remember in 2017 EC mall was needed because it's too slow to do on EVM, but that was challenged in 2019 with Wire strudel. It implemented fast EC mall in pure EVM. By fast I mean it competed.
00:11:25.580 - 00:11:51.936, Speaker B: We're loose. I'm not saying what fast is by gas cost. There's two questions is gas and speed. But wireshooter was what I mean by fast. But wireshooter was optimized for gas use and it was just about equal to the ECMO precompile. This is shocking. How can this be? We needed the precompile because it's not possible to do an EVM.
00:11:51.936 - 00:12:19.260, Speaker B: But no, that's wrong. We could do it in EVM, pure EVM, and there's reasons for it, if you understand the calculation that EC mall does. But it's sort of an interesting story. And also in 2019, EV one EVM one came out, which is a fast EV, one EVM implementation. Pavo showed us that we can do EVM fast, not quite as fast as WASM, but he closed the gap by a lot. And the gap is small now. Smaller, much smaller.
00:12:19.260 - 00:13:20.016, Speaker B: So this is some historical high points and some lessons learned. precompiles are controversial. There's a lot of pushback, there's a lot of discussion, there's a lot of discussions back and forth with client developers. And there are some other pre compiles as well that had more controversy. And one fun question to ask if you're an engineer, do we even need pre compiles? Can we deprecate pre compiles? I know it's a sort of aggressive and maybe dramatic question to ask, but maybe it's fun to think about what would a rule look like where we can deprecate them or where we can have user deployed? Perhaps that's what we might replace it with. So that brings us to and along the way, the WASM was one of the options in the hopes and I'll talk about WASM benchmarking. Now I don't have the URL GitHub.com
00:13:20.016 - 00:14:00.600, Speaker B: eWASM benchmarking, and I'll explain the chart as I'm explaining the text. So the chart really quickly, all the way on the right is BLS twelve pairing check. So it's evaluating a pairing equation in just an interpreter you can see how the dependent access is time in seconds. I don't know if people can see if the resolution is too small, but it looks like it's half a second in the interpreter. All the way on the right you can see it's 469 milliseconds. And all the way on the left is the rust native, 5.1 milliseconds.
00:14:00.600 - 00:14:42.650, Speaker B: So you can see there's a huge like 100 x slowdown for interpreters. So interpreters are too slow, no surprise. But then we discovered that all the way on the right, but look, just left of that, I'm sorry, the third and fourth. So just left of this interpreter are compilers and those are fast, but they're still six x slowdowns from the native. So you can't be lazy. Compilers won't solve all of the problems for you. So we have to dig deeper and understand what the problem is.
00:14:42.650 - 00:15:32.724, Speaker B: We profiled the BL twelve 381, and this, by the way, I should say it was from WASM Curves that's the project that generates the code that we were benchmarking in WASM. I should say WASM Why are we talking about WASM right now? It's relevant to EVM because it sort of motivates EVM because we have tools and we have implementations in WASM and we can use WASM to add an approximation to EVM. And it's important to the whole story, I think. So we profiled this bos twelve pairing check and we found that the bottleneck is in something called Montgomery modular multiplication. It turns out this is very popular to use this Montgomery modular multiplication in many areas of crypto. A lot of crypto uses it. There are other ways to do modular multiplication.
00:15:32.724 - 00:16:03.252, Speaker B: In certain cases there are optimizations, but this is a very popular one, maybe the most popular one. And so we did an experiment and the second one we call interpreter with big int native functions. So not all the way on the left, not the rest native, but the interpreter with big NUMS. We did it in 9.8 milliseconds versus about five. So it's a two x slowdown. We can do better, we think, but already we see that all the way to the right doesn't make sense.
00:16:03.252 - 00:16:33.988, Speaker B: Compilers? I don't know, not quite. But if we do some extra work, we can get performance that might approach native. And there's more to this story. These numbers can be improved for the native as well as for the interpreter with big int. But this tells the story that about EVM. A natural question is can we do the same thing in EVM? So that's where EVM 384 came from. One more comment about WASM.
00:16:33.988 - 00:17:20.152, Speaker B: WASM is sort of perpetually, almost done. There are features that we're waiting for and the MVP is already W three C put out the MVP. But it's sort of very basic and there are very important features that are not finished yet. And so WASM, I don't think we should deploy it yet because we're waiting for for example, interface types and reference types and some other proposals to be finalized that will affect the design of eWASM if it is chosen. But anyway, let's solve the problem. Maybe we can solve this problem based on our learnings from WASM with EVM. So let's do a similar experiment with EVM with these three opcodes.
00:17:20.152 - 00:18:12.312, Speaker B: We call them AdMod 384, submod 384, mole mod 384, and we believe that these will what we call cover all bottlenecks for BLS twelve 381 operations. We hope this isn't confirmed yet, but we're getting closer and closer. We'll talk about it in a moment. And we want to be generic as well. So it doesn't make sense for us to do domain specific, curve specific, modulus specific optimizations because then it's not usable by other people. We are towards this sort of blossoming renaissance of crypt, of user deployed crypto. We want it to be generic for other BLS twelve 381, but also 377, maybe Starks, which are heavy on a lot of crypto, is heavy on polynomial evaluation to verify Stark.
00:18:12.312 - 00:18:38.950, Speaker B: And the polynomial evaluation is just these operations. It's precisely these operations. We're also talking about other ones, some sort of algebraic hashing, things like this. So we don't think that these are very limited opcodes, these are very generic opcodes, in fact. And the EVM 384 might also be a template for EVM 378. The talk is almost done. I'm going to go through some progress that we've made.
00:18:38.950 - 00:19:27.616, Speaker B: But all the progress updates are listed in this magician, so you can click through yourself to get more details. I'm just going to be very high level. Is it feasible? There's a chart on the left is the same rust native, and then this middle one is the same WASM one that's like two x slowdown. And so our first iterations, you can see it's another two x slowdown from WASM with big NUMS, with big int host functions and it's not fast enough yet. We did a synthetic pairing algorithm. We talk about it, I don't have time to explain it, but it's sort of an approximation, it's an estimate of a pairing runtime because we do a similar amount of arithmetic. But there is potential.
00:19:27.616 - 00:20:12.016, Speaker B: The problem is there's awkwardness with the stack, with the EVM, there's just some things that are awkward. So we iterated and we kept iterating. And you can see our iterations. The independent access are the various versions, the dependent access is the milliseconds and you can see the version v one through v seven at a certain point. These are all different interfaces, what we call interfaces. So that means how the stack has to look, how the environment has to look when we call this EVM opcode, these EVM opcodes, and it turns out that we can do some things to make it faster and faster. So we went from much slower than two x of WASM or slower.
00:20:12.016 - 00:20:31.316, Speaker B: We tried these different interfaces along the way. We tried different languages. We started with Yule, and then we went to Huff. Huff. You remember Wire Strudel from earlier? The EC mole breakthrough. That was shocking. They used Huff, which is in EVM, you write sort of in this EVM assembly, but with macros.
00:20:31.316 - 00:20:54.940, Speaker B: So it's not as unforgiving, but you're very close. You're actually using the EVM op? You're writing EVM opcodes. And that gave another speed up. You can see from V One to V two, that was like close to two X. Then from V four to V five, we had another improvement with Huff, we had another, like, two X. And all of a sudden, all the way on the right is WASM, and now we're faster than WASM. This is shocking.
00:20:54.940 - 00:21:20.520, Speaker B: We were hoping that to match WASM with Big Int, but it turns out that we can beat it with a carefully chosen interface. And we settled on Interface V seven. This is all based on this synthetic. It's not the full pairing. We're using this sort of synthetic with something called an adjustment factor. But we want to start implementing. So that's what we did, the full pairing.
00:21:20.520 - 00:21:57.988, Speaker B: A big chunk of the pairing is the Miller Loop. You can think maybe half of the whole pairing algorithm is runtime is in this thing called the Miller Loop. It gets a little bit more complicated, but just at a high level. It's a huge chunk of the pairing. We implemented the Miller Loop from this library that I, I believe holds the speed record now called BLST Blast. But we simplified their mall FP two. They do some handwritten assembly machine code optimizations, which would be expensive using EVM 384.
00:21:57.988 - 00:22:38.480, Speaker B: So we used a more generic simplified version of it, of this Mall FP Two function, and our numbers agree. So we are correct with BLST. The numbers agree. Our EVM 384 Miller Loop and the BLST Miller Loop, they agree on the results after we change this Mole FP Two to be the same one. So we're very close. Correctness is still an open question, but we believe it seems to be that we're on the right track. And notice that our V Seven, we're still using the V Seven interface for EVM Three, D Four, but we have even better numbers than before.
00:22:38.480 - 00:22:55.476, Speaker B: So all the way on the right is our WASM with Big Int. Just left of that is our old synthetic pairing. And we went from 5.5 milliseconds now with our Miller Loop 4.7. So we're getting better and better, and we're approaching native. Now. There's a whole story to be told about native.
00:22:55.476 - 00:23:25.970, Speaker B: We're doing naive things. We're using some Azure VM that's mid grade. There are algorithms, there are optimizations that we're leaving out. But it seems that we can get faster and faster. And of course, maybe all these times can be halved once we do some tricks. And there are some other tricks that we can't do that you can do in native, but EVM 384 isn't generic, but we want EVM 384. So there's a tension with remaining generic, and I think we're okay.
00:23:25.970 - 00:23:57.644, Speaker B: If we're desperate, we can do these modulus specific or optimizations. Not even modulus specific, but just based on what type of modulus it is. We can do some optimizations, but we're not doing them yet, and I don't think we need them. I think we're reasonably fast, and we're fast enough, I think. So where are we right now? Finishing BS. Twelve 381 pairing. To justify we want to say that we want to make the statement we cover with EVM 384.
00:23:57.644 - 00:24:35.304, Speaker B: We cover all bottlenecks or bos twelve 381 pairing and we're pretty fast. We want to make that statement. That statement is close to being made, but not made yet. EVM three D, four EIP is being written right now. We are soliciting implementers. The pairing is one algorithm, but there are other algorithms to be implemented, and we are soliciting implementers advice. We are in discussions with teams and with the BLST people, for example, and with other people.
00:24:35.304 - 00:24:59.650, Speaker B: We are asking if they need this kind of thing, but we're also having an open call. We're soliciting feedback, ideas and implementers especially. It would be great to see this used. This EIP has a lot of support already, and that's where the talk will end. I will open for questions. I don't have the text window in front of me.
00:25:01.460 - 00:25:20.760, Speaker A: All good, Paul. Thank you so much. Excellent talk. I can give you some questions that have come up on the live chat. So, first one I have for you is, let's see, how difficult is it to write the low level crypto operations in EVM using the EVM three eight four, opcode?
00:25:21.260 - 00:25:53.740, Speaker B: How difficult? Oh, goodness. It depends on who you ask, of course. So they're asking me, it depends on your background in cryptography. It depends on your background in EVM. There are growing pains, of course. Once you overcome the growing pains, it gets easier, and it depends on the tools you're using. I think Huff is a great tool, but writing the code in Huff is tedious because the V seven, I didn't go into details about this interface, but we use something called packing, offset packing.
00:25:53.740 - 00:26:40.610, Speaker B: And if something changes with the offset, we have to go in and manually change it. So I have a generator written in Python. It's modeled after the JavaScript generator for the WASM Curves code that we used earlier in the talk. And this generator has been helpful because I just implement, for example, some small parts of the pairing, and then I can reuse them. So I'm generating the code in Python, the Huff code, and then the Huff code is compiled with the Huff compiler. So it's multiple steps, very awkward, and a lot of growing pains, a lot of struggling to debug it's. My least favorite thing, it's the bane of my existence, is going opcode by opcode and finding some bug or something.
00:26:40.610 - 00:26:46.850, Speaker B: So it's very painful at first, but as you go along, like with most things, it gets easier. That's it.
00:26:47.400 - 00:26:58.020, Speaker A: Understood. All right, I have another question, if you have the time, Paul. What are the blockers to saying this on Mainnet? And are there any security concerns?
00:26:59.960 - 00:27:16.716, Speaker B: What are the blockers? The finish of the pairing? It seems like we need to have a concrete evidence. We need to have a concrete here it is. You can't take this away. It works, it's fast. You can't take that away from us. So it seems like that's a blocker. We want to say that it covers everything.
00:27:16.716 - 00:27:52.384, Speaker B: And then security. Yes, there are security concerns, obviously, with a consensus system as big as ethereum, of course there are huge security concerns, but there is demand. And I want to answer this question. There are security concerns with the alternative. So I think this is a path of least resistance in terms of security. The operations we want to implement are maybe 30 lines of code, whereas if the alternatives if we want to do alternatives, perhaps pre compiles, it's much more than that. It could be thousands of lines.
00:27:52.384 - 00:28:04.650, Speaker B: I think it is. So I think that this is the most secure thing we can do if we are to do something like this. But yes, of course. That's it. No.
