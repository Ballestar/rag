00:00:00.330 - 00:00:32.386, Speaker A: All right, thanks for coming. My name is Daniel Wong. I'm the founder and CEO of Loopring. So today I'm going to talk about Looping 30, which use using zero knowledge proof to scale. So scalability is something we want to achieve, but not privacy. Okay? So Loopring is project that started back in August 2007. So we focus on one thing and one thing only, which is the alder based Dex protocol.
00:00:32.386 - 00:01:28.550, Speaker A: So, over the last year and a half, we have deployed three major versions of the protocol. On top of Ethereum, we introduced some cool features, including the ring matching, dual authoring to prevent front running, and some very cool fee models. Unfortunately, the product is not widely adopted. So we ask ourselves, why was missing in the current implementation? So I think it really boils down like, three issues. So right now, the user experience is not good. It's not an easy fix. Right? And one of those issues in this area is the trading the finality.
00:01:28.550 - 00:02:18.022, Speaker A: So for market makers, they really want to see their settlements got finalized as soon as possible so they can start submitting new orders. But right now on Ethereum, you have to wait for like 15 seconds or so to make sure the settlement is built into the blocks. But sometimes it takes really even longer, right? The second one. And the third one is even a bigger problem, right? So the throughput is so low, the gas cost is so high. I'm going to show you some numbers. So, our goal in 3.0 is to make sure we achieve the followings.
00:02:18.022 - 00:03:10.774, Speaker A: So, the settlement should be finalized as soon as possible. This finality is not actually the block level blockchain level finality. It should be like a centralized exchange level finality, so it can be reverted, but you are fairly certain that the settlement is done. And then we want to achieve higher throughput, lower cost, and then there shouldn't have any trade off in security. So we don't want to use side chains, other cool stuff to achieve throughput by sacrificing security. All right, so with the previous versions, this is the number, right? So we can put about 26 settlements in one Ethereum block. So you can do the math.
00:03:10.774 - 00:03:44.402, Speaker A: Right now, it's like less than two trades per second on the Ethereum mainnight. I think this is true even for our competitors, right? More or less. The cost is even a bigger problem right here. So it depends on the price of Ether. The cost is probably ten to $0.20. Right? Imagine when we have the bullish market, the cost is about 30 or even more. 20 or even more.
00:03:44.402 - 00:04:42.054, Speaker A: So with Looping 3.0, we really have two options. First is called with data availability. So what does that mean? So with onchain, data availability means any third party depends on the Ethereum blockchain can reconstruct the state of the DAX for any given moment in the history. So you don't really have to trust anyone, right? Because you can reconstruct the state, which is basically the merkel tree, then you have the way to generate the merkle proof, which will be used by anyone to claim the asset in the decks. So with unchained data availability, we managed to put 1800 settlements in one Ethereum block. So this means like 120 trades per second.
00:04:42.054 - 00:04:59.258, Speaker A: Okay. And the cost for gas is less than 0.2 US cents. This is assume that the price is 190. Right? Now it's a little bit higher, right? But it's not compared to $0.13. It's nothing. Right.
00:04:59.258 - 00:05:44.806, Speaker A: The other one is we turn off the onchain data availability. So we find another Dex operators, they can find another option to provide the data. For example, they find the auditing firm, say, okay, we are going to publish the data on a daily basis, or put it on IPFS, something like that. So there are some risks, right. For normal users, it's possible that they don't have access to the data in real time. And sometimes if the Dex operator do not really honor their promise, maybe user will not have access to the data at all. But if we turn this off, we can put like 7000 transactions or settlements in one Ethereum block.
00:05:44.806 - 00:06:04.154, Speaker A: So this is the current result. So the cost is even lower, right? It's about 0.5 cent. There are now off chain costs. So previously when we do 1.02.0, we put everything on chain. So looping protocol is basically a side of smart contracts.
00:06:04.154 - 00:06:54.914, Speaker A: Now we have off chain parts, right? We have the code to maintain the off chain merkle tree and to most likely, I think most importantly, we have some program called Prover that has to generate a zero knowledge proof. So we tried Amazon AWS with this 48 core Xeon processor with a lot of memories. So for a virtual block that has 512 trees, it takes less than an hour to generate. So the price is $6 per hour. If we use some cloud service in China, this price is going to be like half like $3 per hour. Right? Now, with AWS, the price or the cost to generate the proof for each settlement is less than 0.9 cent.
00:06:54.914 - 00:07:25.690, Speaker A: Right? This is irrelevant. This has nothing to do with the Ether cost. It's just purely the cloud service cost. So if we combine those numbers together, we get the final throughput and cost. Right? So it's 120 with data availability one cent. And this turn the data availability off for 50 and still less than one cent. I think it's pretty good number.
00:07:25.690 - 00:08:17.062, Speaker A: I mean, especially with data availability, that means the protocol is as secure as the Ethereum itself, right? There's no trade off in security at all. And if we find a trustworthy big name to support DAX by auditing the data availability off chain, we can achieve even higher throughput. So we are pretty excited about this. Okay, so this is the design. So the idea is really simple, very similar to GKE roll up. So basically, you move out most of the data off chain, most of the computations off chain into a merkle tree, a single merkle tree. So the merkle tree has three parts.
00:08:17.062 - 00:08:59.974, Speaker A: The top part is the account. So you have multiple accounts as the leaf. Underneath each account, you have multiple tokens, and under each token, you have multiple orders. Right? So this is a single sparse merkle tree that you have to update off chain, right? By updating off chain, I mean, you have to take care of those requests from either on chain or off chain. For each request, you do the calculation to make sure the route is eventually updated. Right now, the looping 3.0 supports the following six different types of requests.
00:08:59.974 - 00:09:39.234, Speaker A: But actually, we simply need to support these three to make the decks fully functional. So the off chain withdrawal, order cancellation, and transfer are really optional. So the way we handle those requests is to batch those requests together into block. So this is like virtual block. It's not the block of the ethereum. So those virtual block got processed as a batch to update the merkle tree. And after this block, we have a new merkle route for the block.
00:09:39.234 - 00:10:18.294, Speaker A: It's the Post processing merkle tree route. We then submit this route, which is 32 bytes on chain. So that's the only data with some metadata. But this is the major part of the data that need to be submitted on chain. So the computation is almost zero. And we just need to pay the guys for those 32 bytes, not bits sorry, 32 bytes and then off chain. When we update after we process the requests, update the merkle tree, we get a better sense of how we updated those merkle trees.
00:10:18.294 - 00:10:48.534, Speaker A: So those data are going to be formatted into something we call receipts and use those receipts. We run the prover to generate the final proof. Okay. And then we submit a proof. So I'm going to talk about the proof verification later. But when we bash those requests, there are really two ways to do that. The first way is to group those different type of requests into blocks.
00:10:48.534 - 00:11:38.410, Speaker A: So those, like, virtual blocks, it's not the Ethereum block. It's our Dex block. You bash those requests based on the time they come, and then you process them. But this turns out to be really bad because we learned the circuit, the zero knowledge proof related computation is really not good at handling the dynamic numbers of requests. It's not really good at handling different types of requests because that will make the circuit really big, and the proving time is like, multiple times than it should be. So this is a terrible design. We tried actually, this is what we did as a final result.
00:11:38.410 - 00:12:14.018, Speaker A: So we actually batch requests of the same time together, same type together. So that the circuit to handle this type of request. Has nothing to do with the logics that handles the other type of request. So by doing this, the time to generate a proof is minimized so we can effectively reduce the proving cost. So this is the way we chose. Okay. And the second point is that circuit is not really good at tunneling the dynamic arrays.
00:12:14.018 - 00:12:57.270, Speaker A: So we have to only provide a fixed size of different blocks for, let's say, for this settlement, right? So we can put like, 32 requests in one block or 62. You cannot put random numbers of blocks here. So request in one block. If we don't have let's say we have only 120 requests, then you have to zero pad, like, eight default requests there to make 128. So the circuit will iterate 128 times. It cannot iterate a dynamic number of times. Right.
00:12:57.270 - 00:13:34.290, Speaker A: So this is some restriction of the circuit. I don't know whether this is going to be like, a solution to fix this. If we have a solution, then we have one single type of block. Right? Now, for this type, we have different sizes, right? All right. So as I said, it turns out for East DAX now we have a virtual blockchain on top of Ethereum main night. So, as I said, we don't use, like, setchains. So these are actually on Ethereum.
00:13:34.290 - 00:14:29.778, Speaker A: The data for each block is 32 bytes with some metadata very small. So you don't know by looking at those number, you don't know how many requests are included into this block because no matter the number, regardless of the number of requests, this size is fixed is very small. Right? So in theory, we can even put more requests in a block. But there are some restrictions in Ethereum that don't support that many very large batch of requests. So this is the only data very, very small. So if we turn on the data availability for off chain settlement, this green block, you have to provide extra data to make sure everyone can use this data to reconstruct the merkle tree. Right.
00:14:29.778 - 00:15:16.834, Speaker A: For onchain deposit withdrawal, you don't have to do that because each on chain already. So the data is available on chain. So only off chain requests needs to provide like, actual data for data availability. And this really has something to do with the number of requests. So the more requests you have, the more data you need to put on chain. All right, so when the block has been submitted, after block submitted, you can run the approver. Once approver is ready, you can submit a proof to a block and the proof is going to be verified on chain using the verification key.
00:15:16.834 - 00:15:51.946, Speaker A: So once the proof is verified, this block is going to be that the status is changed from committed to verified. Okay? And if a block is verified and all the previous block has been verified, then the block becomes finalized. So finalized means this block cannot be reverted at all. So it's final. It's truly final. This is like blockchain level final. So previously I said that we want to achieve the settlement finality, like instantaneously finality.
00:15:51.946 - 00:16:28.314, Speaker A: But that finality. It still can be reverted. It's like a centralized exchange level finality. But here, once we got a block finalized, it's finalized. So it also means if, let's say this is the withdrawal, right? If the withdrawal block is finalized, that means people can actually take money from the smart contract. All right, this is like finalized. So what we can learn from this so we can always commit blocks in sequence, right, one by one.
00:16:28.314 - 00:17:08.446, Speaker A: But the proof itself can be submitted out of order. You can submit proof for him and then for him and then for him. So it can be in different orders. That means generating the proof can be paralleled because it takes like hours sometimes to generate a proof using not that powerful PC. So if you can parallel the proof generation, you can use AWS to do a lot of work in the same time. So this is very important for us to really, truly scale the DAX. Otherwise the onchain part is scaled.
00:17:08.446 - 00:17:45.700, Speaker A: If the off chain part is not scalable, then it's not truly scalable. Right? So this is what we have done. And then we also applied some delay, the max delay between approved submission and approved verification. Sorry, the block submission and approved verification. So there's a maximum like 2 hours. I can't remember the exact number, but during that time, after like 2 hours, if you still don't have a valid proof submitted for a block, then you got penalized. The tax operator got published, sorry.
00:17:45.700 - 00:19:00.890, Speaker A: And their stake may be partially or even fully burned. We also want to enforce the Dex operator to handle the on chain deposit and withdrawal requests because that's really important for user to be able to deposit and then their balance got updated in a timely manner, right? And for withdrawal, if you submit a withdrawal request, you certainly want to get the money out of the decks in a timely manner. So we end up having two very small it's like on chain deposit withdrawal section. It's not really the section, but it's kind of like that. So they are hashed, so they linked together to make sure later when we process those events, the data modification is really minimal. So in general, we also applied max request A. So if a request is submit on chain and the Dex operator don't really handle this request within this time, the Dex operator is going to be punished.
00:19:00.890 - 00:20:06.682, Speaker A: So there's a time limit to avoid Sable attack. We also have applied another restriction for the number of pending on chain requests. So user cannot submit on chain requests if there are already too many requests. Otherwise one bad thing may happen is that a lot of users submit a lot of very small, tiny on chain requests. And the Dex operator don't have time to do the settlement. All they need to do is to handle on chain requests because there's a punishment if they don't do that, right? So this is to avoid that kind of attack. Okay? So if something bad happens, if the Dex operator don't really fulfill their duty by processing requests or they submit some bad data on chain, which is not valid verifiable then the Dex will go to a withdrawal mode, which basically tells the Dex you are broke.
00:20:06.682 - 00:21:28.570, Speaker A: You seize operation. You have to return all the money back to your users before you can get all the stake back. If the Dex operator don't really care about the stakes, they will do nothing. And after a certain amount of time, anyone can, because we have data availability on chain, anyone can reconstruct the merkle tree. And then by providing the merkle root, you can also get your money back, right? So in the future, we are going to sponsor someone to build a tool to reconstruct the merkle tree based on the on chain data availability to help users to get their money back if the Dex operator is doing something evil. Okay, we also introduced a maintenance mode because we have so many different type of restrictions to force the Dex operator to process user events in a timely manner. If the Dex operator wants to upgrade their backend, they will say, hey, I need to stop, right? So this mode is just for Dex operators to do something to maintain their back end, to stop operation for a certain amount of time, so the DAX operator can buy the maintenance time.
00:21:28.570 - 00:22:10.662, Speaker A: So it's not free. So the longer your operation is stopped, the more you have to pay. I think this is very necessary for DAX operators because they need time to upgrade their systems. So in general, looping 3.0 inherits a lot of cool features that I haven't even talked about from our previous versions. Like other aliasing, like antifronron running, partial order matching, et cetera, there are a lot of cool stuff. We also introduced a trading key.
00:22:10.662 - 00:23:03.190, Speaker A: So that means your order don't really need to be signed with your private key, your Ethereum private key. So once you create a Dex account on some exchange, when you do trading, you can just give your trading key to whoever is managing your account, right? You don't have to give them the private key of the Ethereum account right now, I would say this is now still not production ready. A lot of things can change, can be optimized. So with zero knowledge proof, especially Tk Snarks, we need a trusted setup. This is not good. So hopefully we don't need to do the trusted setup. So thanks to Sonic so in the future, maybe we can just share a trusted setup among all the DEXes on Ethereum.
00:23:03.190 - 00:23:54.470, Speaker A: Right now, we have to verify every single proof for each block, which cost half million gas, right? It's pretty expensive. So maybe we can generate Starks for Starks to make it recursive. So we can probably only run the Verifier on chain for maybe every thousand blocks to reduce the gas. The other one also what we're looking forward is the cheaper storage on blockchain. As Vitalik has acknowledged. Right now the storage price is too high, right. Hopefully Ethereum will reduce the cost so we can put even more settlements in one block.
00:23:54.470 - 00:24:38.630, Speaker A: I think the most possible optimization is like GPU enabled proverbial algorithm, right. If we make it run on GPU, then it's going to be a lot more cost effective. So a lot of things can be done on top of 3.0. So right now we are making the 3.0 code really production ready. I think we are still not ready to compete with finance, like the top tier sexes, right. But to compete with small ones or even the mid sized ones, I think I'm pretty confident because this is really secure.
00:24:38.630 - 00:25:04.846, Speaker A: As a Dex operator, you don't have to invest a lot of money in internal security measures, right. So it's a big win. And for normal users, this 3.0 user experience is really similar to the centralized exchanges. You have deposited withdrawal, you have your trading keys. It's like the trading password on finance. Right.
00:25:04.846 - 00:25:44.666, Speaker A: So the user experience is much similar to finance. So this is looping 3.0. We have open sourced our code like three, two or three weeks ago. The smart contract has not been securely, had not been audited yet, but we are working on that. So our plan is to launch a beta version maybe later this quarter or next quarter. So we really look forward to that. So this is 3.0.
00:25:44.666 - 00:25:51.066, Speaker A: You guys have questions? Well, you can go ahead.
00:25:51.168 - 00:26:05.098, Speaker B: Very high level questions. It looks like they're not like side chains, but your merkel tree, like all of that data you're storing off chain and then you commit, you just commit patch.
00:26:05.274 - 00:26:05.998, Speaker A: Yes.
00:26:06.164 - 00:26:11.390, Speaker B: And then these are very basic questions. Do your protocol to enable other people to operate Dex.
00:26:12.950 - 00:26:41.786, Speaker A: That's true. So we have like a parent protocol contract. So use that one you can call a function called create DAX. Then boom, you have a new DAX. So everything is yours and you are responsible to you can choose to stake some tokens there, say, hey, I have something to lose, trust me. Because if I do something evil, then I lost all my stake, right? Yeah. So basically we don't want to run the single best DAX.
00:26:41.786 - 00:27:06.120, Speaker A: We want to open source this. We want to help you guys to run DAX. Yeah, but we will probably also run the DAX, but it's not like exclusive. So the business model is probably different from like stock tax or something, right? Yeah. One more.
00:27:08.970 - 00:27:17.400, Speaker B: They provide some privacy. How much privacy do they provide? Because I know you're getting like approved on chain at the end.
00:27:21.630 - 00:27:48.720, Speaker A: Well, we use Snarks for scalability, not privacy with data availability, everything is available on chain. All the transactions, all the settlements, you see them, the data on chain. So it's as secure, as transparent as the previous versions. Without data availability means you can always request the data off chain, but you should have access to all the trading data. So there's no privacy here.
00:27:49.730 - 00:27:51.130, Speaker B: You guys have one more minute.
00:27:51.210 - 00:28:11.320, Speaker A: Sure. Thank you. Yeah, no privacy. Privacy is not our focus. And we even think privacy may introduce some regulatory issues here if we want to treat security tokens in the future. So this is not related to privacy at all. Yeah.
00:28:11.320 - 00:28:19.540, Speaker A: All right. So that's it. Thank you. Thank.
