00:00:00.410 - 00:00:25.970, Speaker A: This is really going to be exciting. Coming up, just a few things. We're going to have a talk by Vitalik Buterin, co founder of Ethereum. On a recent post he talked about on a collusion. Then we'll have our sponsors give a few words. And after that, I'll be back up here to give you some more information about the logistics for this weekend. So with that, please give a round of applause and welcome to the stage, Vitalik.
00:00:30.670 - 00:00:54.670, Speaker B: Thank you. Oh, cool. It's my face. Yeah. So today I'll be talking about collusion. So to get right into things, there's been a lot of interest recently in things like decentralized governance. DAOs.
00:00:54.670 - 00:01:42.526, Speaker B: You see Moloch Dao here, Gitcoin Grants, the ETH trader donut thing, some Chinese platforms doing experiments and tokens for content curation and rewarding content. And there's a lot of these different projects that are just appearing everywhere in the ecosystem, right? And on the one hand, this makes me really happy to see this kind of experimentation happening because the use of this mechanism design and experimenting with incentives and new kinds of institutions is one of the big things that I've been excited about people using Ethereum for since day one. And it's great that things are finally happening. Yay. Molokdao. Yay. Gitcoin Grants.
00:01:42.526 - 00:02:48.402, Speaker B: Yay. All of these things so good. Now, on the other hand, there's a lot of challenges involved in doing these kinds of things. And recently, over the last year, we've seen some of the pitfalls come into action, right? So on the left, we have a situation that happened on the EOS blockchain about a year ago. So basically there was this scandal where they had discovered that a bunch of the EOS block producers were basically agreeing to vote for each other and paying each other to vote for each other. And there was this kind of cartel of these fairly well connected block producers that were basically supporting each other and kind of cementing their control over the ecosystem. And on the right side, we have one of the recent Aragon votes, and I believe this was the vote where they were voting whether or not to basically forbid themselves from supporting polkadot.
00:02:48.402 - 00:04:16.100, Speaker B: And basically what happened here is that, well, no one but the great majority of no was just one guy. So bribes and plutocracy are probably two of the big issues that you can see with decentralized governance systems and with online content incentivization systems, you see a lot of the same effects. And I'll talk a bit about why it's kind of, unfortunately quite challenging to create systems that avoid both of these fairly nasty consequences. So here is a simplified summary of something that a lot of people try to do, right? So a lot of people try to say, oh, I am going to create a decentralized platform for incentivizing content creation, right? So I'm going to come up with some kind of source of income. And this source of income could be just advertising, could be just pumping an ICO token, could be whatever. And coming up with a reasonable and actually sustainable source of revenue is a separate problem. And then they want to take that revenue and basically come up with a mechanism to distribute it to people who create good content, right? So this could be articles, it could be code, it could be documentation, pretty much anything.
00:04:16.100 - 00:05:07.886, Speaker B: Now what kind of mechanism are you going to use to actually kind of figure out which content creators should be rewarded how much, right? So this is a common scheme that often gets implemented. So basically you have users and users have coins and every user during every period. And we'll think about the concept of a period abstractly. Like it could be 1 second, it could be a block, it could be a week, it could be anything, right? So during each period, every user has the ability to make one upvote. Or it could be that they have the ability to make many upvotes. The math works the same way. If a user has N coins during some period, then whoever they give the upvote to gets a reward of N times k, right? So basically you have the ability to tip people, but there's a limit to how many you tip.
00:05:07.886 - 00:05:59.934, Speaker B: Or possibly if you make many tips, then your kind of allocation gets split between all of them. And if you tip someone, then it doesn't cost anything to you, but it gives them some money, right? So it's just voting on how much money the recipient should get. And it's simple for every vote, if you vote with N coins, they get N times k for some constant k. So here is a challenge with many of these systems. Well, basically any system that works in this way, as written, the optimal thing for a user to do is to just make a post and send the money to yourself. And that's it, right? So it's optimal to send the reward to yourself. And if you are willing to send the reward to someone else instead of sending it to yourself, then you're basically giving that other person the reward that you would have gotten.
00:05:59.934 - 00:06:37.840, Speaker B: So if you're willing to do that, then why wouldn't you have been willing to just donate the money to the guy even in the absence of the mechanism? So if it's optimal to send money to yourself, everyone sends money to themselves. The system just collapses into this equilibrium where everyone has an interest rate of k per period. And that's basically it, right? And the system just becomes useless. So everyone following so far. Who's not following? Okay, yay. Congrats on raising your hands. No, thank you.
00:06:37.840 - 00:07:34.014, Speaker B: No, it's good. People should raise their hands more. Don't be sulky. So here's one way to patch this problem, right? So we have this mechanism where you can vote on just pieces of content that other people create and if they get votes, then they get a reward. So instead of making the reward just a linear function, just be proportional to the number of coins held by people that vote for you, we're going to make it be a super linear function, right? So what that means is that let's say for example, if $100 of token holders vote for you, you might get $0.01. If $200 of token holders vote for you, instead of getting two cent, you might get $0.03. If $1,000 worth of token holders vote for you, you might get $0.50,
00:07:34.014 - 00:08:24.306, Speaker B: right? So the number goes up, but the amount that you get per dollar goes up, the more dollars you have. Now you might want to ask, well, why do people do this? Right? So the idea basically is that this subsidizes voting for posts that are popular more than it subsidizes voting for yourself, right? So if you have $1,000 of tokens and you have a choice, one choice is that you just make a post and vote for yourself. You're the only person voting for your post. And let's say you would get $0.10. But then the other option that you have is you vote for some other post that you think is actually good. If you think it's actually good, then many other people probably also think it's actually good. So there's probably many other people donating to it.
00:08:24.306 - 00:09:26.530, Speaker B: And so if the function is super linear, then that means that if more people already donated, the extra amount that you would add to the amount the poster gets with every dollar that you vote is going to be higher, right? So if you vote for yourself, it might go up from zero cents to ten cents. If you vote for some other post that's actually good, it might go up from eighty cents to ninety five cents or two dollars to two dollars twenty. Right? So there is a benefit to voting for things that other people vote for. So this is interesting and you can kind of see how it improves on the status quo, right? Basically your choices are give ten cents to yourself or give 20 or thirty cents to some other post. And so instead of it just being kind of donating, you're sort of donating at a three to one ratio, at three to one leverage. So you can see how this tries to improve things. Here's the problem with this approach.
00:09:26.530 - 00:10:26.226, Speaker B: First of all, it subsidizes plutocracy, right? So what this means is that wealthy cartels, so people that have lots and lots of money, raise your hand if you're part of a wealthy cartel. Okay, good. So as a proud member of a wealthy cartel, you can gang up with your other friendly wealthy cartel members and you can just throw a bunch of money on just a fake post that doesn't do anything. But you'll have so much money that you have basically as much money as that you throw on the post as tens of thousands of people legitimately voting for a post ordinarily would. And so basically, you give yourselves money at the same three to one ratio, right? So if for a normal person, if they vote for themselves, they would get more money back at a ratio of say, 0.1% per period, you might get 0.3% per period.
00:10:26.226 - 00:11:17.970, Speaker B: So you, as a proud member of the plutocratic class, get a higher interest rate than everyone else. Yay. Now so this is one problem, right? So wealthy cartels get the full benefits of voting for themselves, everyone else doesn't. The second problem is it can still get circumvented by bribes, right? So basically, if you make a post, then what you can do is you can bribe other people and you can tell them, if you vote with $1,000 of coins for my post, then I am going to give you $0.15. Now, if they had just voted for themselves, they would have just given themselves $0.10. So your bribe is a better deal for them, right? They vote for themselves, they get $0.10. They vote for whatever you tell them to, they get $0.15.
00:11:17.970 - 00:11:35.402, Speaker B: So they'll do that and then you get a lot of people voting for you. And so for every one of these thousand dollars that vote for you, you might get a total of $0.30. So you get $0.30 times whatever number of people you bribe, pay $0.15 back to them and you get $0.15 pure profit. Yay.
00:11:35.402 - 00:13:00.394, Speaker B: Bribing are Bribing attacks realistic, right? Actually, let's take a poll. Let's say there was some carbon vote happening on some hard fork and someone offered you a bribe. And they would basically say if you stake Ether on supporting this hard fork, I don't know, let's say it's like issuance reduction or something, then for every thousand ETH that you vote, they would give you a bribe of one ETH. How many people would take the offer? Some people would see what if it's an issuance increase? How many people would okay, see? Still a few, right? So it seems you can kind of see why some people think that Bribing attacks are not especially realistic. Because people think that they're kind of good citizens that are not going to be susceptible to them right now the problem is that, well, it doesn't have to be advertised as a Bribing attack. What you say is, oh, here is a staking pool and if you stake for in my staking pool with your 1000 Ether, then I will give you one ether. So who here will join the staking pool? There we go.
00:13:00.394 - 00:14:13.166, Speaker B: See yay. This is basically what people did, right? So this is a thing that happened in Lisk a couple of years ago. Every member of the Lisk elite except the China delegate, for some reason, must share 25% of his or her forging Lisk to the voters every week. So every member of elite must vote for other members. You see where this is going, right? So these things definitely exist and they can definitely systems can very easily collapse into these kinds of equilibria and it's often pretty difficult to prevent it. Now, can we try to mitigate plutocracy with identity systems? Right? So one question you might ask is, well, if we go back to the mechanism where if you donate or if you vote on some post, then that post gets more money for your vote the more other people already vote for it. So we go back to that mechanism and we try to get this benefit that if you vote for something that's actually good, then lots of other people vote on it.
00:14:13.166 - 00:15:13.374, Speaker B: So you get this kind of higher leverage and we try to make it actually work and we try to make it work in a way that's not plutocratic. By having an identity system, right, by attempting to kind of detect who unique humans are. And instead of the formula being based on the total number of coins, we make it be based on the total number of humans. Now, if you take this mathematically to the logical conclusion, then you basically get quadratic funding, aka liberal radicalism and aka clr, which is what Gitcoin is doing already. So it's a very reasonable path. Identity systems are difficult. So on the left here, we have a guy who basically has a whole bunch of phones on a rack and all of the phones are constantly getting charged and all of the phones just have software running that just keeps on pretending to click and kind of automatically participating in various applications.
00:15:13.374 - 00:16:11.494, Speaker B: So you can do this stuff, right? You can try to just kind of gather up a whole bunch of identities in some way and you can just run the software on a bunch of machines and you can just kind of pretend to be a community yourself, right? So you can try to find some way to gather up a few thousand identities. Then you start voting for the same posts. And if you have enough people voting for them, then you get access to the same kind of plutocratic benefits that you were able to get before when we were talking about systems that were just based on money. Now on the right we have this wonderful website, Buyax.com, that's B-U-Y-A-C-C-S where you can just go and buy Google accounts and you could go and buy Twitter accounts, you could go buy Reddit accounts. So that's great. Now I checked and GitHub accounts do not seem to be available on Buyx.com
00:16:11.494 - 00:17:34.050, Speaker B: so far. So Gitcoin grants is safe for now. There's definitely people selling Gitcoin grants on the dark markets, right? Or sorry, selling GitHub accounts on the dark markets. Basically there are very specialized and highly professionalized channels for these things to happen and people are doing it, right? There's just people that bought up thousands of accounts and there's people that are just pretty much make it their job to sell fake crowd engagement. How else do you think the shitcoin people have more Twitter followers than we do? Weirder approaches, right? So let's say we're not happy with GitHub accounts or reddit accounts because they can get easily attacked. Well, there's been a bunch of really interesting and crazy work that's happened fairly recently about trying to verify identities in a way that's more kind of local and decentralized, right? So on the left there's this concept of pseudonym parties which is basically this standardized way for people to get together in person and attest to each other's status as a real human being. TM.
00:17:34.050 - 00:18:47.242, Speaker B: And they would just go meet up together in one place, have these parties sign each other's keys, and you could broadcast these messages to a blockchain, and you can through this real world community that would be seeded. From some kind of set of trusted identities, figure out a list of people that corresponds to kind of real people in a way that seems to be fairly difficult to exploit. So this is one interesting approach that people have been thinking about. Another interesting approach that I've been seeing people doing recently is making token curated registries. So you can just apply to be classified as a real human and token holders vote on how human you are and either you're human or you're in the list or they don't vote for you and then you're declared to be a bot. So there's experimentation happening around this. If you haven't come up with ideas for hackathon projects, then trying to come up with some kind of medium secure way of just coming up with lists of probably unique human accounts is definitely an interesting project that I would recommend thinking about.
00:18:47.242 - 00:20:47.434, Speaker B: Because if you create a list that even has medium security, where the cost of an individual getting multiple accounts is at least significantly harder than the cost of going to this website and getting a bunch of Twitter accounts, then that's something that would be really valuable for things like gitcoin clr, things like these content incentivization tools and all of these other things that people are trying to do. So that's one thing that you can do and you can combine together decentralized approaches. You can try to do centralized approaches, things like government ID verification, phone number verification, or whatever. And the goal is to basically we're never going to get anything that's perfect, but we want to try to kind of push our way up the security level to the point where these identities are strong enough that you can do some interesting things without your application just completely being taken over by attackers the moment they decide they want to attack it. So this is one thing that we could work on, right? So that's about identity issues. Now why is avoiding bribe and plutocracy attacks and really bribe attacks specifically so difficult? Right? So it seems like for a lot of these applications, especially things that have to do with public goods, things like governance, things like incentivizing internet content, all of these things. It just seems so hard to create mechanisms that can avoid bribe attacks when it seems relatively not that difficult to create mechanisms even for things like blockchain consensus, right? Creating safe and secure mechanisms for incentivizing public goods seems to be an order of magnitude harder than creating proof of stake mechanisms.
00:20:47.434 - 00:22:19.850, Speaker B: Now, why, right? What's so weird and difficult that's happening over here? So cooperative game theory is hard, right? Now, people talk a lot about economics making unrealistic assumptions and often people talk about things like perfect information and perfect rationality and how certain kinds of mechanisms break down if those things aren't perfectly met. But there is one way in which one big assumption that economics and game theory often make about the world, which is actually even more horribly broken and false, that people just seem to still continue to take seriously. And that assumption is basically non coordination. It's that the world is split up into discrete agents, each of which are exclusively thinking about their own incentives. Now, you might think that, well, that's just a worst case scenario. If people can cooperate, then isn't that good? That will give you even better outcomes than you get if people were selfish. It turns out, though, that even though everyone in the world perfectly coordinating with each other would be great partial coordination situations where some groups of people can coordinate better than others and you have these mechanisms and people can coordinate to exploit mechanisms actually gives you worse results than if at least sometimes than if communication between people was completely impossible.
00:22:19.850 - 00:23:59.690, Speaker B: And this is definitely this weird counterintuitive thing, but the math basically says it, right? So there's this branch of cooperative game theory that has to do with taking seriously the possibility that subgroups, groups within the group of participants are allowed to communicate and coordinate and advance their own interests together. So in standard game theory where you have a bunch of agents and every agent makes decisions separately, every game has an equilibrium and it's possible to engineer games that have equilibria that target a very wide variety of outcomes, right? So there's things like second price auctions, generalized vicar equal art groves auctions, there's mechanisms for incentivizing contribution to public goods, all of these things, blah, blah blah. And if you look at the math and if you take all of the assumptions, then they work well in cooperative game theory. So in this version of game theory where groups of people are allowed to collude and advance their interests together, it turns out that much more instability is the norm, right? So on the bottom right, I have this example which is this majority game that basically says if you could get together a majority, then you can grab the entire reward and you can distribute it among yourselves like as you want, right? So you can think of it this as being a kind of very crude representation of say, many kinds of political processes. So at the beginning we'll start with a fair division. We have three players and each one of them gets a division of one third one. So you have one third, one third, one third.
00:23:59.690 - 00:24:37.318, Speaker B: In the next round, A and B get together and they're going to say, hey, how about we exclude C and then we're going to go up from a third to a half. So they do that and then in round two they both have a half. This outcome is better for A and B. So A and B cooperate to make it happen and C is left with nothing. Now in round three, A gets even more greedy and A goes to C and says, hey, have you been feeling oppressed lately? Well how about you joined an. Even you were cartel with me. I'm going to get two thirds and you are going to get one third, which is still better than zero.
00:24:37.318 - 00:25:04.154, Speaker B: And we'll cooperate to make this happen. A and C are two people and they get together, they make this happen. A has two thirds. C has one third. B is loft of nothing. In round four, B comes along and says, hey, C, how about you know how A is cooperating with you? Well, I can also help you feel not oppressed. And unlike that nasty evil A, I'm not going to take two thirds.
00:25:04.154 - 00:25:55.198, Speaker B: Only want one third. So your reward goes up. So how about you cooperate with me instead? So now B gets a third, c gets two thirds, and A is off to nothing. Does anyone here want to guess what round five is going to look like? Hint it involves a feeling oppressed. So basically so basically in these game theoretic environments where co op cooperation and kind of partial coordination are possible, you do get more instability, right? And this fact kind of manifests itself in many ways. So collusion in public goods funding, right? So let's suppose that there's some public good. So this public good could be even just writing technical documentation, writing some piece of software.
00:25:55.198 - 00:26:59.926, Speaker B: It could be cleaning up the environment, could be anything. Now suppose that there is a community of 10,000 people. And suppose that we'll kind of make a mathematical model where for every $1 that gets spent on the public good, each one of these 10,000 people would get a benefit that they value at one over $1,000. So $10 of total benefit, right? Now who here thinks that it's better for everyone if this public good gets funded? Okay, so still need to explain better, right? So who here is ideologically opposed to public goods? Okay, so basically, let's suppose that each of these 10,000 people puts in $1, right? So each of these 10,000 people is going to put in $1. So there is a total of $10,000 that gets spent, right? So each of these 10,000 people would benefit 0.1 per one dollars. So we're going to multiply 0.1
00:26:59.926 - 00:28:22.882, Speaker B: by 10,000. And so each of these 10,000 people get $10 of total benefit, where they each spend one dollars. So who here thinks that this is a good deal? Okay, so here's the problem, right? In reality, we don't have a list of public goods that get handed down to us from the gods of Satoshi that we know we have to fund, right? We don't even know what the public goods are often. So let's say there's something that's X and we don't know is it a real public good or is it a fake thing pretending to be a public good? So suppose that we have a game, an economic mechanism, and you could think of this as being like markets, voting like anything in this category where each individual can influence how much money gets put toward X. And individuals have the ability to make two signals. One of their signals causes X to get one more dollar, and the other signal causes X to not get one more dollar, right? So we can say that, let's say the cost of making a signal that causes the spending to go up by one, if there is a cost, right? It could be costless, so it could just be a voting mechanism. But if there is a cost, the cost can't be more than 0.1
00:28:22.882 - 00:29:26.946, Speaker B: because 0.1 is the amount that each individual gets from one more dollar being spent on the public good, right? So if, for example, the game that we're talking about is just giving individuals the ability to donate money, then the cost of giving, of giving X one dollars to an individual is one dollars. So nobody's going to do it. But if we have one of these games that we talked about for things like incentivizing content, then maybe we can set one up so that the expected cost is 0.1 and then people would do it. But then here's the problem, right? If we have this kind of game, then a fake public good producer, someone who's producing something that's not a real public good, could just bribe people $0.2 to support them, right? So basically, in order for these mechanisms that determine whether or not a public good gets funded or how much to work, people need to have the ability to kind of contribute at really high leverage.
00:29:26.946 - 00:30:08.994, Speaker B: But if you give people the ability to contribute at really high leverage, then someone can bribe them. People following so far, great. So plutocracy is also really hard to build or to beat, right? So let's say you do not have identities, so all you care about is money and how much money people have. Then a wealthy individual with 10,000 accounts or with just a lot of money, so think of him as a lot of money. Split up between 10,000 accounts could submit a fake public good. And this fake public good would just give money to themselves. They would pay whatever the fee is to kind of signal that this thing is a public good.
00:30:08.994 - 00:31:24.202, Speaker B: And if it's less than 0.1 per unit, so less than $10 in total, they could just give themselves $10,000, right? So in any situation where a legitimate public good would get funded, in any situation where the leverage is kind of high enough to overcome people's selfishness, if the thing is actually legitimately a public good that serves a distributed community, then a single wealthy individual can just pretend to be an entire community and exploit the thing to hell. Are people following so far? Okay, so basically, if a system is secure against either Bribing or plutocracy, then it seems like the system just can't fund genuine public goods. And if it can funds genuine public goods, then the same kind of leverage that allows it to actually fund public goods also allows it to be horribly exploited. So this is hard, right? So two ways to resolve this. One of them is collusion resistant games. And even though making games that are collusion resistant is harder than making games that are not collusion resistant, it is still possible, right? Even ethereum's proof of stake is a fairly collusion resistant game.
00:31:24.202 - 00:32:13.766, Speaker B: Like there is no way for people to kind of collude together to just give themselves more money. And it's also a game that just listens to how many coins you have. It doesn't try to kind of measure identities. So prediction markets are collusion resistant, security deposits are collusion resistant shelling games. So things like auger, things like these decentralized oracles are collusion resistant up to the 50% level. So there definitely are some mechanisms where they do not require any notion of identities, they can be purely coin based, and where they don't run into the same collusion issues because they don't kind of operate in the same way. Right? So here's an example governance mechanism.
00:32:13.766 - 00:33:37.414, Speaker B: So this is like a sort of futarky light way of building a Dow that I haven't seen tried yet. But the idea is basically to take a voting system and just augment it with a little bit of a prediction market so that you try to make it more secure against bribes. So here's how it works. If you have decisions for every decision, you can vote in favor of the decision, you can vote against the decision. If you vote with Ncoins in favor of a decision, that vote also has to come with an offer backed by collateral ETH blah blah blah to buy n more coins at a price equal to 99% of the price of the Dow token at the start of the vote if the coin wins, right? So basically, if you vote for a decision and that decision wins and the price falls, you're responsible for bailing everyone else out. And if a terrible vote wins, and if. Someone tries really hard to bribe to make a terrible vote win, then the winners are basically required to buy everyone else out, right? So the idea here basically, is that the reason why this is not vulnerable to bribe attacks is that if you try to bribe someone to vote for something that's really bad for the Dow, then they're not just responsible for kind of the tiny impacts that they have on the decision themselves.
00:33:37.414 - 00:34:38.242, Speaker B: They're responsible for basically their share of this big drop in price of the Dow token that the decision would cause. And whatever that price is, whatever that price decrease is, the people that voted for it have to cover it. So you can do things like this, right? You can also do security deposit mechanisms. So for example, if you want to have a Dow for verifying humans, then one mechanism you could have is one that says so first of all, for a new human to be added to a list of known verified humans, some number of existing members in this who have been verified have to vote for them. And there exists a challenge mechanism, right? So there exists some game where you can claim this account actually isn't a human or that these two accounts are actually the same human. And you can resolve them with an auger oracle. You can resolve them with Claros, which I think doesn't get enough love, decentralized court mechanism with kind of multiple layers of voting.
00:34:38.242 - 00:36:12.066, Speaker B: You can just probably plug into Claros for this and the voting isn't a kind of just dumb vote and forget about it, right? If you voted for a human that gets rejected, you personally get penalized. And so if someone tries to bribe you to vote for them instead of just having to bribe you a really tiny amount, they have to bribe you pretty much to cover the entire penalty that you would pay so much more secure in this way, right? So that's one path to try to solve these issues, right? Basically you rely on prediction markets, you rely on security deposits and you try to make it so that voting for bad things actually is costly for you personally. So this is one strategy. Sometimes though, you can't do this, right? If we're talking about rewarding online content creation, then there's no way in which if you vote for a post and it turns out that post is bad, there's no feedback mechanism with which the facts that that post is bad really can get detected by the system and used to penalize you. So here's another approach add collusion resistance. So basically we can try to prevent bribing by coming up with infrastructure that allows these mechanisms to be run in such a way that you cannot prove how you participated even if you want to, right? So it's not just making it anonymous, it's not just making it hidden by default. It's that even if you wanted to prove how you participated, you can't.
00:36:12.066 - 00:38:04.410, Speaker B: So this is actually even harder than doing Zge snarks, right? And I actually made a post feel free to kind of photo this to remember the link on kind of minimal anticolution infrastructure. If people want ideas for a hackathon project also highly recommend trying to just go and implement this. Basically the core idea here is that there is some operator and the operator could be centralized, it could be a decentralized multiparty computation thing and the operator is trusted for the collusion resistance property but not for any of the other properties, right? So if the operator is compromised, then you can bribe people but you still have the guarantee that the vote has to proceed correctly. Nobody can cheat in any other way. Basically, the idea is that users broadcast their actions to the blockchain and they broadcast their actions encrypted with the operator's public key and signed with their key. Now, users also have the ability to send messages that change their key and this is really important because if you have the ability to change the key that your future votes get verified against then if you look at any single vote you can't actually prove whether or not that vote is valid, right? Because you could have changed the key before. So with this mechanism, basically users lose the ability to prove how they participated but then the operator does a ZK snark and publishes the outcome at the end with a proof and so the operator still proves that the operator gave the answer that actually is the correct answer of applying all of these votes, right? So it's secure against operator maliciousness and the operator proves that the calculation is correct but individual participants don't have the ability to prove how they participated and so if you try to bribe them, well, they could take your money and then just vote the way they were going to vote anyway.
00:38:04.410 - 00:38:25.780, Speaker B: So this is the other way to try to solve these kinds of problems, right? So use cases for this regular voting, quadratic voting, gitcoin, CLRS content, curation content, incentivization all of these things that people wants to make decentralized things for. So thank you and enjoy.
