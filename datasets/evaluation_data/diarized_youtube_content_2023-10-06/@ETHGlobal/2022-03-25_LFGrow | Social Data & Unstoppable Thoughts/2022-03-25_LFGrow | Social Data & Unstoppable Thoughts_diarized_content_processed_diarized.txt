00:00:05.290 - 00:00:27.954, Speaker A: All right. With that, we are ready for our next amazing discussion. So the next topic we're going to talk about is on social data and unstoppable thoughts. It's a pretty broad and abstract sort of topic. We'll kind of dig deeper into kind of how we think about it. And for this conversation, like to welcome Jonathan from Starling Lab to join me. Welcome, Jonathan.
00:00:27.954 - 00:00:31.480, Speaker A: I'm glad that we're able to kind of talk about this and hi.
00:00:32.490 - 00:00:36.038, Speaker B: Thanks, Karthik. Awesome to be here. Really excited. Awesome.
00:00:36.124 - 00:00:50.314, Speaker A: So I want to start off by just kind of getting more context for everybody else and kind of people understanding what you do. So we'd love to kind of get an intro on who you are, what Starling is, and just everything that you spend your time on.
00:00:50.512 - 00:01:51.482, Speaker B: Sure. So the Starling Lab is based at Stanford and USC, and we are focusing on how to use Web Three technologies to advance human rights in three domains history, law, and journalism. And we've been at this for about three years, so we've understood that as with everything in Web Three, you got to be patient because stuff breaks and you got to figure out not only what are the possibilities of the tech, but our big focus has been how to actually integrate different solutions. So rather than thinking about one protocol or one solution that can try to do everything, instead, we're realizing that there are different tools that are out there that can be integrated together to create really robust solutions. And so that has been exciting because you can imagine in the types of things we do across the different domains, you need to be flexible. Today journalists don't know how to use these tools straight out of the gate, so you need to listen closely as to how they get their work done. Or for that matter, we're starting to work on work in the Ukraine.
00:01:51.482 - 00:02:12.120, Speaker B: It's a fast moving situation, it's very dynamic, and we understand what the lawyers need. But we also know that Web Three tools are struggling to even work in a basic way. So we need to simplify and create robust solutions. And that's really what the lab is all about, to just cut through the hype, make real stuff happen.
00:02:12.890 - 00:02:26.940, Speaker A: Amazing. Is that more kind of a comment on how do you guys decide what to spend your time on? Is it a project based thing or is it like a situation based thing? Obviously you talked about Ukraine, but how do you sort of measure the outcomes as well as what to focus next?
00:02:27.950 - 00:03:00.582, Speaker B: Well, we got into this because we realized that there was just natural and intuitive things for us to do. So we started by focusing on taking vulnerable data and sensitive data and seeing if we can get that on chain. And that started with historical records. That was a natural thing. But what we realized very quickly was that we could start our chain of custody actually upstream right. Rather than just taking records as they are. When we create new records, could we start, let's say, with video or images, with a chain of custody that gets on chain in the camera itself? Right.
00:03:00.582 - 00:03:35.578, Speaker B: So part of what guided us was realizing that there were these interlocking things. So we have storage, we have capture, and then finally verification. That was another area that very naturally led us to think about how as experts are reviewing information and trying to build confidence and context and clarity about it, we needed to provide tools there. So that essentially was our approach to creating a framework. And all our metrics are around how we can deploy into case studies that are in the domains that I spoke about by using this type of framework. Again and again, amazing.
00:03:35.764 - 00:03:58.646, Speaker A: And kind of obviously there's a lot of room here to kind of go deeper into all these things, but I guess specifically focus on just what you just kind of are spending your time on now. What are some recurring themes that you sort of get into as you talk to the end users of these technologies? What stands out when they think about Web Three leverage kind of solutions or any recurring themes around? Like this is what you get complaints.
00:03:58.678 - 00:04:53.878, Speaker B: About all the time with Web Three technologies? Yes. Wow. It's a big question. Well, let me start off just by talking about the problems in general and then we can kind of create the subset for Web Three. Today, I understand you guys are focusing on hacking around social media and with Lens and all sorts of really cool things that are being experimented with in creating new types of social profiles and methods for sharing information, et cetera. And what I can say is that the number one thing that we're addressing is that the social media platforms of today have very little context around the information which is distributed within them. So as an example, if I send a photograph to you on Twitter, one of the very first things that Twitter does is it actually strips out all of the metadata that might help me establish the veracity or the authenticity of that photograph.
00:04:53.878 - 00:05:45.302, Speaker B: So it becomes a massive problem because people are essentially with that original choice which has some wisdom to it, but in my view it's outdated. We're now really just struggling to catch up from behind. So a lot of the challenges that we're addressing and a lot of the problems are that there's just bad hygiene. People haven't done proper schema, they haven't thought through the interlocking protocols and figure out actually what's the optimal workflow. Essentially it's just bad planning. So I would say that the number one challenge that we're seeing in Web Three is that it can't actually address those problems. It takes humans to actually come up with better plans and better strategies and then use new Web Three technologies to help build confidence around good choices that you make at the beginning.
00:05:45.302 - 00:05:49.818, Speaker B: Because if you're authenticating something, really it's garbage in, garbage out. Right?
00:05:49.904 - 00:05:50.106, Speaker A: Right.
00:05:50.128 - 00:06:28.338, Speaker B: So I think that's like, the number one thing that we see is that it's just people have rushed stuff is Kludgy. They haven't thought through all the best practices. So that's in the human rights context, while we want to act and we want to be responsible, at the same time, the stakes are so high and so we can't afford just to put stuff out there that's rushed. That's kind of one big piece that we look at, just clarity and structure. The second, which is really important, is about performance. And thankfully that's getting better with Web Three. So I know the story of the last 18 months is surely a story about efficiency in terms of cost and performance.
00:06:28.338 - 00:07:22.966, Speaker B: And so that keeps getting better and better. And I think that we're now at a point where interchange work is also going to get better and better. And so that I'm really hoping becomes a major accelerant. And a story of 2022 is that we can start to use different protocols for different things and that maybe I kick it off with an NFT, but then I immediately go into using three or four other protocols to achieve the type of consensus that I want to and the type of distribution that I want to. And I think that likely will produce more complaints. Right, because there's more systems, more problems. But at the end, it's just really important because if we're going to keep Web Three decentralized and we're not just going to go and recreate the BMS of Web Two and end up with the same problems that kind of got us here in the first place, that requires us to be dedicated to this idea of interoperability.
00:07:22.966 - 00:07:28.698, Speaker B: And so in spite of all the challenges, it's worth it and we're hoping people keep at it.
00:07:28.864 - 00:08:08.790, Speaker A: No, that's an amazing answer, kind of coming back to sort of what you're spending your time on now. This event to Sackathon is all about thinking about new ways to create social media platforms that are kind of crypto native or Web Three native. And there's a lot of ways you can slice that. There's a lot of ways you can think about what you want to pick on. There's a realm of text, there's a realm of kind of possibilities around just other types of media consumption and all these things are sort of being tried on for the next two weeks. But as you kind of look at the situation right now that's out there in the world, what do you believe is the role of social media in kind of documenting, in a way, war crimes or any conflict?
00:08:09.370 - 00:09:00.650, Speaker B: Yeah, well, to give you some context, because this is very applied for we about three weeks ago, as the situation in Ukraine worsened and the war began, we realized that we had to spring into action. And our lab has been working for years on doing perfecting various forms of documentation for war crimes. Documentation, human rights violation in Syria. Now, that conflict, which got started eleven years ago at the time, if you remember Karthik, it was the Arab Spring was dubbed like the Facebook revolution, right. Kind of unofficially. And you had all of these giant at the time they were kind of growing. But Web, two platforms that were offering a new opportunity for people to start to document things just with their mobile phone.
00:09:00.650 - 00:09:34.674, Speaker B: Right. It was this incredible revolution. And they thought maybe naively, well, certainly naively at the time, that would be enough. If you could just document it online, then you're good to go, because the truth would be out there and dictators would come down. And Google has estimated that with that spirit, that there are now more hours of documentation on YouTube of the Syrian conflict than there are actual hours of the war in real life. Wow. For the last seven years, that's how the torrent of information okay, so now, eleven years later, here we are.
00:09:34.674 - 00:10:15.354, Speaker B: We have a tremendous challenge in trying to bring people to justice, and people are documenting like they've never done before. However, the torrent of information that's coming in there, and also the mechanisms for authenticating the information, we still have a really, really difficult task ahead. Just showing the photo is not enough. As we saw, Zelensky was just featured in a deepfake video that was claiming that he had surrendered. So he had a lot of challenges just around trying to build trust. Right. At the same time, just because you document something doesn't necessarily mean that it's going to get into be admissible for evidence.
00:10:15.354 - 00:11:12.094, Speaker B: So there's a whole set of protocols that you can take to ensure that something has the best chance of being admitted in a court case. And if that's your goal for documenting war crimes as an example, we need to take preemptive steps. And then the last thing, and this is really critical, the part of the problem with the rush in Web 2.0 was that everyone just put stuff online and they had just no idea as to what to do with dealing with the safety of the people that were featured in the video. And I think my biggest concern right now is that we are rushing and doing all forms of documentation which is critical. But that record of all the things that people are putting up can be very easily taken. And spun around from a tool that is just simply a tool of documentation for good, to being a tool that now is used to surveil and to condemn people, to find people in their homes and take them away and imprison them, et cetera.
00:11:12.094 - 00:12:31.882, Speaker B: This is the reality that many people in Ukraine may face as and how Russia proceeds in capturing territory and potentially taking over the country. And so while the initial intent is very important to preserve that there's a spark of good here, the reality is that this can all go wrong very quickly. Okay? And then the final thing, which is that as you're trying to arbitrate whether or not to keep something up, content moderation becomes really challenging. And what we have found is that YouTube and Twitter and Facebook were put into this really difficult situation in which they had to decide what information do you actually keep up? Right? So if you want to protect people or maybe there's terms of service violations around the brutality of what people are showing, does that deserve to stay up in spite of it being against common sense terms of service? Right? But if you take it down, then maybe that would be then destroyed and potentially unavailable for war crimes investigators. So trying to find that balance of how you deal with securing the privacy of the individuals involved, but at the same time getting information to the authorities that can act upon it and making sure it's admissible. All these things you could think of as problems, we think of it as opportunities. And we are really excited because we have been working let me take that back.
00:12:31.882 - 00:12:46.420, Speaker B: There's nothing exciting about any of this. We are passionate and we are dedicated to the idea that Web Three can potentially help. And so we're very carefully looking at how the tools that we've been working on could start to make a difference.
00:12:47.670 - 00:13:39.780, Speaker A: Thank you so much for that just kind of thought process around. I mean, there are a lot of challenges here and there's no perfect or right solution. There are multiple ways you can think about solving each of these as you look at all the time that you spent understanding what should be done here as an expose of action. If I'm understanding this right, and please correct me if I'm wrong, is kind of the clarification here that this is more of a nuance between moderation and the content existing and the fact that the data persisting is still separate from what should be done with it. And right now the complation is that in the Web Two world, if the data doesn't persist, that it means there's no other way that somebody would find out about it because suppression is directly tied to the existence. Is that a fair statement or is that kind of where we are starting off of?
00:13:40.550 - 00:14:48.470, Speaker B: It's all about authority, right? Kartik it's like somebody has to make choices, right? And in the Web Two world, the platforms have said we're the ones going to make all the choices. So we're going to set the metadata standards, we're going to set the modes of content moderation, we're going to figure out how to deal with identity and security, right? And that worked for a period of time. It kind of bootstrapped us to the point in which everyone got on these platforms. But now obviously we've realized that well, I'm not so sure that I want Mark Zuckerberg determining the course of war crimes documentation. Doesn't seem like they may have all of the interests of everyone in mind here. And indeed, I mean, to be generous to some extent, the platforms have been active this time around and doing a lot more and they've been consulting with the international human rights community. But the same challenge persists, which is it's about agency, right? And so what I'm trying to emphasize here is that if Web Three people talk about like cryptography and crypto and all that, right, well, what exactly are the features that we really want to use? So the first part of it is that we want to use the ability to encrypt.
00:14:48.470 - 00:15:58.030, Speaker B: And when you encrypt and if you have the agency to encrypt, that also means you have the choice of who to allow access to this information and you can then choose who can decrypt. Right? So that first thing. If it's put in the power of the users, we already think that's a better solution or if it's put into community where a group of users can come together and make that choice, that's great. Separate but related is the other part of the cryptography coin, which is authentication. So that I know that as I distribute the information and I want to lock in all the facts around my initial documentation of something, I can authenticate it using a hashing algorithm and signing algorithms. And then what that allows you to do is ensure that no matter where this goes, no matter where it stays stored, where it's consumed, et cetera, that we have some provenance and we know where it came from and we know that if it's been manipulated or not, which is critical for chain of custody. And Web Three is built on these primitives, right, that you have authenticity, that you have some method of protecting users with anonymity or pseudo anonymity with encryption.
00:15:58.030 - 00:16:20.310, Speaker B: So as you guys are building and hacking away over the next couple of days, really think about it. It's like, how can you allow users to try to flex these really powerful tools on their own with their own agency, but then also in groups that expand and expand and essentially keep that agency with the users rather than the platforms?
00:16:25.240 - 00:17:10.500, Speaker A: No, this is really good kind of way of thinking about it because what I was going to ask next was just go into a bit more detail around what are other lessons learned from how existing Web Two networks do this and how we actually kind of think about making a list of everything we need to address. And as we're thinking about a brand new way to experience, in a way, a social network in Web Three, it's kind of like a choose your own adventure sort of thing, which is the data is separate from the users, which is separate from the platform, which is separate from the user experience, which is separate from the front end and the platform we're going to look at it from. And there's multiple things that you can tweak on every layer of that stack. And the question becomes, like, what is important to focus on and what is ephemeral versus what is actually variable?
00:17:11.160 - 00:17:25.480, Speaker B: Right. Yeah. That sounds daunting. Right. Because you've essentially disintermediated all functions. Yeah, exactly. And that's a lot of pressure, right, if you're a developer and you now have to essentially make all those choices.
00:17:25.480 - 00:18:10.504, Speaker B: Yeah. I'm extremely empathetic in a sense that it's like, this is, I think, what the engineers are facing the next couple of days are they're obviously like a multitude of choices, but also a multitude of responsibilities. So let me give you the one thing where when we consulted with the leaders in the human rights space, they said to us, it's actually really simple. What you need to do is create platforms that allow for you to air grievances and to provide feedback. So you have to basically assume that you're going to get things wrong at some point. It's assured, right. Every major type of implementation is going to stumble in some way because that's what happens when you work at scale, right.
00:18:10.504 - 00:18:55.508, Speaker B: That's what happens when you make something public. And so if you look back at Web Two and you think about, well, did they really listen? Were they actually humble in their approach and trying to say, you know what, we're screwing up and let's make some choices that might actually make a difference? Right. Or did they give agency to users to start to develop solutions around better information right. About what was wrong? I think at the end of the day, we can say Web Two failed in that respect. The early experimentations around voting around proposals and trying to get feedback. I mean, you may remember this, right? Facebook advertised this, right, as like a key thing they were going to do. Right? I forget what the threshold was.
00:18:55.508 - 00:19:36.050, Speaker B: It was something like 100,000 votes or something like that could yield some sort of change. It should sound familiar, right? Like Dow governance and stuff like that. Right. And of course, they didn't stay committed to it, in part because you could argue maybe some part of it was impractical, but also they were arrogant. I think that in retrospect, they would admit that. So that's what we need to flip on its head is we need to think about not just governance for the sake of decision making, but you need to make people informed through this process. And so you need to be super committed to finding ways of getting feedback from users and then creating grievance processes that are structured ahead of time, not belatedly once really bad stuff happens.
00:19:36.050 - 00:19:49.030, Speaker B: So I'd leave that message with everyone. This is not an afterthought. This is actually core to the success of your platform. Is being able to hear these types of things. Absolutely.
00:19:51.320 - 00:20:19.760, Speaker A: I kind of listed some features that I think are just from a framing standpoint, things that we need to solve for in this world. And you kind of have direct experience thinking about and addressing some of these in production, for lack of a better term, kind of from your perspective, what are some of these key requests that you get or key features that all these new platforms should have? And how should you kind of think about breaking down or solving or checking for? Like what is the right check? That, hey, we have a sufficiently good enough solution if that check meets.
00:20:20.500 - 00:21:21.012, Speaker B: Yeah, well, the first thing is thinking about identity, right? It's a super core and I'm imagining that everyone's going to spend a bunch of time focused on that. And identity is complicated because it's obviously multifaceted. And I think most people are realizing that personas are what is going to be one way out of the problem with identity, which is that you can have essential identity that defines, that you can essentially speak for and have agency, but that you might want to present your persona in different ways under different circumstances. You might want to have a lot of choice around that and that persona in some cases can be anonymous, pseudo anonymous. You can make varying levels of security features around that. So I think that's one of the core requirements of a social network, I think we're to rearchitect this is to find ways of establishing a multifaceted identity. That then leads to the second piece which is around content moderation which really flows from this concept, which is that you want to find a way to generate community here.
00:21:21.012 - 00:22:48.304, Speaker B: So now we have a set of personas that can come together and they can help manage some complex tasks and that core feature really important. And when we think about, for instance, content moderation, it's one thing for instance, to have content moderation happen for a broad distribution of content. It's another thing where it would be content moderation for a bunch of war crimes prosecutors, right? And so clearly they have different needs and agendas and feature requests. So I think that having the ability to shape community with a whole set of different requirements around what the community requires organically, that's super important. Okay? And then the last thing which I'll mention is really about authentication and provenance. So much of the problem that we have right now is that information is flowing with very little information, a metadata accompanying it. So you have photos that have no time and date, you have challenges around establishing location and even things like the veracity of information, like its underlying hash, right? Has it been manipulated or how can I authenticate it as close to the source as possible? Now this one holds tremendous promise, right? Like we're already seeing for instance, images from other wars being recycled in the Ukraine conflict because it's just they're evocative, right.
00:22:48.304 - 00:22:57.312, Speaker B: They get people to think and to care. Right. But of course, that's falsified information. Right. That's a big problem.
00:22:57.446 - 00:23:08.660, Speaker A: Do you also clarify the nuance in that third point about how much of that kind of is already coming in as a feature for just being on the blockchain versus the additional information that you would have to amend or append?
00:23:09.080 - 00:23:29.724, Speaker B: Cool. Yeah. I'm glad you paused me there. All right, well, let's think about it. So the first thing is about ordering, right? So blockchains are really good about establishing the order of events of something. So if you can register something, we have at minimum, we know what happened before and after. We have some relative sense of time, and then we can align that with potentially, like, real time, say, this date, this time.
00:23:29.724 - 00:24:25.356, Speaker B: So that is kind of the first thing. The second is that if you in that record, can pack in things like location as an example or information about the device that took the image, et cetera, you can help start to build confidence that when someone says, hey, this actually happened, that you're starting to say, well, I have now additional information there, and that's giving me some more confidence that, yeah, indeed, this happened the way that this person claimed that it happened or it's not a deep fake or it's not a shallow fake or some sort of recycled image. So that's really important. But I'm going to be a little bit of a stinker on this. The immutability of that type of record is challenging because today I might want to disclose that information and tomorrow I may not. Right. Today I might be free and able to do this type of capture safely.
00:24:25.356 - 00:24:51.460, Speaker B: Tomorrow there may be a completely different security situation, and I now need my anonymity. Right. So choice is very important to ensure. So as you're developing these features, it's not about opting out. It's about opting in. And that's really important because of the nature of the immutable nature of these types of devices or systems. And I'll tell you, by the way, Karthik, this is fascinating.
00:24:51.460 - 00:25:28.256, Speaker B: This is not abstract fear at all. As we were developing cameras and applications that did exactly this, it would take a photo and you would know it's in this exact time and place. Right. Hasn't been changed. Our security researchers let us know that actually ten years ago, north Korea actually pioneered a lot of this work and has made that a standard feature of every phone that is shipped in North Korea that's approved by the government. So that form of authentication powerful, amazingly helpful if I choose to do it. But when it's forced upon you, then it's a completely different ballgame then.
00:25:28.256 - 00:25:32.900, Speaker B: Now we're in the case of surveillance. So those are the table stakes. Right.
00:25:32.970 - 00:26:25.860, Speaker A: I think the engineers of a double edged sword. Wow. I think a lot of it is I feel like otherwise I'll capture by saying I don't think it's a solved thing. I think there's still a lot of improvements to be done. I think we get a lot of things built in in this world, especially on the persistence and largely the availability as well as kind of the immutability of information. And it feels like a lot of what we're thinking about or talking about here, and especially discussing is that a way to think about moderation and different ways to improve moderation? How do you think about breaking that down? Is this just a world where everybody says bring your own algorithms and if you're doing this for war crime then you have a different script you're going to run on the same data. If you're doing this thing for understanding what could go viral, you have a different sort of algorithm.
00:26:25.860 - 00:26:32.360, Speaker A: Are we just going to see all this fragmentation and bifurcation here? How does that world kind of change and evolve from your perspective?
00:26:34.140 - 00:28:03.632, Speaker B: It's complicated because I don't think we've done content moderation successfully, even with billions of dollars being spent on it and platforms that have maybe not a moral interest, but a profit interest that they have put forward to say, we got to solve this because this is hurting our brand, this is hurting our reputation. So let's try to unpack it. I think the biggest challenge right now is that there is no way to actually moderate content within community. And so I think the ability to create more robust groups that can make choices around the types of things that are acceptable and the values that they want to stand for is an important step forward. Now, mind you, that requires you to make sure that people actually are doing thinking about their values, right? And that ideally those values are stated, they're clear and that governance is built around those. So that I think is the very first set of types of features I think that we would want to see here about content moderation is to instead of thinking about it as a centralized function that a platform needs to handle, instead we're starting to localize it to affected parties, to stakeholders, right? The second thing is that their content moderation is tricky because obviously we want to promote freedom of speech as much as possible. That's a core tenet of democracy.
00:28:03.632 - 00:28:58.070, Speaker B: But the reality is that not all forms of speech are protected, right? And so, again, like spending time preemptively to figure out the nuances of how you want your community to deal with this and then maybe forming Webs of Webs, right, where good practices from another community might be something that you can now have, like a Dow of dow type of relationship here where then you can have those values disseminate. And probably the key to that is really transparency so that you can understand exactly what's going on here. And remember even that was something that we. Didn't really know what the standards were in Web two. Right. There were these kind of investigative reporters that would uncover crumpled PowerPoint presentations that explain how content moderators take down content and they were like insane to see because some of them were really wrong headed. Right.
00:28:58.070 - 00:29:10.052, Speaker B: So I think making just a lot of that process more transparent and more governable is going to go a long way. Won't solve everything, but it certainly will be much better than the current state of affairs.
00:29:10.196 - 00:30:19.756, Speaker A: Absolutely. So to kind of give you a little bit more context into this event, a lot of people so we have 500 developers who are working on creating different ways of reimagining social networks, whether it's on the Twitter or Facebook side or media content or live streaming, just different ways we can have more consumer social interactions. And it's all leveraged on Lens protocol. And kind of the one key interesting piece here is that kind of what you're fundamentally sort of facilitating is a standard around how people have a shared identity that gives them the ability to just get a graph of all the users who have also interacted in any same realm. And I think that's to me, a super interesting sort of primitive because we kind of have almost everything open and transparent on blockchain. You can inspect this, you can inspect the metadata, you can inspect kind of A to B transactions and destinations. But there hasn't been a strong incentive or even a lot of attempts right now to really figure out a way to think about how do I, in a way, roll up the activity or the identity of a user.
00:30:19.756 - 00:31:03.870, Speaker A: On a different platform and sort of leverage that to make sense of it on another, whether that's like a reputation sort of score or an aggregation of this is what you've done that comes in. And this is kind of one of the bigger problems with social networks too. Like, I can't quit Twitter because everybody I follows me must do the same thing, or I have sufficiently enough of an audience that I can say, I'm going to quit this thing. I'm going here, please follow me. And I hope that majority of them do. Do the same principles exist as you kind of think about in this kind of Ukraine case or the war crime, sort of like, does the network actually matter or is it largely about the outcome of kind of the situation and that's sort of the thing? Or do you think this actually enables more interesting cases or not?
00:31:04.960 - 00:31:05.710, Speaker B: Wow.
00:31:07.440 - 00:31:08.536, Speaker A: There'S a lot here.
00:31:08.658 - 00:31:37.188, Speaker B: I'll try to break it. Well, just I'm just excited to think about how I can answer this in a clear way because I think there's a lot of possibility. Right. The first thing I just want to talk about is you've described here the possibility of creating a social network that has portability as like a key feature. Right. So I have portability of my data, my identity, et cetera. And I just want to put out there that portability does not equal interoperability.
00:31:37.364 - 00:31:37.944, Speaker A: Great.
00:31:38.062 - 00:32:29.690, Speaker B: So I can take my data and maybe I have it, but if I can't use it on the other platform, then forget it. There's like nothing there. And so I think that's really important for people to distinguish and stay ahead of, because you saw this, like when the handwriting kind of came out with Web Two, they said, well, you can just take out your data. Okay, but what can I do with it? Right? And by the way, what type of data is actually being taken out? In many cases, the analysis of my data, which was arguably the most important thing that the platform was doing that was still kept proprietary. So I think portability and interoperability, which are now, by the way, requirements under things like GDPR, they are really important to build into the design. And I think we still need a lot of innovation there. So that's an important piece.
00:32:29.690 - 00:33:52.516, Speaker B: The other thing which is complicated about this, but I think an opportunity is that you really need to figure out what are you betting on? And I think what we're all betting on is not that you have portability and interoperability and identity and the ability, like robust forms of security, but you're really betting on emergent behavior, emergent features. And that means that your design surface is not just around the primitives of how I'm going to do something at a tactical level, but that you really want to think about what are the emergent things that are going to happen when this actually gets deployed and at scale? And so I'd urge people to think about getting the Lean prototype, experimenting with some things, but then really being it's that next stage of the innovation, which is actually where you're going to find out what you've got. Right. It's because what you're looking for is changes to the fundamental content and the behavior that merges from the features. I'll give you a funny example, but it's a good one. Until Netflix decided to go in and basically stream things in the way that they did and make their catalog available in the way they did, the phenomenon of Binging wasn't possible. Right.
00:33:52.516 - 00:34:23.340, Speaker B: And so what happened is that you now had a new pattern of viewing, right. That's the first level of innovation. But then the content changed, right. Like the actual television product, you had variable length, you had new ways of thinking about episodes and series, et cetera. I think that's a really intuitive example to say. Yeah, it used to be that you had linear content which was distributed on broadcast television that occurred weekly in half an hour chunks. And it's like, wait what, 20 weeks?
00:34:23.410 - 00:34:30.656, Speaker A: And then you got to wait another six months for the next five. And then here you see 14 episodes dropped in the same night. And people going crazy.
00:34:30.838 - 00:35:28.480, Speaker B: Exactly. So the innovation is not just about the fact that, okay, here's the content. It's available to you in one day. It's that like, oh yeah, this story is way different than a sitcom, right, or some whatever kind of classical television format. And so I think that's a good analogy for what's going to happen here. You want to say, like, okay, we're making things interoperable, we're making them portable, we're making them secure and authentic, but like, okay, now what? And so that's, I think the broader conversation that you guys are probably having. But with respect to war crimes documentation, I think that there is a really interesting phenomenon that we're on the cusp of, which is that right now the challenge is that this type of work is centralized through the investigative authorities that are doing this work, for the most part.
00:35:28.480 - 00:36:23.216, Speaker B: And I think that there's still some wisdom in having experts deal with content of this kind. That makes sense to me. But engagement is still really important. And that what I think is going to happen, is that communities are going to rise up and they're going to say, we want to be a part of accountability here. And so as open source intelligence gets out there and people are going to start processing that information, I think the emergent behavior is going to be that we have now open forms of analysis as well as just open forms of documentation, and that people are going to say two things. One, I want to use cryptographic protocols to actually retain the integrity of this information and to preserve it. And so I think the archive of this war is not going to be centralized in one repository or like one AWS instance, right? I think it's going to be distributed.
00:36:23.216 - 00:36:24.592, Speaker B: I think that we're going to find that there's.
00:36:24.656 - 00:36:26.196, Speaker A: I don't think it has to be.
00:36:26.378 - 00:36:56.232, Speaker B: Well, one would hope, right? So we're working on that. And that's what will make it resilient, because if Russia even decides to attack or destroy or turn things off, okay, great. Well, now this information is out there, and it's the wider and the more diffuse pattern of that storage, the better off we are. And the emergent behavior is that people are committed. They're not forgetting they're engaged. Right. Because preservation is a very high form of engagement.
00:36:56.232 - 00:37:07.940, Speaker B: And then the second thing is that they're going to look at the content in some cases, where it's responsible to allow people to look at things, and they're going to find evidence that maybe investigators can't find because they're too stretched.
00:37:09.880 - 00:37:40.236, Speaker A: I think those of paralyzation, which is kind of what we haven't seen in moderation, there's a fair amount of good, but largely, I think, a lot of not great cases where you see kind of reddit mops hopping up and they end up trying to solve certain things or find clues from just little information. And it does end up often leading to results. But that's also one sort of side of moderation at scale and we just haven't been able to do that. Largely social existence, central networks yeah and.
00:37:40.258 - 00:38:47.716, Speaker B: The chaos is basically that it's like with the analogy, it's a mob, right? So it just forms on its own and then it's instructed to essentially go in kind of through the crowd, the thinking of the crowd, right, go and attack something. I think in this case that's the power of these types of solutions that are on chain is we can start to delegate, we can create more structure, we can think about ways of encouraging participation but not having it be so unruly. So I hope that that's an emergent thing as well. I can tell you having worked on the Syria conflict which is now in its 11th year and that still most of the major war criminals have not been brought to justice in any meaningful way by the way. Nothing on the international level and sparing work done in domestic courts in Europe. The reality is this is going to take a while and that what we really need to be thinking about here is a solution that's not about these intervening weeks and months. This is a decade plus type of work on accountability, growing challenge with no.
00:38:47.738 - 00:39:34.624, Speaker A: Way to call it this is done, this will mutate in different forms. I do want to end on a note that sort of helps the attendees for the hackathon sort of get some more direction towards what they should be thinking about. I think one thing you did point out, which is a really good thing I would like to repeat is just the emergent behavior. I think a lot of us, when we think about, oh, let's have a decentralized social media network, we're saying, okay, I need to have some insurance from getting banned from Twitter or YouTube. So I just need to clone that and have the same one to one mapping of what this would look like now, just that the data is more distributed. That doesn't count as emergent. I think the emergence comes from the fact that we are seeing new use cases that either just are not possible or we can't think of yet or we haven't figured out how to put that right combination in place.
00:39:34.624 - 00:40:14.450, Speaker A: And obviously NFTs did that, they did that with music just now and that's kind of an emerging theme. We're seeing that with just how people interact and sort of form graphs and that's a really interesting thing. But the hard piece about this is that we're hoping that there's something new will come up but there's no way for us to kind of prescribe or give a category because by definition it'll be impossible. I will kind of put you on the spot but I'm not going to have you answer that question. I'm curious if you were to kind of give some guidance to the attendees here to think about what they should build or what different ways you would like to see social media networks evolve. Granted, they only have ten days to try something out into a minimum viable product. What are some things that you think are important?
00:40:16.900 - 00:41:11.804, Speaker B: One thing, and we can direct people towards looking at some really cool things on authentication. So provenance is really a cool feature that we are looking for in social media networks. So the ability essentially to track content when it's first uploaded, then who gets to basically how it gets shared and then finally how it's consumed. In the end, provenance is a really interesting area to think about for innovation, specifically with images and video, which are really important. The other thing I'll just come back to, I will beat the drum again on issues around grievances and feedback. So really cool mechanisms for content moderation that are driven through awesome methods of feedback and grievance. Addressal is seriously the biggest challenge that social media has at the moment.
00:41:11.804 - 00:41:53.532, Speaker B: And I think small experiments here might be really cool to check out. Like how if you have like a massive queue of complaints, for example, how do you sort through that? What signals could you bring in that could allow something to jump up to the top and that people wouldn't game the system necessarily, right? So I think some of those kind of dynamics are really cool to think about. And finally, I think the idea of the personas is really powerful and going to be a tough one for people to look at and really meaty. So I'm hoping people, if I'm a user on the platform, how can I exist in different spaces and shape reputation and my activity in a meaningful way?
00:41:53.666 - 00:42:18.400, Speaker A: What does the Web Three version of that look like? You're saying that my address or my identity underlying is the same but it morphs based on the platform I'm on because there's a second sort of abstraction of who I am. How do you kind of manifest that on chain? Is it just like me saying this is a list of topics I'm interested in and that's sort of what I fill in for a different platform? Or how would I kind of dedicate my persona?
00:42:18.480 - 00:43:12.516, Speaker B: I mean, declaration is certainly really important because you obviously want to make sure that people can retain their privacy and disclose what they want to disclose. So I think that's important. The other thing is just keeping certain things sequestered in a way, right? That's another piece of the puzzle, right? So if you really want to potentially you may not necessarily want to associate one persona that I have to another persona, right? So thinking about some innovation, about how I could potentially keep different parts of my identity separate, that seems really important. I know privacy norms were really challenged in Web Two and Zuckerberg kind of famously said that privacy is like a generational thing. I think that Time has not looked favorably on that quote at all. I think there's a lot that we've learned about why privacy really matters. I think a new generation has maybe new ideas about expression.
00:43:12.516 - 00:43:41.280, Speaker B: That's really awesome. But I also think that they recognize that choice and agency that comes with end to end encryption and some form of security means that you can actually have more robust expression if you have things like security and encryption, because you can, in those types of settings, maybe be your more authentic self. Right? Yeah.
00:43:41.350 - 00:43:45.024, Speaker A: That safety exists. You're right.
00:43:45.222 - 00:43:54.980, Speaker B: Yeah. If we can play with those ideas and now say, okay, how does that relate back to an identity that practically I can use? That's really the kind of the area of innovation.
00:43:55.480 - 00:44:08.500, Speaker A: There's a lot of things that are actionable from everything you said today. So I want to thank you for taking out the time and making this amazing chat happen and kind of working on something that's super important and relevant right now. So really appreciate this, and thank you so much.
00:44:08.650 - 00:44:12.670, Speaker B: So great to be here. Big fan of the community and looking looking forward to doing even more.
00:44:13.280 - 00:44:15.960, Speaker A: Can't wait to have you back. Thank you so much. Jonathan. Cheers.
