00:00:10.210 - 00:00:32.240, Speaker A: All righty. Hi everybody. Welcome to the building. Decentralized APIs on top of ethereum with the graph workshop. Here we have Nader from our sponsor, the Graph. And yeah, if you guys have any questions, just hold them off till the end. He's going to do a little bit of A-Q-A and then you guys can send those into the chat when he's ready.
00:00:32.240 - 00:00:37.578, Speaker A: Yeah, go ahead. Mater, you can go ahead and start your presentation.
00:00:37.754 - 00:01:35.270, Speaker B: Okay, great. Go ahead and get everything set up here. All right. Okay, I'm going to go ahead and share my screen now. All right. So can everyone see that? All right, I guess that's good. Okay.
00:01:35.270 - 00:02:03.548, Speaker B: Yeah. So thank you for coming and checking out this presentation. My name is Natter Dabbott. I'm a developer relations engineer at Edge and Node, working with both Edge and Node, as well as the Graph protocol. And what we're going to be talking about today and what I'm going to be demoing today is how to build a subgraph using the Graph Studio and the Graph CLI. And a subgraph is essentially an API on top of blockchain data. That's kind of the way you could think of it.
00:02:03.548 - 00:03:27.992, Speaker B: So I'm going to kind of go into why the Graph exists and why you might use something like this. So the Graph is an indexing protocol for querying networks like Ethereum and IPFS. So the reason that you might use something like the Graph well, in the past, if you wanted to build out a Performant or nice user interface or front end application on top of any blockchain data, it's actually not that easy to get really good querying capabilities directly from the chain. Now you can hit a chain like Ethereum, for example, and you can query a smart contract at a certain point in time for usually like a single piece of data or maybe an array of data at that point in time from that transaction or from the current state. But it's not easy to, for example, get more robust or more complex queries that you typically would think of needing in real world application. So, for instance, let's say you wanted to kind of filter or search or do some type of compute that needed to get you like a selection set. So maybe you're building out something where you have messages and you want to get maybe the friends of a friend or let's say you wanted to kind of only get messages that came in or were created during this time period, or you wanted to kind of sort or filter or anything like that.
00:03:27.992 - 00:04:16.552, Speaker B: It's not something that's possible directly from the chain. So to get around this, a lot of DApps and a lot of projects, I guess you could say, or applications or anyone building something on top of blockchain data, what they were often doing in the past was that they were building out their own in house indexing servers. So what you basically would do in that situation is that you would spin up maybe a server on AWS. You would then go and look into the contract that you're interested in saving data from and you would actually go through each and every transaction and you would save all of that data and you would store it locally. And then you would build out your own API on top of it. Now, there are a couple of drawbacks to this approach. First of all, you're actually breaking the entire idea around why someone might use a decentralized data source in the first place.
00:04:16.552 - 00:04:49.056, Speaker B: Because you're no longer decentralized. You now are centralized into this one database. You also have a single point of failure. So if you have any issue with your own server that goes down or whatever, you now have this just single point of failure. And then on top of that, it's just resource intensive. So let's say you have a new idea that you want to implement and you need like a new selection set, or you need a new view on top of your data. You now have to kind of build out that functionality, deploy it, and then it takes that type of work to kind of made available.
00:04:49.056 - 00:05:52.740, Speaker B: So the graph actually solves a lot of those issues by allowing developers to deploy these open APIs to a decentralized network. And the graph sits in between the smart contract itself and the front end. So with the graph, you basically have a protocol of people running nodes that are doing the indexing for you on your behalf, distributed around the world. So let's say that you need to build an API on top of something like an NFT smart contract, which is going to be what we're working with today. And you want to serve up queries where people can search for an NFT by name, maybe they can search for an NFT by the creator, or maybe they want to just return the NFTs that they've purchased or that they've created. So we want to build that and we want to be deployed in an API in a decentralized way. You can write the subgraph, you deploy it to the decentralized network indexers around the world, pick up that subgraph, they index the data for you.
00:05:52.740 - 00:06:40.564, Speaker B: You're given an API endpoint and an API key. You can then query that subgraph from your application. And depending on where the user lives in the world, or where the user is calling that API in the world, the closest and most efficient indexer to that user will be serving up the data. So you end up having not only a performant API at the actual implementation level, but it's also being served geographically closest to the user or the application calling the API. So that's kind of an overview of what the graph is. There are a lot of applications using the graph, so some of the more popular ones that you may have heard of are projects like Uniswap Foundation Synthetics. If you go look at the graph.com
00:06:40.564 - 00:07:16.380, Speaker B: and go to the Graph Explorer, you can kind of get a good idea around a lot of the different subgraphs that are out ENS. You know, a lot of these are popular DApps, so there's a lot of subgraphs that are out there, a lot of projects using it in the real world growing pretty quickly. We hit over a billion queries in one day in July, which is something that we thought was really cool. And there are now over 20,000 developers that have built over 16,000 subgraphs. And this was actually data from a few weeks ago, so it could be even more than that at this point. So the UI looks something like this. You have a view where you can kind of drill down into anyone's subgraph.
00:07:16.380 - 00:08:05.424, Speaker B: subgraphs are public, so anyone that deploys a subgraph, it's available to anyone that wants to look at it, use it, signal on it, which is something I'll talk about in just a moment, or just kind of get the data about what's going on. So when this subgraph launched, there was a lot of GRT that was curated on it. Again, something I'm going to talk about in just a moment and it kind of tells you all the metadata about the subgraph. So here you can see things like the overview, the indexers, the curators, and the playground. The playground is kind of like an API playground. So if you've ever worked with something like Postman in the rest world as a developer, you may have been able to kind of just input an endpoint and you're able to query that endpoint well. With GraphQL, you have something called graphical, the graphical editor that we've built in.
00:08:05.424 - 00:08:58.508, Speaker B: And you have self documenting entities on your right hand there where we have like the Uniswap factory, the token, the pair and the user. And then we have the query playground on the left, where you're actually able to run these queries and get data back. So the graph is powered by a network and there are a few different ways that participants participate in the network to make it decentralized and make it work the way that it works. So you have indexers, you have curators, and you have subgraph developers, and then you have delegators. So to participate in the network in one of these different roles, you would acquire some GRT, some graph tokens in some way. And let's say that you wanted to run your own graph node. Then you could participate in the network as an indexer running the graph node software.
00:08:58.508 - 00:09:44.700, Speaker B: You would basically be able to index and save data for other people's subgraphs and serve that up. You would be participating in the network in that way. As an indexer, you earn a portion of the query fees paid to the server or to the API. You earn a portion of those query fees and you also earn a portion of the tokens that are made available as rewards to the entire network. So there's something like percentage inflation from the total tokens that are available that get paid out to anyone that's indexing. And the same thing goes for people that are deploying or a subgraph. Let's say that you have a good idea for an API.
00:09:44.700 - 00:10:27.672, Speaker B: You deploy it to the network and you want people to use it. You would then become a curator by staking some GRT to signal that that subgraph is a subgraph that people should check out and use. Once you signal on the subgraph, indexers will start picking it up and indexing the data. And then you also will return I'm sorry, you'll receive query fees as well as indexing rewards or network rewards, I would say. So that's kind of an overview of the network. So how do you create a subgraph? Well, you initialize a subgraph using the Graph Studio as well as the Graph CLI. You define the data sources that you would like to index.
00:10:27.672 - 00:11:06.176, Speaker B: So, for instance, a data source would just be a smart contract address. So we might say we want to index data from the cool cats smart contract, or we want to index data from the crypto punks. Or in our case, we're going to be working with Zora, which is an entire marketplace. You then define the entities that you want to save. So in the case of an NFT marketplace, an entity would probably be something like a token, a non fungible token. And then you model that data in GraphQL, which is a Schema definition language. Or I would just actually say more like a data modeling language.
00:11:06.176 - 00:11:43.190, Speaker B: And also a GraphQL schema is the data model, and then the GraphQL is the actual API implementation. And then you configure your assembly script mappings, which is kind of like the only code that you actually need to write to build a subgraph. And then you can deploy this to the network. And this is what we're going to be working on today. So we have 17 minutes, so let's go ahead and try to see if we can't do this. And I'm going to be working off of a workshop. So if you're watching this or if you're watching this at a later time, or if you just want to check this out at a later time, you can go to GitHub.com
00:11:43.190 - 00:12:22.864, Speaker B: Dabbit Three, and then you can find a project called Building a Subgraph Workshop. And this is the project that I'm going to be following today. So here I am, and I'm in the workshop building a Subgraph workshop. And all this is it's a combination of a README, a GitHub README that kind of describes how to do this. It's kind of like a tutorial. And then there is an actual Zora NFT subgraph folder that has the code that we're about to write. So let's go ahead and start doing this so the first thing that we want to do is we want to go to the Graph.com
00:12:22.864 - 00:13:00.850, Speaker B: Studio. And if you go to the Graph.com, you'll see that we have this drop down menu here and we've added now the Graph Explorer and the Subgraph Studio. We would click on Subgraph Studio. And here we're going to go ahead and click Connect Wallet and we're going to go ahead and connect one of our wallets. We're going to sign the request and now we're in our Explorer, our own personal Explorer, I would say, and we're going to go ahead and click create a subgraph. So I'll call this something like ETH Global API or something like that.
00:13:00.850 - 00:13:41.656, Speaker B: And now we have the place that we can deploy our subgraph to. So we have the subgraph slug, which is kind of like this right here we have the deploy key, which is what we're going to need for authorization. And then we have some other metadata here. So if we did deploy this, you could kind of set the description, the code URL, like on GitHub your website, as well as up to three categories. All right, so now that we've created that, we can go ahead and initialize a subgraph locally using the Graph CLI. So you would NPM install G Graph protocol CLI there, which I've already done. And then we're going to go ahead and use the Graph init command.
00:13:41.656 - 00:14:35.304, Speaker B: And I'm just going to copy this command here and I'm going to kind of walk through it from the command line. So here we are in an empty directory and here we're going to say Graph init and I can pass in a few different flags. So the first flag is going to be the contract name. So if your contract address has multiple contracts, you need to define which contract you want to build your subgraph off of. Like what is the main contract. In our case it's going to be token and you can add multiple contracts, of course, but for us, we only need one. We're going to pass in the index events flag, which means it's going to look inside of the contract's abis and it's going to look for any event and it's going to automatically pull down that metadata and create some boilerplate code locally for us because the way that we're basically getting that data that we're going to be indexing is from these events.
00:14:35.304 - 00:15:12.730, Speaker B: So for instance, when a token is minted, there is a transfer event that's emitted. When a token is transferred, that same transfer event will be emitted. And then also there is events that we're going to be listening for, for when a token has its content or metadata Uris updated. So let's say you have an NFT, you change the description or whatever those events would be handled here. And then finally we have the from contract address and we can go ahead and just hit Enter. And this should go ahead and set all this up. The only thing we need to pass in is the subgraph slug from the dashboard here.
00:15:12.730 - 00:16:00.762, Speaker B: We can go ahead and accept all these and this should go ahead and create our new folder here. So once that's created, we can go ahead and change into that new folder. And we're having some stuff being installed right now, some node modules. But while that's installing, I'm going to go ahead and open this up in my text editor. So the three main things that compose a subgraph are the GraphQL schema located at Schema GraphQL. Like I mentioned before, that is the data model and I can go ahead and just kind of delete that for now. We're going to go ahead and fill that out in just a moment.
00:16:00.762 - 00:16:43.080, Speaker B: The other file that we're going to be working with is the subgraph YAML. The subgraph YAML is the configuration that tells the indexer, what information to index. Essentially it kind of describes your subgraph to the indexer. So we're going to open that and then the last thing that we're going to open is our mappings. Because I mentioned before the mappings are going to be the code that we actually write to describe, I'm sorry, that matches, I would say the data coming from the events to our data model. All right, so for the GraphQL schema we're going to be indexing data from Zora. So if I go to Zora co I see that we have these NFTs and stuff.
00:16:43.080 - 00:17:36.870, Speaker B: So basically what I want to do is say, okay, let's know an NFT and we might want to get the price or the metadata, whatever information that we want to get on it. So let's go ahead and create an entity for token. And then we also might want to have relational data or links because I can actually click on this and then I can also look at the author or the creator and I can see all the NFTs they've created, right? So how might we model our data? So we have relationships like one to many relationships, many to one relationships, those sorts of things. So for us to do that we're going to have two entities and our data model is going to consist of a token and a user type. We're going to have different fields on each of these. So when we query for a token, we want to have different fields on that token. So we might want the token ID.
00:17:36.870 - 00:18:23.766, Speaker B: Of course we want the content and metadata Uri because this is going to be where the actual NFT images is images and other information. And then we might want whatever other metadata we want to associate or that is available. So we might want to be able to sort by when it was created. So we can kind of show the newest NFTs or whatever. We also are going to have fields for creator and owner. This way we can have relationships like I mentioned before, the other type is the user type and the user is going to be able to have an array of tokens that they've created and array of tokens that they've purchased. So we have those two different relationships and we can actually do the one to many relationship here.
00:18:23.766 - 00:19:21.354, Speaker B: Like a user has many tokens by using this at derivative from directive which is part of the graph CLI and graph node. It's kind of like part of the API for that and to create the relationship all we really need to do is pass in the field from which the relationship is derived. So this relationship is derived from the creator of the token which is going to be an address and this relationship is derived from the owner field which is also going to be address an address so we can go ahead and save that and we're done with that. So we can go ahead and close this. The next thing we'll check out is our subgraph configuration and the first thing we might do here is look at the entities. So the two entities that we actually created in our GraphQL schema were token and user. So let's go ahead and update that here.
00:19:21.354 - 00:20:14.582, Speaker B: So we have token, we have user. The next thing we need to think about are like what events that we want to listen for. So in our case I mentioned we want the transfer event, the metadata updated and the token Uri updated. So we already see that we have these event handlers created for us and these were created because we passed in index events meaning that we told the CLI to go ahead and look in the Abis and generate this boilerplate code for us so we can actually keep almost all of this. The only thing that we want to delete that we're really not going to be working with is the approval and approval for all. So we have token, metadata Uri updated, we have token Uri update and we have transfer. So we can kind of work with those three events and the last thing we need to do is actually handle these events as they are handled.
00:20:14.582 - 00:21:12.030, Speaker B: So when we deploy this subgraph to the indexer it's going to go and it's going to find this smart contract address and it's going to look for any of these events and when one of these events is fired it's going to call this function here passing in these arguments. So we're going to be going like transaction after transaction after transaction and every time that we find one of these events we're going to call these functions. Now we can also tell the subgraph like where to start because if we don't tell the subgraph where to start it will start at the genesis block. So let's say we want to say a start block and then here we can deploy our subgraph to start indexing from the address, I'm sorry, from the block where the contract was first deployed itself. So I can go ahead and just set the start block here. You can find this very easily on Etherscan. And now we're pretty much done with the subgraph YAML.
00:21:12.030 - 00:22:36.782, Speaker B: In order though, to create our mappings that will handle these functions, we're going to need talk to both the Graph node to kind of like save the information, but we also need to talk to the smart contract itself. So when you're dealing with the NFT, the ERC 721, the only three main pieces of data that you're going to have in this event are going to be the address from the previous owner, the new owner and then the token ID. So how do we get the other metadata? To get the other metadata, we need to actually talk to the smart contract. So Graph has a library called the Graph TypeScript Library and we can actually generate a bunch of helper code for us to kind of do that using the Graph CLI. And all we really need to do is kind of just make sure that we're in the right directory here and we can run graph code gen and the graph code gen command will now look at our updated GraphQL. Schema and our Abis and we'll generate a bunch of boilerplate that will allow us to interact both with the graph node as well as the smart contract itself. So now that that's been created, we have this updated generated folder where we have a schema and if we look at the schema, it should kind of match our GraphQL schema where we have a token and a user.
00:22:36.782 - 00:22:40.460, Speaker B: We don't really need to ever touch this code. Just kind of showing you that it's there.
00:22:43.070 - 00:22:59.120, Speaker A: Yeah, lesson setup. So when I forked it on my GitHub, the branch from the GitHub link forking and cloning are one and the same, right?
00:22:59.650 - 00:23:14.020, Speaker B: Yeah, we'll bring it down locally and then forking it. We'll just have it copied over to your GitHub repo. But yeah, either way it's fine if you want to get a copy of it. Yeah.
00:23:16.730 - 00:23:17.720, Speaker A: Thank you.
00:23:18.570 - 00:24:18.054, Speaker B: Sure. And I think the last thing we need to do is just to write our mappings. So if we go to SRC mappings here, we can go ahead and just start we can really just copy all this code, but I'm going to kind of go through it slowly, a little bit more slowly. Even though we only have five minutes left, I'm going to try to just kind of walk through a little bit. The things that we're going to be interacting with are going to be, again, the Graph node, like saving or even in the future if you need to, reading from the node itself and then also talking to the contract itself. So in the generated schema we have some code and some helper functions and stuff like that that will allow us to talk to the Graph node and then in this token folder. Token TS will give us helpers and functions and even events for type safety that allow us to talk to the smart contract.
00:24:18.054 - 00:25:05.014, Speaker B: So we're just going to import the ones that we want to work with there. So token and User token Uri, updated event, token Metadata Uri, updated event, and transfer event. So these are the three events, and this token contract will give us an API to talk to the contract itself. And then we need to just handle those three events. So the three events that we're going to be handling are transfer again, handle transfer, handle Token URA updated and handle Metadata URA updated. And all these do are just match these three handlers here and they can be written, of course, in any order. We're just making sure we export those.
00:25:05.014 - 00:25:52.200, Speaker B: So the main function actually, like with the most code here is this handle transfer. And I'll walk through this when this function is powered, this means someone's either minted a new NFT or they've transferred ownership of an NFT. So because of that, we need to take in consideration that there may be a token in existence or this might be a brand new token. Okay? So if there is a token, we go ahead and try to go ahead and fetch it right here. And if it does not yet exist, meaning that it is not yet in the graph node, then we need to go ahead and create it. So we go ahead and create the token. We set the different fields that we've defined in our GraphQL schema, like the creator and the token ID.
00:25:52.200 - 00:26:42.790, Speaker B: We then also set a couple of other different fields by talking to the smart contract itself, because we did not get the Content Uri or the Metadata Uri in the event. So we need to actually go into the contract, talk to it, ask for that information, and then we kind of save it here. So the token, if it doesn't exist, we create the token and then we update or set the owner. Because if it's transferred to a different owner or it's being minted, either way we want to set the owner field and then we just save it. So this saves the data to the graph node, and then we do the similar thing for the owner or for the user, I would say. If there is that user existing, we go ahead and do nothing, I would say. But if the user does not exist, we go ahead and create the user.
00:26:42.790 - 00:27:17.982, Speaker B: And then the last two handlers are really simple. All we're doing is updating the token Uri or the metadata Uri. So we just say token Metadata Uri is equal to the new value that comes into the event, and we just save it. So these two functions are very simple. All we're doing is updating either the Token Uri or the Metadata Uri, and then from there we should be done. We should be able to go ahead and deploy this. So to deploy we need to first authorize.
00:27:17.982 - 00:28:13.930, Speaker B: So we just run this graph off Studio and this is going to go ahead and prompt us for our deploy key. And the deploy key. If you remember, we can just copy it from our Graph Studio dashboard here to our clipboard. Just paste it there and then the last thing we can do now is we'll go ahead and copy the slug and we can say, graph deploy Studio pass in the slug, give it a version. It doesn't really matter what version you give it. And this should go ahead and deploy. And if deploy successfully, you should see something like this where you have an ID for the build and then you see where your API was deployed.
00:28:13.930 - 00:29:29.380, Speaker B: And if we go to our dashboard again, we should see that the data is starting to be indexed and right away we see that it's already 100% synced, meaning that it's literally gone through and indexed every single event and we should be able to start querying for it. So if I hit query, then I start seeing that we have our data coming back and we're given like an example query where we're kind of just returning the first five tokens. But we can also do which is one of the reasons that people use the graph filtering sorting. You can do full text search, all types of stuff. So one thing we might want to do would be like let's try to return one of these items that we're seeing here because we want to get one of the more recent items. So we might say order by created at timestamp and then we can say like the order direction is like descending because this way we can just bring back the most recently created NFTs and then we see that we have the token ID being 41, whatever. So let's go ahead and copy this content Uri and see if this matches any of the NFTs that we see there.
00:29:29.380 - 00:30:11.428, Speaker B: So we have that looking thing there. I don't see it here, but try this one more time. Maybe they have not refreshed with the newer stuff because this should be like the newest thing I think created. There we go. So this is the newest thing that came back and then that's right here. So we're getting the exact data, the same data that Zora is serving up now. We're about finished on time.
00:30:11.428 - 00:30:57.556, Speaker B: So I'm not going to go into publishing to the network because right now we're kind of in a sandbox and we're not really published the decentralized network. But if you wanted to publish this and start testing it out in a development environment, you could publish to Rinkabee. If you wanted to actually start using this in production or having other people pay you to use it or whatever, or try to signal towards it with GRT, you would publish to. Mainnet, which would be something you probably don't want to do until you're ready for sure, because to make an update, you actually have to deploy a new subgraph. But anyway, so that's it. And I actually cover that part in this tutorial as well. So there's a link to a video here and also a link to a full tutorial that shows you how to deploy to the network there.
00:30:57.556 - 00:31:11.750, Speaker B: And that's it. So thank you for checking this out. If you want to follow me, I'm on Twitter, and I'd be happy to answer any questions. Twitter David three, and hit me up with any questions that you might have there.
00:31:13.960 - 00:31:34.570, Speaker A: All right, thank you so much, Nader, for running this workshop for us. And thank you so much to the graph for sponsoring hackfs this year. I want to encourage you guys to continue this conversation in the graph sponsor Discord Channel. And yeah, that's pretty much it for the workshop. Thank you guys so much for coming and have a great rest of your day.
