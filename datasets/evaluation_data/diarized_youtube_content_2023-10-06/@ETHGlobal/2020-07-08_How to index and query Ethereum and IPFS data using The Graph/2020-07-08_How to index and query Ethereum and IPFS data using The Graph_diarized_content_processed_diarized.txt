00:00:19.710 - 00:00:48.666, Speaker A: Awesome. Yes, we are live. So let's get this going. Welcome, everybody, to the Graph Workshop. We're going to get an introduction to how to use the graph, what it is, how to make subgraphs, and a bunch of the tools that you can hopefully leverage during hackfs from Janice Coleman. He's a member of the graphs team, and so we're very excited to have him with us today. For the next hour or so, going into these resources, we also have another team member, Martin.
00:00:48.666 - 00:01:22.966, Speaker A: Martin, as you wish. He's going to be monitoring the chat and you guys will be able to surface questions to him. And the way we're structuring it is we'll be able to surface questions during the session. We won't have to wait until the end, and then we'll try to make it a little bit more interactive for people. As always, please make sure to stake, if you haven't already, for Hack FS. The cutoff for that, I believe, is tomorrow, midnight Eastern. So Thursday midnight.
00:01:22.966 - 00:01:51.410, Speaker A: Please make sure to do it before then. And then after that, we'll be removing people who haven't staked from the event because they're no longer eligible. But I'm sure everybody here has already done that and they've gotten that out of the way. No problems. All right, so right before we jump into this workshop, we're going to do a quick little something. I'm going to invent a game really quick. Let's see if we can get as many people to turn on their videos.
00:01:51.410 - 00:02:18.106, Speaker A: If you can, no worries. If you can't. And the game we are going to play needs a few more people. I'll give it ten more seconds to turn on your video. Thank you, michael Ann Mall. All right, game is on the count of three, or whatever the equivalent is. When you hear this through zoom, you're going to put up either a one or a two.
00:02:18.106 - 00:02:54.280, Speaker A: This is not really competitive, but you get assigned to a team as soon as you put up a one or two. And yeah, we'll see who wins. One, two, three. Don't change it, Andrew. You count the ones whos take it by a wide margin. Sorry. We should keep a running tally of all the wins because I think I'm winning most of these games, sorry to say.
00:02:54.280 - 00:03:07.770, Speaker A: Well, okay, feel free to keep your videos on or turn them off and then, like always, put your questions in the chat. And now I give it to you. Janice, tell us about the graph.
00:03:08.910 - 00:03:45.510, Speaker B: Thanks. Hi, everybody. Glad to see so many people joining. So we'll be walking through how to build a subgraph, how to get started with that. Obviously, we're not going to build like a complex one today, but we're going to play with one a little bit, see what kind of features you have available to index data of ethereum and IPFS and also awev if you want. And so the graph, first of all, if you don't know it yet or don't know us yet, take a quick look at the website. I hope I can bring that up.
00:03:45.510 - 00:04:46.860, Speaker B: There we go. So the Graph is essentially an indexing and query protocol for the decentralized web right now focused on Ethereum and IPFS, with other blockchains being planned for the future. And what it allows you to do is to build really fast applications, DApps on top of Ethereum without having to go to Ethereum nodes a lot for small pieces of data and having really long load times. Instead you can define a custom schema for your data upfront and you can then use events and other information from the blockchain to trigger data extraction transformation and then you can query that data later on with GraphQL. That's basically the gist of it. We are participating in this hackathon and we are giving away, I believe, let me double check that. I don't get this wrong.
00:04:46.860 - 00:05:35.290, Speaker B: We're sponsoring two prizes of 1000 die each to the best new subgraphs on the graph. And yeah, what I want to share with you to start with is a few of the resources, where to find them and how to get started and then we'll dive into building an actual subgraph. So we have on the Graph.com hackathons, we have overview of the hack, of the hackathons that we're participating in. For hackerfs, we're obviously linking to the official page and you'll find more information there. I guess that's not new for most of you or for any of you. And the main entry point for you will probably be the Explorer.
00:05:35.290 - 00:06:32.902, Speaker B: So that is where you create a subgraph on what we call the hosted service. That's a hosted cluster where you can have your subgraph indexed and where you get endpoints that you can query or use in your applications. You can also run everything or almost everything, not the Explorer, but like the stuff behind it. So the graph node that does the indexing and also provides the query endpoints, you can run that on your own machines as well. I imagine for this sackathon, I believe for this sackathon, it's a requirement that they are submitted through the Explorer. And so the Explorer gives you first of all, when you come here, you can browse around, see what projects have already built a subgraph and are using it potentially. So the Decentraland Marketplace, for instance, is a live DAP that use decentraland data for querying.
00:06:32.902 - 00:07:15.050, Speaker B: And so you can send GraphQL queries to that and you can see what kind of data there is and you can explore that a little bit, see what kind of filters you have, for instance, to narrow down the data that you need in your application as pagination, et cetera, built into. We'll get into that later. And all subgraphs basically look like this. You have like a progress bar when it's processing data because there's a lot of blocks on the blockchain. So depending on how much data you need that'll take some time. And so this gives you an indication of how things are progressing. You can see some more data, like how many items you've actually or how many entities you've actually put into the store, how many records that you can query.
00:07:15.050 - 00:08:10.262, Speaker B: And then you also get like an endpoint that you can use in your app and you can basically just copy and paste that. There's a bunch of really good GraphQL libraries out there in different languages. JavaScript usually people use Apollo, there's a few others there as well. And you can also use just generally any kind of HTP library and just send JSON queries, GraphQL queries to this endpoint and get the data back. There's a bunch of subgraphs up here, there's more down here, so when you create yours, it'll show up here and you can also search through what's already there. And then there's also a dashboard. So once you sign in for that, you need a GitHub account right now because we're basically piggybacking on the GitHub account know, with organizations and users.
00:08:10.262 - 00:08:51.930, Speaker B: Figured most developers already have GitHub account. In the future, that will no longer be the case. GitHub is after all, centralized, but for now this is fairly convenient. So there's a dashboard where you can see your own subgraphs and can see both the subgraphs that you have created as well as the subgraphs that you've bookmarked, for instance. And so if I go here, for instance, I can also see my organizations. So when you have an organization, you sign up with that, hopefully you'll see it. If not, there's some instructions here on how to get your organization into the Explorer.
00:08:51.930 - 00:09:45.078, Speaker B: You get an access token that you can use to deploy subgraphs under your account. From the command line we'll get to that. You'll notice the purple button on the upper right corner, that's where you add a new subgraph, which we'll also do in a moment. And then you see your own subgraphs and they look basically like any other subgraph, right? So just what we saw with decentraland and you can also see the logs. Those can be a lot if you have a lot of data, a lot of events that you're scanning, you might get a little bit lost here. So that's why we have like a fuzzy search bar up there where you can pretty easily search, let's say, for processing, where it's processed events. Now this one I think is pretty old, so as subpress get older, the logs load slower.
00:09:45.078 - 00:10:33.334, Speaker B: So in this case we might not find anything. Doesn't surprise me right now, but yeah, yours will load pretty fast and at different log levels, obviously. And you can also do your own add your own logging to subgraphs, not just the stuff that we generate automatically based on what's happening with the subgraph. Cool. So that's the explorer. When you get started, there's some documentation on basically some introductory information of what the graph actually is and what the gist of it is and how it roughly works. But then there's also quick start guides for both local development, where you run your own node locally, as well as the hosted service, which is the main interface being the Explorer.
00:10:33.334 - 00:11:34.000, Speaker B: But there's also some interaction from the command line with it, and that walks you through what you need to install on your machine, how you create a subgraph from scratch, how you then deploy it. I think that's maybe that must be mentioned somewhere. And then this is a bit outdated by now, I think. But there is an example application that we wrote for, I think, or like refreshed for Last E Denmark, where you can see how the GraphQL endpoint is wired up and how queries are sent and so on. But for most of these subgraphs that you can find in the Explorer already, there's apps out there that you could also potentially look at. So most of these are, of course, open source, so you can have a look around as well. And we're happy to provide guidance always on how to do things.
00:11:34.000 - 00:12:13.306, Speaker B: And then there's pretty detailed instructions on how you define a subgraph, what kind of elements that includes. I'll get into the details there in a moment. There's instructions on how you deploy it to, let's say, the Explorer, how to create an account. So basically what I just showed you in the Explorer, your dashboard and so on, that's all kind of explained here a bit of GraphQL documentation as well. I think some of that is a bit hidden under the query API. I think that takes you to this one. So that's where a lot of the filters that are automatically generated for your schema show up.
00:12:13.306 - 00:13:07.740, Speaker B: I'll also get into more hands on details there. And when you build your subgraph, you'll probably spend most of the time in the actual data extraction transformation and reading stuff from the database, changing it, writing it back to the database. And there you're working in a language called assembly script, which is more or less a subset of TypeScript that compiles to WebAssembly. So all your subgroups run in like, isolated sandboxes in WebAssembly. And for convenience reasons, most front end developers are using JavaScript or TypeScript. We picked assembly script as a language for that so that it's not like such a big disconnect between the front end developers and the subgraph. Authors or developers might even be the same people.
00:13:07.740 - 00:13:53.690, Speaker B: And so here you find a lot of information about the Ethereum API. What you can do with Ethereum, the Store API where you load data and write data back, usually you won't interact with that directly. There's a logging API. There's an IPFS API to read files from IPFS if they are anchored on chain JSON API, because often data on IPFS is JSON crypto API. I think that's a bit of an exaggeration. I think that's one function, right? Yeah. Then we provide some built in types for big decimals support for big in support to support these really large numbers on Ethereum, that JavaScript and also TypeScript and assembly script don't provide natively.
00:13:53.690 - 00:14:38.838, Speaker B: You can convert between the different types as well. And primarily we'll look at some of these when we walk through the actual subgraph. But yeah, that's the docs. Pretty easy to find up there in the navigation at the graph.com docs and what you don't find there please you can join our discord and we'll be happy to answer any questions there. We have a support channel that's pretty active and yeah, we can then point you to specifics or explain things that is not things that are not explained in the docs yet. So easiest way to get there is the Graph.com
00:14:38.838 - 00:15:38.458, Speaker B: discord but I think we also link to it from the website if it's not sure if it's in the footer somewhere down there, not on the docs. Okay, but go to thegraph.com scroll down and there's I think the discord link down there, this one. So yeah, you'll be sure you'll find that cool. So any questions up to this point? I don't actually see the chat right now. Martin, what is private message we'll get to? What a subgraph? Martine, you suggested I should cover what a subgraph is. You mean the documentation section or just as a general overview? Right, let's do that.
00:15:38.458 - 00:16:23.642, Speaker B: Let's see if there's a description up here. I think it's easiest to explain the easiest by A, looking at the way you can interact with it and use it and B, the actual subgraph contents and then I'll explain more there like what the building blocks are. So let's get to that. Now let's create a new subgraph. Guess we'll call it Hack FS Workshop and we give some guidance here for good names. Tests usually not a great name, but Workshop should do it'll, be happy with that. So you can pick the organization or the personal account that you want to create this under.
00:16:23.642 - 00:16:54.126, Speaker B: You can create an image, you can also edit that later. Demo subgraph for the hackathon. You can put a detailed description in there that will be shown GitHub URL if you want to point people to the source code. You can also hide it if you don't want it to be seen in the explorer. But for now I'll just create it publicly. There we go. And then here you'll also find some instructions on what to do next if you don't follow the Getting Started guide.
00:16:54.126 - 00:17:45.150, Speaker B: In the docs you'll see some commands you need to install the Graph CLI which you can use to build the subgraph and deploy it. There's some instructions on creating a new subgraph from scratch on the command line because this is basically an empty container right now and then also how to deploy it. But we'll do that. So first thing usually is that you need your access token and you need to authenticate with the service. So what you do there is you do Graph Auth Htpsapi, the Graph.com deploy and then you paste your access token in and that'll store it in your secret system key storage and automatically fetch it from there as well when you run deploy commands. And I think that's covered probably here under Deploy, yeah.
00:17:45.150 - 00:18:08.780, Speaker B: So you don't have to remember that now. And I've already done that. Let me really quickly see. So we've created the subgraph in the Explorer, right, that's there. And we can also confirm, I think, that it exists and it's shown in the browser. So there it is. That takes us to the same site, the same page.
00:18:08.780 - 00:19:15.634, Speaker B: And the next step then is to actually create the actual contents for that subgraph, the code that decides what or the hooks that decide what kind of events you want to listen on and process the schema that you want your data to be represented through and that you can then use to query data. Then there's two ways to do so. Generally, it's called graph in. It that you get by installing Graph Protocol, Graph CLI and then Graph in it has a from example flag and a From Contract flag. So the from example one, I'm not going to run these now because my network has like weird SSL issues and half the NPM or node dependencies don't download. So I've done that just before to not have to do it again. But the from example one, you basically give it a name or you don't, doesn't matter.
00:19:15.634 - 00:19:53.086, Speaker B: You can then choose it later on. It walks you through like an interactive form where you can make that a little bit bigger, where you can type in all the bits and pieces that are needed to create the subgraph. But this creates a subgraph that's very simple. It's a gravity based subgraph. So gravity is like I think it was an experiment to bring gravitas to Ethereum where you anchor images on Chain and that are stored on IPFS or something. Or maybe it's just URLs that you put on Chain and you add your name. And then basically you have a Gravitar that's associated with your Ethereum address.
00:19:53.086 - 00:20:45.680, Speaker B: And wherever you paste that you could in theory then look up the image. That's a very simple example that has like a couple of events that you listen on and that's it. The other way to do it is to use From Contract. And the way From Contract works is you can go to say, Etherscan and you'll find a contract that interests you or that you have already deployed perhaps where you have uploaded the abi to Etherscan or where it is already uploaded to Etherscan. For instance, like this Molog contract here is, I think, verified and the Ethereum abi has been uploaded. You can see the code here, you can see the abi. So what you can do is you can basically copy that and you can say graph in it from contract paste in the contract address.
00:20:45.680 - 00:21:17.926, Speaker B: You don't need to pass this in, sorry. And then you walk through a similar form where you can then create a subgraph from an existing contract and that'll fill in some pieces already for you that might or might not be familiar to you from the contracts and you can then fill in the gaps to index data. So let's look at that. Where am I? Here. Workshop. Let's do this. Molog one.
00:21:17.926 - 00:22:14.490, Speaker B: So Molok is a Dow, has proposals, members, votes, that kind of stuff, I think. So if we go to that directory, open it in an editor, we'll see a few files here and a few directories. So the first thing is it's kind of like any JavaScript package in that it has a package JSON with a couple dependencies. So we have like TS should probably be called as or something because it's the assembly script library with our big decimal types and so on. All the APIs that we provide on top of the standard assembly script. And then there's graph CLI, which we then use to run code generation, run builds, deploy the subgraph and so on. That's basically like any other JavaScript project where you can add dependencies, but you can use JavaScript or TypeScript dependencies in your subgraph code.
00:22:14.490 - 00:23:05.930, Speaker B: That doesn't work because that code is assembly script. So sometimes confusing, but there may also be some assembly script libraries out there that you can use after that. Kind of the main entry point is, is the subgraph manifest. And that kind of puts all the different building blocks that make up your subgraph together. And it consists of a few main pieces. So one is the schema that defines the shape of your data. What types do you have, what fields do they have, what relationships do they have? And that then gets translated into that GraphQL API that we can play with in the Explorer for instance, or that you can use in your DAP.
00:23:05.930 - 00:23:43.782, Speaker B: And then the other thing is the so called data sources and you can think of currently of a data source as a contract. And so there's a kind that you pass in say Ethereum Contract. You can give it a name that's completely up to you. You give it the network that it's on. So like Mainnet, Rinkobee, Robson, Covan, Gurley, XDI, there's a few more that we support. So basically all the testnets and I think Poi Core as well. So a bunch of options there that work on the hosted service.
00:23:43.782 - 00:24:17.780, Speaker B: But if you have a provider and you run a local node that you can hit with an Ethereum JSON RPC API compatible blockchain, then can use that as well. And then the contract lives at an address so that's the source is the address. And the Abi, the Abi is basically just a name. Further down there there's a list of abis that you can add. So you can add multiple Avis for any contract that you want to interact with. And we use those to generate some code for you. I'll show you that in a SEC.
00:24:17.780 - 00:25:09.342, Speaker B: And yeah, the address is where the contract lives at on Ethereum, right? So that's what we looked up on Ether scan. Where does that contract exist? Copy that. Over. And that means I'm indexing this particular contract and then a data source comes with a mapping. And the mapping defines the triggers, primarily the triggers that you want to perform some indexing work in reaction to, and the list of abis and the actual code that does the data extraction, transformation, so on. So in this case, because we did graph in it from contract, it basically fills in all the events that exist on that contract already. And there's handlers for all these events.
00:25:09.342 - 00:25:45.550, Speaker B: So whenever a proposal is submitted on Molloc in this contract, this function is called in your mapping. And you can then do whatever you want with that, more or less. And yeah, you can add a bunch of Abis. So in this case, we've automatically pulled the Moloch Abi from Etherscan. And it looks like this. And that's basically all the methods, all the functions that that contract has, all the public state variables and all the event abis. And so we have that.
00:25:45.550 - 00:26:38.750, Speaker B: How do we use it? What's this mapping file and what are these handlers and how do I use them? What do I do with them? And also, let's start with the Schema. Like, what does the Schema look like? What shape can my data have? How can it be relational? Et cetera? So the Schema is a GraphQL schema written in the so called GraphQL schema, definition Language SDL. And what you can do there is you can define types like example entity, or we can actually check here. What do we have? We have proposals, we have votes. Let's create a type proposal. We tag it with this called directive entity directive to declare that it's an entity that we can then query later. We give it an ID that's mandatory.
00:26:38.750 - 00:27:15.370, Speaker B: And we can then give it some fields like these were pre filled in just to have something there. What does a proposal have? It's a good question. We'll find out. So for now, just call it, just give it an ID. We can add another one for votes, let's say also give it an ID and we'll see what we can do with this. That's the schema. And you can have different fields that can have, let's say you can have like a big in field or you can have, let's say, small count, just int that's just int 32.
00:27:15.370 - 00:27:40.466, Speaker B: This one is arbitrary size. You can have big decimals here for really large fractional numbers. You can have bytes for any byte data, like addresses, for instance. So that could be bytes. And the exclamation mark means the field is required. So the default in GraphQL is null. So it can't be null if you leave that off.
00:27:40.466 - 00:28:42.466, Speaker B: It can also be left out and you don't have to set it. And then we have what else we have, we have lists, so it can also be like addresses and you have bytes in non null, bytes in a non null array, that kind of stuff. And you can also, I'm assuming votes have like a proposal that they are for. So you can also, let's say, do proposal, and then you can say that points to a proposal and we'll see how that works. So you can have relationships between them and you can also have all the votes for a proposal as a list of votes that is derived from the field proposal in this not sure, done this in a while. And this will automatically allow you to query all the votes that have been created against the proposal without actually having to manage them. You just have to put a proposal ID into the votes.
00:28:42.466 - 00:29:33.570, Speaker B: So we'll look at that in a moment. So that's the schema. And the other thing is the mapping. So the mapping has all the handlers that you define in your manifest and you have to export them as functions and they receive the thing that you trigger on. So event handlers trigger on events, so you get like an event parameter that is typed based on the API and you can then get data off of that event. So for instance, you can get the transaction of that event and you can get the sender from that transaction and that's an address. So you convert that to a Hex string, and you can then use it as an ID for an entity, for instance.
00:29:33.570 - 00:30:17.640, Speaker B: And you can try to load that entity. And if it doesn't exist yet, you can create it with the same ID. And you can set fields on the entity. Like with any OD JavaScript object, more or less. And ultimately, when you're done with writing your entities or like changing your entities or creating them, you can save them to the store. And at that point the new changes, well, as soon as the block has been processed, that data can be queried. So as soon as you save changes and all the events in your subgraph from that same block have been processed, they are all transacted into the database in one single step and you can then just consume that data.
00:30:17.640 - 00:31:08.490, Speaker B: And what else can you do? This is commented out and it's basically listing all the things you can do here. The Molar contract has a bunch of functions that you can call to get extra data that's not on the event into your subgraph. So for instance, you can access the members here. I'm not sure what the parameters are, but what you can do is the event comes from a contract. That contract has an address and you can then bind that to. You can basically bind the contract class that we create for you from the Abi to that address. And then you have an instance of the contract that you can interact with, can make transactions against that, because that would be mutating things on chain and who would be the signer of those transactions.
00:31:08.490 - 00:31:47.154, Speaker B: Doesn't work. But what you can do is you can bind it and you can then in theory not just in theory, you can then call functions on it, like get the current period, like voting period. I assume for instance, stuff that's not in the event because the event has a limited number of fields, probably. So yeah, we stub out basically all the event handlers for this contract automatically if you create it from an Abi. And then you can just fill in the gaps. So that's something I'd like to do. Now, you'll notice that there are a few errors here.
00:31:47.154 - 00:32:26.942, Speaker B: So you can't find certain files. That's because some files are code generated from the Abi. And the way you generate that code is you run yarn CodeGen and that will take the manifest all the Abis and create code files for that. And so you can see here loaded the contract created this one. It's created a Molloc contract class, and it's also created some types for the schema that you can then use in assembly. So now maybe I have to reopen this. There we go.
00:32:26.942 - 00:32:53.270, Speaker B: So, example entity. I've removed it's. Now proposal. That's the type I just created in the schema here. Let's just wipe all of this for the moment. We can create something new. So what do we want to do in addition? So, first of all, we have the proposal class now, so we can say whenever there's a new proposal submitted, we create a proposal.
00:32:53.270 - 00:33:22.800, Speaker B: New proposal. And what should we use as the ID? Every entity needs an ID. There's probably something on here. Proposal index could work. IDs need to be strings, so we can convert that to a string, which gives us like the decimal string of that number, and then we can save that proposal. Right? Easy. That's a pretty boring proposal, but might work.
00:33:22.800 - 00:33:47.414, Speaker B: Okay, let's do it. Let's try it. So if you want to test whether that builds locally, you can just run yarn Build or NPM run Build, which will run graph build. Seems to be okay. The next step after building would be to deploy it. And by default, when you create your subgraph, you already give it the name that it has in the Explorer. So I've not done that.
00:33:47.414 - 00:34:49.990, Speaker B: So I need to go into package JSON and change Yanis Molog to yanis what is it? Hackfs workshop. So it's just a command graph deploy, providing some URLs, like the IPFS node that all the files get uploaded to the hosted service as the endpoint to deploy the subgraph to, and then the name of your subgraph. As like a URL, like a URL representation, not like a display title or something. If I do that now, I hope that it works. So this builds the mapping, or the mappings. If you have multiple data sources into WebAssembly, which you can see also, what else does it do? Yeah, that's all the compilation it does. But then it also collects all the other files involved, like the Abi, the schema, the manifest.
00:34:49.990 - 00:35:57.970, Speaker B: It puts them all on this IPFS node that you've provided and giving you like a final IPFS hash for the top, like the root of everything, which is the manifest file. And then deploys a subgraph and the subgraph or the explorer gets told, or the service gets told this IPFS hash and then it knows, okay, I'll go to IPFS and I can retrieve the entire subgraph data from that or not data, but all the files involved, I need to run this subgraph. And so if we refresh this page now, we should see a subgraph syncing. I hope it speeds up a little bit, but I can show you a trick on how to make that faster. So it's starting to scan the entire history of the blockchain with filters based on your data sources. So we have one contract, we have all these events that we're scanning for, and it'll go through the entire history of the chain, filtering all the events there based on these parameters. And I think right now there's very little.
00:35:57.970 - 00:36:27.610, Speaker B: Like, if you go to Debug, you'll see some more details. It's found in this range. It found zero relevant blocks, so it doesn't load any. Then it scans the next range and so on. That usually doesn't take particularly long, although this looks somewhat slow. What we could do is find out when Molok was actually created. So this was the transaction, that is the block number of that transaction.
00:36:27.610 - 00:37:11.738, Speaker B: And so in our manifest, we can set a start block, which is that number. So we basically skip everything up to that point and just start indexing from when the subgraph, the contract was actually deployed. That is helpful. Let's send that up. And that'll also in this case, it'll immediately replace this version because that hasn't finished indexing yet. If you already have a version that's indexed, it'll like show a little if you refresh it'll, show a little pop up here to switch between the current version that's already synced and the one that you just deployed. So you can switch between them.
00:37:11.738 - 00:37:46.130, Speaker B: Shows you different endpoints that you can play with. Okay, so we're looking better. We're at 70% roughly, and it's found some triggers, it's processed some events. Submit vote, submit proposal. And you can see some extra information there, like, what block was that on? And you can then also search by that. So I could let's say submit proposal is the event I'm interested in. So I can see what happened there, if it found any events et cetera.
00:37:46.130 - 00:38:09.610, Speaker B: It should have entities by now. I'm not sure. I think this is a little bit cached. So the entity number it was showing there may not be updated yet, but we saw some proposals being submitted. So we should have some proposal IDs, some proposal entities. TADA. So we have some data.
00:38:09.610 - 00:38:39.000, Speaker B: It's not particularly interesting, but we have proposals. And you can see the two types that we created on the right hand side, the schema, the proposal with the votes that are not set. We can see if we can get some votes here. No, it's all empty lists, so that's all right. It's a start. Right? Let's see what else we can do here. And please interrupt me if you have any questions.
00:38:39.000 - 00:39:17.010, Speaker B: Or Martin, you interrupt me if you've collected any questions. So, the proposal right now doesn't have a lot of data on it, but there's more data on the event. So, params, there's an applicant, there's a member address, there's shares requested and a token tribute. So we can basically put all these on the proposal. Let's say if you wanted to store, like, the shares, let's say the shares requested on this proposal, we can try that. Okay. That field obviously doesn't exist.
00:39:17.010 - 00:39:58.720, Speaker B: And I think if I were to run this, it'll deploy this, it'll work, but it probably failed to build, I think also do yarn build Watch, which will ideally keep watching your subgraph, show you any errors on the way. So, yeah, shares requested doesn't exist. Tough luck, we'll add it. So, shares requested I think that was a big end. See, it says Big end there. If you hover, it get some information. So let's call it big End.
00:39:58.720 - 00:40:31.580, Speaker B: And then we have to rerun code Gen because we changed the schema. So whenever you change the Schema or you manifest, you have to or the Abis, you have to rerun code Gen. But after that, we should be good to go. And this seems to compile, so can deploy that as well. And we'll let that actually we can look at it right away. It's uploading. Okay, cool.
00:40:31.580 - 00:40:46.430, Speaker B: All right. I think it's already deployed. The new version. You can always double check. Does this IPFS hash subgraph deployment. ID match ends with NR six. This ends with NR six.
00:40:46.500 - 00:40:46.686, Speaker A: Okay.
00:40:46.708 - 00:41:11.720, Speaker B: It's the same version. Cool. So, proposals, share requested, shared requested an ID. Cool. We have some more data, and we can then, for instance, filter using a bunch of things. Right now, we have just two fields on this. So we can do some filter by certain ID properties, or let's say everything where the shares requested are greater than 100.
00:41:11.720 - 00:41:47.470, Speaker B: This is a big int, so it's represented as a string, like in the Big Number JavaScript library that's used all over the Ethereum Ecosystem. Okay, there's no proposals with that yet, but maybe there's some less than 100. Cool, that's one. Okay. So you can then also say if you want everything that has more than that. You can say order them by the shares requested, order direction, say descending. So we find the ones the proposal with the most shares requested.
00:41:47.470 - 00:42:29.102, Speaker B: And you can also say just ask for the first five. And now that did not work. Why did that not work? Let me see something here does not make sense. Okay, greater or equal? Okay, there we go. So there weren't actually any greater than that. Oh, yeah, I did try that first. Okay, so we can say like, first five, order by shares requested, order, direction, descending, and then let's just buy that off and let's yeah, cool.
00:42:29.102 - 00:42:55.442, Speaker B: So 102, 100, 100, 100. You can trust me that's everything. There's no missing pieces here. Okay, so how about votes and relationships, which is pretty important. So whenever there's a vote submitted, a bet that has proposal index on it. Proposal ID. Proposal index.
00:42:55.442 - 00:43:26.100, Speaker B: Cool. So let's create every time a vote is submitted, let's create a vote. We can import that from the generated code for the Schema event params there's a vote ID, I assume, so let's use that too. That may be a I'm not sure what type is it? U invotes that's any I'm not even sure what that means. Not quite sure. I trust that any looks weird. We shouldn't have that.
00:43:26.100 - 00:44:14.714, Speaker B: I'll use the we'll use it another thing we could do, we could do that. So if we assume there's only one vote per transaction, we could then go into event transaction I'm using the wrong version here. Okay, let's stick to that in theory, you can also go to the transaction and any transaction data on it, like the transaction hash, for instance, use that. Let's use a proposal in the member address. It's not ideal, it's not great. There may be multiple votes for the same member, but let's use something do two hex or two X string. Here's an address, convert that to a string.
00:44:14.714 - 00:45:06.420, Speaker B: Let's save the vote as well. And vote has a few more fields. So, proposal, for instance, and we are using the proposal index as the ID for proposals and to link them together, we use the IDs again. So in this case, we just set the proposal not to like an object of the proposals, but to the ID of that proposal. So in this case, that will be proposal index to strings, the same thing that we use when we create the proposals as the proposal ID so we can link them up together like that. And so now we explicitly establish this relationship from the vote to the proposal and these relationships or this relationship will be inferred or derived at query time. So based on the value of the field proposal in the vote, so we'll basically find all the votes that match the current proposal's ID.
00:45:06.420 - 00:45:42.240, Speaker B: Let's deploy that as well. And then we'll quickly look into contract interactions and then I think we'll wrap it up on the subgraph creation. Maybe we'll quickly look at the docs one more time, see what other things you can do there. Cool. Let's refresh this one and let's see. So what about the votes and that we have? Do we have votes? We have one vote. Cool.
00:45:42.240 - 00:46:13.880, Speaker B: What proposal is that for? This one. Great. What votes does that proposal have? Okay, there's more votes now, but let's assume it was this one. It has votes now we can query those. Even though all we did was put the proposal ID into the vote, they are automatically linked together. And that works both ways. So you can also have it the other way around where you infer the other side.
00:46:13.880 - 00:47:08.620, Speaker B: So yeah, we can now, for instance, find all the proposals where the vote we can't filter on the votes. That's right. But we can for instance, for all the proposals, we can get the ID and we can get the other shares requested, and we can get the votes and of those again, we can then filter them by whatever. So we can also just say, give me just the first one vote for everything, have all the proposals, and then we get a bunch of proposals, but just one vote each. So that's how relationships work, roughly. You can also have them explicit. You don't need to have this derived from you can manage them on both sides if you want, but often this is quite convenient because you just put the ID in there.
00:47:08.620 - 00:47:56.520, Speaker B: All right, that is that contract interactions. So this is something you will often need is not all the data is on the event that you want. Let's say a proposal was made in a certain I think what was the contract? Let's first create the contract instance. The contract is Mollock, which we can import from the generated code for the abis and we can then bind that to the damn, I hope this compiles. This is running a different version locally that's a bit broken. In theory there's an address here, or in practice there is. I hope that it compiles anyway.
00:47:56.520 - 00:48:53.130, Speaker B: And what you can then do is on the contract, you can, for instance, get the current period I don't know what exactly the period is, but you can then also store that on the entity, for instance. So if we added a period big int on the proposal type and we bind the contract, we can make calls to that contract at that block that this event comes from. So not at the current block, but at the block that the event came from. And so that gives you powerful abilities to extract more data out of the contracts, which normally you would do in your like what traditionally you would do in your DAP. You'd go to the contract, you get some data out piece by piece. But here you can do it over time. You can pre aggregate data there if you want, and then have it really quick when you query it from the client.
00:48:53.130 - 00:49:46.070, Speaker B: Okay, we've done these. I wouldn't say it's built out, but that's, I think as far as I'll take it. Here in the docs under Define a subgraph, you'll find a bunch more features. So we've covered contract interactions, we've covered event handlers, the GraphQL schema, how you define entities. There's also interfaces, so you can have multiple types that have shares and fields and you can define them as interfaces and you can also query the interfaces and you can have relationships on the interfaces too. There's a full text search feature as well where you can more in a more powerful full text search manner. You can search across the entities.
00:49:46.070 - 00:50:37.658, Speaker B: You're not limited to these filters that are pre generated. There's data source templates. So if you have a factory or a registry contract where that creates other contracts and you want to keep track of those as well, but you don't know them obviously, at the time you're building your subgraph because they don't exist initially. You can also create data sources dynamically at runtime from within your mappings for those contracts and you create them basically like the data sources but under a field called templates. And you leave out, I think, the contract address. And that's it. You basically just pass the contract address into the instantiation of that data source template start blocks we've looked at, you can do that in all the data sources to speed things up.
00:50:37.658 - 00:51:27.290, Speaker B: There's call handlers, so some things are not available, some contracts don't implement events for everything. So the ESC 20 contract, for instance, or Standard, I think doesn't mandate, for instance, Mint events. And so one way to work around that is that you can define call handles that trigger on transaction functions being called from either the user directly or from another contract. It's definitely more expensive and slows things down. But try it if there's no other way. There's block handlers too, even slower because basically pulls down every block that's relevant. Either all the blocks not a good idea, probably, or just the blocks that involve a call to your contract.
00:51:27.290 - 00:52:11.020, Speaker B: So that allows to filter them a little bit. Yeah. So that's not everything, right? There's plenty of things you can do in the API. They provide, for instance, like the logging capabilities, pretty cool. You can use placeholders and kind of printf style log, some stuff that you can then see in the Explorer. You can then search to see to debug your subbrows and so on. Questions? I'm basically done with the walkthrough and I'm happy to take any questions about features or things that maybe went too fast or anything at all.
00:52:11.020 - 00:52:21.900, Speaker B: Can surface a question.
00:52:22.670 - 00:52:23.900, Speaker A: You hear me?
00:52:28.590 - 00:53:03.914, Speaker B: Think you can hear me, right? Yeah, there was a question about creating subgraphs for getting data from IPFS packets. Yeah, I can quickly show that, although probably not in action because there's no IPFS hashes anchored on Molok, I think. I don't know. So the way the IPFS API works is you can import IPFS from graph. TS. So our API library and what you can do then is you can do caps. Usually what people do.
00:53:03.914 - 00:54:10.154, Speaker B: There's more a capable version called Map where you can map over the lines in a file if there's a very big file in JSON, but usually cat is enough. And if you have an IPFS hash anchored on chain and you maybe pass it to an event so that you can process it off chain or something, you can then pass it into this IPS cat call and you get a result back. And I think the result is bytes. So it could be null if the IPFS cat call fails, because unfortunately, the distribution of files in IPFS is not great. So it's often the case that you try to get a file as an IPFS node, but you can't reach it in the network. And so eventually you time out. And so if you really want to make sure that your IPFS files can be found, you can pin them on our IPFS node, which is the one that you're also using for deploying.
00:54:10.154 - 00:55:03.150, Speaker B: So an HTPs API, the graph.com IPFS, that's a full IPFS node, and you can just pin files there if you want, if you get the data back. So if it's not null, let's say the error handling here, if there is a file and there is data, you get it as bytes. And quite often what happens is you have a JSON file there. So what you really want to do is get the JSON data. So then you can import the JSON API from our Graph TS library and you can do from bytes, and you can then just pass the result in and you get back a JSON object. It's not as convenient as like a JavaScript object, where you can just arbitrarily dive into the object.
00:55:03.150 - 00:55:53.322, Speaker B: You have to often check what the type of the specific JSON value is that you're looking at. It could be an object, could be an array, it could be a string. So you'll be wise to not just convert to like an object blindly, because you can't always trust what this data really is on chain. It could be garbage too. So there's a try from bytes. Try is kind of there's no exception handling here in assembly script yet. So for both for JSON parsing as well as for instance the contract calls there's try variants which can fail and the result in that case both of the contract calls as well as the JSON loading.
00:55:53.322 - 00:56:20.280, Speaker B: Parsing is a result object and that then has an error or a value on it and you can then check what happened. And yeah, you'll also get logs for the failed try calls. Okay, that's roughly how IPF works here. Sorry. Look at it. Of course.
00:56:22.730 - 00:56:53.620, Speaker A: Yeah. Anybody? If you have questions, feel free to unmute and just ask directly and we'll try to get to them. We do have to wrap up in a few minutes, so if you can surface them sooner rather than later, that'd be very helpful. Yeah, go ahead. I guess maybe you covered everything.
00:56:55.510 - 00:57:35.102, Speaker B: I'll show one more thing, how do I actually use the data outside the explorer? People don't always spot this URL or don't know how to use it. So sometimes people think that it can just send this string to that endpoint, it'll work. That's not quite how GraphQL works. So GraphQL is JSON. So it requires a JSON object that has a query field that has a string value and the string value is this query. So let me try that real quick. So I can do this, but that's cheating a bit.
00:57:35.102 - 00:58:44.390, Speaker B: So this Http is like a nice command line tool which gives you an Http command and you can basically just create JSON object by saying by passing in Nike value pairs and so that's not the one. So I can send this a query and it says okay, that's not a query, this is not really a query, but you already get the JSON response back that you're expecting. And this is a GraphQL standard is to have all the errors and arrows key. You can then say let's say votes and the ID. And now we get something back and in curl that looks something like you pass a query field in with a string value and that string value is votes ID, what else? And then you do curl URL. And so it works with any Http library, works with more powerful GraphQL clients like Apollo. We're happy to share our experiences on discord like send you links to clients documentation for those tools.
00:58:44.390 - 01:00:12.222, Speaker B: Just fire away with questions even now if you want. So how is it if I do this indexing a subgraph? If I push something into the index with the next call on an event, could I already query what I have been indexing in the call before or is that not guaranteed? That's possible. So first of all, everything from a block gets transacted into the database together at the next block. You can certainly query it already and load entities that you've created before you can do it in the same block because the stuff that is not transacted into the database base is of course kept in memory. And when you do like a lookup into the store, it looks at the in memory stuff, sees if anything has changed there, eventually falls through to the database if it makes sense, and thereby merges the two states, like the in flight state and the database state. Okay, great. This also handles reorgs behind the scenes, so sometimes we get that question how do I handle reorgs with this? Good thing is you don't have to because the way it works is basically like I said, we transact all the data from a block into the database as, like, one batch.
01:00:12.222 - 01:00:53.380, Speaker B: We also keep track of when data was changed, and so when we realize that the chain has diverged and we have some blocks, some data from blocks that are no longer on the chain, we just roll them back one by one, like all the changes we made, and then move forward again in the right direction. So to your subgraph, it just looks like there's events being emitted and you process them and that's it. And it can happen a bunch of times, I think. Gurley has particularly many reorgs, so you'll see that in the logs. Sometimes there was a reorg and went back to a certain state and stuff, but there's not to worry about that.
01:01:00.790 - 01:01:11.474, Speaker A: All right, I'll do one last check of YouTube to see if there are any questions there, and it looks like there aren't, so Martin, unless there's anything oh, go ahead, Joshua.
01:01:11.602 - 01:01:13.218, Speaker B: Are there any subscriptions?
01:01:13.314 - 01:01:15.560, Speaker A: Is there even a place for that in this?
01:01:17.130 - 01:02:16.566, Speaker B: There are. We've hidden them because the current implementation is not particularly optimized and stable. So, like, a bunch of projects, particularly Mintbase is very vocal about the benefit of switching to polyng queries that make their DAP a bunch a lot more robust. If you replace HTPs with WSS, you'll get a subscription endpoint, and that basically follows the live query approach. So you can send a query or multiple queries to that WebSocket subscription endpoint following the GraphQL over WebSocket protocol, which clients like Apollo implement already for you with a bunch of helper libraries, I think, and you basically get a new result whenever there's an update. But you don't get like, a streaming update where every new piece of data is sent over. Instead, you get a new view of the data that has changed.
01:02:16.566 - 01:02:24.240, Speaker B: So there's two different approaches now. How to handle that. We picked that one. I'd like to have both, but what, one day?
01:02:31.410 - 01:02:54.226, Speaker A: All right, I think that might be it. 54321. All right, questions are closed. Just kidding. You guys can hit up Martine or Yanis in the Slack. They'll both be there with the rest of the Graph team. Definitely ask some questions, figure out more how you can use this as part of your hack.
01:02:54.226 - 01:03:10.060, Speaker A: FS hack. It's definitely a useful tool, so be sure to chat with them. And I think we can wrap there. Thank you again, both for coming and walking through some of the code and helping to answer questions for the hackers. It's great.
01:03:10.670 - 01:03:25.460, Speaker B: Yeah. Good luck, have fun. Hopefully see a lot of you on Discord. All of you, ideally, yeah. And just whenever you have questions, just ping us, we're there. And the support channel on Discord is the best channel for those questions.
01:03:27.350 - 01:03:41.154, Speaker A: Cool. All right, we'll see. Everybody, remember to stake. There's a couple more events, including one more in half an hour with Juan Benet talking about filecoin system. We'll see you in slack and elsewhere. Bye, everybody.
01:03:41.272 - 01:03:42.926, Speaker B: Bye, everyone. Thank you. Bye.
