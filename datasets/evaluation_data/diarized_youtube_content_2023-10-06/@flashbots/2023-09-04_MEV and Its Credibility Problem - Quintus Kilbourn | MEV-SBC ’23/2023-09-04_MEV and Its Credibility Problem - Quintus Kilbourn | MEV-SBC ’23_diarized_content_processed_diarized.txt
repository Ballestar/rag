00:00:03.130 - 00:00:56.350, Speaker A: Hello everyone. Today I'll be sort of giving a mental model for how to think about mev or how I've been thinking about mev. And the argument or the claim I think is that this is where the frontier of a lot of the mev research is. And mev thinking is I'm trying to sort of encourage more people to think about the mev problems in this lens. So first I'm going to identify some of the key issues of mev and sort of understand why they arise. And from that point we'll move on to examining the classes of solutions or briefly mention sort of roughly the classes of solutions that people have mentioned earlier today and we've been looking at over the last couple of years. And then I'll point to sort of a new class and a lot of it isn't new but I think the framing framing is new and hopefully that we get something out of that and then I'll identify some of the challenges to making use of this new class of solutions, quote unquote.
00:00:56.350 - 00:02:09.174, Speaker A: And I think that is where the frontier lies. One caveat I'll mention is that I'm coming at this from an ethereum focused perspective and so some of the assumptions or the worldview comes from that model and maybe of different desiderata in Cosmos land or whatever. But I think a lot of the points apply across different chains. So what are the issues that people usually associate with mev? We have normative issues with power asymmetries people feel that the sort of the miner or the validator makes a lot of money out of mev or different kinds of activities classified as mev and people don't like that. But then there's also inefficiency arguments, economic inefficiency because some activities labeled as mev impose taxes on users, maybe make trading more expensive and these kind of things. And that reduces economic inefficiency. Increases economic inefficiency, but also technical inefficiency because we have failed transactions or spam or like additional messages on the network protocol incentive distortion, incentive to reorg or uneven yield across the validator set, maybe.
00:02:09.174 - 00:03:02.614, Speaker A: Causing centralization and revenue sharing, which is sort of thinking of the applications on Blockchains that might feel that they are trying to capture some of the mev that they create. Again somewhat of a normative issue. But today I want to focus on the first two which we can think of maybe as like demand side issues in mev as opposed to supply side which is this other two. And so in order to justify the solutions that I'm coming up with later, I think we should first understand what's to call this asymmetry and to think about this. I'll present a simplified mental model in which we have sort of like two actors. One being the miner but that's just a stand in for block producer. It could be a validator and whatnot and then users, everyone is sophisticated of course, like sophistication differences also play a role in these kind of things, but let's forget about that for now.
00:03:02.614 - 00:04:00.578, Speaker A: Everyone's payoff depends on the next block, on the chain, in Ethereum, for example, but also the state of the world outside of that. So the binance price is a good example at the time the next block is produced. And then just think of things in two stages, block construction, two stages to simplify things. And already here you can sort of see this very basic example of block construction. And the two stages here have the users acting, forming transactions, setting that to the Miner who then acts second before the block is constructed. And sort of an immediate, very simple point to make here is that the users face a lot more uncertainty than the Miner does, right? And we can segment this uncertainty into strategic and fundamental uncertainty. Strategic uncertainty being uncertainty, being uncertainty around what other actors are doing in the ecosystem or other actors who have transactions in this block.
00:04:00.578 - 00:05:09.626, Speaker A: The Miner can see all of these transactions, users have no idea what other people are submitting or maybe they can see some amount, but not nearly the same as the Miner. Fundamental uncertainty here would be uncertainty around the binance price. And because the users necessarily have longer latency than the Miner to the block being produced, they have less certainty about what the binance price will be at the time of block construction. And just a brief note that these terms of fundamental and strategic uncertainty are taken from this paper, which is interesting, but sort of outside of the scope of what I'm talking about today. And I was sort of compounding this informational asymmetry that I was trying to highlight in the previous slide. I think we can also look at computation and the cost of computation as sort of a confounding factor or not a confounding factor, as a contributing factor to this asymmetry right? You can think of cheap computation as local computation and expensive computation as like, gas consumption. But of course, maybe there's some stuff in the middle and the miner has access to all of the information that they have throughout.
00:05:09.626 - 00:06:31.290, Speaker A: The system their high confidence about the state of the world and the block is produced, their strategic certainty because of the view of transactions and they can reason about all of this locally not having to pay much for their compute whereas users, on the other hand, when using local compute only have a little bit of information. And it is true that when the block is constructed, users actually in some sense have more information because the transactions execute on the state of the EVM, which incorporates information about transactions which were executed ahead of the user in the block. But still, this computation is very expensive and so this combination of information and the ability to reason about it cheaply, I think really contribute to this asymmetry another common asymmetry that people point to is the Miner's ability to differentiate between different outcomes and choose the one which favors them. And this is a spectrum of course, it really depends on the setting. On one end of the extreme a miner can choose to produce an empty block or maybe just a full block. The one that we're most familiar with is the miner receive these end transactions and they can sort of choose between the different orderings all to the end of them. And on the far extreme we have maybe just the miner holding all the private keys which is like binance effectively.
00:06:31.290 - 00:07:50.670, Speaker A: And so what contributes or what are the sort of different factors that decide how valuable the Miner's ability to make decisions is? One factor is that the miner the first factor is that there's going to be fundamental contention, right? So it's going to be some opportunity on chain, some arbitrage, some liquidation. Multiple people want to access this but it's exclusive and the Miner has the ability to make a decision and in this sense they have access to they should be the sort of beneficiary of this competition. But a sort of underrated point I think is that information still plays a really big role. Information asymmetry the first point is that the first aspect of this is the miner knows the value of the different alternatives and so they can compare those and choose the most valuable one. And clearly not knowing this sort of nullifies the value of being able to make decisions. But the other and I think the most important is that the reason the miner has all of these outcomes to choose from is because the users do not have enough information at the time limit. They take action and therefore must entertain multiple different outcomes.
00:07:50.670 - 00:08:31.998, Speaker A: A very concrete example of this is a slippage limit. When the user chooses to swap, they don't know if other users will be swapping on the same asset pool in which direction. And so they leave some leeway to entertain multiple different scenarios. What this means though is that the miner has many different orderings to play with and of course here sandwich attacks and these kind of things come into play. But that's a rough intuition. And so with these asymmetries in mind, the kind of solutions we've come up with in the past have been roughly around information minimization of the minor where we say okay, the minor has asymmetric information. And the way we're going to address this is by making them blind, by reducing the information.
00:08:31.998 - 00:09:46.258, Speaker A: We can use threshold encryption, we can use commit reveal schemes. On the other hand we have sort of these ordering rules which reduce the minor choice by limiting the space of valid blocks. Right? So verifiable sequencing rules we have first come, first serve. As we were discussing earlier today and there's been a lot of research about this which I'm not going to go into much. But I think something that's sort of underrated and what I'll sort of classify as this new class of solutions again to in a second is actually what we see happening in practice which is that there's this kind of intermediate computation which comes around. Instead of addressing this asymmetry between the user and the Miner by reducing the information or the action space of the Miner available to the Miner we improve the sort of information available to the user and make the computation on this information to the user cheaper than it might have been in the EVM, for example. And so concretely, what does this look like? Can we think of some examples? The user wants to interact with Ethereum and I'm claiming that something happens in between which is like this intermediate computation.
00:09:46.258 - 00:11:26.966, Speaker A: Here are some examples order flow auctions cowswap is the example I'm using here where multiple different user orders are aggregated by the service. The information, strategic information for all these users is used to construct one transaction that clears these transactions at a single price for the same asset pair and this incorporates a lot more strategic information in an off chain way, so it's a lot cheaper. Blockbuilders provide revert protection which means that users instead of having to compute the more preferable of many different alternatives within the EVM can speculatively send, try different like trade routes or something like that and have the blockbuilder on their behalf decide which is the most valuable opportunity. Bundles are another example in which users submit transactions in sequence and the sequence allows a transaction to reason about events that happen in the EVM after it has been executed. So giving the user effectively more access to more information during execution. Roll ups are a clear example, right? Of course, you have to interpret this a little bit loosely, but in some sense, assets are still available on the theorem mainnet and the roll ups provide users a way of reasoning about the optimal trade routes and these. Kind of things in a cheaper fashion then something which the academic community might not be very familiar with at all is like telegram trading bots which is something which has taken the ecosystem by storm in some sense in the last couple of months.
00:11:26.966 - 00:12:46.778, Speaker A: Very large user adoption and effectively this is like a UX or UI that operates through telegram. Users basically provide their private key to some botan and these trade on behalf of the users often aggregating information from many different users to do things like token sniping as a new token pool is launched. Usually something like Pepe or I don't know if people here are familiar and again here I would argue that they're giving much more information to the user. This requires sort of a much deeper data analysis which I didn't do and others have done, but I didn't have the time to sort of synthesize. But based on those analyses and some back of the napkin map, some approximate lower bounds we can come up with is that 50% of Dex volume goes through at least one of these services, right? The largest of that being sex dex arbitrage going through bundles 20% of gas usage as well as a lower bound. And so clearly this intermediate computation, these intermediaries are facilitating a lot of the activity on Ethereum. And what I'm trying to get through today is this basic sort of shift, this mental model, the matrix.
00:12:46.778 - 00:14:08.460, Speaker A: The way that we've been viewing the world, which I think holds us back is that users have this direct channel to the minor. There's only these two actors at play. But what we've seen in reality, and I think probably we'll see going forward, is that intermediaries pop up between the user and the Miner. And we have to accept this in our worldview if we want to really reason about what blockchains look like in practice. And so if we accept that we have this intermediate computation and that perhaps it is desirable, we should ask ourselves what are the new problems if this sort of solves some of the mev problems we had earlier? Are there additional problems that have now popped up? And I think there's sort of like a host of problems which come out of this one fact that the intermediate computation we see on Ethereum today, and I think pretty much everywhere else, relies on trust, right? So reputation in repeated games, the Miner swaps out because of the consensus algorithm every 12 seconds or whatnot, but these intermediaries stay and so they can engage in these repeated games and users are effectively trusting these guys to not do what they are worried the Miner will do, sandwich them and these kinds of things. And so there's several problems that come out as a part of this. One comes from the fact that trust imposes a high barrier to entry into this market.
00:14:08.460 - 00:15:12.110, Speaker A: And what this means is that if, for example, there's Kaosoft that runs an order flow auction and I would like know, as nobody would like to challenge this order flow auction with a better design ofa prime. First I will have to get all of my users to trust me to believe that I won't abuse them. And because it is very hard to do this because trust begets trust and you have this cold start problem which means that arguably these intermediaries face less competition amongst themselves, stifling innovation, but also enabling rent extraction. Low competition means you could charge higher fees and these kinds of things. And obviously monopolistic behavior is observed in many, many situations around the non crypto world and there's no reason we should expect this to be any different for us. Another problem is that trust is flimsy. I guess we are all sort of familiar with this concept, right? But trust can be abused.
00:15:12.110 - 00:16:38.140, Speaker A: I actually don't know who came up with a saying, but the moving from don't be evil to can't be evil is sort of something which we hold very dear in crypto and there are reasons for this. Obviously in traditional finance where a lot of similar activities happen, these trusted setups have been not enough to prevent these intermediaries from abusing their positions. And then of course, even if these intermediaries can be trusted, there's some things which are just out of their control. And so moving from a trusted model where someone isn't evil because they're trustworthy actors, we want to move to one where the sort of properties of the system are guaranteed more so by the design of the system than by the decisions of the actors. And sort of my take on this problem or this set of problems is that this is what Flashbots and Suave has been focusing on for a while. How can we provide the benefits of intermediate computation? How can we provide the efficiency that this provides without relying on trust and encountering all of these problems which obvious worked through. So that's most of my talk I just wanted to finish off with sort of like three problems or three kind of questions that I think people should think about going forward.
00:16:38.140 - 00:17:58.520, Speaker A: One is this problem that I just explained, which is this sort of credibility and trust problem. How do we get the benefits of this intermediate computation without relying on trust? The second is I've spoken about the asymmetries which come out of computation or this relationship between expensive and cheap computation and information and the relative differences between different actors in the ecosystem. But clearly it wasn't very formal. And one open question is how can we study this formally? The last point is sort of directed towards researchers working on ordering policies and general blockchain design, which is to say if we assume that an incentive that leads to the existence of intermediaries means that we will have these intermediaries, how does that change the way we design blockchains? If we have an ordering policy which is like first come, first serve or really any kind of policy, are the properties that this policy is supposed to enforce still met when users have the option to go through an intermediary? And with that I'll finish my talk. I hope that I've inspired some people to work on these problems that at least made sense.
00:18:18.420 - 00:18:31.770, Speaker B: Okay, Quinn's, question for you. When we have intermediaries at least competing in the PBS auction, how do we make sure that they don't end up pushing all the revenue to the proposer? By competing with each other?
00:18:32.540 - 00:19:14.254, Speaker A: I think the question is what do you mean by all the revenue? When Blockbuilders compete and push value to the validator that ends up being value that is sort of accessible throughout the stack and if the miner was directly building the block, they would be able to access that value as well. I think what we're trying to do is try and design systems where that value isn't available in the first place. Right? So if users go through like cowswap, for example, versus directly swapping in the mempool. There's a difference in the value that's ultimately available to the validator or the miner or whatever. Yeah. Cool. Great.
00:19:14.254 - 00:19:16.510, Speaker A: Thank you, Quintessential.
