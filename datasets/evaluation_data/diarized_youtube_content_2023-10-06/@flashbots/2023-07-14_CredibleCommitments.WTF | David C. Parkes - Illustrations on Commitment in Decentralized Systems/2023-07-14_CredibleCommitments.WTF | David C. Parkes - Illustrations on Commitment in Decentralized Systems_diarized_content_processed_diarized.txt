00:02:02.000 - 00:02:48.948, Speaker A: Yeah, sure. And this was supposed to be animated, but it's not. But that's okay. So first of all, I want to talk about credible mechanisms. This was an idea that was introduced by Lee and Akbapor 2020. They wanted to ask at high level what happens if the entity that is operationalizing a mechanism is able to deviate from the intended rules of the mechanism. So maybe a canonical example to have in mind, which you're all familiar with in this audience, I think is a second price auction would not be credible because there are deviations available that are not visible to the participants and they formalized this.
00:02:48.948 - 00:03:34.480, Speaker A: So I want to spend a minute on this. So they said that a rule describes an intended behavior. For example, the intended behavior might be take all bids and run a first price auction. They describe the concept of a safe deviation. This is a deviation from the rule that generates an output for which there exists an input consistent with the rule, given each participant's knowledge of the input. So you may know your bid, you may not know the other bids, and then you observe the outcome. Is the outcome consistent with some possible completion of the input? If it is, then this is a safe deviation.
00:03:34.480 - 00:04:27.910, Speaker A: The entity operationalizing the mechanism may have deviated from the intended behavior, but in a way that is not observable to any party based on what they know. And then they say that a rule is credible if there is no profitable safe deviation. So they don't require there to be no safe deviations, but they require there to be no useful safe, no useful safe deviations. So I think it's useful to imagine that deviations that are not safe are sanctioned in some way. You're staking your reputation as a mechanism entity on following the rule at least up until the point where your deviations can be caught. There are other things you can do that nobody will know about. You're not making any guarantees in that regard.
00:04:27.910 - 00:05:25.670, Speaker A: And we still want to be able to say useful things about the mechanism. And what they proved in this paper, they proved a trilemma, which I'm not going to step through in detail, but they proved, for example, that revenue optimal first price auctions are credible, but second price auctions are not credible. And I think when we think about commitment, then I'm going to try to tie things into commitment. I think we could say that credibility gives a self interested mechanism commitment power. If my mechanism rules are credible, then I can commit in a credible way to follow those rules. It is incentive compatible for me to follow them and not to use a safe deviation. Okay? So this notion of credibility, which now you can kind of situate this in the DeFi space.
00:05:25.670 - 00:06:58.396, Speaker A: So in the DeFi space and let's think about transaction ordering into an AMM in the DeFi space. A rule is an intended behavior. It might be take all transactions that you have seen and follow a particular sequencing method to order those transactions onto an AMM that might be the intended behavior. And then a safe deviation is one that again generates an output for which there is an input that is consistent with the rule. Given knowledge of the input, I think oftentimes when we think about blockchain, we will think about the input as being observable, that is the input that is used as being observable. So when I think about DeFi, for example, concretely, we can all observe the transactions that were pushed through uniswap in that block. So in that sense, we all have information about the input and what does it mean to be credible? It means that a safe deviation is any deviation where either if there's some space in the rules, you still are following the requirements of the rule, or a deviation where you perturb the input.
00:06:58.396 - 00:08:07.364, Speaker A: In some way, you're allowed to perturb the input, it's just that you have to follow the rule given what people see about the input. And here the input is all of the transactions that are written into the block. I'm going to mention in a second a result we have, and it's just a slight tweak on the Credibility definition. So the definition I gave you earlier is there is no profitable safe deviation. The definition I'm now going to use is that any profitable safe deviation from the rule still achieves design goals that we care about. So there may be deviations, and I'm okay with that as long as any deviations that the mechanism chooses to follow still lead to properties that are good for me. For example, a property I might care about in the DeFi context is I'm okay with mev, but only if the execution price on the transaction that is mev is good in a way that we could formalize and again think about other deviations being sanctioned.
00:08:07.364 - 00:08:58.584, Speaker A: So this is Credibility where I say I'm going to follow this particular sequencing rule. If you ever see, based on what you see about the input that I'm using that I didn't follow the rule, you can sanction me. Everybody will know that I deviated. And now going forward, people will choose not to submit transactions to my mechanism. So here Credibility gives a self interested party commitment power to achieve desiderata, where again, desiderata might be what we could think about informally. As tolerable mev it is incentive incompatible for me to achieve these disarata, even if I might choose to use some safe deviations. So we have a forthcoming paper that I'm not going to get into in any detail other than to advertise it here.
00:08:58.584 - 00:09:53.900, Speaker A: You can ask me about it later if we want to go there, which is coming up in stock, where we give a verifiable sequencing rule that ensures this kind of tolerable mev property. So it ensures that for any executed transaction, a either the price of A is as good as if A was the only order to execute, or no mev is gained by executing A. And you could think about, for example, builders and Relays choosing to adopt that rule. And then now they are committing to be observed and have staked their reputation on not deviating. So they're committing. And the question is whether those rules have nice properties. That's the first thing that I wanted to talk about is the role of credibility.
00:09:53.900 - 00:10:58.956, Speaker A: Second thing, I want to now jump back in time and talk about this idea of faithful implementations. The backdrop to this was that algorithmic mechanism design started in around 1999 2000. There was a flurry of activity around polynomial time mechanisms. And then some people, particular Joan Feigenbaum and Scott Schenker, started thinking about what would happen if we had distributed algorithms that were implementing the. So now the question wasn't so much is there a polynomial time centralized algorithm that can operationalize the rules of a mechanism, but is there a decentralized algorithm with nice communication complexity and computational complexity that can run the algorithm? And they wrote some very nice papers. I would encourage you to read them. The question they didn't ask is, they didn't ask whether it was incentive aligned to follow the distributed algorithm.
00:10:58.956 - 00:12:04.416, Speaker A: So they said, here's a distributed algorithm where if it is run, it will effectively compute the output of the mechanism. And they wanted mechanisms, because mechanisms were providing incentive alignment around inputs, but they were not insisting that parties wouldn't want to deviate from the algorithm itself. And yet at the same time, their motivating story were often things like BGP border gateway protocol for autonomous systems on the Internet, which are self interested parties executing decentralized algorithms. And there's no reason to really think they would choose to follow the algorithm if they could benefit by deviating from it. And so what we did in this work was we wanted to add this additional criterion of incentive alignment with choosing to follow the algorithm. And that's what I mean by a faithful implementation. So there was a podcast paper, there were two RMAs papers.
00:12:04.416 - 00:13:11.268, Speaker A: So it's nice that we're adjacent to RMAs today. I called this specification faithfulness, so it's work with Jeff Schneider and want to contrast it to credibility. So in credibility there is a privileged party, say a mechanism that receives inputs, can tamper with them in various ways, and then selects an output. When we were thinking about faithfulness, we didn't have any kind of center, any privileged party, we wanted a fully distributed system. So I would often draw these types of pictures here's a center, and here it's like no, you take the rules of the mechanism and you give them to all of the participants in the system and they're all doing some part of the distributed computation. And we wanted all of that communication and computation to be an equilibrium. So it's a weaker form of commitment reflecting that multiparty aspect.
00:13:11.268 - 00:14:16.320, Speaker A: It says it's incentive aligned for me to follow my part of the mechanism rules, given that others do the same. There's an equilibrium notion, all right? And what we did is we asked the question, can following a protocol be made in x post Nash equilibrium? Roughly, this says as long as others follow the protocol, then whatever the inputs, you also want to follow the protocol, whatever the private inputs. That's the x post aspect of it. And if it's true, then we say that the specification is faithful. We formalized it by breaking up the strategy now of an agent represents the computation that they're doing. And we thought about that in terms of a revelation component, a computation component, and a message passing component. So revelation is computation you're doing that is touching your private input.
00:14:16.320 - 00:15:37.800, Speaker A: Computation is work you're doing that is depending on inputs that you've received. And message passing is you sending messages to others. And we developed a proof recipe that I will flash and not spend a lot of time on, where we first of all defines this notion of algorithm compatible, which says that an agent will choose to follow the suggested computation in equilibrium, communication compatible, an agent will choose to follow the suggested message passing in equilibrium. And then we strengthened AC and we said, well, strong AC is that you will choose to follow your suggestive computation whatever you do in regard to your revelation action and your communication action. So assuming others do what they're supposed to be doing, but even if you were to deviate in arbitrary ways for revelation and message pattern, it still incentive aligns for you to do the computation correctly. And you can similarly strengthen communication compatibility. And then we can prove, it's quite easy to then prove that if a mechanism is strategy proof and you have a correct distributed specification that is strong AC and strong CC, then the specification will be faithful.
00:15:37.800 - 00:16:20.948, Speaker A: So then the game is all about how to establish these properties. And we provided techniques for that in these papers. RMS four, almost 20 years ago. It's hard to believe distributed VCG methods. We had our BGP protocol, which was in Podc, and then a more general distributed optimization algorithm in RMAs Six. So that's about faithfulness. Go back one year now, strategy proof computing, this is something I was playing around with pretty early as a professor at Harvard.
00:16:20.948 - 00:17:16.532, Speaker A: And I remember giving this talk, actually it was in a little room in Acapulco at Ijkai in 2003, and I don't think I've talked about it since. So thank you for giving me the chance. I think this paper has ten citations. So I was developing this notion of what it would mean to have something called strategy proof computing. And I'd been motivated by what's known as the end to end principle in network systems, where somehow you don't try to do too much in the network you facilitate innovation on the edges. And I wanted to kind of think through what would that mean for mechanism design? And my main idea was, well, you don't want there to be one designer. You want there to be innovation amongst mechanism designers.
00:17:16.532 - 00:18:38.384, Speaker A: You want anybody to be able to deploy a mechanism and have kind of a competitive landscape for which mechanisms get used. And then I was thinking through, okay, what would that mean? How might that work? Is there an AI agenda here? One thing I decided was that I wanted each mechanism to be strategy proof, at least kind of locally for the things that it's doing. And so what I mean by that is that strategy proofness doesn't compose very well if you're trying to buy a bundle of stuff. And I give you a strategy proof mechanism for one part of the stuff you want to buy and a strategy proof mechanism for the second part, it doesn't mean that your dominant strategy is to bid truthfully for this part and bid truthfully for this part because you might not put everything together correctly. So there's this composability problem which I raised in the paper. But what I did want to insist is that if somebody deploys a mechanism to allocate this particular bundle of resources, that that mechanism should be strategy proof in a particular way and should be certified as such. So this is the abstract of the paper wanted to support continued innovation and competition, focusing on resource allocation, arbitration of resources, and by individual users can treat other resources as their own.
00:18:38.384 - 00:19:19.980, Speaker A: This is the notion of simplicity that comes from strategy proofness that you shouldn't have to game in the requests that you're making for resources. You should just be able to describe what you're interested in, just as you would if you weren't competing with others for those resources. And I laid out some challenges. I'm just going to tell you what they were and then I will point you to the paper, which I think we've posted on the web page. So I laid out five guiding principles and then I laid out five AI challenges. Principles were we should care about incentives, we should be focused on utility, not utilization. We want incentive compatibility, we want openness and we want things to be decentralized.
00:19:19.980 - 00:20:09.264, Speaker A: And then the challenges were design were how to describe what it is your mechanism does and who it is designed for and what properties does it have, how we can verify in a data driven way the incentive properties of the mechanism. Because I had in mind that the infrastructure which was vaguely discussed in the paper is monitoring inputs and outputs to these mechanisms and is able to, by looking at the trace of inputs and outputs, notice violations in strategy proofness. I say I sanction you, you are not strategy proof. I have proof. By looking at the things you've been doing over time, I can see you're not strategy proof. That's the way I was thinking about this. And we did later work on that.
00:20:09.264 - 00:21:16.196, Speaker A: I have a paper on that verification step compositionality and I'd forgotten about this until I looked at the paper yesterday. I talked about the idea of learning, using machine learning to try to design mechanisms as well in that paper. So then fast forward to this year where we are using machine learning to design mechanisms. And I've been working on this idea of differentiable economics now for a few years with a number of collaborators and the particular project that I wanted to briefly mention is about contract design that fits with commitment devices. And I didn't mention commitments here, but what I wanted to say is that assume the ability to commit to the rules of a mechanism that you are not going to change the rules of the mechanism. This was an implicit assumption in my paper that you can deploy something and you will not change it. Which today I think we can roughly do that.
00:21:16.196 - 00:22:20.504, Speaker A: So that's good. Differentiable economics. This was something we started in 2017, whole bunch of co authors including Zhao Fong and Psy Ravendranath, more recently Jeff Zhang and Tonghan Wong in my research group. Simple idea it says, okay, let's represent the rules of a mechanism via a differentiable function neural network and let's use differentiable techniques to try to optimize the rules of the mechanism. The technical challenge is there are a few, but one technical challenge is that you need incentive compatibility. So if I gave the network the objective of minimizing negated revenue or maximizing expected revenue, so I would say your loss function is negated revenue. Well, it's going to do that in a non incentive compatible way.
00:22:20.504 - 00:23:01.708, Speaker A: It's going to kind of charge you. Your bid, of course is not sensible economically. So we have to have a way to regularize penalize in some way the mechanisms that are learned, which we do in this research in various ways. Just as a quick example before I talk about contracts, in the first work we talked about optimal auction design. Very simple example just with one bidder, just to illustrate what happens. And you can have auctions for single bidders. I know it sounds a little silly, but actually digital goods do tend to decompose cross bidders because they're what's called a non rival.
00:23:01.708 - 00:23:41.796, Speaker A: Good. So suppose we had a single bidder with an additive valuation function. Uniform one, frightened one, uniform one, frightened two. The theoretical economic literature tells us what the optimal design of an auction is. This is what it is. It says that if the value is in this space, less than this number for item one, less than this for item two, then don't allocate if your value is high for both allocate if it's high for one but not two allocate item one high for two but not one allocate item two. And then the payments follow.
00:23:41.796 - 00:24:17.804, Speaker A: From typical auction theory so if you just want to decompose it down, this is the allocation rule from theory for item one. And this is the allocation rule from theory for item two. So it has this threshold kind of structure to it. And when you train the network, you learn things that look like this. So this is the density plot of a tan H based neural network. So you can see it kind of smooths out the boundaries, but it's approximately doing what it should do. Okay, so just basically my last slide.
00:24:17.804 - 00:25:13.648, Speaker A: Hopefully we will have enough time for discussion. Working paper led by Tonghan Wong in my research group on using this technique for optimal contract design. Let me tell you what I mean by a contract here. And I mean it in the very classical sense from economics. So we think here about there being an agent with unobservable, costly actions, each action causing a distribution on observable outcomes, and there being a principal, another actor in the system with value for the outcomes. So think about the agent as your contractor. If you're improving your house, you don't watch what the contractor does all the time.
00:25:13.648 - 00:26:04.370, Speaker A: But based on the behavior of the contractor, your house is high quality or not, is on time or late. You can contract on payments with the you can offer your contract to payments that are conditioned on whether or not the outcome is high quality or low quality, on time or late. And the goal is to in our work is to learn a contract. What is a contract? It's these outcome contingent payments to maximize the expected utility of the principal. So think about for a given contract, this induces a distribution over outcomes. You have an expected value for that. You have an expected cost because you're paying and you want to find out of all possible contracts, the one that is best.
00:26:04.370 - 00:27:01.300, Speaker A: So what we do here is we recognize that if you think about the design space, this is a bit washed out, but this is a two dimensional contract space showing the utility function of the principle. The utility function of the principle, as you move in contract space is discontinuous. Because as you move from one contract to another, the principal's best response, the agent's best response action can change. And that can lead to a discontinuity in the utility to the principal. And so we notice that, for example, railu networks are piecewise continuous approximations. So we introduce a new network architecture which gives a discontinuity, which is appropriate to modeling this problem. So we learn the utility function to the principle, and then we do inference on that space to find the optimal contract.
00:27:01.300 - 00:28:09.560, Speaker A: Going back to commitment here, this is assuming in the background the ability to commit to a contract once. If you can commit to a contract which at least outcome contingent payments, then there's a contract design problem that can be solved using machine learning. So just to wrap up wanted to give you these four illustrations on alignment and commitments. Emphasize that each of them has a different notion of commitment in credible mechanisms. Your commitment power comes from it being in your own self interest not to use a safe deviation or in your own interest to only use deviations that are tolerable in the faithful implementation space. Your commitment power comes from it being in your self interest to follow the rules of the protocol as long as others are doing the same. In strategy proof computing.
00:28:09.560 - 00:29:53.580, Speaker A: We assumed in that work that different parties are able to commit to the rules of mechanisms. And then we argued that it would be in the self interest of a party to publish a strategy proof mechanism because the infrastructure is going to run a reputation system to catch a deviation. And then in this optimal contract design work, we're assuming the ability to commit to a contract, which is an outcome contingent payment rule and using machine learning to design that commitment device. That's all I had. I wanted to kind of share this with you because I think these are all examples where I hope that ideas from distributed AI, multi agent systems research, econ CS research can continue to get picked up in the crypto space and I'm guessing a bunch of you are building out and designing things in that space. Thanks. I'm curious if the kind of the fire challenges do you think any of them have been kind of which ones do you kind of currently see as the kind of biggest outstanding ones that are still here? Progress on any different sources, what is that standing basically yeah great.
00:29:53.580 - 00:31:15.846, Speaker A: I would say good progress on mechanism design, good progress on the automation design. People haven't really worried so much about developing languages to describe mechanisms. A lot of work on this idea that I'm describing at that paper of I can get treated of input alpha solutions from At Hennessums and developing algorithms I can give with high probability guarantee for in fact the innocent is strategy proof. We did some work on this by more work and maybe there's a whole different approach to this which more based on modern cryptographic techniques which we weren't thinking about here, maybe we can chattel about that. Compositionality is something that people are very aware of. There was some work on this after I wrote this paper there was by Moalan and Minsan that gave one way in which you can compose factors together. We also did some work where we talked about mechanisms for options.
00:31:15.846 - 00:32:37.566, Speaker A: So you don't buy a resource, you buy option to use the resource which gives you better compositionality because you're not exposed to having to buy the resource. We did some work on that, but I think that it was Mike Wall number one said to me and know, you're never going to have commonest royal auction or all of the resources in the world. And so there are always going to be boundaries between mechanisms. And I think you'll still happen to be very much kind of understanding that space. I suppose the price of anarchy works in the theoretical computer science community has proved some things about what happens if you use very simple decoupled portions that I suppose you could think about as a confidentiality argument. Yeah, building off the description point, I'm curious about your emotional credibility and faithfulness and thinking about how other economic security models that can broadcast phase have played out and I know correctly in the faithful notion of faithfulness comes from notion of equilibrium where you consider only deviation of individual agents. But another concept people look at often is collusion threshold.
00:32:37.566 - 00:34:05.898, Speaker A: And then another angle as well is looking at the economic security budget in that if there's some unbounded activity users like the blockchain, you never know that the volumes of money mutually are out. There might be some upper bowel, at which point the mechanism just uses its faithfulness or credibility or whatever. So curious if you thought of other extensions to the notions of grid ability to cover these kind of security. Yeah, great question. First of all, I think that coalitional refinements of what I talked about can certainly be defined. I don't know that people have really taken either credibility or faithfulness low yet and done that. The most constructive positive thinking I've done about coalition currently has our coalitional deviations within the automated macron design framework where we learn mechanism because what we'll do with that framework is we penalize unilateral deviations with a loss function.
00:34:05.898 - 00:35:35.880, Speaker A: I didn't talk about it, but that's roughly what we do. So you could penalize coalition alleviations and I think you could use that framing to be able to build mechanisms that are more robust. I'm generally pretty bullish about using machine learning techniques to alternate that intensive design loop and I think it's quite flexible. So I think if there are collisional things you care about or other things, it would be interesting to study it in that training. The other thing I would say is there was some nice work early on by people like Vanessa Teague and Jim Halpern on rational secret sharing. There's a secret sharing multi policy computational literature that takes what? A classical assumption adversaries that can behave in arbitrary ways and talks about robustness against some fraction of the participants deviating the way the work get in the mid to belt. But you can say, okay, what if the pictures have only been not Byzantine in that way, but are rational active and they gave some kind of coalition robust properties there? Did that be a question? Do you have nonsense questions? I think yeah.
00:35:35.880 - 00:37:11.750, Speaker A: Joel Hathburn and Vinissa T and then we had follow up delio Vidan and myself had a follow apart on that as well. Yeah. Okay. And Bianca needs what kind of techniques can mean to achieve. Yeah, I'm still not sure I have anything particularly excited to say in particular about commitment with compositionality, the way those two come together. But hopefully we can get there during the conversation today. I think the best thing I can say in regards to computationality is first of all, just contrasted in differential privacy.
00:37:11.750 - 00:39:00.810, Speaker A: A lot of the things people love about differential privacy and so it's always been incredibly frustrating to me that these mechanisms buy in settings seem to not be able to achieve the same properties, which is why we did think about it through options a little bit. But I think the best thing to say is and actually that was part of my motivation for strategy proof computing. Part of my strategy proof computing notion was to let there be innovation where mechanism designers could kind of draw the boundaries in the appropriate way in resource space. Resource space could literally be spatial, could be temporal, could be other things. But try to draw boundaries in ways where you draw the boundaries that match the separability of utility functions or say the majority of participants in the system so that their problems will blockly break along this way and this way and they can independently make decisions here and then make decisions here. As I talk to you, I wouldn't be surprised if there are things we can do by thinking about some of the graphical modeling techniques that people use for probabilistic models, where these conditional independencies and dag structures where you're willing to make assumptions about the lack of dependencies between random variables in the world. But maybe things like that that we can also leverage or kind of ideas like that all the graphic or representations we can write down that capture the types of conditional independencies where if I give you this resource, then now your values for these resources are decoupled.
00:39:00.810 - 00:40:07.086, Speaker A: You got them independently inside over here, they get independently decide over here. This is the type of way that we should be thinking if we want to think about how to break apart problems. But maybe we shouldn't be that naive and maybe we should just be thinking about how to be structured so that other people can kind of move their mechanism domains around and trying to be smart in a way that helps humans kind of follow up question to elaborate on that somewhere from your other paper. Strategy proof computing was that it would be the market itself that would find the ocean regions and now you're talking more of a top down kind of thing with the priority. So what do you think it's more promising there for the meta problem, not designing the mechanism but partition? Yeah, I would say definitely bottom up. But still those participants will still need the right heuristics to know how to carve out the resource space. By the way, I did do a lot of work on Commonness World auction so that's something that I've learned a lot about.
00:40:07.086 - 00:41:57.250, Speaker A: And there are. Various preference representations in that literature that capture these types of independencies or couplings. So I think there are things we can borrow but yeah, I would say try to build infrastructures that allow for innovations over time probably not very controversial in the audience. So you mentioned a couple of times like credibility and I was wondering what your thoughts have been over the years starting with having reality now about how to enforce those. We've talked about reputation at one point but how has this been part of the research? Sometimes, let's say you can verify a sequence of transactions as not being respected or there was like a litigation problem what we are expected to yeah, I was just wondering how you thought yeah, thanks. I did initially think about that as more of a kind of an extension ecosystem, like a reputation system where there are checkers that are motivated to find problems and call out the problems. But there was a period of time when I did work on using homomorphic encryption type ideas.
00:41:57.250 - 00:43:27.598, Speaker A: We were using a pretty lightweight of that where the way we were modeling it was on a way we didn't want to prevent the mechanism getting knowledge of the impulse, but we did want the mechanism to have to prove to anybody that computation done correctly. We were using various we were calling random log techniques with straight line computation. I can talk to you about it more offline, but there's techniques as a workload of Michael Raven. He was not retired and Christopher Harvard and there it was, this proven verifier model where you run the mechanism and then you could deviate. But if you deviated, you wouldn't be able to prove that you've done the right thing. So thinking about that for things like normal, non decentralized exchanges, because there are all these problems with dark pools in finance where it became a paradigm over the years. The banks were not able to credibly commit, not to use information they weren't supposed to use.
00:43:27.598 - 00:45:11.346, Speaker A: And so I wanted to know whether we could use crypto techniques to have them commit to a rule and then not be able to prove that they heavily deviated. So I suppose all I'm trying to say is that over time in today's world with smart contracts and other technologies we have much more ability to commit to rules. There is always a question about what happens if you okay. I mean there are various flavors of that. Of course it could be literally that I have no available deviations but I think typically in the crypto space I can commit to the rule but I cannot get the inputs there necessarily right? So the malfeasance of then playing with the inputs that hit that function and that's why I think that combining that ability to commit to a function that acts on whatever it does get with credibility which is bringing incentives to the table to complement that. I think that works really nicely together because then you've got the incentive alignment around the inputs being correct or not modified in a bad way with the crypto providing protection against the output. Yeah, I wanted to expand on this epic and I wanted to see if you have any intuitions on how can we prove faithfulness of an optimal smart contract that's based on a machine learning model.
00:45:11.346 - 00:46:48.782, Speaker A: Would we want to improve the learning? Do we want to prove that to us using correct data? What would it even mean for a smart contract not to be faithful? I suppose where my mind is going again, it's about eight months. Right, so is it a smart contract a lot closer to what I frames as be something more like credibility would be? Absolutely. But if the contract itself is created by an engine on a machine learning model then wouldn't you want to prove data to the insurance? Yeah, maybe I could take your question this way but feel free to push back on this is actually really a good thing, I think would we use differential economics to learn credible mechanisms? I think that's where my mind went. And you said that on the mysterious rare endings in my group. Omni verifinable sequencing rules work. Any, me have been thinking a lot about credibility in the blockchain space and can also continue that conversation. But I think credibility is very nicely suited to blockchain and I think that would be super interesting.
00:46:48.782 - 00:49:42.620, Speaker A: I've never thought about using differential income for credibility. If you constraint do you have any intuitions or the statement yeah, I think so, I think that would be where I would start. I would code up the types and deviations that are represented through the credibility concert and I would want to penalize them when they go against the delete process. I originally chatted with in the context of this thing about that wasn't about iterative but multi like the ODS of but there are other limitations and like some of almost fundamental things. Yeah, right so life adoption is definitely a challenge. What I'm thinking about you don't want to leave everything to a reputation reputation may not nobody starts using my method but how can reputation by the way, it's an interesting story about the launch of ebay in that regard. Ebay launched in 1995 and as of 1996 had a reputation system.
00:49:42.620 - 00:50:58.354, Speaker A: It's found by now on the internet's first ever reputation system and they designed a two sided reputation mechanism where buyers could leave feedback on sellers and sellers on buyers. People always ask why would they have sellers provide reputation feedback on buyers? One reason that's given if the buyers could build a reputation as a buyer and then use that reputation to sell. So this idea of letting reputation be portable from one way you're acting into another way you're acting. So maybe one way to think about food strategy and reputation getting better efficiency is to think about whether or not you can contribute your reputation to others. A little bit like the way we think about things like page rank, site mechanisms. But I've seen also that and I'm also thinking that it shouldn't just be about reputation and collecting data, it should be about proving things as well. We don't want all of it to be about having to wait and see what happens.
00:50:58.354 - 00:51:32.190, Speaker A: We want as much of it as can be about truthable property. So anybody can check on the reputation side of things. There's also this question of how the correct property is, but how that came about. Yeah, essentially. You get all of the same problems. That the meta bunches. And there's lots of interesting work on attacks, on reputation.
00:51:32.190 - 00:52:27.200, Speaker A: Page act is basically robust. You get a loop of people pumping each other, pump feedback, score. Around so that the random war can sit this verdict holding it there. And so John Shockcraft, where we used hitting type, which is another stochastic process, and proved that that symbol there's being worked there as well. Any questions? You guys ask me, I can probably point somebody in the past 20 years, but exactly, like, what is the right thing for the problems you're battling with? I'm not sure the references are appreciated. Yeah, once I will finish. My text, but I can.
00:52:27.200 - 00:53:58.554, Speaker A: I have a question I want to kind of go back to the one SEC people make a commitment to a petty or deploy. So you were mentioning, like, what are some productive ways to think about coalition. Also making the inner gleam blockchain easy to kind of meet with rules. But the inconsistent rules can be manipulated, as in the case or whatever. And over there, the way people usually solve those problems that is the job processing the input, providing the input to one person to adjust the process? Yeah. Or can you somehow encourage those two parties one party to hold? Data availability mechanism encourage competition is given as much as possible. However, blockchain also makes mechanism design deployment too easy in the sense that it is super easy for those to party as in kind of manner ends up what do I think? I guess wasn't some constructive ways to think.
00:53:58.554 - 00:55:02.666, Speaker A: About traditional. So let's be precise as well, coalition and Lily referring to coalitions of participants in mechanism, whereas now I think you're thinking about coalition of the mechanisms, coalitions that are somehow setting themselves up to be able to work together to defeat the divine intent. Some separation. I don't think I've thought about this. You may have defeated mechanisms. Most American design legitimately just takes the standpoint of a single mechanism design. So even the notion of the being mechanism design in the context of modern mechanisms is relatively understudied.
00:55:02.666 - 00:56:30.960, Speaker A: And then the notion now I'm making excuses, but now the notion of, like, coalitions of mechanisms I think it's even that's another study. But let's see. Do I have anything to say? Yeah we can kind of see that because very often and people many people want to deploy essentially for example somebody use an Oracle service people want to deploy some these are not happening. Sound like animals. Let's see sometimes I've adopted a notion of that the existence of the menopause shouldn't create newest sense of concerns. Something else, one thing that came to mind when you said that there is work on information, but that work typically assumes that the only thing you're trying to do with the particular vote is to get a sharing. You don't have any outside.
00:56:30.960 - 00:57:57.420, Speaker A: So it doesn't work for the Oracle. But what you do want in that case is that if you deploy an infrastructure station mechanism, you don't want it to introduce new incentives to be acting in some different way of the world to change the events of them being. You can try to formalize the types of interactions that you don't want and then try to prove that the Mandalorian is robust against that was a very click. We'd be thinking a little bit about that sounds like a child for AI. There we go. Where I get stuck. I either wait in your guts or we think about so anybody has any last questions that was contrary what can you solve with this differential economic contracting? So the the answer of the moment, which is not very satisfying because I'm still working.
00:57:57.420 - 00:59:16.942, Speaker A: Okay. So the computational technique for contract that most people would use for problems like what I described would be using linear appropriate where you can solve a linear you can solve a separate linear program for every action. So that if you have a very large number of actions, you've had a very large we avoid that here. In fact, here the shows never commence. The record data that we see is contract design. So it's scale. But I don't think I yet have a certain concern for the columns because interesting, Ashley, as far as I know, the kind of applied contract design literature is a little bit less developed than the applied and so I haven't yet kind of economic usually sort of multidimensional.
00:59:16.942 - 00:59:59.280, Speaker A: Yeah. So multidimensional. Yeah, some multidimensional. Do you mean multidimensional? We've been thinking about a related problem for data market design, which sounds a bit like contractions. So if you have anything in mind, we could try to try to take it. This is very new. We haven't tried to apply to anything really serious yet.
00:59:59.280 - 01:00:21.320, Speaker A: Yeah. So one of the softest challenges about auditing I forgot all of the name. Basic verification. I'm going to be a step this guy. Okay. Yeah. And you mentioned that you weren't thinking about water.
01:00:21.320 - 01:01:50.378, Speaker A: That's fine. Referring to your knowledge mechanism yeah. Do you think that unsolved on the inside? Obviously and I think even just smart contracts where anybody can look at the description of the contract not obviously, because the property are interested in proving something about is strategy proofness, which is a kind of a derived property of massage. So even if I describe the function to you, it may not be I don't think we know very much about how tractable it is. There's a little bit of very recent work, but I don't remember the authors. But I think we don't really understand how tractable it is to somehow we read that outshit and decide whether it is strategy proof or not. Zero knowledge techniques actually I think Yanai guntresi have been work on zero knowledge inserts so it may be that's where it's also if you don't deal with it, which is developing the bench.
01:01:50.378 - 01:02:55.320, Speaker A: Right. So the idea just that like you need a math math when you don't have math math book, but you do have in fact it's all in data that we have somehow zero knowledge in the null sense would just prove that you correctly function really with the collective it wouldn't prove a property, right? Yeah. And I think that's the zero non thing right to commit to a map. I guess what you could prove it's not really satisfactory, but you could prove it easily that there's no useful unilateral degree in a lot of it. That's something that's that's not bad, you know please. All right, thank you.
