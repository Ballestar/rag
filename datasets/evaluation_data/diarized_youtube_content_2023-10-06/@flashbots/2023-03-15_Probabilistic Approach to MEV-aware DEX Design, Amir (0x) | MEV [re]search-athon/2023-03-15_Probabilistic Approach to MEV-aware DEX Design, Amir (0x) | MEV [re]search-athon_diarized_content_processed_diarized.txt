00:00:03.210 - 00:00:03.326, Speaker A: Yeah.
00:00:03.348 - 00:00:52.266, Speaker B: So today I'm going to give a talk on how our thoughts have evolved over the last couple of years and a pretty unique design that we have since put into quotes. All right, so yeah, we'll give a very high level overview of RQ. I think it's a much more well understood system at this point, how to think about dex quotes, dig into a bunch of data, and then we'll after. All right, so quick timer on what RFQ is. So RQ allows you to trade peer to peer against professional market makers. So user comes in, they request a quote, what's the best price you could give me for if I want to make a trade of this amount? All the market makers respond with their best quotes, user agrees and submit the transaction. RFQ has some really nice properties from an mev standpoint.
00:00:52.266 - 00:01:30.090, Speaker B: So trades are always, they always happen at a predetermined price that is fixed in the signed quote. Therefore they always have zero slip. No mev is possible when trading. The quotes are tailor made for the taker as well. So the order format actually specifies the taker's address as the only addresses library order. Therefore they can't be front run or anything like that. And yeah, back when I did a presentation a couple of years ago, RFQ was making up roughly 40% of volume through Zero X.
00:01:30.090 - 00:02:16.600, Speaker B: So yeah, just reminder for those who aren't too familiar, zero X is a liquidity aggregator, so it routes between RQ and all the other on chain liquidity sources. So 40% of trades were mev free. But if you take that step further, it is not actually enough. Right? If we're comparing an RQ quote, which always has zero slippage versus other quotes that potentially have slippage, you can't actually really treat those quotes equally. And yeah, most people don't really understand this, but yeah, AML quotes are kind of bullshit. They don't really mean too much. The expected value of a quote is going to be less than the quote itself.
00:02:16.600 - 00:03:44.334, Speaker B: They don't account for any market action. Anything that's happening in a mem pool, anything that's happening in private mem pools don't account for any hidden fees like positive slippage. And yes, you thought you were done with Tom means, but that is from so yeah, another way to think about this is that what people think of as market orders in decentralized exchanges are really basically limit orders. So they're currently kind of framed as, okay, I'm going to make a market order at this price and I'm willing to pay up to some other price. But if we rephrase that, what you're really doing is you're placing a limit order at that second price and you think maybe you could get that first price, but there are no guarantees around that at all. So we can do better. So we seek out how do we address this problem? How large is the problem? First of all, since we are an aggregator, we have a lot of data, right? We see all the user quotes, we can try to map those to the actual trades that are settled on chain and we can compare the two and have a lot of data on realized slippage across every single token.
00:03:44.334 - 00:04:45.362, Speaker B: Basically, this is a histogram of realized slippage and the scale is normalized. So don't read too much into that. We could see on the right hand side the positive slippage falls with power log distribution so that's when your realized price is actually better than your quoted price, that is possible to happen. But the negative slippage on the left hand side is pretty interesting. We see these spikes where users are realizing higher than average slippage and we think that is happening because those are the levels which users are setting their slippage tolerance. So I will show you more data proving that that is actually happening. Here's another chart showing slippage exhaustion across all trades.
00:04:45.362 - 00:05:49.820, Speaker B: So, this is a metric we created, which is the realized slippage divided by the slippage tolerance of trades. So if you set your max slippage to ten basis points and you realize nine basis points of slippage, that's 90% slippage exhaustion and also more or less looks like a parallel distribution until the very end. And you see there's a huge spike where a larger than average amount of trades are actually hitting very close to that max slippage tolerance. So what's happening there is that Me researchers are basically treating these as limit orders. They are capturing as much of that delta as they can. And we can also see that this problem gets worse as trade sizes get larger. So the likelihood of you hitting your map slippage for a very large trade is going to be something like 14%.
00:05:49.820 - 00:07:13.986, Speaker B: And then we'd also see this kind of quantifies in dollar terms how bad the problem is. We can also see that slippage trends up as trade sizes get larger for all of these major pairs. So we have all this data, how can we actually put this into use and help out users? So we created this feature called Slippage Protect which I think is a pretty unique design. I haven't really seen anyone else do anything like this, but the idea is to essentially make the aggregation routing mev aware. So we have all this data on what is the average slippage for every single given liquidity pool, token, pair and trace size bucket. And then when we are routing through all of these sources, we can actually essentially penalize certain routes if we think that they are going to realize slippage and route people towards things that will realize less slippage. Yeah, so our hypothesis is that by factoring in average slippage, users should have higher quote accuracy, it should decrease their realized slippage and overall should improve execution quality for users.
00:07:13.986 - 00:08:05.458, Speaker B: So I kind of think of this as like an order flow preprocessor. So you're optimizing the route to minimize the mev that is extractable after the fact. So it actually worked well, you can see the difference in orders that use the slippage protect feature and orders that do not. So it's optional for users of the API. So some people use it, some people don't. But we can see on the right hand side that the trades that are using slippage protect actually realize pretty significantly less slippage on average than those that do not. So yeah, what are the implications of the feature? Users are going to get improved accuracy of quotes.
00:08:05.458 - 00:08:53.778, Speaker B: It's going to end up routing more volume through liquidity sources that do not have slippage or have less slippage today. That's pretty much just RFP which has zero slippage and also some order books has zero slippage. Trades on average should have better execution. But yeah, one limitation is that does not mean that every single individual trade will have better execution. It's actually possible for trades to end up having a slightly worse price, but on average it should be much better. And yeah, like I mentioned, it's basically an order flow preprocessor, so it should decrease the total mev that is possible to take out from searchers. It's also just automatic for users.
00:08:53.778 - 00:09:13.694, Speaker B: They don't need to use custom RPCs or anything like that. So as Tom mentioned, with MetaMask, there's no way to force your users through a private mempool. So especially if it's a non technical user. I assume most people don't even know what a private mempool is. This is really going to help out.
00:09:13.732 - 00:09:15.070, Speaker A: That type of user.
00:09:16.530 - 00:09:32.130, Speaker B: One limitation is that if you are using a private mempool, this does not perfectly account for that, although it should be somewhat reflected in the data because the data set is using transactions that went through both public and private.
00:09:34.390 - 00:10:17.058, Speaker A: I guess two questions. One is of a straw man to be like, oh, the quoted price of the CFM, whatever, and therefore that should be the expected price. I don't think anyone actually thinks this, and it's kind of weird to say like, oh, maybe cycles are CMM but not no one's going to give you the same price. No one's going to be like, yes, you can trade your million for exactly that's. Fundamentally, the point is there's only a certain amount of liquidity that you get from market makers. So it's maybe a less explicit version, I would say, than kind of a trading curve that you get. So I don't know if you have any thoughts on that.
00:10:17.224 - 00:10:34.040, Speaker B: Well, I think there are actually a lot of products out there that do treat quotes equally, right. Like most aggregators in their routing algorithms, they're going to look at all them the same Meta aggregators that compare multiple aggregators, they're going to look at quotes in exactly the same way.
00:10:36.650 - 00:11:05.666, Speaker A: I actually think that's also great because the routing problem over CFMS is convex, but you can just solve it right? I can just give you a very fast algorithm that can solve it for like 10,000 pools and like 100 milliseconds. Actually, we have code online for it too. But how does that compare with the slippage? Like certain markets that have slippage, we need to solve the problem optimally in the first place. Why not just solve it and then post it on chain? Does that make sense?
00:11:05.688 - 00:11:08.420, Speaker B: Sorry, I cannot rephrase the question. Yeah, you have to.
00:11:11.350 - 00:11:19.750, Speaker A: So what you're doing is you say, let me make sure I'm understanding this correctly. We're going to remove pools for which there's a lot of observed slippage.
00:11:20.490 - 00:11:25.586, Speaker B: You don't remove the pools, you simply penalize them for the expected slippage of miles.
00:11:25.698 - 00:11:53.680, Speaker A: Sure, okay. But the point is, okay, what are you doing? You're saying like, look, I'm going to give you give me a bunch of e and I'm going to give you a bunch of shiba, right? And I'm going to guarantee that in fact, the amount of shiba that you get out maximize. That's ideally what you're trying to solve. Right? That's the whole objective. So my claim is that that problem is actually efficiently solved. Too often that's a global optimality. So why not just do that instead of the heuristic where you analyze the.
00:11:54.710 - 00:11:55.858, Speaker B: How do you solve it?
00:11:55.944 - 00:12:36.106, Speaker A: Yeah, actually you should check it out. Look at Cfmmrouter JL, and there is a very top dollar with a CfMM. Exactly. Sure, yeah. But that's why you have, like, you're giving me a dark pool in the first place, right? Why not just submit the order and then have it be executed at something? And you can pretty much guarantee it's going to be accurate. You have the same problem even in the case of orders. The only way to kind of cat your slippage on a particular pool is via the limits for that pool.
00:12:36.106 - 00:13:01.586, Speaker A: Right. If I say revert this transaction, then you're going to have a reverted transaction, arguably even worse than having my trade. Slightly worse. You'll already have this. The point is, by definition, solving the optimal problem. It means that you're already considering the slippages in the first place. That's what it means to optimally solve.
00:13:01.586 - 00:13:03.170, Speaker A: You're already doing that by default.
00:13:03.250 - 00:13:16.634, Speaker B: But how do you optimally solve it with all these unknown actors interacting with if you factor in the worst possible, then you're going to buy way more.
00:13:16.752 - 00:13:39.460, Speaker A: Towards you can do it in an expectation. You can do a probability. When you say slippage, you're talking about some sort of realized model probability over. Why is there such a difference in different pools? Is it just like certain standard trips just happen to live in certain pools and bite the people who go across it?
00:13:40.630 - 00:13:52.818, Speaker B: I think it's not that much different across AMMS. It probably depends if it's more like UDP Two or a kickbase AMM, but yeah, I think generally.
00:13:52.994 - 00:14:03.900, Speaker A: But it seems to be more of a property of liquidity rather than a property of that particular pair. So then what I'm saying is you can just have a model for that in the first place. Not like the slippage based model.
00:14:04.750 - 00:14:06.458, Speaker B: You already know what the slippage is.
00:14:06.464 - 00:14:33.860, Speaker A: Going to be ahead of time. Right. That's the whole point. Maybe I'm not quite understanding what the mechanics of this, like slippage. When you say slippage, do you mean price impact? I will explain that's what I hear you say. Yeah, I'll define it for you. This is den, right? Yeah.
00:14:33.860 - 00:14:41.000, Speaker A: Does that make sense? There you go. That's liquidity for you.
00:14:44.090 - 00:15:00.300, Speaker B: You're more mathematically inclined than I am. But yeah, it's interesting to look into. That's your question.
00:15:00.830 - 00:15:11.120, Speaker A: How do you think about is it a market based approaches to sort of pricing like Tesla versus zero S?
00:15:13.750 - 00:15:20.110, Speaker B: I think for this specific model, it is largely stackable with other models.
00:15:20.270 - 00:15:33.510, Speaker A: I don't think it's like one or the other, but yeah, I think internal agent type models are the same and prepared. I have a question. When you do the analysis of slippage.
00:15:34.410 - 00:15:36.038, Speaker B: On lower slippage orders, you have like.
00:15:36.044 - 00:15:50.290, Speaker A: A higher chance of your order reverting. It's cheaper for someone to make your order. Did you incorporate your multi block bill? If users get reverted and they submit the same overt quarter over and over again and they keep reverting, do you account for that or do you just assume that they get filled in the first block?
00:15:50.310 - 00:16:05.726, Speaker B: That's a good question. We do not do that. Although we have thought about it. You can measure like lost gas block, you can't really measure lost time that well. And overall I'm just not sure if.
00:16:05.748 - 00:16:07.034, Speaker A: We can support the squeeze.
00:16:07.082 - 00:16:10.282, Speaker B: But it is what the potential optimization.
00:16:10.426 - 00:16:29.958, Speaker A: I think for the average retail user doesn't really matter, but for wallets that have been tagged in some form of low the information you give up, I just suggest the fact that it's a weak slope. In the end, I'm not sure really matter that you have any strong guarantees you'll get the first bill and that you can effectively be censored from above other essentially large wallets that have our perceived information for.
