00:00:03.050 - 00:00:30.150, Speaker A: Cool. Thank you for having me. This is a really cool discussion. I'm going to talk about Tea based smart contracts. My viewpoint here is a little bit different than I finally understand now what this point of suave was. How you're viewing at Flashbots SGX as a way of having an encrypted mempool to do the mev. But this is still going to then produce use bundles of blocks that get published on Ethereum in plain text when they're finally committed.
00:00:30.150 - 00:01:08.498, Speaker A: The perspective I'm coming from is how to make privacy preserving smart contracts. So those who don't know me, I'm from IC Three and a researcher at UIUC, and I work with Zcash Foundation. I'm also starting a new venture called Honey Badger Cooperation Labs. And something we're doing is building a zero knowledge credit network application on top of Te based smart contracts. I'm putting out that there just so that, you know, off the bat, you're not trying to guess where I end up at the end of this. I'm an SGX and Tee optimist, but you'll see the nuances and what it takes to get there. Even a little more background on the perspective that I come from.
00:01:08.498 - 00:01:48.446, Speaker A: My research directions for the past decade have all been about privacy and functionality added to smart contract programming. Smart contract programming is what I care the most about. But I've kind of followed this progression of doing everything we can with the simplest technologies, like just the plain text world just commit and reveal and then zero knowledge proofs. I viewed this as like progressing down a more and more complicated stack. And of course, what's been so interesting in the past few years, and it's still booming now, is just how pervasive zero knowledge proofs are through the developers mindset. Zero knowledge proof tools. Everyone's working on it.
00:01:48.446 - 00:02:19.526, Speaker A: All the big brains are doing zero knowledge work improvements. It's kind of diffused through the developer mindset. Smart contracts know that they're there. What I've been working on, though, for the past several years, and I'm basically all focusing on now, are applications that need a more complicated platform for which the zero knowledge proofs and commitments stack are not enough. And for those you need some form of threshold assumption or multiparty computation. Those are the same thing to me. Or you need trusted hardware enclaves, or possibly both.
00:02:19.526 - 00:02:54.674, Speaker A: And really my best frame of reference is the Akitan research paper from 2018. I had a small role on that. This was mainly the work of Fan and Raymond and a bunch of other authors. And this paper is the basis for the Oasis Project, although ideas from here relate to a whole bunch of the other projects too. So I'll kind of make some references to that as well. I'll say just a little bit because this is kind of clear from some of the talks that have come before and I think Henry has a good way of explaining this. I'll mention and maybe it'll come back later.
00:02:54.674 - 00:03:59.878, Speaker A: So I want to get into the weeds a little bit about the details of SGX smart contracts, but I do think that there's a missing point to smart contract developers where maybe some people get this, some don't, but the line isn't so clear. When is zero knowledge proofs appropriate for your application versus when do you need to make the jump to either enclaves or this MPC threshold? The motivating example that I have for this is the issue of residual bids. I think you could call this something like rev. It's like more than multiplock mev, but it is kind of of that flavor you can build with commit and reveal an auction where at the end of the auction you know what the winning price was. But there's a lot of people that didn't win the auction and whatever their bids are, that basically is forecasting their unmet demand, that might be a good predictor of their bidding strategies in the future. So maybe the minimal information disclosure from an auction is just the winning price. If you build a commit and Reveal auction, then you're also disclosing these bids that were not met, and that is strategic information being leaked.
00:03:59.878 - 00:05:14.240, Speaker A: And no way that you build a smart contract for fair ordering or anti mev techniques is going to touch this issue at all. Because it's not even about fair versus causal ordering, because later bids may have depended on the previous bids inherently, but still this unmet demand is leaking to someone like to a manager or an aggregator. If you use a zero knowledge proof based roll up to make this kind of application and hide this issue of residual bids, you have to build your application, your auction application, using MPC or some threshold encryption or Tees. And in general, I have a bunch of other ways of making this point go to this one. So in general, I view this as like a framework where you maybe use the simplest tools that you can only move your way up to enclaves and multiparty computation if you really need to. But from the viewpoint of prototyping, it's really the other way. Once you get the idea of how you can do smart contract programming on Tes, it gives you so much more flexibility to define your privacy and disclosure policies that I can't even imagine going back to being stuck programming in the framework that doesn't provide that kind of a fine grained control.
00:05:14.240 - 00:05:56.590, Speaker A: I think that this point kind of needs better explaining to where smart contract developers really see where that limit is. I think that the way that it's explained in the Penumbra protocol is pretty clear. I think I'll move on though. I have kind of like a spicy comparison table that places the Tee based contracts what they're capable of, along with all of the other alternatives. A couple of these are worth going into describing, but maybe only in the panel or if I get questions on it, I want to really move on to basically talking about where we're at with development of Te based smart contracts. And the kind of really palpable thing is everyone's concerned about SGX attacks. We'll talk a little bit about that in a moment.
00:05:56.590 - 00:07:02.830, Speaker A: That's a legitimate concern, of course, but my view is that we have swung kind of the other way. It's like humorous how more people know that SGX is bad than they know any other details of it. And so even though this kind of like developer discourse that you see between consensus protocols, variants of proof of stake and all of that, and even now the zero knowledge proofs, really detailed technical discussions that are carried out throughout our developer ecosystem for SGX, it's not at all. Yet we're basically still just scratching the surface of even repeating mistakes that we already know how to deal with. From my perspective, a bunch of mitigations and good ideas were already presented in that 2018 Akitan paper and they just aren't yet even have made it to implementation. And even the onlookers who are trying to watch these projects aren't really spotting the critical features that are missing. So my hope is really to basically advance this developer discussion so we understand some of the details of what it means to have an SGX design, not just getting lost on kind of the high level trust model of SGX.
00:07:02.830 - 00:07:50.100, Speaker A: So to start with, I'm going to talk at the kind of high level view of what the Te based smart contracts are about. And this is meant to be kind know, broad and vague such that it captures kind of all of them. It doesn't have exactly the details and there are differences in details from them. But this should give you the idea. In a nutshell, smart contract tee just means you take the contract execution and that takes place in these secure SGX enclaves. Practically what this means is that there's some secret key material that never leaves the enclaves, but there's a public key that you can use to send encrypted messages to the enclaves. So if you want to make a transaction in a Te based smart contract system, you send a transaction encrypted under the public key that corresponds to the secret key that only enclaves have.
00:07:50.100 - 00:08:21.600, Speaker A: Just the enclave kind of exists on the processor. It doesn't have that much memory available. So practically there's an untrusted storage that's sitting next to the enclave and the enclave interacts to get and set values to this untrusted database on the side. And so this untrusted database on the side. Well, the point of it is to be an encrypted database. So all the keys in the key value store are encrypted, all the values in the encrypted value store are encrypted. That's the basic idea.
00:08:21.600 - 00:09:04.902, Speaker A: Besides just sending encrypted transactions, you need some way to get some users are authorized to access their own account balance for example, some outputs of contracts are published for everyone to see. So there's either events that get sent to you encrypted under your own address as an encryption public key, or you make a query directly with some interaction. Either way, what you get back is the response from that query that would also be encrypted under your address. That's the basic idea. I guess the last component that shows up at this high level is you also need some way of adding new nodes to the network and tolerating nodes that crash. So it can't just be there's one central enclave node. You need a network of enclave nodes.
00:09:04.902 - 00:09:51.850, Speaker A: They have to have some mechanism that the new enclaves nodes that join those enclaves can get access to the secret key by some mechanism. Okay, so that's the very high level view, and that's really the only high level view of a diagram of this that we'll get to. But what I'll talk about kind of next on Pitfalls pokes a little bit below this and I'll come back and refer to this. Before getting to those, I'll just point out a couple of details about what it is that this is the blockchain platform interface described. But this is built on top of what the SGX primitives themselves give you. So understanding these two views is really what you need to have in mind in order to start picking apart issues. So there is the enclave.
00:09:51.850 - 00:10:30.218, Speaker A: The enclave has not the entire system memory available to it, but what it does is it can access more memory. The processor has like at most 100 megabytes of memory on chip. To do more than that, you need to access Ram. SGX has like a Ram handling system, so it'll do virtual memory with pages, but all of the data on the pages are encrypted. There's also integrity checks that are sort of built in by SGX, so your enclave programs look like they have a big virtual address space. You interact with an enclave by making e calls. These go from the Untrusted operating system into the enclave and run some programs.
00:10:30.218 - 00:11:17.726, Speaker A: So for example, you might have an e call for processing a block of encrypted transactions. You typically will have to have an e call that starts up a new node by generating keys to communicate with just that node and begin on bootstrapping and getting access to other key material from the network as a whole. In order to e, calls can't just generally be processed on their own. They need to request further services from the Untrusted operating system host to access a key value store, for example. So those are done through O calls, those are calls out to the Untrusted operating system. That's typically how you interface with the disk from an enclave. The last two concepts that it's useful to know are that the memory is lost if the process restarts.
00:11:17.726 - 00:12:12.950, Speaker A: Like there's no way to load the memory from a prior process if the enclave process crashes. So for persistence, even just on one node restarting, you use a thing called sealed files. These have like CPU specific keys, and basically you can write to the file, store some secret data there, you can read it back, but only the CPU that wrote that file is the one that can read it. This gives you kind of a persistence ability. And then the last component that's essential to using these for Know to make it so that you don't have to trust the validators or you don't have to trust the Know flashbot operator is remote Attestation. So this is where one of your enclave E calls outputs a report. This report gets signed by intel, and then this signed report basically has output from your E call whatever it chose to put in the report data field and the hash of the program binary that generated it.
00:12:12.950 - 00:12:49.566, Speaker A: So this Attestation report is kind of where the magic happens. This is where you get a guarantee that this output was produced by some enclave running exactly this program. And that's basically the source of your root of trust. So I want to talk about some specific pitfalls and explain them in terms of the high level thing that I've set there. And these will follow along with some posts. You can read more data about these. So the first one is the issue of what it is that you do when an SGX vulnerability occurs.
00:12:49.566 - 00:13:50.946, Speaker A: So SGX vulnerabilities have occurred in the past over years, there's been dozens of them. They range in terms of how catastrophic they are to all of the intel chips or just some intel chips, and whether you can just get the Attestation keys out of a chip, that's like the worst case scenario or something more mild. What happened with secret network and APIC leak was that so APIC leak was the absolute worst case scenario for an SGX vulnerability. This was publicly announced in August of last year, but it had been brewing for nine months. Like, the first disclosure from the people who found it to intel was like in January, earlier in 2022. So like a nine month period had occurred during which mainly like, motherboard developers, Lenovo's, HPS got kind of private advanced notice to be able to build patches against it. And Cloud services were able to try to make their plan in advance for what to do when this disclosure would be announced.
00:13:50.946 - 00:14:54.874, Speaker A: When the disclosure is announced, it basically means, okay, anyone using a remote Attestation system is at risk of having fake nodes that aren't even enclaves, generate fake Attestations and show up. Really what's called TCB recovery is what intel calls what do you do when an SGX vulnerability is found and it involves releasing patches that you can patch to upgrade your own processor? The problem with remote Attestation is that your threat model are other people on the network who have not upgraded their processor. The best response for TCB recovery is something like shutting down all new node registrations. Until you can enforce that, everyone has updated their patched code in order not to be vulnerable to this. What happened with Secret Network is that they had judged that none of the nodes that could join the secret network were specifically vulnerable to APIC leak. But this turned out not to be true. So when we went to basically look into this, like two months later, it still hadn't been shut off.
00:14:54.874 - 00:15:48.330, Speaker A: It was easy to join new vulnerable nodes to the network and then so we were able to get some secret data out of it. Another detail about this is that the Akitan paper had a bunch of concepts on it, one of which was compartmentalization and rotation. These are both hardening. At the time the Akitan paper was made, this had already been after the first handful of SGX attacks, so the need to prepare for a potential SGX vulnerability was already clear to us then. The basic idea of compartmentalization is that there's not just one master key that everyone has. Instead there's a small number of nodes that together share master keys. Ideally, even those should only share them in a threshold multiparty computation, threshold encryption way, and then worker nodes maybe get contract specific keys on a need to know basis.
00:15:48.330 - 00:17:10.702, Speaker A: The result of that would be that if there were this break, there would be a much smaller attack surface of nodes that could leak the master key, and perhaps a larger number of nodes that might have a portion of data threatened, but not the whole network. Secret chose not to have any compartmentalization for other trade off reasons, sure, but the result was that this attack enabled us to get the master key to the entire network. We're still showing on this SGX Fail site more details about how this works and like a demonstration, like we can still decrypt on their testnet transactions today. Part of the response is you want to rotate your keys when a vulnerability is announced, because you don't know for sure whether or not the prior data will tomorrow turn out to someone, could decrypt all of it and goes and publishes on the black market. So you should at least rotate your keys so that new people using the network ongoing transactions aren't vulnerable if the old key is compromised. So this is something that Secret but is developing as part of their rapid response to the disclosure that we made. Oasis is still developing this too, and plans to launch their mainnet without that feature in there's more to say about this also, Tom, my students, one of the authors of this, and there will be more presentations about SGX Fail, so I don't want to go more into that.
00:17:10.702 - 00:17:51.570, Speaker A: I'm also running out of time, so I want to say a couple of other things, but there's a lot more detail on the SGX fail website. I'll go really quick through this emmer signer because I want to make a couple of other points, but I've eaten up a lot of time. Here another thing that we had wrote about it, and you can read about it on this post on the IC Three site. But there's a centralized developer backdoor that's built into some of the code bases that includes obscureo and secret network at the time, although they're both fixing this and it relates to how the ceiling data works. So SGX nitty gritty details, there's two options. I mean, they're not that nitty gritty. They show up on kind of the learn to use SGX 101 website.
00:17:51.570 - 00:18:30.414, Speaker A: Sealing has two modes, enclave mode and signer mode. Enclave mode says that only the exact same program binary that generated the sealed file can read the sealed file. mrsigner says that any program signed by the code developers can read the sealed file. So that means if you seal the data with mrsigner, which is what Secret did and what Obscuro did, I mean, they haven't launched, but I looked in their code base and that's what they had when I looked at it. That means that the code signers, the developers have a master decryption key themselves. They could just code sign a malicious program that dumps the consensus seed. They have the key that they need to get it that way.
00:18:30.414 - 00:19:28.386, Speaker A: So this is like a footgun cell phone kind of unnecessary mistake. Maybe I will end after this next one just because I want to say it briefly, but in this picture I mentioned that the enclave boundary sort of ends where the memory begins and the disk access through O calls begins. Well, this means that you need to be concerned about access pattern leakage. So the Secret developer documentation says that when you access the key value store from a smart contract, okay, it's a key value store, so the key is encrypted and the value is also encrypted. So that's great, but that doesn't reveal the contents of the key. But it'll still be apparent to the untrusted operating system if the same key is being accessed or not. So if you write to an account balance, this is something that snip 20 tokens have to do.
00:19:28.386 - 00:20:27.140, Speaker A: What you want is that you can't tell which account is being written to, but what the interface gives you is that the access pattern is revealing that the same account is being used from one transaction to another or not. That's a problem. And the only solution to this problem, or the only solid solution to this problem, is to implement an oblivious Ram algorithm. This is something that could be added, but it's something that none of the different smart contract based systems currently feature at this point. In principle, you need to do this not just for your disk storage, but clearly for that you do need to do it for your disk based storage. But you also need to do it for your memory accesses, because the Untrusted operating system gets to see which pages in memory are being accessed. So you could learn if smart contracts are stored in different spots in memory and you're just using the virtual memory system that SGX offers you're leaking an access pattern that very well may lead to the difference of telling which account just received a transaction or not.
00:20:27.140 - 00:21:20.002, Speaker A: What else did I want to say? I might cut it there so that I have five minutes for questions. I have a couple of other ideas that are about things that could even be let me just kind of do the summarize for this. Right? So I think that we're basically at the extremely early stage of kind of developers awareness and understanding of the details that go into SGX. I'm sure we'll talk about the panel, about the high know trust issues. You have to trust intel, you have to be aware of the potential for further attacks, but there's a lot of other kind of defenses and good ideas that could be built into this. I'm really a fan of this idea, but I won't be able to explain it in this talk. But that is that you should be able to have applications defend their privacy rules even against the code signers, and even the majority of validators shouldn't be able to make a hard fork to change the rules.
00:21:20.002 - 00:21:41.440, Speaker A: Like the Dow hard fork was obviously the rule change in order to cause a change to the application functionality. With Tes you have the ability to make applications that can defend themselves even against the tyranny of the majority of the chain that they're running on hard forking. So yeah, I'll end it there and see if we have any questions.
00:21:45.490 - 00:22:30.826, Speaker B: Thank you. Andrew. Very interesting technical deep dive into SGX. I mean, one thing that I've been wondering about SGX is why do remote Attestations have to go through? Like why does intel have to sign the transcript, the report? Wouldn't it be so much easier if basically transcripts or reports are signed by the Enclave key that's unique to this one CPU? And then intel just tells you what the list of valid pub keys are? Those that are trusted basically at any.
00:22:30.848 - 00:23:39.010, Speaker A: Given point in mean that's nearly how it so a slight more detail about how remote attestation works is it's split up into what's called a provisioning phase which kind of necessarily involves intel. But you do that once per chip. You don't have to do it for the different applications that you run. Then there's the Attestation step which in the default setting, that Secret and Oasis currently, I think that's the case currently use every Attestation goes through intel again as well through the Intel Attestation service. There's an alternative called DCAP, where intel is still involved in the provisioning process, but someone else can do the second step of it. I think that that can be made in a decentralized way, but I don't know the details of DCAP so well, the important thing is that you will have intel still be required as a kind of point of trust for at least the provisioning phase. But there's no reason why intel needs to be able to know, block some applications or block other application or not.
00:23:39.010 - 00:23:52.710, Speaker A: And that's something that using the DCAP alternative almost certainly avoids the need for. So even with SGX today, you're not necessarily as reliant on intel as the current software projects make it seem.
00:23:55.210 - 00:24:01.510, Speaker B: Okay, great. Decentralized DCAP. Sounds interesting. Any other questions from the audience?
00:24:05.070 - 00:24:14.910, Speaker C: Do you have any opinion on the just recently released TDX system from intel, which is kind of like a separate but similar system to SGX?
00:24:15.970 - 00:24:58.938, Speaker A: Yeah, I've heard about it. I don't have any thoughts on it yet. My first question, so one thing that I've noticed is that there's a kind of huge gap between what I want from remote Attestation and Tees, what we want for these decentralized applications and what the kind of bread and butter use of SGX is. So the standard case is it's a two party versus three party thing. Like the standard case is there's a developer and there's the cloud provider, and you don't trust the cloud provider, but you, the developer, are the one who puts the program there and gets the result, and that's it. There's just the two of you. So, very simple, remote Attestation can work for that, and I think that TDX is a good fit for that.
00:24:58.938 - 00:25:35.846, Speaker A: What I care about is this three party disintermediation world where there's a service provider in the cloud, sure, but there's a developer as well, and the developer is also not trusted. There's clients who don't want to trust the developer. They only want to trust that the enclaves work the remote attestation that SGX provides fits that kind. Because you don't have to be the developer. You get these portable signed reports that you can use to know that you're talking to an enclave on the network running the right program. I couldn't tell from my first look at TDX whether it supports that or not, but my sense was that it doesn't. If it does, then maybe that would be a good fit.
00:25:35.846 - 00:26:02.560, Speaker A: I had a similar kind of concern in working with Sev. I only know SGX as well, and even that only so well. So it may be that it's possible to use Sev to do this, but my understanding was that you could not get a Attestation report that's sufficient from Sev to provide the kind of guarantees that we want out of this for the smart contract setting. So that's my view now. But I'm not very knowledgeable about TDX or Sev, so that might be wrong.
00:26:04.390 - 00:26:06.162, Speaker C: There's a question in the chat maybe.
00:26:06.216 - 00:26:09.010, Speaker A: Jonathan, if you want to ask. Sorry, Justin.
00:26:10.710 - 00:26:45.130, Speaker C: Yeah, sorry. I have the second oldest Mev Rose participant here. Next to me. So apologies if someone is crying. I was wondering about the diagram you showed in the beginning, Andrew, on using Tes for smart contract execution. But do I have to send my or encrypt my transaction with a public key of a specific validator? Or is it, say, the same secret key, private public key pair for all Tes in the validator network?
00:26:45.290 - 00:27:29.034, Speaker A: So it's a little more different than that, but only by a little. And there is a little bit of difference between the different systems. And I've just said these different systems, but I have on my mind like Secret Network already has launched their main net. Oasis Sapphire is an EVM based smart contract chain that I believe has not yet launched their main net. But you can use Oasis Sapphire on a public test network and Obscuro also is meant to be an L two for Ethereum that has this weird policy where all privacy is canceled after one year. So it's only like a temporary privacy, just the policy that they have that also has a public test network and so that's running adjacent to Ethereum. So I kind of say like those as the whole industry of these.
00:27:29.034 - 00:28:14.742, Speaker A: So with Secret Network, there's really only one master key that all of the enclaves share at a slightly lower level detail. There's like per contract derived keys, but you can derived all of them from the master public key. And so you send your encrypted transaction to the public key associated with that contract. But there's one master key for everything that everyone has. So it's kind of the same as this diagram, effectively. And then in Oasis, not only do you send your transactions to the key associated with the particular contract, but the worker node that is proposing the block or whatever carrying out the execution for that only gets the key from the key manager nodes. The workers only get the key for the contract that they have to process at that point.
00:28:14.742 - 00:28:25.530, Speaker A: So it kind of limits the attack surface and the amount of contracts that would be boiled if one of the worker nose is able to break inside its own enclave.
