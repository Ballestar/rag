00:00:00.410 - 00:00:16.910, Speaker A: Yeah. Oh, actually, first of all, a couple of words about myself. Like, hi, I'm Georgia. Currently. I'm on DeepMind. I'm also a professor on Live currently. And I've been collaborating with Ethereum back from around, like, 2017.
00:00:16.910 - 00:01:15.460, Speaker A: So had discussions with Vitalik and many other people. Vlad Zamfir, Virgil Griffith, and this is has been an ongoing discussion, has been very instructive from my perspective because it helped me somehow coming from a background in theoretical computer science. It helped me somehow question hidden assumptions that somehow was very myopic to treat it being emerging from a theoretical area where you really like to prove things and you tend to develop somehow some myopia on hidden assumptions of your model. Right. And now talking to Vitalik, oh, yeah, this is great proof. It's not going to work. Here's why immediately? And then somehow I tried to develop a methodology, actually a mnemonic rule in terms of where do these assumptions are hidden? And I want to briefly share this with you and hopefully this could be valuable to your research too.
00:01:15.460 - 00:01:53.566, Speaker A: Is there any way to maybe let me just take this off. Yeah, perfect. Thank you. Yeah. All right, so I will go over the so the word to remember is presto. The T is not capitalized. And then I will go through each of these letters and I will say, like, here's the related concept to keep in mind.
00:01:53.566 - 00:02:34.750, Speaker A: Okay. And this is not in order. So we start with O, all starts for optimality. So this asks how well does the system solve the problem that you're looking for? For example, let's say here we have your global metric. You think of your load function. Or let's say I want to maximize social welfare of my system, of my users. How close does my solution come to satisfying this data in the system? The second E is for efficiency.
00:02:34.750 - 00:03:18.918, Speaker A: Efficiency says that like, okay, in pursuit of my first goal of optimality, my system is going to use a bunch of resources. Resources come in different flavor. Resource can be time, it can be space, it can be the use of randomness. It can be things like network bandwidth and so on and so forth. All right? And actually this is square theoretical and actually computer science like lives. So somehow we work on the intersection of these two areas. If we only care about optimality, we'll be mathematicians.
00:03:18.918 - 00:03:58.626, Speaker A: But we don't care just for finding solutions of that. We want to find them, let's say, as fast as possible. Okay, but then we just say, like, okay, some algorithms, we cannot make them run in deterministic time, polytime. But maybe randomness can be very helpful. And understanding these trade offs, let's say decentralized computation, like, what can I do if I don't have to have all of my data in one space? Okay, so this is what theoretical computer science does. Actually, not all computer scientists. Let's say people like myself and David, we go further down into this world.
00:03:58.626 - 00:05:01.034, Speaker A: And now we think about st, which we call like stability or stationarity. All right? So now we say like, okay, great, you have a system. Your system is, let's say, approximately optimal, approximately efficient. Now, is it the case that the system in itself is in equilibrium? That somehow the agents who implement the system, they're not forced somehow to participate, but if given the opportunity to participate, then they will actually follow the system, right? And now this can actually come with many different flavors. Let's say from the classical perspective of mechanism design, we think of stability from the perspective, let's say, of the users. The users is like, I'm coming and I participate in auction. Am I going to bid truthfully? If the mechanism is, let's say, proof that's the whole idea, right? That it's in your best interest to beat your true value.
00:05:01.034 - 00:05:39.026, Speaker A: But stability or stationary could also be applicable to other entities like the designer themselves, right? So for example, David talked about credible mechanism. Credible mechanism. Suppose I viewed my mechanism from the perspective of the designer. Would the designer actually stay in this point in the mechanism space or they would deviate themselves, right? Okay, so this is already like pretty packed, but we're actually not done. Suppose you've done this, which is already pretty impressive. So you create credible, super stable mechanism. That's a fist in the noctimal.
00:05:39.026 - 00:06:17.498, Speaker A: Are you done? Well, no vitalik. You say, well, this is where we start. You say, what about robustness? Okay? Now this is actually a tricky concept. It would say, like, to talk about robustness, you actually have to topologize somehow your protocol. So your protocol, think of your protocol, your solution as a point in some space. Okay? So let's say, yeah, probably the easiest way to think about this. Yeah, let me think about the following.
00:06:17.498 - 00:07:56.750, Speaker A: So when you think about standard mechanic design, you think that let's say all of the agents are perfectly rational. But now you could say like, okay, what if I allow N 1% of Byzantine agents? Okay? Now this is not in my original, so I've expanded my space to sort of invalidate some of my assumptions of the protocol. So I'm looking in the larger space and now I want to try to understand how do my guarantees that I have understood before degrade as I move further, further away, as my assumptions of my model get invalidated? Okay? So for example, it could it be the case that if we have like 3% bizarre agents or 10% bezadine agents like that, at some point there's a violent phase transition, right, and your system performance goes from 100% to zero, like vitali. Okay? We have to think very carefully about this, right? And then there's the last very last point of this that I call persistence, okay? Robustness is an issue about local deviations, okay? So you say like, okay, look, I've written a very nice mathematical model but there's always mispecification on my model between model and reality. Specifications would be typically small because I've done quite a bit of work in terms of believing my model. Make the model good. Okay? So as long as my guarantees are in, let's say they degrade gracefully, then my system is robust.
00:07:56.750 - 00:08:46.650, Speaker A: But then listening comes from vitalika blood and the early days of ethereum, we think. What about a ferrous entity that comes in and say, let's say they're willing to burn like $100 million to destroy ethereum. How would they do it? So there you have to be forced to think about radically, somehow moving. Okay? If you are again in your parameter space here. So this is your point in your parameter space. Now you've been moved very far away, okay? And now you want to think about is my action, let's say system here, my design system itself an attractor. So somehow, if it was valiantly to move away from its point of okay, then it would actually self organize to what I actually chose.
00:08:46.650 - 00:09:21.702, Speaker A: Right. And this somewhat remind me of what Banaba said about this point of last defense. So you think about now you really have to think very carefully about this, almost like Black Swan kind of event. Because if you don't create something that has true persistence in the real world, eventually something very off would happen. Now, clearly, I'm not saying that okay, you should create a system that checks all of these boxes, right. But the ways to think about this more like a pirate frontier. So make your choices.
00:09:21.702 - 00:10:06.410, Speaker A: Let's say, for example, I really care about this and this 10% 10%. This is maybe not relevant to me, but somehow at least being like going through this checklist and this also applies to AI safety issues, I think it's also useful for you. Yeah. Going through this checklist can really help you discover these blindfolds. And if you want to look more details about these ideas, these appear on a joint paper with Stefanos. So the way to Google this, I would guess it would be Leonardos et al. And Presto.
00:10:06.410 - 00:10:23.610, Speaker A: Okay. So this is Sevanos and with Daniel at SGD. Yeah. So that's yeah. And I'm happy to take questions and kickstart the discussion. Sorry if you can send sorry. This is the end of the monologue.
00:10:23.610 - 00:11:12.398, Speaker A: Okay. That's it. Yes. I was wondering useful theoretical framework to include all these parameters. I'm sure some kind of complex system theory actually metrics properly. I was worried if you went as far as actually coming up with some kind of metric or useful framework to evaluate your system and design this. But it is hard to come to all of it.
00:11:12.398 - 00:11:52.026, Speaker A: But I think it's even harder evaluate. I would ask it in two ways. In one sense, yes. So I have done some work exactly at instantiating these things in a specific formal ways. But I would actually encourage you not to necessarily but in some sense. I don't feel that there's a unique way of translating these ideas to useful mathematical frameworks. There have been some ways that have been useful for my research, but I don't want to stand here and advocate, like, no, this is the way to doing this.
00:11:52.026 - 00:12:27.382, Speaker A: And clearly, like, there's a lot of analogies, of course, with what David was saying this morning. And this is not by any means somehow I'm not going to fight here. Just use my terminology. Right. All I'm saying is that this is something that has been useful for me in my work, specifically in blockchain systems, to think about things that I take for granted. Okay. And I would encourage you to try it out or develop your own methodologies again, explore the literature or related work.
00:12:27.382 - 00:12:33.480, Speaker A: Okay. That's it. Yeah, Adrian, we have.
00:12:46.550 - 00:12:50.882, Speaker B: I'm sorry, was that a question to me? I can't really hear I could hear George as well.
00:12:50.936 - 00:12:52.180, Speaker A: Yes. Okay, great.
00:12:53.830 - 00:13:11.500, Speaker B: So, yeah, I can hear some people well and others not as well. But first of all, thank you so much for having me here very much at the last minute. I'm sorry to jump in remotely. I'm happy to see some familiar faces. I see David there. I saw Angelis earlier, and George is, of course. So hi, everybody.
00:13:11.500 - 00:13:48.658, Speaker B: So my role in this panel first of all, I'm not a blockchain expert. I'm interested in it, but my expertise that's relevant here probably is coming a little bit more on the cooperative AI side and in particular there, I have more of a game theory view on that. I run the Foundations of Cooperative AI Lab at Carnegie Mellon University. I also have a part time appointment in Oxford, but this happens to be the time that I'm not there. So generally what's of interest to me is just kind of abstractly thinking about languages in which you can express very general commitments.
00:13:48.754 - 00:13:49.014, Speaker A: Right.
00:13:49.052 - 00:14:21.834, Speaker B: So we're very interested. I've done a lot of work over the years on commitment, in game theory, in mechanism design, and now increasingly also in program equilibrium type of setups where we commit to a program. In some sense, their commitment seems like it can be very helpful to attain cooperation and to establish trust in all these things. At the same time, we're also learning that commitment isn't always a good thing. And there are certain kinds of commitment that in broader society we actually try to avoid.
00:14:21.882 - 00:14:22.094, Speaker A: Right.
00:14:22.132 - 00:15:01.390, Speaker B: Commitment could also lead to things like extortion or collusion or vote buying. And I imagine many of those are interesting to you as well. So that's kind of where I'm sitting. I kind of want to think about, well, how do you structure things so that you get the good kinds of commitments and not the bad ones, the ones that result in beneficial cooperation rather than collusion and extortion and these types of things? I know cusper and Lewis, I think, are going to be there tomorrow as well, and you're in good hands with them. And so I don't need to talk too much, but if I can be helpful with anything, that's great. And otherwise, again, you're in great hands with Casper and Lewis tomorrow.
00:15:15.760 - 00:15:19.870, Speaker C: Oh, okay. So can you hear us right now? Okay, great.
00:15:22.660 - 00:15:29.664, Speaker A: Yes. Okay, nice.
00:15:29.782 - 00:16:33.990, Speaker C: So, yeah, we're going to have some time, maybe 40 minutes, with Vincent and George to answer some questions about commitments. Some of these questions were asked to you with this quadrating voting mechanism. We got four replies, so we have some data to know which questions are the most interesting to the audience to first. So one question that was seemingly very interested to the audience is the idea that commitment devices, what are their roles, limitations and trade offs? And specifically, the question was both crypto and cooperative AI have focused significantly on commitment devices, a decentralized way of implementing coordination. So how does this study in crypto, Blockchain and cooperative AI relate to what we know from, let's say, traditional literature on the way to implement coordination with, for instance, mediators or mechanism design, maybe? Vincent, can you take this question first?
00:16:34.680 - 00:17:49.950, Speaker B: Yeah, great. I do think there is a lot of overlap, again, especially at this kind of abstract level of thinking about the languages in which we make commitments and the ways in which we make commitments. And I think both Cooperative AI and also Blockchain have somewhat of a decentralized view that there isn't necessarily a well established institution already in blockchain, maybe you have a protocol, but besides that, things can emerge naturally. And in some ways that's a nice environment, but in other ways there may be also things to worry about, right? That somebody gets some kind of strange first mover advantage that leads to extortionary dynamics or other bad dynamics. And so how do you prevent that? I think I don't have the answer to that at this point, but I think that's a good thing to think about. And one thing that seems to play a large role also is who has access to which information, right? That if we can have a private side channel within which we can also make commitments, that is something that can enable collusion better than, for example, if everything is necessarily public. But how do you keep things public if they can be encrypted and so on.
00:17:49.950 - 00:18:53.810, Speaker B: So that's, I think, one aspect. Also from the mechanism design angle, there's a question of whether all the information is already included. Right. Normally in mechanism design, we think about there are things like the revelation principle which tell us that, well, in some sense we can simplify the mechanism, but in the end, from the user or from whoever we value, we still need this input of what is it that they actually value, how much do they value it? And without that, we can't necessarily play the game. And again, I think in this context, there are interesting questions about to what extent is that private information already out there and can you commit to it? To what extent do you eventually need to query a human being where you can't really monitor or make any kind of guarantees about what they might say? And how does that play into these stories about commitment and cooperation? So I think that I just listed off a whole bunch of different things, but I think those are some of the things that are relevant to all of us.
00:18:55.300 - 00:18:56.470, Speaker C: Very nice answer.
00:18:57.400 - 00:19:51.844, Speaker A: Yeah, I'll happily take a stab at this. I would say, yeah, definitely. There's a lot of interest from both communities, let's say, on this issue of commitment, but probably from a somewhat different perspective, I would say the way I think of commitment in blockchain is a very somehow practice oriented first approach. Okay, so how can we solve the issues of a resolution? Okay, here's like a hard limit on gas. If your program needs more steps, tough luck, right? So on the other hand, somehow Vincent and his group, they've done, of course, very elegant theoretical work of understanding very powerful commitment devices and what you can and do with them. And I think it would be very interesting somehow to try to maybe follow kind of like gradient. If I would go to the take combine maybe like David's perspective here.
00:19:51.844 - 00:20:35.270, Speaker A: And I would say, okay, let's think of, suppose think of how ethereum does commitment resolution like today, and then say like, okay, what's the most promising direction? What's the minimum capabilities that we can add to the system so that they maximize somehow the promise of the systems, right? So I think here is like where and then it's not about implementing everything, but somehow, again, going for a minimal change, literally, somehow like a gradient step. So it could be very useful if somehow some of this rather general theory could say could be somehow revisited from that perspective. Right?
00:20:36.200 - 00:21:08.956, Speaker C: And going at it gradually, is this also perhaps a way to hedge against the risks that Vincent was talking about, that when you expand the space for people to make commitment, you might also expand the space of bad commitments that they can do with it? And perhaps going at it piecewise and just adding features one by one is one way to kind of check that it works well along the way? Or is that insufficient as AI safety, for instance, thinks about it, which is that either you have an AGI or you don't have an AGI and there's not really, like, a way to be.
00:21:08.978 - 00:22:01.176, Speaker A: In the well, if I will take this, maybe part of my answer is already on the board. It's always a good idea to move in small steps. Why? Because maybe in a real world, most of the properties of most systems are relatively stable. So hopefully, if you do, like, a small change in the system, you won't create a catastrophic error. That being said, we do know that there are systems which undergo critical phase transitions, and I think that's a lot where the real theory comes into play and say, okay, do we have evidence to believe that we're close to such a regime? And then we can try to study this both theoretically and somehow experimentally. Right. And then as long as we don't see any sort of evidence for such phenomena, then I think we can be more confident.
00:22:01.176 - 00:22:04.030, Speaker A: A small step won't be the catastrophic one.
00:22:06.400 - 00:22:49.116, Speaker B: I agree. And this is a context where we definitely can do experiments as well. Right. Maybe some things fail, but sometimes it's really good to see what actually happens in practice. And some of these things are so complex to think about. cusper has some nice stories about earlier program equilibrium type of competitions and kind of Axelrod tournament style, where at that point, a lot of people were thinking about logical analysis of the other programs and establishing cooperation that way. But it seemed that the competition just devolved into this weird situation that a lot of people put some keywords into their code that made it look like they were thinking about cooperation and so on.
00:22:49.116 - 00:22:59.984, Speaker B: But in the end they were all just effecting on each other and trying to, in very superficial ways, trick the other programs into cooperating. Could you have predicted that?
00:23:00.022 - 00:23:00.512, Speaker C: Well, maybe.
00:23:00.566 - 00:23:39.740, Speaker B: But in any case, I think it's good to do those experiments. And I think this is a context where we can have fairly not all too high of stakes experiments. They need to be high enough that people are really motivated to actually try things and come up with for example, if we are worried about extortion being possible in this kind of framework, we actually want to incentivize people to try to do that. To the extent that we have an experiment and we want to learn what is possible and what isn't. So we need some stakes, but at the same time, the stakes can still be low enough that we can think of it as an experiment.
00:23:40.800 - 00:24:11.252, Speaker A: Speaking of stakes, I think Ethereum has offered a great example of such a transition, like in the real world. Right. So the transition from proof of work to proof of stake. This goes back to discussions with Vitalik and Virgil around 2017, where that's when the first somehow favorite kind of work happened. And we know that in theory this would work. But then of course, you start testing it. Initially you have computer experiments, then you move to testnets multiple testnets developed by independent groups.
00:24:11.252 - 00:24:36.690, Speaker A: This gives you confidence that it's not a fluke. And then eventually you actually do the change in the main net. So there's not one step. There's like multiple steps. Right. But this is actually a great success story for theory. This all started with pen and paper arguments where we say, like, look, you can do everything without game theory and not somehow burning millions of dinosaurs per day.
00:24:36.690 - 00:24:44.176, Speaker A: So hopefully maybe we can replicate some of this idea for other elements of the protocol.
00:24:44.368 - 00:24:46.644, Speaker C: Nice. Yeah, I definitely want to come back.
00:24:46.682 - 00:24:48.996, Speaker A: On the program equilibrium because this was.
00:24:49.018 - 00:25:51.370, Speaker C: Something that was highly rated in our informal survey. But before moving there, there was a question about we often think of blockchains as their value proposition is really about being this available commitment device that is just sitting there and that people can deploy things to. But we have only recently been thinking about this whole strand of literature that has been existing for quite a while on the idea of commitments in games and exactly these principle agent problems dows of extortion the credibility of mechanisms as a, let's say, practitioner of this field for quite a while. Is there something that we should have on top of our mind when we're thinking about this problem? We're coming in with fresh eyes but is there maybe like a critical learning from the field that we should be very mindful of and that seems to apply in this situation? Maybe this was a question for Vincent.
00:25:54.640 - 00:26:47.884, Speaker B: Sorry, I thought you were talking about blockchain practitioners which I'm not commitment devices practitioners. Yeah, this is good. So I think in game theory and mechanism design, right, most of the literature on commitment is sort of implicitly in mechanism design that there is some entity out there that is in a position that they can commit to the rules of the game and they're often creating the rules of the game for other players. Right. That in the end often we think about the mechanism designer or whoever's running the mechanism as not really even a player in the game, they're just setting up the rules and that's the way that we get commitment. And that's a kind of commitment that I think also in these contexts can be helpful. But at the same time here maybe we are thinking a little bit more about players that are at the same level we're talking about program equilibrium then we're really talking at some level about this mutual commitment, right.
00:26:47.884 - 00:27:22.708, Speaker B: That I commit to do something if you do the same thing and vice versa. And that is in some ways very powerful to get things started and to build up from nothing. But there are a lot of details there about how those commitments come to be and again, if you have somebody who is a first mover and who can commit to something before anybody else that radically changes things. A lot of these program equilibrium concepts actually allow for many different equilibria.
00:27:22.804 - 00:27:23.112, Speaker A: Right?
00:27:23.166 - 00:28:41.792, Speaker B: And so that's another issue that there may be a difficult equilibrium selection problem. Again, a first mover might try to take most of the benefits from the cooperation but at the same time that might also fail and somebody else might be trying to select a different equilibrium. So at some level, maybe you still need some kind of norms and expectations. Because again, there are so many different equilibria that you could have in principle that in the end there probably needs to be some kind of community enforcement of whatever standards we're trying to uphold to prevent things from going all too far in the wrong direction. And so that's very interesting. To what extent would that emerge naturally and would that emerge in a good way? Or do we need to think about that more proactively beforehand and think about what should be the norms, what is the kind of behavior that we should be punishing and what mechanisms do we have to punish certain kinds of behavior or block it? Those I think are difficult questions that again probably experiments would be very interesting to me to see what actually would happen. But I think we also still to some extent lack the abstract framework, even though there has been for quite a few years.
00:28:41.792 - 00:29:51.816, Speaker B: This literature. A lot of it gets very complex very quickly and we usually look at fairly abstract models where everybody gets to commit at the same time. Everybody gets to see everything and that's easier for us to do the analysis but may not really track the real world, especially as there is private information that's being held somewhere that we can't see. People move at different times. We have dynamics, there's updates about the world coming in and we have to be a little bit flexible. People are maybe not going to use every aspect of the language that you provide them with and so presumably again there will be some evolution of the kinds of things that people express and that they know how to analyze and that then their programs will be looking for to see. So I feel like there could be many different kinds of equilibria and so the key questions are how do you converge the good ones? To some extent we can try to maybe design the good ones or at least encourage people to use the good ones, make those sort of very focal or salient that like, okay, well, this is really the natural thing to do.
00:29:51.816 - 00:30:01.210, Speaker B: My worry is that things can go wrong in a number of ways if we're not mindful and if we don't have the ability to roll some things back some of the time.
00:30:05.920 - 00:30:12.370, Speaker C: Is there something that the blockchain community should know about AGT that we're not paying attention to?
00:30:15.140 - 00:31:04.050, Speaker A: Yeah, that's a good question, at least for algorithmic game theory. I think that there's been a good and I guess increasing communication between these two fields. So I don't think there's any sort of real, absolutely hidden secret, hopefully not, definitely not. But I think what we should be doing more is I think remove more silos. Right? And I think this is something that takes a lot of effort and somehow even relationship between people in creating societies. Right? And then we'll be doing some of this work I think, for example, EC has become much more like blockchain friendly. And now, of course, there's a lot of professors in the area which are with their students doing work.
00:31:04.050 - 00:32:04.560, Speaker A: And I think maybe the thing to show, to see next emerging is I would say a tighter knit between the academic community setting commitments and let's say maybe the more traditional att community that already speaks blockchains. So for example, if I were to talk about this, here's a good idea. Maybe I don't know if Emas is the home base, let's say, of commitment, theoretical commitment on research, but then collocating Ms and EC and having somehow like a tutorial by Vincent and David on these kind of issues would be really helpful to spark somehow to accelerate research. And again, somehow the reason why I think we're doing again this work on why you see it became much more blockchain friendly is because ethereum actually with vitalik. There was this big tutorial back in 2018, something in Ithaca, and then everybody said, oh look, we can actually solve these problems. We're going to have impact. These are like real world and people got excited.
00:32:04.560 - 00:32:23.130, Speaker A: And I think here clearly there's an exciting interface and if we really start talking with each other, I think we're going to have important, I think thank you guys for actually making this happen. I've never had this conversation before and I think this is a useful step in this direction, for sure.
00:32:24.380 - 00:33:19.672, Speaker B: Yeah, I agree with Georges and especially this idea also of having these kind of workshops but also more broadly we could have workshops, for example, also at EC to allow, because usually these things are somewhat gradual, that I think it's completely true that EC has become friendlier to this kind of work. But it's very gradual, little steps. And here we can clearly see a mechanism design problem, right? So we jump on that. Or here's a very clear game theory problem where some of the other things are maybe still a little bit more speculative. And so it would benefit from having some kind of environment like this workshop, but also maybe workshops with submissions at EC or something to allow people to experiment a little bit and think a little bit more about what could be a contribution. What could be? A paper. Maybe some papers that maybe aren't technically strong enough to be at EC yet, but have an interesting idea.
00:33:19.672 - 00:33:22.280, Speaker B: I think we probably need some more of those venues.
00:33:24.080 - 00:33:58.260, Speaker C: Yeah, that would be definitely very nice. What is, would you say, the best approach? Like when you think about cooperative AI and the questions that the new types of AI are kind of raising? And when you think about blockchain, are they new objects for this theory of commitments? Do they just extend the space beyond what the theory has been thinking about? Or are they objects that you can somehow represent them in this already existing theory? And maybe this. Informs the way to talk about it to people who are practitioners.
00:33:59.720 - 00:34:49.380, Speaker B: Yeah, I think, I mean, you'll find some people who say, well, basically everything you can model in game theory, right? And there's some truth to that. Game theory gives you this extremely general language for representing these kind of settings and thinking about them, but in part because it's so general, there's many things you could model within it and many things have been modeled within it. I think this interaction and thinking about blockchain specifically in this context will get people to think about specific models, specific games to be played that we haven't really analyzed as such yet. So I do think that, yes, at some abstract level, there's nothing new under the sun and we can model everything as a game. These specific setups we haven't really studied yet. And I think there's a lot of value in thinking about that. Some of that can, I think, probably be pretty abstract.
00:34:49.380 - 00:35:51.496, Speaker B: Some of it in some cases, maybe it doesn't really need an abstract analysis. It doesn't really matter whether it's on blockchain or not. You can represent it fairly generically as a kind of commitment game or maybe some kind of program game where you can commit to a certain program that may then have applications on the blockchain. In other cases, I think you probably do need to know a little bit more about the underlying architecture and you can think about designing the underlying architecture in order to enable certain things that you otherwise couldn't do. So that's, I think, kind of the space to think about. Generally, it's good to keep, in my view, keep things as abstract in general as possible, without losing the important aspects, but then also be able to go back and actually build these things and think about, well, what are the fundamental primitives that we need in order to enable these kinds of mechanisms, these kinds of commitment devices and so on, right?
00:35:51.598 - 00:36:57.680, Speaker A: Maybe to iterate a bit of this and maybe to counter propose here here's I think that something will be very useful from the perspective of practitioners in the blockchain space is to do something even in a more formalized way of your presentation today where in some sense, you give a very nice high level but also a good level of detail of the current somehow reality of the ethereum ecosystem. And in some sense now I would like to see such a description that could almost act as an API to say, like, look, now create somehow a program equilibrium specification that can actually talk to this abstraction. Right? And this of course, abstraction will not be, of course, ethereum specific. It should be clearly more general. Right. But I would say, like, look, we're going to create something that at least feels more tailored to the specific constraints and this could allow us to make progress. Right, because it's exactly going to be these constraints that say, like okay, look, we're not going to talk about everything under the sky, but we're going to talk about, let's say, program equilibrium for blockchain.
00:36:59.780 - 00:37:28.700, Speaker B: Yeah, I really like that perspective. I think thinking about the APIs or what are kind of the fundamental abstractions and interfaces that we need to be able to modularize and sort of say, well, I don't really care exactly about the underlying implementation as long as it gives me this that's I think the level at which we want to interface between some of these cooperative AI ideas and actual implementations on the blockchain. And that's where we should have that conversation.
00:37:31.280 - 00:37:49.824, Speaker A: I do have a question. As an expert in cooperative AI, where is the dialogue on cooperative AI happening nowadays? I know this is kind of like diffused discussion, right? Yeah. But as an expert in the area, where would you go? Where would your best ideas appear and so on? Help us.
00:37:49.862 - 00:38:05.936, Speaker B: Help us. Thank you for letting me advertise. So we have a cooperative AI summer school coming up in Oxford. Sorry, I think it's in London, actually. And so that's in July, if I'm right. So that's coming up. So we're thinking about building up these events.
00:38:05.936 - 00:38:52.628, Speaker B: You can talk more with Lewis as well. I think there's a plan for a NeurIPS workshop. So I think for now, it's a little bit of these special events. I think some of the work we have a couple of Itch guy papers on our work now that I think fits very much under the cooperative AI agenda. So there are the kind of familiar candidates of the AA Itch guy Amuses, also ECS of the world that I think are a good home for at least the more game theoretic approaches to this. There are other approaches to cooperative AI as well, maybe a little bit more reinforcement, learning oriented ones, for example, that naturally would have homes at. So there's that aspect of it.
00:38:52.628 - 00:39:37.412, Speaker B: Some of the technical contributions will just be some part somewhere in some session of some bigger conference. But the kind of more dedicated events, I think, is also really valuable to think where can we really have the discussion about what cooperative AI even is, which we're all still trying to figure out at some level as well. And so the summer school will hopefully set some expectations for that. And then at some point, maybe we have more dedicated workshops as well. Maybe we can host something at CMU at some point. So I think we need some of those little bit more dedicated events. Probably we won't have a whole separate conference like at the level of Amos or even a smaller version of that just yet.
00:39:37.412 - 00:40:21.120, Speaker B: I think it is valuable to have those papers appear in the more general venues, and that way you also get feedback, right? Because sometimes maybe we think we have an original idea, but somebody else as well, actually, that's technically very close to this other thing. Right. So, you know, it's important not to be too insular, but at the same time, we're definitely thinking about creating more of these venues and places to discuss more specifically, like, what do we want this broader agenda to be? What kind of topics do we see as fitting in there? What's of interest to us? I think probably like, with any academic area that will kind of emerge over time and it'll be a little bit of a like, we know it when we see it kind of thing. But yeah, still very much in flux.
00:40:23.880 - 00:40:30.404, Speaker C: So we're being told that the room is actually closing and I think we need yeah.
00:40:30.442 - 00:40:31.990, Speaker B: At seven there's a bit I think.
00:40:33.560 - 00:40:34.820, Speaker A: It'S the same flab.
00:40:38.620 - 00:41:22.868, Speaker C: It's about coordination. Okay, then I'll finish then on one question was really about the future direction and the ways to take this further. I'll just read it because I think it was very nicely written. How can the field of AI leverage the benefits of crypto economic commitments to address coordination and alignment challenges? And what might be the biggest potential obstacles in implementing something of this type? Are there fundamental limitations or in other ways? How can blockchain be used to constrain the risks of alignment in AI? Maybe georges can you yeah, I mean.
00:41:22.874 - 00:42:03.616, Speaker A: It'S a great question, but I would go like, one level back. Yeah. So actually, working somewhat on the intersection of these areas actually, let me rephrase this. Working on both areas, let's say, of blockchains, and I would say game theory AI, and being on the committees of a lot of conferences in this area, I think the intersection is not quite there. Right. For whatever reason, there are people who do blockchain and a lot of interesting work, people who do AI. In some sense, the computational constraints of these two worlds are vastly different.
00:42:03.616 - 00:42:25.092, Speaker A: Right. And then somehow, at some point, it seems people choose one of the paths versus the other. Right. So, first of all, I think we need to make these two worlds closer together. Right? So yeah, for example, I did mine. Nobody said like, hey, hi, judges, explain to me this about blocks. It there's no such urgency.
00:42:25.092 - 00:43:15.640, Speaker A: Right. But people, on the other hand, they care about AI safety quite a bit, but somehow, to the extent that blockchain solutions would be an enabler, I think that's not in the conversation right now. Okay. I would want to believe that blockchains and specific commitments, for all the reasons that we understand from, for example, equilibrium and generally this filter, cooperative systems should be useful. Okay. But how to actionalize this? I think we're probably going to need a combination of things that in some sense we need, like a tricecta. I think this idea of how do you put these two things together? Let's say blockchain, cooperative AI, and for example, this idea of differentiability that David talked about, if you can describe this.
00:43:15.640 - 00:43:41.280, Speaker A: So it's not only that you have to put, let's say cooperative AI and cooperative AI and blockchains together. You also have to put neural networks. Okay, done. I think it's important. Right. But you see, just doing two of them together, you're already in the suggest new ground. So now it's about putting effort together.
00:43:41.280 - 00:43:56.630, Speaker A: Yeah. Good, let's do it. So I think it's exciting. It's exciting. It's definitely hard work. And the way to do it is to understand the works that are already done on two of the three areas and try to understand how to add the extra component, actually. Okay.
00:43:56.630 - 00:44:23.150, Speaker A: And as I said, this kind of conversation is definitely, I think, a step in the right direction. Okay. And we should start small. That's the other thing. I think a lot of time when people talk about solving everything and I'm saying like, no, give me the epsilon step that I can believe in, that does not scare me too much. So I believe that make some progress there. So I think this is the interesting thing to go for.
00:44:23.150 - 00:44:38.560, Speaker A: What are the gradient steps in that direction? Right? Yeah. I don't have good ideas. I would invite all of you to try to participate in discussion.
00:44:39.720 - 00:45:30.404, Speaker C: So we have some good news. We have a room for ten more minutes. Perhaps I would suggest we can move away from the problem of metacordination and dig deeper into the technical specifics of coordination and specifically program equilibrium. So, Vince, you said earlier that there is a work by Kasa on basically having a population of programs interact with one another and sort of selecting away what is the winner or the dominant or evolutionary dominant program out of them. It feels to me, as I've read more of this literature, that the problem of composition of these programs or how different programs relate to one another is very central to the current state of the art. So could you tell us more about what are the biggest unsolved questions in the field?
00:45:30.602 - 00:46:33.576, Speaker B: Yeah, very good. I don't think any of these competitions or other things have had a clear resolution as that this is the right way to do it. But I'd say there are sort of three different approaches. One is to look for identity in programs, right? Like you're looking really for a very specific program that you're actually going to scan, whether it's that specific program, maybe the same one as this program, the program that I am. Let's say that's one way to establish cooperation and so that in some sense works very easily and is easy to analyze and gives you folk theorems about being able to cooperate and do other things. But it's also very brittle because this really requires coordination on one particular kind of language, one particular kind of thing that you express and that might at some point fall short as the environment changes and you need something else, or as you start to interact with another community that converts to a different equilibrium. So that's where that one falls short.
00:46:33.576 - 00:47:31.784, Speaker B: There's this other one where people try to do logical analysis of the other programs and actually try to prove things about the program. So given a program expressed in some language, we try to prove whether it will in fact cooperate with. So that's a very interesting direction and gets into lots of unusual mathematical logic results like Lubb's theorem. And so it's interesting, but also a little bit mind blowing and hard to think about and hard to really get your handle on. And I think that's exactly what happened in this competition that I mentioned before. And I think in some sense the most robust one that I know about now is actually Kasper's approach that relies more on simulating the other programs as opposed to trying to really analyze them, just getting to run them. Now, this is tricky because in some cases this leads to, in some cases, even an exponential blow up in the number of runs that you need to do that if I need to simulate both of your programs.
00:47:31.784 - 00:48:10.616, Speaker B: But both of your programs actually also try to simulate the other two programs. Well, this is never going to end, right? And there are some tricks around that, that we maybe randomly sample some programs to simulate and we end some things early. So that's I think a little bit the leading edge of where these ideas are going. But simulation in some sense is a very powerful way to proceed because if nothing else, the thing eventually needs to be able to be run, right? So if that's the only property that you can rely on, that whatever crazy thing somebody puts together, at least it.
00:48:10.638 - 00:48:11.210, Speaker A: Has.
00:48:13.340 - 00:49:26.624, Speaker B: To be, or otherwise maybe it's just going to time out, then it's nice to be able to build on that and get the cooperation that way. So that's what I currently kind of see as the most promising approach, especially as these systems would get more complex at some point, right? Like at some point maybe they're all Georges'points that he just made about, well, what we can afford computationally is very different when we're talking about a foundation model versus something on the blockchain. Maybe one day that comes together with off chain computation or something like that. And in those cases, it really becomes hard to just analyze. How are you going to analyze the code of a self driving car that seems going a bit too far, but at some level you can audit it, you can run it, and you say like, well, I'm going to put it through the sequence of tests, right? The more I think we can rely on that, that all we need to do is run the program, maybe run it under different conditions. That I think is probably the most robust way to proceed. And that's a lot of what we've been working on recently that we just think about simulation access, right, and nothing else but just being able to simulate it.
00:49:26.624 - 00:49:32.880, Speaker B: And even that can give you cooperation in various contexts. So that's where we've been focusing.
00:49:35.760 - 00:50:17.740, Speaker C: So this would have been actually my next question. How do you think about developing and let's say deploying these programs in environments that are not only complex but maybe, let's say I need to make a commitment, but the environment in which I'm playing, it changes over time. It has a lot of features that maybe I'm unaware of. So are there results of game theory when things that look at how should I make commitment or how should I deploy my program that plays on my GitHub when I have imperfect information about the game that is being played, I don't even know the full space of strategies or what other players might be doing. Is there something to be said about this setting?
00:50:18.240 - 00:51:10.988, Speaker B: Yeah, very good. So I think in general you can think about dynamic settings, right? There's a whole literature on dynamic mechanism design, but most of those approaches do require that you have some kind of concept about the kinds of things that could be happening once you start going to really open worlds. I would worry about committing to certain things too much. Right. Practically in human societies, usually we have ways of rolling back our commitments that our laws, for example, usually can always be overturned. Some things need maybe we require a larger supermajority to overrule, but things are fundamentally set up to be somewhat flexible. Now that also creates some tension, right? Because if you can overturn everything, then commitments stop being credible potentially as well.
00:51:10.988 - 00:52:26.564, Speaker B: So that's, I think, where you need to find some kind of balance, where sometimes maybe you need to say, like, well, we're going to commit that as long as things stay within the parameters, stay within certain intervals, then we are in fact committed to do this. But we have some escape clauses that if something really unusual happens, then we can exit from the commitment. Right. And I think that's what we see in human life as well, that if circumstances get really unusual, then we change the laws and we change the expectations and we change the norms. You can think about, for example, in Ukraine recently, when that started happening, a lot of the laws were kind of put on hold and say, okay, well, we're not going to worry about people doing this kind of thing because it's now obviously not our normal situation anymore. I think that's sort of a characteristic of how we as human beings handle this. And there's probably something to that in any sufficiently kind of open world where things might really change drastically, that you need some kind of mechanism by which to come back and say like, well, all these things that we committed to before made sense in the context when we committed to them.
00:52:26.564 - 00:52:31.930, Speaker B: But now that context has changed. So much that we need to have some kind of escape clause for that.
00:52:33.980 - 00:52:35.610, Speaker C: There's something new.
00:52:38.620 - 00:53:24.536, Speaker A: Actually, some thoughts. I mean, the thoughts that I was thinking about is more about maybe kind of like a convincing application, let's say. Yes. Right. So I think all of these tools are going to be useful if they can show that, look, there's the blockchain world before the introduction of these commitment devices, and then the world like, let's say after, and now there's this explicit new capability that people actually care about and use. Think of something like, let's say citizens talk about DeFi markets and moving like trillions of dollars. Well, clearly people care about that and then can talk about the capabilities that allows this to happen.
00:53:24.536 - 00:53:45.890, Speaker A: Now I think there could interestingly be some new such market that can only be built in the presence of more powerful devices. And I think that's fancy to also like to be in mind because then we have a reason to actually jump into these complexities and struggle with them. Right.
00:53:47.140 - 00:53:55.520, Speaker C: So for the last two minutes that we have, maybe I want to open the floor to the audience if there's any question on the topics.
00:53:59.550 - 00:54:01.546, Speaker A: Yes. What question do you think we should.
00:54:01.568 - 00:54:02.906, Speaker C: Have asked you, but we didn't ask.
00:54:02.928 - 00:54:20.000, Speaker A: You what the meta question. Yeah. So the question was what question you should have been asked by the audience, but we did not ask you.
00:54:23.740 - 00:54:58.470, Speaker B: Always a good question, but I think we've touched on what I thought were going to be the most relevant things. Right. Again. I really liked George's idea about thinking about what are kind of the fundamental abstractions or primitives that we want to build off of. On the cooperative AI side, what is what we need and then what can be delivered. On the actual implementation side, I think that's a really nice place for us all to come together and think what those are. I would encourage more of that.
00:54:59.160 - 00:56:00.072, Speaker A: My ask to this would be not what, but who. I think you should definitely ask like, bannerberg, like more stuff in some sense. I think the more you understand the present capabilities of the blockchain ecosystem as a computing formalism, that will be the most useful thing to take home, especially if you don't have a background in this. Okay, so your goal after today is, say, like, okay, here's during machine abstraction of a computer, right. But for the theorem, and then somehow and then if you're going to go home with a much better approximation, I think that's very useful. And asking Banner based and the other practitioners, I would say either Banner based props you for all of the people who do the hard work. Okay, that's it.
00:56:00.072 - 00:56:01.112, Speaker A: Yeah. Thank you both.
00:56:01.166 - 00:56:05.704, Speaker C: It was very engaging session and hope to see you soon.
00:56:05.902 - 00:56:06.790, Speaker A: Thank you. Awesome.
