00:00:02.330 - 00:00:15.662, Speaker A: I'm American. I know, I know. You can boo it's. Fine. You can boo it's. All right. Oh, thank you.
00:00:15.662 - 00:00:40.572, Speaker A: Thank you. It's a relief. Okay, thank you everybody. My name is Matt Stevens In. I'm a behavioral economist and I work at Block science, not streamer. Streamer Henry couldn't be here to present. So what we're going to do is we're going to talk about the process of designing the token economics of streamer and how we developed it.
00:00:40.572 - 00:01:10.936, Speaker A: But first, I do want to start with a bit of an overview of Streamer, which is best done via this video, which I'm going to kind of narrate. I'm going to use my best narrator voice for this part, but the rest will be non narrated. So let's see if I can make the clicker play it. No, let's try one more time. Okay, we're going to improvise. I'm going to skip to a slide that does this. Everybody shut your eyes so you can't see these slides I'm going through.
00:01:10.936 - 00:01:54.320, Speaker A: And then I'll just yeah, it's good stuff. Okay, so basically what you see is streamers are messaging infrastructure for Web Three. A publisher app publishes the stream. Their node relays it to subscribers wanting better service for the stream. A sponsor deploys and funds a bounty broker. Nodes watch for a stake or watching for the bounty stake to join the stream. Nodes relay the stream which claim rewards from a contract brokers being limited in the streams they can join get staked by delegators who pay into a stake pool, giving broker nodes the funds to join more streams.
00:01:54.320 - 00:02:13.516, Speaker A: So that's the ultimate structure. And that would have been a nice video, which I would encourage you to watch. I believe it's on the streamer website. It will be soon. And now we're going to do this forwards. Everything you just saw, forwards and backwards. So here's the sort of high level overview of the talk.
00:02:13.516 - 00:02:47.328, Speaker A: We're going to start with the system goals for Streamer, which we really ultimately just reviewed. But we'll talk about that a little more. The emergent incentive systems, the way of thinking about streamer as a structure of different groups that might have differing incentives that need to be coordinated. The way you might imagine Streamer as a generalized dynamical system. And then the games which occur in that generalized dynamical system. Then we'll move on to the testing, which will be a little lighter in terms of the slide because there's still more to be done. But CAD, CAD modeling, simulation of different agents behaviors.
00:02:47.328 - 00:03:29.476, Speaker A: And then designing for the testnet, which is forthcoming in late August, as I understand it. And then the plan to revisit some of the simulations and assumptions with real data, which is an exciting thing to do. So starting with design, we talked about the system goals and who participates. Well, what you ultimately see here is there is a sort of enabled and enabling economy produced by Streamer. Right? You have a group who wants to pay for streams. You have a group that wants content. They are the enabled economy and the enabling economy are the people who participate in the streamer structure itself, right? So you have delegators and you have payers and so on.
00:03:29.476 - 00:04:30.504, Speaker A: And so this conceptualization of an enabled and enabling economy bridged by this platform abstraction in the middle is where we start. And when we start to look at what this platform abstraction might be, the first thing to look to is how do these systems exist in the real world? Not exact, but like what's the closest analogy? Because what you want to avoid is this you're trying to predict the behavior of some complicated system, just model it as simple object and then add some secondary terms to account for complications. I just thought of this is the notorious physicist approaching a problem they don't understand approach. Right. And so to avoid this, I think it's important that you take what I call the ostrom step, where you look at the closest analogs that exist in the real world to the sort of problem you're trying to solve. And when you do this for the case of streamer, you find that there are certain private trackers and groups and there's some research and literature on this that have certain emergent mechanisms. So first of all, it shows that the problem doesn't solve itself, which that's what we assumed anyway.
00:04:30.504 - 00:05:01.884, Speaker A: But it's nice to know that this doesn't just sort of people want to stream and pass across different nodes. That doesn't just naturally happen if you tell people to do it. Paying people incentive systems and so on can be helpful. And these are some examples of the incentive systems you find in the real world. So punishment which don't think punishment like somebody's going to jail, but closer to like staking and slashing right reputation classes with promotions. You'll find certain social norms. Groups will stay small enough or tight enough or coherent on some sort of identity such that non monetary incentives can remain robust.
00:05:01.884 - 00:05:44.044, Speaker A: People will feel a level of like reciprocity and let's say and then we have heterogeneous performance metrics and those are quite heterogeneous as far as we can tell. So what you ultimately are seeing here is this kind of you might call it a Cambrian soup of different incentive structures that emerge to solve different particular problems. And that's one of the interesting things. We go into the approach of incentive design with this sort of assumption that you might have heterogeney in the way you want to approach these performance or you want to incentivize these people. So at the same time you start to develop a GDS model of streamer. This is a generalized dynamical systems model. Now obviously, I'm going to walk you through every piece of math here for the next 15 minutes.
00:05:44.044 - 00:06:44.256, Speaker A: I hope you all have coffee. No, we're just kind of going to flag this here and say what's trying to be done here without going through anything in particular is to understand, okay, what's going to sit in the state. Like what are going to be the state variables? What are people, the agents interacting going to want to look for in the state? What are they going to use to understand and to understand the system and find it to be legible and thereby coordinate. And so you put this all together and you get this picture of one aspect of streamer as a dynamical system where you have brokers joining, they're staking, they are recovering these bounties according to a particular logic that might be set by the payers or in some cases groups of brokers. And then they're claiming it according to another set of logic. Right? Now this is a big complicated system and I think one of the important things as you start to try and recognize that you're building for humans is that people experience big complicated systems as games. I would like to contend.
00:06:44.256 - 00:07:13.040, Speaker A: So what game is this? Becomes an interesting question as you start to move into the mechanism design. So what shape is this? I wasn't expecting a call in response but triangle I hope you said. Okay, great. Yeah. So everybody's at least thinking triangle. But of course if you really look, if we want to be pedantic about it, that's not a triangle at all, right? You can see that the bottom right line isn't connected. The top right line isn't connected, right? You can see that it's too curvy.
00:07:13.040 - 00:07:42.996, Speaker A: If you ask a topologist really what this shape is, who knows what they're going to say. It's a very complicated object. We see this complicated object as a triangle for whatever reason. And similarly people who participate in these complicated systems often see them as one or more incentive games. And in particular the incentive game that comes up in this aspect of Streamer is a minimum effort coordination game. Now that sounds complicated but it's not especially complicated. So we have a payoff structure there.
00:07:42.996 - 00:08:23.024, Speaker A: I won't exactly walk you through it. The intuition of a minimum effort coordination game is think about an airplane getting ready to take off, right? You have to clear the cabin, you have to load the new passengers, you have to refuel, right? Like there's all these steps and all the steps must be completed before the plane takes off. So let's say one of these steps takes 2 hours. Well it doesn't matter if the other steps go really, really fast, right? You can refuel in five minutes but if it's still going to be 2 hours before the plane is loaded again you won't take off for 2 hours. Thus you could have refueled over the course of 2 hours. There's no efficiency gained, right, by being more efficient if it's minimum effort. That's the nature of a minimum effort coordination game.
00:08:23.024 - 00:09:26.000, Speaker A: And so this is of course the case at least in a sparse network. So you can see that if you have a publisher paying to pass a message across nodes, the fidelity with which those nodes pass the message is minimum effort because the highest latency, let's say whatever the case is, whatever low effort one of these nodes might put in is going to be the ultimate thing that determines what the subscriber actually gets, and thus the value of the network. Right? So the people participating in it from the broker side, that's how they experience it as a minimum effort coordination game, right? They don't want to do the wrong thing. They don't want to free ride in the sort of public goods sense that maybe some of us know. But what they do want to do is figure out what everybody else in their network wants to do and they want to be efficient along that dimension and match effort. And this is fortunate that this is the structure because there's a lot of interesting evidence on this. So for instance, humans can participate in a minimum effort coordination game and do it quite well and do the best possible thing under a couple of conditions.
00:09:26.000 - 00:10:17.960, Speaker A: One condition is that you pay them. Another condition, I'm summarizing a lot of literature here, so I shouldn't say it's absolutely essential you pay them, but for the most part you have to pay them. And the second condition is that they get to in some sense choose their neighbors. So this is from Rydell 2011. So you can see that if you just sort of run this generally on the left, what you're seeing is that people start to give worse and worse effort because what they're seeing is that they're being burned, right? Like they're giving a high effort, they're passing, let's say, these messages with high fidelity, but somebody else in the node is not it's doing low fidelity and thus the entire structure they're participating in is of lower value. But if you let them choose their neighbors, if you let them choose the people they're passing the messages to, they will stick in this high equilibrium. So that brings us to a second core component of the streamer design.
00:10:17.960 - 00:11:39.920, Speaker A: I'm previewing a little bit here, but the first one I didn't mention explicitly, but paying people can help. The second one is that we might expect to emerge these what we call general contractor agreements. Basically agreements between nodes such that they will whitelist one another and you will get these organizations that are closer to the kind of Cambrian soup we mentioned earlier of different incentive structures, such that instead of it just being random people who show up to be a node. You now have groups of nodes who can sort of choose their neighbors, as it were, and ensure that you get a high quality stream. Okay? So now focusing on testing this and this is the part I'll try to be light because there's a lot, a lot of simulation that goes into it but that's not always so interesting to hear about. We ran this computer simulation but the essential idea mapping it back to the model in the beginning, the mathematical model is you take the generalized dynamical structure and then you start to code it up in a system and then you start to put the agents in a system. So you can see here we have variable names along the right and you start to look at the likely behaviors sometimes drawing on experimental data, experimental literature of actual humans behaving in this and sometimes just testing very broadly against plausible parameters.
00:11:39.920 - 00:12:52.136, Speaker A: And you test to see if the system is robust according to the system goals at the very beginning. And one of the ways you can sort of look at this and start to think about performance is there's a hierarchy of coordination that you naturally see emerge. So the easiest way to get everybody to do what you want them to do is to make sure they make the most money. So this is the sort of going to the moon coordination, right? The particular graphic I'm showing has a path toward public good problem which I'm not going to cover here but actually does have a little something to do with robustness. Happy to talk about it later but this coordination path on the right you have the idea that, okay, can you turn the coordination game into a prisoner's delight where everybody makes the most money? If you can, then you probably have solved this minimum effort coordination problem or the coordination problem in general. Can you not do that well? Can you make it the least risky? Can you make it what's called risk dominant? If you do that people can naturally kind of cooperate as well. And worst case, can you make people sort of start and stick in this equilibrium? So these are the three solution concepts we'll expect to see in these agreements in the emergent incentive structures that come up.
00:12:52.136 - 00:13:47.268, Speaker A: And so beginning to test for these and see the parameters which correspond to this from an agent's perspective in terms of the amount of money they're making or the amount of risk they're taking becomes an important part of the process as we build toward going live and learning from what we expect to see. And here's just a simulation, for example. So this is focusing on what we call decoupling risk. This is the idea of maintaining the fidelity of price as an actual signal. So if you were a payer you want to be able to assess quality of stream. Is price a good signal in the real world? It often can be but it isn't under all assumptions. So ensuring that these structures are robust such that you have price as like an actual signal of quality and it turns out we were able to establish under a decent number of behavioral finance assumptions that this can be done to some extent so that was one of the cool results.
00:13:47.268 - 00:14:33.464, Speaker A: But of course, you have to test it live. And we all remember this slide from the very beginning. We're not going to go back through it, but I would call this is hard won simplicity at the end of the day, right? Like, we have taken a system that is incredibly complex and we have learned to understand it from an agent's perspective such that we can start to get a sense of how is this going to be legible to the humans who participate in it? How will they conceive of this game? How will they think of the incentives? And do the incentives make sense for the system goals? It's looking good. We're confident that they do. And of course, we're going to test it. So I believe the test net, last I heard, will be in late August, at which point we will revisit these models with real data to see if they correspond to what we were hoping for or assuming. And then we'll take the math spec.
00:14:33.464 - 00:15:17.090, Speaker A: One of the other things I didn't mention that's nice from the mathematical specification early on, is that you can get a smart contract oriented math specification out of that pretty well because we're already thinking in terms of state variables, stateful parameters and so on. So that's a sort of overview of where we've been and looking forward to the testnet, rolling out and getting some real data on this. Thank you. Am I supposed to stay up here for Q and A? No, real quick, because we're running late, but if you want to ask questions, super quick question. No, we're good. Okay. All right.
