00:00:01.610 - 00:00:25.926, Speaker A: All right. Hello, everybody. Originally, there was an animation on this slide, but I think the conversion to PDF screwed up the animation, so we're just going to pretend it's like a zero knowledge title. I'm Christopher. You may have noticed, if you were looking at the original schedule, that this talk was originally planned to be given by Fatima, whom I work with at Heliox. Unfortunately, she could not make it today due to some last minute schedule changes. So I'm stepping in for her.
00:00:25.926 - 00:01:01.534, Speaker A: Fair warning, I may be giving a slightly different talk than she planned to. You know, if you were looking for that, you might be surprised, but I hope you're not bored. I'm going to talk about security and privacy in general, and then in Namata, which is a product that we at Helix are working on. And before I do that, so that I hopefully can keep you all entertained, I want to conduct a brief survey of privacy familiarity. So who has heard of Zcash? Raise your hand. Who has used zcash? Keep your hand up. There's quite a stark difference in these two numbers.
00:01:01.534 - 00:01:15.182, Speaker A: Who has heard of tornado cash? Raise your hand. Who has used tornado cash? Keep your hand up. Right. Okay. So what I conclude from this is that privacy has a user experience problem. Who's heard of Zcash? 95% of people. Who's used zcash.
00:01:15.182 - 00:01:55.946, Speaker A: Like, three people. And I'm going to talk a little bit about that. But first, let me just say namada is joint work by Adrian Awa and myself and everyone at Helix. Unfortunately, way too many to list, but you can find us here. So maybe you're already convinced, but just in case you're not, I want to talk a little bit about why privacy matters, because I think there are a few reasons. They're both first order reasons and second order, third order, fourth order, and third order reasons to worry or want to worry about privacy. I think a first ground of why privacy matters is for local sovereignty, for national, and for community defense at all sorts of different scales.
00:01:55.946 - 00:02:37.822, Speaker A: If the data about what you're doing and this can be in a nation, this can be in a dow, this can be in a group of friends, is visible to everyone else in the world, or to people who have some kind of especially asymmetric power advantage over you, they can always use this data. They can select from it to misrepresent what you're doing. They can use it to target you if they know some of your actions, if they can paint you in a particular light, which might not represent a sort of fair assessment of what's going on. And the only way to defend against this at the community level at many different scales is privacy. That's reason one. Reason two is something I'll call nudge surveillance capitalism. So who has heard of the phrase surveillance capitalism? Raise your hand.
00:02:37.822 - 00:03:39.678, Speaker A: Okay, this was popularized originally in a book, the Age of Surveillance Capitalism by Shoshana Zuboff. Boy, it's like four or five years ago now, but it refers to this trend of what you might call data monopolists, using their intense or extreme amounts of data about everyday interactions to kind of slightly alter actions to put advertisements in front of you to show you particular YouTube ads when you search something on your phone, even to the point of detecting where you are in the world and showing you pertinent ads for local things. Right. At the surface level, if there's not any direct infringement on rights, it doesn't necessarily seem like a catastrophe. I mean, maybe these ads are more relevant to you, right? That's the argument they make. But it's this kind of nudge, right? Like, these companies have become very adept at figuring out when, precisely, to show you an ad to change your behavior just slightly. Maybe you were considering going to the local coffee shop and they can show you an ad for Starbucks.
00:03:39.678 - 00:04:46.978, Speaker A: Maybe you were considering buying a phone, and they can convince you to buy a slightly different phone. Right? These changes seem small, but they add up. If 50% of people who might have considered going to the local coffee shop now go to Starbucks, then the local coffee shops go out of business, right? So even though the individual decision seems not to change very much, in aggregate, the effects can be very large and very concerning. Third reason why privacy matters is that it is, I would say, a necessary substrate for the protection of rights. So let's take the case of abortion, which was, say, recently, the subject of a lot of debate in the United States of America and in other places. Regardless of your views on the particularities of this question, if you don't have privacy for what you're doing, then pretty much anyone can target you. So if you use a period tracking app, if you search for certain things on Google at certain times, even on the behalf of somebody else, these companies have more than enough data to identify, perhaps not with Certitude, but with high probability, what kind of medical procedures you might be considering or a significant other might be considering.
00:04:46.978 - 00:05:34.258, Speaker A: And this can be looked up. In fact, this data is already sold to, say, activist groups on multiple sides of this issue, and they can use it to target people. Regardless of sort of your views on the social question, without privacy, there's no real substrate protecting individual rights. It's only up to a kind of benevolence of not only what your government decides, but what everyone else decides. And that is quite a tall order. So if you want robust protection of individual rights, you really need privacy so that you want to make the cost of targeting very high. Right? And this brings me to my fourth point, which is that it's kind of odd that we need to be making arguments for privacy, because privacy throughout most of history was the default.
00:05:34.258 - 00:06:13.650, Speaker A: It's not only that some governments maybe claimed not to target people on the basis or claimed kind of adherence to individual rights, but also that it was, like, quite expensive to operate a Secret Service and it required wrecking your society and it required hiring all these people who have to go around and who could themselves be deceived. Right. But with this kind of global surveillance network, enabled, of course, by these very devices you hold in your pockets, violating individual rights just becomes very easy. And when it's very easy, it's very tempting to do. It's very tempting to come up with justifications for why governments need to be doing it that turn into propaganda. But we should really consider here the long arc of history. Privacy is the historical default.
00:06:13.650 - 00:07:07.970, Speaker A: It's only digital systems deployed in this kind of totalitarian surveillance fashion that have changed that equilibrium. Also, privacy is hard. Especially usable privacy is, you know, of course, these aren't blockchains, but here's some examples. I know my father, who I love very much, always wrote his passwords on Post it notes and stuck them to the front of his screen. Luckily, we lived in remote Oregon in a place where that was pretty unlikely, someone was pretty unlikely to see that. But if you run around with, your know, you open your laptop, post it notes on your screen, someone's got their phone with their camera going by oops, right? So if you lock your bike to yeah, that post not going to work so well, et cetera, et cetera. So privacy is hard, and in order for it to work in practice, privacy has to be combined with usability in a way such that not only is the technology capable of delivering the privacy guarantees in theory, but also the use of the technology delivers them for people in practice.
00:07:07.970 - 00:07:55.646, Speaker A: Now, I wanted to talk a little bit about the state of privacy in blockchains. So, so far, at least as far as I'm aware, users have had two choices, which I kind of demonstrated in my expositional questions here. When they wanted privacy, the first choice is to use a sovereign chain which reissues assets, generally all assets, or a specific asset, which is the only asset you can use. So Zcash and Ironfish both fall into this category where you can use Zcash and get privacy, but you have to use Zuck. The other choice available has been some sort of privacy preserving solution built on a smart contract chain. So Trinidad, Cash, Aztec, some other solutions in Ethereum fall into this category, and both options, at least it seems to me, come with some pretty serious trade offs. If you use a sovereign chain which reissues assets, you may not necessarily have the asset that you want to spend privately.
00:07:55.646 - 00:08:42.766, Speaker A: Zcash, amazing project, but the monetary economics of ZEC are not necessarily suited to paying people for coffee, right? Doing regular, everyday transactions and these other kinds of more exchange related transactions for which you really want privacy because they convey essential data about your purchase habits. So we say privacy preserving solutions built on smart contract trains are usually more flexible with regards to assets. But because they have to be built on the smart contract chain, they tend to be more expensive to use. They require longer latency times, and the privacy guarantees are not generally as strong because, just like, it's difficult to build something that's compatible and fast and cheap at once. So users including like Me and Acadeliax, want simple, understandable privacy. They want it for any asset. They want fast and cheap settlement.
00:08:42.766 - 00:09:07.302, Speaker A: They want strong security guarantees. These users, man, they want everything. They just like, don't compromise. But can we provide that? So we're working on a blockchain called Namata, which aims to kind of synthesize across these trade offs. So Namata is a sovereign proof of stake blockchain, uses tender into BFT consensus. It has something called cubic Slashing, which I'll talk about in a bit to discourage validator centralization. It has a native trustless, Ethereum Bridge.
00:09:07.302 - 00:09:56.454, Speaker A: It is focused exclusively on enabling multi asset private transfers for any asset, and accordingly, it treats privacy as a public good. Let me spell out what all of that means. So Namad's key feature is something called the multi asset shielded pool. The Multi Asset Shielded Pool is an extension of the Sapling, a lineage of circuits originally developed by the Electriccoin Company for Zcash that extends Sapling to be asset agnostic. So that in one shielded pool, you can transact privately with both fungible and non fungible tokens. And we've crafted also the sort of implementation architecture for WebAssembly proofs that can be crafted or written, authored proofed in browsers and mobile devices, and the usual sort of set of additional keys for selective disclosure of particular transactions without compromising all of your transaction history. So the key feature of the Multi Asset Shielded Pool is that privacy is additive.
00:09:56.454 - 00:10:55.706, Speaker A: So if you use many different assets, different users can be using different assets, namata doesn't care. They can be using ETH, USDT, Dai, etc, CryptoKitties, NFTs, all in the same shielded pool. And the more assets that are used in that shielded pool, because when you send a transaction, it doesn't reveal which asset was sent, the more privacy everybody gets. But we don't think that's enough. Privacy is a public good in that if you use a system, if you use a shielded pool, not only do you get some privacy for your own individual transaction by doing so, but you give more privacy to everyone else who's using the same shielder pool. So we've come up with a system called burden mint, which creates a kind of incentive for privacy while allowing the interactions to remain completely private, where when users deposit assets into the shielded pool, they get a kind of boy, I stray away from the term yield because it's a bit nebulous, but you could call this a public good subsidy, right? Or privacy yield for putting assets in the shielded pool. There's no risk involved.
00:10:55.706 - 00:11:23.266, Speaker A: It's just like this is intended as a positive nudge, right. If you're considering sending a transaction and maybe you don't care about privacy, but if you send it in the shielded pool, you're creating privacy for other people. So we want a way to capture a little bit of that value that you're creating for other people and pay it back to you to give you a reason to do that. So burn a mint accomplishes that. Right. Security. So if you look at too many proof of stake networks right now, you observe a pretty concerning power law in stake distributions.
00:11:23.266 - 00:11:53.482, Speaker A: I e. Proof of stake is centralizing. So this is a snapshot of the Cosmosub blockchain top seven validators taken this morning from a Block Explorer. And you see that the key threshold in BFT networks is one third, right? More than one third of participants can compromise safety or liveness. And you see here that the number of participants required to reach more than a third is seven out of 150 validators. It's seven oops, not great. So why? One reason I think, is that current proof of stake incentive schemes do not reflect the risk to the network of validator centralization.
00:11:53.482 - 00:12:35.462, Speaker A: Right. If we could find a way to price that in, then there would be some reason for validators not to have such a steep power law of stake distributions. So how do we do this in? Nomado, we implement something called cubic slashing. Cubic slashing attempts to punish correlated faults because the more correlated the faults are, the more the risk is to the safety and safety and liveness of the network. Right. So with cubic slashing, when infractions are detected, instead of just like slashing individual infractions, the network kind of keeps infractions for a period of time and figures out how many infractions and what total stake associated to those infractions happened within a particular period. Then the amount of slash is proportional to the cube of the total voting power involved.
00:12:35.462 - 00:13:19.366, Speaker A: So this means that even if you try and split up your validators to get around this, if you set up all your validators with the same setup and they get slashed at once, you get punished as if they're one big validator. So the idea is that this creates a kind of anti correlation incentive that maybe they're still, you know, maybe there's still Binance, right? But at least now binance has some reason to split up its validators and run them in different jurisdictions and use different software stacks so they're unlikely to be slashed all at once. And this does provide better security and practice to the network, right. So another important factor for security, especially for chains as Damata is, which do not want to reissue assets, is bridges. And the word bridge used to mean something specific. And now it kind of means something very general. There are things called optimistic bridges.
00:13:19.366 - 00:13:36.398, Speaker A: I'm just an old, cranky old guy, but I don't know her. Optimistic bridges? Really? Bridges kind of something else. With Nomada's bridge, we try and avoid additional security assumptions. So we do this in particular by making the validators do extra work. Right? Got some validators. They're getting paid. Might as well make them do extra work.
00:13:36.398 - 00:14:12.658, Speaker A: In Nemata, we make the validators run ethereum full nodes. And this allows us to have a kind of trustless bridge where on Ethereum, we have a light client for Namata. On Namada, namata validators run ethereum full nodes. So if you're using this, you have just the same security as you would using only Namata, but you can bridge all of your assets from ethereum. Another thing we add to the bridge is the kind of defense in depth. So many bridges, you see, like, lots of publicized bridge hacks, XXX million. And basically all of these could have been prevented even without architectural changes to the bridges, if they just had a little bit of defense in depth.
00:14:12.658 - 00:14:34.834, Speaker A: I e. Limits, like no more than $100,000 per hour. It does not seem super hard, but of course, costs extra gas, extra implementation work. But we think this is important. So for Namata's bridge, we have limits on deposits and limits on transfer throughput. And defense in depth changes the value of attacking a bridge. So it also greatly improves sort of practical security.
00:14:34.834 - 00:14:58.700, Speaker A: Attackers will go somewhere else. I think I'm probably running out of time, so I will finish this up quickly. In case you're interested in Nemata, we have already a private testnet running. Contact me if you'd like information, and hopefully we'll be able to provide some privacy with better UX in a few months later this year. Thank you very much. And maybe I have time for one question. Yeah.
00:15:03.710 - 00:15:11.962, Speaker B: On the burn and mint, how do you cover the return leg? So when you have to mint back on the original chain, how do you make that the original token? Or is that a bridge?
00:15:12.106 - 00:15:38.980, Speaker A: Right. So burn and mint is a function that runs purely on Namata. It's independent from the bridge. The bridge Namata uses to ethereum and to other chains. The bridges are based on the IBC sort of token transfer system. So escrow mint, voucher record. Does anyone have more questions? That's all done.
00:15:38.980 - 00:15:40.880, Speaker A: Thank you.
