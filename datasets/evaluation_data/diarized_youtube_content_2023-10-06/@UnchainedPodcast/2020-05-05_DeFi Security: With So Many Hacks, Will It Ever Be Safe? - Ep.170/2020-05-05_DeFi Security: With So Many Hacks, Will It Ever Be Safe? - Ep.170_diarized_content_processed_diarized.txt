00:00:04.250 - 00:00:27.746, Speaker A: Hi, everyone. Welcome to Unchained, your no Hype resource for all things crypto. I'm your host, Laura Shin. Twitter fights, medium posts, scammers, fishers, and promotional content. Want to cut through all the noise in Crypto? Sign up for my weekly newsletter@unchainedpodcast.com to get a quick and easy summary of the top news stories every week. The Stellar Network connect your business to the global financial infrastructure.
00:00:27.746 - 00:00:43.254, Speaker A: Whether you're looking to power a payment, application, or issue digital assets like stablecoins or digital dollars, stellar is easy to learn and fast to implement. Start your journey today@stellar.org. Slash Unchained Kraken is the best exchange.
00:00:43.302 - 00:01:00.800, Speaker B: In the world for buying and selling digital assets. It has the tightest security, deep liquidity, and a great fee structure with no minimum or hidden fees. Whether you're looking for a simple fiat onramp or futures trading, kraken is the place for you.
00:01:01.650 - 00:01:25.426, Speaker A: In response to the challenging times, crypto.com is waiving the 3.5% credit card fee for all Crypto purchases for the next three months. Download the crypto.com app today. Today's topic is security in DFI. Here to discuss are Dan Guido, cofounder and CEO of Trail of Bits, and Taylor Monahan, founder and CEO of MyCrypto.
00:01:25.426 - 00:01:27.110, Speaker A: Welcome, Dan and Taylor.
00:01:27.530 - 00:01:29.190, Speaker C: Hey, there. Happy to be here.
00:01:29.340 - 00:01:31.740, Speaker D: Yeah, super excited to talk about this.
00:01:32.350 - 00:01:43.130, Speaker A: Before we dive into the meat of today's discussion, can you each describe what you do in crypto and how you came to be involved in DeFi and or security? Why don't we start with Dan?
00:01:43.870 - 00:02:29.642, Speaker C: Sure. So Trailbits is a software security research and development firm. We were founded eight years ago by myself and two other expert hackers in order to improve the foundation that we all build on. So I used to do just plain old code reviews for folks for many years, but in Trail of Bits, we try to actually engineer software and build new solutions that others can use to kind of lift all boats. So we do a lot of work with DARPA and the DoD to build really advanced tools, and advanced fundamental research companies hire us to build high assurance software for them on their behalf. And then we also do really detailed product security reviews and training that help engineering teams build more secure software in the ethereum space. This was actually out of personal interest.
00:02:29.642 - 00:03:06.102, Speaker C: We're out of blockchain. This was out of personal interest. We had a couple of folks on the team that were as excited about the technology as folks that were working in the field, and we saw this tremendous greenfield opportunity to come in and build the kinds of tools and techniques that other fields really ought to have adopted at their first steps but did not. And that's what we did. Now, in 2020, we have this massive suite of tools that people can use to build secure code and a vast amount of public knowledge that we've been able to communicate to folks that helps them build secure code. And that's what we continue to do till today.
00:03:06.236 - 00:03:08.154, Speaker A: And Taylor. What about you?
00:03:08.352 - 00:03:57.818, Speaker D: I have a very different background. I started out just because I was in crypto. Then I accidentally, as I say, built this wallet that became immensely popular. And my security knowledge and the obsession I have towards everything that could possibly go wrong has sort of evolved over time and as I've watched things go wrong again and again and again. And so my crypto is a wallet. Previously I built my Ether wallet and both of these products have really interesting attack vectors. But also there's a lot of unexpected things that happened as I was growing these products.
00:03:57.818 - 00:04:18.960, Speaker D: And so today, really, I'm just quite obsessed with how things go wrong, how we can prevent things from going wrong, what steps we need to take to improve on both, like the user side, on the general community side, and then obviously the technical side is a huge part of it as well.
00:04:19.730 - 00:04:56.074, Speaker A: Yeah. So over the last several months, DeFi has seen a number of security issues. And it's funny because when you look at the discussions around all these attacks, they're just so new that usually people are even arguing about what to call. I think, you know, obviously we can safely say that most of them are attacks or bugs. They're generally just ways in which the behavior of the protocol diverges from the intention of the creators. And so let's start by talking about one of the most recent one of these security flaws, which was on Hedgek. Dan, you were actually involved in this one.
00:04:56.074 - 00:05:03.242, Speaker A: So let's actually have Taylor describe what happened first from an outside observer perspective and then you can jump in afterwards.
00:05:03.306 - 00:06:16.022, Speaker D: So taylor yeah, so know, the way it came on my radar was I was scrolling through Twitter, as I often do, and stumbled upon this tweet by them. I didn't actually follow them, so it was retweeted by someone that said there's been a typo, you need to take this action. Warning, warning, warning. And then a couple of other tweets and then obviously a whole bunch of replies to that original tweet with people kind of questioning how this happened, why it happened, what exactly is going on, et cetera. And as I dived deeper into everything about this tweet and discussion, I realized that there were some really overarching problems with just everything about it. So the first being that they initially called it a typo, which it obviously, while it may be factually correct, is not painful to watch people try to downplay issues like this. And that was pretty frustrating right off the bat.
00:06:16.022 - 00:06:17.410, Speaker D: That put me in a bad mood.
00:06:17.490 - 00:06:32.038, Speaker A: Yeah. And just to clarify, and maybe I'm wrong, but essentially this quote unquote typo is that if people kept their money in there, the money would be frozen. Not like stolen, but frozen.
00:06:32.214 - 00:07:07.186, Speaker D: Right. And so that was the second thing. I'm already in a bad mood. I'm like ten characters and I'm in a bad mood. And then they tried to clarify, but they ended up saying it's not a security issue. It just ends up that everyone's funds are locked. And now I was very involved in the Parity multisig situation, which was, I guess two years, two and a half years ago now, in which all the funds were locked.
00:07:07.186 - 00:07:26.460, Speaker D: And it was a huge thing. And so to just kind of like juxtapose those two experiences and then have someone be like, oh, it's not a security issue, I just found it preposterous. And I would say it went downhill from there.
00:07:27.310 - 00:07:46.950, Speaker A: Yeah, a lot of people were tweeting about how they should call it a bug, not a typo, and spelling out what could happen to people's funds if they didn't remove them. So Dan, can you now explain how Trail of Bits was involved in the Hedgehog incident?
00:07:47.130 - 00:08:15.750, Speaker C: Sure. So, in line with my introduction, we try to remain as open as we can and work with everyone that wants help. In the ethereum, in the blockchain community, there are folks that are at the beginning of their journey building a product and there are folks that are partway through or at the end right before they're about to deploy something. And there's always some guidance that we can provide. So I try to keep my door open when people show up and they say, I have written something and I need your help to secure it. And that's what the folks behind Hedrick did. They showed up, they said, look, this is a small project.
00:08:15.750 - 00:08:59.640, Speaker C: We don't have a lot of money. We'd like you to take a look at it. What can you do for us? And, and over the course of three days, we found a large number of issues in a project that was at a very immature state of development. And we described those issues to them and said, here are the things that you need to do to improve the security of this app. Now, they took that and it can be difficult sometimes. There's all these competing interests in the blockchain community around how you describe to your users that you are doing the diligence required to build something that others can rely on. And sometimes that gets boiled down to a Tweet sized byte of information that, hey, we worked with Trail of Bits or we worked with XYZ Firm, whether it's us or somebody else.
00:08:59.640 - 00:09:34.914, Speaker C: And there are ways to do that that is nuanced and correct. And there are ways to do that to transfer risk away to a third party. Because a lot of firms that build software and we don't make any choices about how they built the software. They choose what development methodology they'd like to use, what build tools they'd like to use, how adequately they'd like to test it, the architecture of it. And we just come in and we try to do our best to make sure that it gets better after we leave. So instead, in this case, we provide those recommendations of hey, here's how you should talk about your security process. And they didn't do that.
00:09:34.914 - 00:10:27.460, Speaker C: They said, look, our code is all safe because trail of it's used it and we're launching it today. Now we put out a summary document that said, hey, here's what the project with the hedgehog looked like. We did three days of work for them, which is a very small amount of work and we found a large number of issues only two weeks ago. So from my perspective, this is a page and a half document that includes a page and a half of fairly negative information about the maturity of the product. But most other people didn't read it that way. Most other people looked at, well, Drillibitz found some bugs, hedrick fixed the bugs, therefore the code is safe, which is really not the right takeaway and there's know things that I can do to improve that. But there's a lot about the community where the way that they are investigating what financial opportunities to provide their money to is kind of not producing the results they want.
00:10:27.460 - 00:10:44.842, Speaker C: So there's a larger discussion here of like, what are the factors that I should use to trust a given project and how can I interpret the information that's been provided to me about the safety or the viability of a given DeFi project. But what is your question?
00:10:44.976 - 00:11:39.900, Speaker A: Well, I wanted to ask about something that you mentioned at the very beginning when you said you will work with a project of any stage. Because based on the screenshots of the emails that the anonymous developer Molly Wintermute sent to you, this person wrote the letter Z for the word the and the numeral two for the preposition two. Obviously, you know, I'm a journalist, so the way the grammar and spelling and all those punctuation, all those things are very important to me. But just looking at that, that looked like a red flag even before receiving the code. It's like literally just the query itself to me. And I'm not trying to be judgmental of anybody who makes a grammatical mistake, but this is like a totally different thing. It's like somebody purposely not using right.
00:11:41.470 - 00:11:43.882, Speaker D: Really weird, it's really off putting.
00:11:44.016 - 00:11:46.254, Speaker A: But my question is like so why.
00:11:46.292 - 00:11:49.374, Speaker C: Work with someone like that at all? Isn't that such a right?
00:11:49.492 - 00:11:59.426, Speaker A: Because for me it would be like, oh, this business relationship may not turn out super well. That is what I would think if somebody sent me a message like that.
00:11:59.528 - 00:12:45.474, Speaker C: That's totally correct. And my thinking behind that is there are a lot of strange folks in the blockchain community. We've worked with somebody named Barada Barada before who ended up being an extraordinarily talented software engineer that helped provide input to build to enhance the quality of a product that we've created called Critic. We worked with a pseudo anonymous personality over at Makerdow named Rain. He would show up on video calls as a black silhouette and never went by anything other than those words. So sometimes in this community, because of the privacy and kind of very crypto punk cyberpunk kind of approach, people want to remain pseudo anonymous. They don't want other people to know exactly who they are.
00:12:45.474 - 00:13:03.526, Speaker C: And they kind of approach their work in this way so that alone, while, yes, it's really weird, it's really strange, I didn't want to slam my door on working with this person because they were, in my view, purposefully trying to obfuscate their identity, which is a thing.
00:13:03.548 - 00:13:05.750, Speaker A: That we've seen from by using that language.
00:13:07.050 - 00:13:50.418, Speaker C: I don't think anybody actually types that way. What they probably did is they have some kind of script that they process all their text through in order to create something that's more difficult to fingerprint. You've seen this a lot back in the old days when there were like hacker crews and everybody went by all kinds of different handles. And you'd try to obfuscate any of the publications that you made by processing it with some kind of script to eliminate the writing style that you have so that people couldn't figure out who you are. There's all these techniques that come from Stylometry and trying to figure out who Shakespeare was and whether he's like this guy or that guy based on their published body of work. You can apply that to software engineering. You can apply that to text files that people read on the Internet.
00:13:50.418 - 00:13:57.670, Speaker C: And it's something that I have seen before of people trying to just avoid discussion of precisely who they are.
00:13:57.820 - 00:14:14.960, Speaker A: Okay, I don't know if I totally think that obfuscating someone's writing style is the same thing as switching out the letter Z for the word the. But anyway, I don't want to get too far down that, but Taylor, what did you want to.
00:14:17.250 - 00:15:14.750, Speaker D: Was? Okay, so when I first saw her, I guess, writing style, I was taken aback by it and had the same sort of feelings as you. I think that there's a couple of different things going on. One is that, yeah, the crypto space is just weird. And so when you see something like this, it's not as weird as if you're in, say, a normal corporate environment and you get an email like this. And the other is that the cipher punk mentality and the value that these sort of cipher punks can provide makes it so that sometimes we'll give people the benefit of the doubt when they don't necessarily deserve it and would never get it in another sort of industry or situation. And I think that's definitely what happened here. And Dan is not the only one who has brought up this know this on purpose obfuscation.
00:15:14.750 - 00:15:54.334, Speaker D: And one thing that lends itself to that theory is that hedgick has a lot of writing out there that is not written like this. The Hedgehog Twitter account does not write like this. The white paper is not written like this. The website's not written like this. And so I'm not exactly sure why this personality, Molly, every time she writes, there's the Z's and the twos when she's obviously capable of writing in a normal or what society deems as normal. Welcome to crypto. That's all I'll say on that.
00:15:54.452 - 00:16:29.420, Speaker C: And those are things that we looked at, too. Obviously, we've been approached by people that are building pyramid schemes, and it's really easy to figure out when somebody is fraudulently trying to manipulate users in that way. But from the kinds of things that Hedgek was talking about, from the kinds of things that were documented in the white paper. There were friends of mine that were following their Twitter account already, so they kind of had at least some items here that meant that, hey, maybe this is something that ends up becoming important in the DeFi space, and maybe I should look at them despite this weird interaction that I'm having by email.
00:16:30.110 - 00:17:14.790, Speaker A: Okay. Well, one other thing, actually, that I did also want to ask about was so Taylor did such a great tweet storm dissecting the audit summary where she basically, you know, all this is written in a very professional way. But here's what they're really and correct me if I'm or correct me for me or Taylor if this was wrong, but she was you know, trailozitz is saying they didn't even do basic arithmetic correctly. They didn't even do the basic thing of having documents. So I just wondered around things like like, would it ever make sense for an auditing company to state that potential clients need to meet certain requirements before they can have an audit?
00:17:15.290 - 00:17:54.658, Speaker C: I think there's never a point where it's too early to engage with a security professional. That just kind of brings up this question again of are there people that I should tell to go away from my queue of folks that are asking for help? And I don't think that's the right answer. However, there are a couple of things here. So first off, the fact that we found yes, we found all these critical issues in basic arithmetic. We found ten issues that essentially could have stolen everybody's money two weeks before this project was going to deploy. They fixed only those specific issues, and they didn't address any of the root causes of any of them. Right.
00:17:54.658 - 00:18:30.206, Speaker C: You can see that in a public GitHub repository. And you can square that up with what we said in the summary report, that there was no substantial foundational improvements made to that code beyond patching individual lines of code. So that's something that you need to understand about these security reviews, is that they're usually focused on, hey, we spent X amount of time looking at the code and we found Y issues. If you found a lot of issues in a small period of time. It doesn't mean security improved dramatically. It means that the code is probably filled with bugs. Like big number is bad.
00:18:30.206 - 00:18:33.280, Speaker C: And I think most of the community thinks that big number is good.
00:18:33.730 - 00:19:32.306, Speaker D: Yeah, and I think that there's like a couple of really important things that this has brought to light. And one of them is the way that I read audits and I look at teams is very different than a lot of other people look at them, I guess. And the way that I look at them is not what does this audit say about the code, but what does this audit say about the team or how they're approaching the code or how they're approaching DeFi. And so when I was reading the review, I was like, this indicates to me that they're not really taking much seriously. They went into this audit pretty unprepared. There were some pretty basic things that they could have fixed before sending it to audit, et cetera. People on the technical side kind of tend to miss how human all of this is.
00:19:32.306 - 00:20:27.506, Speaker D: And people that don't have any technical experience don't realize that they can read these audits and apply sort of like the softer skills or the culture takeaways, even if they don't understand the literal technical underlying stuff. And that's one of the I think the biggest missing pieces is like, you have to have both. Like, you have to fix the bugs, but you also have to try to understand why they even got in the situation in the first know, why is this code being given? Basically handed to Dan in trail of bits with a chunk of money being like, okay, we're ready to go live, except we want a third set of eyes on this. And if you send it over in that state, that alone to me is a red flag because in theory, you thought it was as good as it.
00:20:27.528 - 00:21:03.498, Speaker C: Could be to push back on that a little bit. I don't know what they're planning to do when they're sending me the code. A lot of people. I would have thought that a reasonable thing to do with this code was after review from us, put it on a test net and play around with it for a little bit, that this is a step in their development methodology where there are many more steps they have to take until they release it to Mainnet. But instead what they did is they shrunk all that down and they said, okay, it's ready to go. Like ship now is when we're going to do this, because I think this would have been great if they just said like, okay, great. We've got some feedback about the maturity of our development.
00:21:03.498 - 00:21:19.174, Speaker C: We've gotten consultation from experts. They said that the code is not great and that they listed out all these things we should do. Let's show it to users, get it some testing and continue to work on it. And that would have been the perfect use of an engagement with us. But that's not what they did.
00:21:19.292 - 00:21:56.480, Speaker A: Well, wait, so I guess maybe I just have a misconception around what role an audit should play in DeFi or any kind of security. But if I sort of compare it to the way a magazine article gets published or something, I would imagine that the audit would be one of the last steps where you would get the most bang for your buck. If you put forth the best effort, you can get it as ready as you can, like as close to perfect, as close to launch as you can. And then at that point, have somebody come in from the that do not do that.
00:21:57.170 - 00:22:15.640, Speaker D: I'll just point out before I let Dan finish because he's going to say he's going to be right. But I just want to preface this by saying that the ideal way to engage with security experts is not how anyone's doing it right now. And that said, Dan's going to tell you how it should be done.
00:22:16.250 - 00:22:55.282, Speaker C: Yeah, sure. So a couple of things here before we get too far away from the point. I do want to say that what Taylor brought up about the context around the code and kind of the organizational behaviors and their own maturity at dealing with security stuff is a really important thing for users to understand that I don't think shows up in many of these security reviews, these PDFs that come from vendors like mine. We try to do a good job at that. We always list out long term recommendations that address the root cause of a bug being introduced. Not too many other security vendors do that and we do right. We're good in that respect, but I think we could do much better.
00:22:55.282 - 00:24:22.026, Speaker C: So some of the things that we've discussed internally since this Hedgek thing kind of blew up is ways that we can provide literally a color coded graph around the maturity level of various controls of projects in the DeFi space and the blockchain space. This kind of like takes a lot of inspiration from the way that we do threat models for companies, which is a different kind of service that to get back to your original question now, how should people engage with a security company is they should understand a little bit more from a strategic level where their risks are. And one of the ways that people do that is they use things like threat models. So threat models are a technique to understand what data you currently collect and manage and process the sensitivity of it, the components that do the processing, and the requirements of those components to properly protect it. If you have an understanding of that stuff early in your development cycle, then you've got a set of guardrails that make it much harder for you to get into situations where you inherit way too much risk more risk than you're capable of mitigating. Examples are like if you engage with a security professional early, there might be ways that we can discuss with you your goals and then, within the context of those goals, help you avoid manipulating low level solidity calls in order to achieve them. Because manipulating low level solidity exposes you to a vast amount of risk that maybe you can avoid.
00:24:22.026 - 00:24:49.466, Speaker C: And then there are hundreds of bugs that will just never enter into the code base at all. If you wait until the end and you've gone out on this limb and you've built all this code, and that's the first time that you're exposed to a security engineer, there might be a lot of cases where the code has been engineered in a way that is fundamentally unsafe and requires rearchitecture. So there's no way that I can secure a code base at that point. All I can do is point out all the things that are bad.
00:24:49.568 - 00:24:53.130, Speaker A: So basically there should be like, multiple engagements. Is that what you're.
00:24:55.390 - 00:25:30.658, Speaker D: Sort of like? So what Dan's talking about? When we get into the solidity side, it can get really technical. But a perfect example of this is when we were first putting together the first version of my Ether wallet and sending it out into the world. We had assumptions. We wanted to make this tool, whatever. We weren't really thinking that it was going to blow up, et cetera, et cetera. But even down the line, we never engaged with someone who did this for a living, who really, really understands security. Fast forward to 2017.
00:25:30.658 - 00:25:59.434, Speaker D: All of these things came out of the blue and just hit us upside the face, right? Like the phishing attacks, the malicious browser extensions, on and on and on, all of these attacks. If we had talked to a security professional at any point before that point, they would have said flat out, no exceptions. Don't put private keys in the browser. It's unsafe. The browser is unsafe. There's all these different ways that people will attack you that you can't control. BGP, the underpinnings of the internet.
00:25:59.434 - 00:26:36.726, Speaker D: Like, all of this is insecure. And instead, because we didn't for various reasons, we basically built an insecure product that by the point, we realized how insecure it was. It's really hard to take steps back and move away from it. And I think that's a bit of a more accessible example. But the same exact thing applies to D five products, to smart contracts, to pretty much everything. You don't want to get too deep into it before you realize that you're going to have to change the entire nature of your product or your system to ever be secure.
00:26:36.918 - 00:27:04.020, Speaker A: And one other thing I wanted to ask about, because this was also a point of dispute, but basically it looked a little bit like Molly Winter mute wanted maybe like a week long review. And then you guys were saying, oh, a three day review should be sufficient. So what amount of time would you recommend teams seek for an audit or I guess there's multiple audits, so maybe at different points in their project.
00:27:04.390 - 00:27:47.322, Speaker C: Yeah. So I think part of the issue here is that we keep using the word audit as if it's this fundamental scientific process where we can eliminate all the bugs from the code. And Taylor and I are both of the opinion that instead this is like a divining rod that lets us figure out where hotspots are and whether there's an underlying issue that needs to get remediated or needs to get rearchitected or needs to get fixed somehow. So in the span of three days, yes, we got good coverage on the code. And what we found was that the code was bad. That was a sufficient amount of time for us to understand the current state of the project. So in those three days, we found ten critical bugs that allowed us to steal everyone's money and manipulate all the things that you thought you could depend on.
00:27:47.322 - 00:28:24.094, Speaker C: That is not a great result. And we only needed three days to get there, so the extra two days for a full week wouldn't have told us anything different. It would have been a waste of money, in fact. So they already had now a list of things to do. Really what a security vendor like ourselves is trying to provide to people is a backlog of activities and investments in security that you need to make. So we build up that backlog. There are now a half dozen or a dozen different things for you to do, and we want to try to provide the most information, guidance to you in the least amount of time.
00:28:24.094 - 00:28:33.474, Speaker C: Which is why I'm not going to oversell somebody on a project when I know that I can provide the results they need within a smaller time period. Does that make sense?
00:28:33.512 - 00:29:03.282, Speaker A: Sounds like you were saying yeah. That they were looking to you to fix all their problems or to kind of like whereas you're saying that really the responsibility lies with them and that yeah, you can point out the ways in which maybe their process or their culture around the way they're building this is going to lead them into trouble. But you cannot be the ones responsible for the security of their project.
00:29:03.436 - 00:29:31.970, Speaker C: Yeah, I mean, they've been working on this for weeks, months, years. There are many people on the team. And just by the virtue that I looked at the code for three days doesn't mean I'm ultimately responsible for the security of their entire company and product. That's just the bottom line. There's a lot of other questions that you could ask too. Like there's things that are outside the actual code that determine the security of the product that I'm sure Taylor knows about just as well. Things like the owner privileges in the DeFi space.
00:29:31.970 - 00:30:32.038, Speaker C: People are. Obsessed with that. How decentralized is the application? Things like the Oracles that are providing feeds of information that the DeFi application might make decisions on how many of them are there and can I manipulate them. Things like upgradability there might be changes to the code that get made after a review is done. There could be things about monitoring like, do you even know when things have gone wrong in the future? And those could be things that firms ask me to help them with. Like, I can help you build a process around security monitoring so that instead of the public finding out that you've been hacked, you find out that you've been hacked first and can take some kind of remediation, maybe immediately issue a contract migration that saves some portion of your user's data or money. But there are many things that can go wrong, and it's really on the owner of the DeFi project to fully understand what those things are, and they can use our help when they ask for it.
00:30:32.038 - 00:30:44.986, Speaker C: And I'll provide them the best guidance I can, all the best practices, all the new solutions, and we'll bring in all the expertise we can to accelerate them, but ultimately, it is their responsibility to build a secure product.
00:30:45.168 - 00:31:23.686, Speaker A: Yeah, this is actually a perfect moment to take a break because you basically listed a whole bunch of things that I'm going to ask you about in the second half of the episode. So here we'll get a quick word from the sponsors who make this show possible. In response to the challenging times, Crypto.com is introducing three measures to help the community. First, the 3.5% credit card fee for all Crypto purchases will be waived for the next three months. Second, you could get up to 10% back by using the MCO Visa card on food delivery and grocery shopping at merchants like Uber, Eats, McDonald's, Domino's Pizza, Walmart, and more.
00:31:23.686 - 00:31:44.320, Speaker A: Don't have a card yet? Buy gift cards on the Crypto.com app from merchants like Whole Foods, Safeway, Burger King's, Chipotle, Papa John's, Domino's, and more, and get 20% back on food and 10% back on groceries. This is a global offer, so check out which merchants are available in your country. Download the crypto.com app today.
00:31:44.930 - 00:32:23.414, Speaker B: Today's episode is brought to you by Kraken. Kraken is the best exchange in the world for buying and selling digital assets. With all the recent exchange hacks and other troubles you want to trade on an exchange you can trust, kraken's focus on security is utterly amazing. Their liquidity is deep and their fee structure is great with no minimum or hidden fees. They even reward you for trading so you can make more trades for less. If you're a beginner, you will find an easy onramp from five fiat currencies. And if you're an advanced trader, you'll love their five X margin and futures trading.
00:32:23.414 - 00:32:29.660, Speaker B: To learn more, please go to kraken.com. That's Kraken.com.
00:32:30.590 - 00:33:19.382, Speaker A: The Stellar network connects people to global currencies and assets. Stellar lets you make near instant payments in any currency with anyone, anywhere. It's an open blockchain network that access payment rails for applications and institutions around the world and designed so that existing financial systems can work together on a single platform. Transactions powered by Stellar are low cost, transparent, and fast, saving both businesses and end users the time and money associated with traditional payment networks. With Stellar, your business can issue digital dollars or exchange existing fiat currencies without the need for complicated smart contracts or new programming languages. Its robust documentation toolkits and multi language support let you quickly integrate Stellar into your existing products and services. Learn more about Stellar and start building today@stellar.org.
00:33:19.382 - 00:34:26.146, Speaker A: Slash unchained. Back to my conversation with Dan Guido and Taylor Monahan. So let's actually just now turn to another recent pair of attacks, these involving imBTC on Uniswap and then also on the Deforce Protocol's Lend FME platform. Hopefully the audience here caught my Unconfirmed episode with Haseeb Qureshi on these incidents because it was actually really fun chatting with him and definitely it's a crazy story, so you should check that out. But essentially both of these attacks were caused by this ERC Seven Seven token, which is sort of like a more kind of upgraded or advanced version that has basically just other kinds of functionality that ERC 20 tokens don't have. However, if an ERC 77 token is used in an older smart contract that does not recognize that, then an attacker can perpetrate a reentrancy attack using that token. So I was wondering how you guys thought about situations like this.
00:34:26.146 - 00:34:33.700, Speaker A: How do you think DeFi should handle situations where the technology advances but then opens up new?
00:34:35.590 - 00:35:50.390, Speaker D: Like, this is actually the thing that scares me the most about smart contracts in general. I have no doubt that at some point we will get to the point where we can write secure, solidity or whatever language it's going to be. I have no doubt that we can get the community on board with understanding what makes a secure team, et cetera, et cetera. But when you think about the fact that there are all of these systems, right, like there's the Dforce system or the ERC seven seven system or the Uniswap system or whatever it is, you can make all of the pieces secure and you can have them implemented by good teams that are security minded. And then you combine two of them and everything goes out the window. And now there's problems. And when you think about just how many different combinations there are and the fact that you could combine two or three or ten of these systems, it's really hard to imagine on a purely technical level, there's no way to ever have the system as a whole, every single possibility, every single combination.
00:35:50.390 - 00:35:53.330, Speaker D: There's no way that it's ever going to be perfectly secure.
00:35:53.510 - 00:35:55.614, Speaker C: I have a little bit of a different take on this one, actually.
00:35:55.652 - 00:35:58.800, Speaker D: And I wonder okay, go for it.
00:35:59.330 - 00:36:07.314, Speaker C: In the uniswap deforce case, they're affected by the world's most well known bug class in ethereum. They're affected by reentrancy. Right?
00:36:07.352 - 00:36:07.940, Speaker D: Yeah.
00:36:09.750 - 00:36:11.874, Speaker A: In case people don't know what that was.
00:36:11.992 - 00:36:46.480, Speaker C: Right. It's incredible. It's so funny because up till this point since the Dow, there hasn't been a really exploited reentrancy attack on main net ever. Everyone talks about it so much, but the kinds of things that are actually causing people harm are somewhere else. And now, all of a sudden, in 2020, we have a reentrancy that's used to steal real money. That was the most surprising part of this to me. And when I think about it a little, like, why weren't they aware of a basic re entrance flaw in a set of contracts that's got a lot of eyes on, like, has actual development teams that are trying to do their diligence to build it.
00:36:46.480 - 00:37:00.770, Speaker C: And you look at the technologies that are being used. So in the uniswap case, it's Viper, and the tools for a lot of secure development and bugfinding and vulnerability discovery are written specific to Solidity.
00:37:01.750 - 00:37:04.402, Speaker A: Dan, just go back. So Viper is what is that?
00:37:04.536 - 00:37:52.126, Speaker C: So there's choices that you can make around what programming languages to write smart contracts in. Most people choose to use Solidity. Solidity is filled with foot guns. There are many ways that you can step on sharp objects and end up really hurting yourself with solidity. So there's a community of people that have developed a new language that looks a lot like Python called Viper. Now, Viper, while it has a lot less footguns, a lot less like sharp objects all over the ground that you could potentially step on, there are still some fundamental things that you need to do correctly, and avoiding reentrancy is one of them. So the problem here is that a lot of the best tools in the space for detecting basic security flaws like this have trouble working with Viper.
00:37:52.126 - 00:38:32.320, Speaker C: So the issues with adoption here of those tools may have created a scenario where it was more difficult to find in a uniswap and imBTC kind of scenario just because they've chosen to use different sorts of tech. Now, on the other hand, the deforce folks are in a different position because they did use Solidity. And that's simply a question of there is a checkbox yes no answer that you can get of, have you evaluated your code for known flaws and ensured the absence of them? And for Deforce, the answer was, no, we have not, because this would have been detected immediately by any kind of off the shelf security scanner that exists in the space.
00:38:32.930 - 00:39:22.320, Speaker A: Yeah, and just especially for people who didn't listen to the episode with Haseeb, I think it was OpenZeppelin did blog about this last summer in July, so it's been known for quite a while. But actually one other thing I wanted to bring up about this is that one thing that haseeb said was that for instance so Dforce had copied compound's code. But what he was saying is the reason that this issue didn't come up on Compound is because Compound knew about the issue and made sure that no, ERC, seven seven tokens were put on Compound. But that happens because they have kind of more centralized control. So I feel like there's this tension between the decentralization philosophy and then having good security. How do you guys think about that?
00:39:22.690 - 00:40:20.306, Speaker C: Yeah, common thing in the DeFi space, there is a lot of risk around composability, which is, I think, the word we've settled on to describe all these emergent behaviors and potential interactions between things that happen on Chain and the security risks that come from them. When we work with projects, we've worked with compound as well. And a lot of the way that you have to approach this is by whitelisting the behaviors that you have studied well enough that you trust and slowly opening up the ability of your contracts to interoperate with other stuff. So if you don't fully understand all the repercussions of working with arbitrary ERC seven seven contracts, then maybe you should wait until you're fully clear on what that means before you allow your contracts to do so. Now that's like one strategy, but at some point composability is unavoidable. Right? Like, I don't know, an example, you could buy insurance on a margin trade that's been collateralized with Dai. Right.
00:40:20.306 - 00:41:22.520, Speaker C: And then there's three systems that all interact with each other. So at some point there's no real way that you can avoid that composability. So it's really everybody's responsibility for ensuring that the contracts and systems they use, that the interactions they have with them are safe. It's something that I haven't seen many DeFi projects fully internalize where I think most projects in the space still depend on outside experts like Trailabits or someone to come in and advise them about what's going on and what they should pay attention to next and new objectives they should build towards. But there's definitely a point where it makes sense to have a smart security person on staff. Like, we've talked to a DeFi project where they had an Arbitrage contract on Chain that was abusing their app. And investigating that issue required them to identify the Arbitrage contract, download the binary code, reverse engineer it with one of our tools, and then deeply understand the way that it was abusing their work.
00:41:22.520 - 00:41:32.666, Speaker C: That's something that I think DeFi projects are going to need to come to terms with, that they really need their own deep understanding of these issues to deal with them in the future.
00:41:32.848 - 00:42:17.320, Speaker A: Right. But yeah, that still is, I think, a more centralized model. And this kind of is also related to the upgradability thing. So the way I asked the first upgradability question was just about when there's advancements in technology, then what do you do? Especially if your project at that point is more decentralized and you have less control. But then another question is just like, how should each system be upgraded? I had this discussion with Matt Luanko about TBTC the other day where he at different points in the interview. Like one time he was like, oh, we're going to set it and forget it kind of attitude. And then later he talked about the next version and he was like, oh yeah, well, actually there probably will be a V two.
00:42:17.320 - 00:42:39.310, Speaker A: But yeah, I just wonder, how do you think? Because I can't imagine. So let's say D five becomes a thing ten years from now. We're not going to be using those current smart contracts, right, but yet how do we get from here to there while keeping in mind all these different principles like decentralization and security and upgradability, et cetera?
00:42:39.650 - 00:43:31.566, Speaker D: Yeah, so the way that I look at it is right now the biggest threat is like we are writing bad code, we are creating insecure systems and so in the short term, I would prioritize centralization and security over decentralization. That's not to say that we should just forget about decentralization and not have it be sort of part of our goals or our philosophy. But just right now, the worst things that can happen can either be mitigated or eliminated by having, say, just like a kill switch. And I really lived through the Dow and I can say that everyone who is there is in the same mindset because we've watched what happened when you try to fully decentralize everything and you're not ready to oh, wow.
00:43:31.668 - 00:43:35.198, Speaker A: But I'm sure you're aware you just made a controversial statement.
00:43:35.294 - 00:44:38.742, Speaker D: I mean, I do get it and that's the thing. It's definitely a conflict within me because I'm building on Ethereum. I love decentralization, I love what it empowers, but in the short term, we're never going to be able to get there if every single contract is the Dow and it just blows up and everyone loses their money. And so there's some really interesting ways where you can strike a balance in the short term and then as the system becomes more secure and more mature and you have confidence in it, you can ramp down. Matt Luongo, obviously he has one approach that's a bit too decentralized up front for my taste. I've talked to him about this. But just as an example, you could have a smart contract where you have a big red button where if something goes wrong, you push the button and it stops everything except it allows for one function that allows the user to withdraw their money.
00:44:38.742 - 00:45:29.398, Speaker D: And so now if a hacker or a Flash loan or an arbitrager comes in and starts screwing with your system in a negative way, you can prevent them from doing that, you can prevent the bad things from happening, but you don't necessarily lock the user out. They can still go and withdraw their money. And you can also do that in a way where the user can withdraw their money, but you can't, et cetera, et cetera, et cetera. And so these are the things that I think in the short term we should definitely actually be encouraging because again, if everything blows up and every single project basically launches huge fanfare and then everyone loses their money, we're never going to get to a point where any of this stuff is actually useful. So, yeah, baby steps, please.
00:45:29.484 - 00:45:44.566, Speaker A: Yeah, there's been a lot of hacks, but one thing I just wanted to ask was when you said the user should be allowed to withdraw their money but you can't when you said you did, you mean the developers of that protocol?
00:45:44.678 - 00:46:28.760, Speaker D: Yeah, exactly. Just because I know this is like almost a meme at this point, but the decentralization is a spectrum. It really is true. You can create a mechanism that allows you to turn all of the smart contract off and that's centralized, right? That's the developer making a centralized decision to turn it off, but that doesn't necessarily mean that you have to be able to turn it off and steal everyone's money. As the developer, you can have a system where a centralized party can turn it off, but they can't touch the money, they can't withdraw the money and still allow, in a decentralized way, each individual user to withdraw their money from the system.
00:46:29.130 - 00:46:52.880, Speaker A: I find that idea really interesting because basically what you're doing with that is you're making the risk for different levels of people in the system, different. So if you're building it, then their risk has to be higher, they have to put more effort into making it secure. But for users, their threshold is a little bit lower and by the same token, they have more ability to go in and out.
00:46:53.810 - 00:48:03.270, Speaker D: Exactly. And we have not seen I don't think we've seen a DeFi specific product that has exit scammed or taken advantage of the centralized mechanisms to steal everyone's money, whether that's either like a team pretending to be good and they're actually bad, or a hacker like Abusing. No, I lie. There have been hackers that have abused the admin functionality of a smart contract. You know when Dan mentioned earlier, like threat modeling, right? Is the team itself good or bad? Are there attackers on the outside coming in from the outside attacking? Are there users that are inadvertently doing bad things on accident or on purpose? There's all these different parties and you do have to be aware of them, you do have to try to protect against them. It's never going to be, especially in the short term, perfect and secure against every single party. And that's why for me personally, again, prioritizing the safety and the pause buttons and those types of tools.
00:48:03.270 - 00:48:07.320, Speaker D: Yeah, do that for now.
00:48:07.690 - 00:48:36.640, Speaker A: And I just wanted to ask you guys about one other thing that isn't exactly in your wheelhouse, but I was so curious to know your opinion. So with the D force attacks, they did call the Singaporean police on the attacker. And I just wondered in like, do you think the traditional legal system should be a way to deal with these kinds of DeFi attacks? And if so, would it be the developers of the protocol who would be responsible? Or how would that all work?
00:48:38.550 - 00:49:16.586, Speaker C: You're right. That is a little bit outside, I think, our area of expertise. But if it's an option for you, then I don't see why you shouldn't take it. There are two things that I want to address about what Taylor mentioned. The upgradability conversation doesn't just affect the security of your product. You can also think about your product may be safe today, but another contract on chain could upgrade or change their behavior, and now their interactions with you are unsafe. And that's where the whole Flash loan thing comes in, where there have been contracts that have been deployed for weeks or months or years, and this changes the entire kind of threat landscape.
00:49:16.586 - 00:49:56.694, Speaker C: All the bad things that can go wrong are suddenly much more severe and much more likely to occur. And it was through no code change of yours. Your code did not change a single line, but things outside of you did. So that's other things that you need to be aware of and have an ability to respond. And I think empirically right now, the level of decentralization in the DeFi space is very low. Like, you can go download all the code for all the DFI apps and run it through Slither, our static analyzer, and you'll see all the owner privileges that just drop out, and it's extensive. I don't think anybody, right now, very few people are really achieving that ideal goal of being fully decentralized.
00:49:56.694 - 00:50:04.400, Speaker C: And I think that's okay. I'm with Taylor on this 100%. You have to take baby steps to getting there, and it's going to be a long road.
00:50:04.770 - 00:50:44.538, Speaker A: Yeah. Well, since you mentioned the BZX attacks, let's definitely talk about those. I guess actually something that interested me is what you just said. You kind of sort of call out the Flash loans as one of the issues, but actually, somebody else that I interviewed, Lev Livnev, when I had him on the show, he was saying that for the BZX attacks, he felt like they weren't necessarily the culprit. Obviously they made it cheaper to make an attack, but he felt that really, this was more like actual bugs in their code. So I was curious to know, do you think Flash loans are a problem? Because there definitely were other people at that time who were saying that they are a problem.
00:50:44.704 - 00:51:04.320, Speaker C: Yeah, so there's some nuance there. Like, there was a specific coding flaw in BZX that allowed this attack to happen. Right. They had a short position that should have been closed because it was under collateralized but it wasn't. That's the bug. Right. However, the ability for somebody to exploit this became significantly easier because flash loans were a thing.
00:51:04.320 - 00:52:02.738, Speaker C: So what I think most DeFi projects need to understand is the bar has now been raised that issues that were low severity before are high severity now, and that it's insufficient to only focus on a couple of things that a firm like Trail of Bits reports to you that you actually have to go through and fundamentally address. Every know this gets back to how do you actually secure a DeFi project? Or what is the process for securing a smart contract at and like ensuring that you're not exposed to known attacks is great but at some point. You have to have a deep understanding of what your own code is supposed to do and be able to prove that it operates the way that you expect. And that's defining security properties and testing security properties during development. That's like the next layer of a pyramid that I visualize of application security maturity where a third level might be all the token economics and the incentives that you've created which is just a whole nother thing that very few people have a handle on.
00:52:02.904 - 00:52:49.170, Speaker D: Yeah, I was about to say in addition to all the technical issues that we should be scared of, there's the whole thing where financials and incentives and economics and tokens when you start thinking about that those are attack vectors. Like if your token economics don't ensure that everyone is making money in the way that they expect to, bad things could happen. It may not be as drastic as say like the Dow, but if you're promising a sustainable business and you're actually losing money every single month, that's unexpected behavior and I think we are going to see way more of that come to the forefront as these more and more D Five projects start launching.
00:52:49.590 - 00:53:19.930, Speaker A: Yeah, and in a similar vein, I actually wanted to ask about bug bounties because this was actually another issue with the BZX attacks where the attacker was unhappy with the amount of the bounty offered which was $5,000 whereas with compound bug bounties range from as little as 500 to all the way up to 150,000. So I was wondering how should protocol teams determine what amount their bounty should be? What do you guys consider fair? How is that determined?
00:53:20.510 - 00:54:03.686, Speaker C: So I don't think the conversation is about the bug bounty dollar amount. There are some people for which the dollar amount is not a thing. They don't care. There are good people and there are bad people in the world basically. There are some people that are going to do things to screw with you and there's nothing you can do to convince them otherwise. And there are other people that are good people that just want to help you and they're very receptive to any sort of assistance or acknowledgments or thanks or money that you provide to assist them. And kind of what you want to do is you want to make sure that all those good people that are out there that are willing to communicate with you are kind of incentivized and it is easy for them to contact you and get those issues fixed.
00:54:03.686 - 00:54:43.782, Speaker C: You don't want them to not know where to go, to end up tweeting about it, to end up putting it on reddit or like wherever else you want to make sure that you actually hear all the things that people have to say. So providing that free flow of information is the most critical thing for a bug bounty program. And that means describing things like safe harbors where you have language on your page somewhere that says, here is how you can skip the support queue, you don't have to email support at whatever and create a Zendesk ticket. No, you can reach our security team directly and if you do so, we won't sue you. And here are all the different ways that we won't go back and harm you. It is safe to tell us things. So that's really important.
00:54:43.916 - 00:55:39.834, Speaker D: Yeah, I'm with Dan on this one as well. The bug bounty number, there's all sorts of philosophies on it, but that's the least important bit. The most important bits are everything else because if you think about typically they're called like gray hats, right? There are these people that are somewhere in between a perfectly good person and a perfectly bad person. You want them on your side, you want them to be white hats for you. And so the ways that you can do this are essentially by not pissing them off and by making it very easy for them to get you information. And both of those are insanely important. Because you can imagine that if someone either accidentally stumbles upon something or is hunting for something, and then they try to get a hold of you, or they try to share it, or they try to figure out what this piece, how it connects to that piece, or whatever it may be.
00:55:39.834 - 00:56:15.654, Speaker D: Every single one of these steps is going to irritate them more and more and more. And it doesn't take that much to piss people off on the Internet. And again, if the person is somewhere in between perfectly good and perfectly bad, they may either just not disclose it, just give up and be like, screw this. Or they may be like, hey, I don't know what the heck's going on, but here's this huge exploit and just dump it on Twitter. And we've seen this again and again and again and again. So yeah, bug bounties. Like you should have the page, you should encourage people, you should give them all the ways to communicate with you.
00:56:15.654 - 00:57:00.846, Speaker D: You should respond to those really quickly and professionally. You should have sort of your security information everywhere. Dan has a repo called the Security blockchain security contact list if you're not on that list when, say, Sam's son finds an exploit, he has to go into Telegram and be like, yo, anyone know how to get a hold of X team? And then we're all sitting there know. And again, Sam is this example of pretty damn close to perfectly good, but most people aren't going to be sitting in a telegram with a whole bunch of blockchain people and ask for a contact and then get an answer in 2 seconds.
00:57:01.038 - 00:57:44.382, Speaker C: So the other thing to say here too is if this person was truly motivated by the amount of money that was being offered, that person still should not be able to ruin your day by virtue of them tweeting about some bug in your contract. Like you can't depend on the fact that the bug bounty exists, that no zero days will ever get dropped on your system. So this goes back to that security response discussion we had a few minutes earlier where you need to have processes and procedures in place where you know what to do and you can safeguard people's money and you can take appropriate steps to respond to issues when they come out. Because just because you've got a bug bounty doesn't guarantee that people are always going to do the quote unquote right thing and work with you.
00:57:44.516 - 00:57:44.826, Speaker D: Yeah.
00:57:44.868 - 00:57:46.558, Speaker C: So it's still your responsibility.
00:57:46.734 - 00:58:49.560, Speaker A: What does that process look like? Because with BZX there was yet another issue where later on it was revealed that one inch exchange had actually previously notified them of a different vulnerability and then took issue with the fact that BZX did not pause their protocol during the 16 hours in which they created and deployed a fix. And so user funds were basically vulnerable during that time. There was a similar incident with Curve and during that time they kind of couldn't figure out should they alert people of what's going on? Because if that happens, then black hat hackers could take their money and their contract actually didn't have any kill switch or upgrade ability, so they ended up deploying a new version. But what they did and the new version had the fix, but they didn't disclose any of that. And then they kind of waited until most people migrated over to the new contract and then afterward they announced it. So just curious, how do you think teams should handle bugs when they find out about them?
00:58:50.410 - 00:59:49.500, Speaker D: It all depends on the situation. The very first parody that was like the huge conversation because the people that were discovering this situation were discovering it all based on public information. Like we were all just looking at the chain, which means that anyone else could discover it. And of course we're not the Parity team and we're also not able to put a kill switch or anything. And again, this is one reason I'm a fan of kill switches, because if you can kill it, it. Takes a lot of the options off the plate and yeah, striking that balance between not telling people and keeping things secret and the flip side of telling everyone and knowing that everyone also includes people that are just going to exploit it and steal all the money. It's a really tough position to be in.
00:59:49.500 - 00:59:55.114, Speaker D: And this is why kill switches should exist, because it takes that decision away.
00:59:55.152 - 00:59:55.306, Speaker C: Right.
00:59:55.328 - 01:00:10.320, Speaker D: If Curve could have said, oh shoot, and then just press pause, they wouldn't even have to go down that path. Because once you're going down that path, there's no right decision, there's no good decision. You're in that situation where what's the least shitty position?
01:00:10.930 - 01:00:53.374, Speaker C: Yeah, context certainly matters here. And the first part of any kind of incident response plan is to prepare your company to deal with those unforeseen circumstances. So what are the set of things that could go wrong and how will we react to them when they do? You're not supposed to figure that out on the fly. You should ideally have that in place while you're developing the product. And there are many choices that you can make. Some are going to work out like Curve in their case, maybe withholding a little bit of information, but then clearly explaining it after they took actions to secure their users funds might be the right decision for them, but it could be the wrong decision for somebody else. So I don't have any specific concerns about what they did.
01:00:53.374 - 01:01:02.554, Speaker C: I think that the ends justify the means a little bit in that case since you safeguarded people's money. But it really depends on context.
01:01:02.682 - 01:01:33.980, Speaker D: Yeah, exactly. And the thing is that with all the situations where people withheld information and then revealed all shortly thereafter, I don't take issue with that. It's when they don't reveal all or when the information is so available. Yet this core group is denying, denying, denying. Once the swing has swung, you have to go all in and make sure that people do have all of the information.
01:01:34.910 - 01:02:11.480, Speaker A: Now let's discuss Oracles. That's an area that's pretty susceptible to attack and they can also be ripe for manipulation. And last summer there was an Oracle for the price of the Korean wand on synthetics. That was just incorrect and somebody was able to obtain a billion dollars in profit with their bot. Yeah, exploiting that. So I just wondered what your opinion was on Oracles. Is it too early to have reliable ones? And if not, are there any particular characteristics that give you more confidence in certain Oracles versus others?
01:02:13.130 - 01:03:27.438, Speaker C: Yeah, this is just a huge discussion around the security of your code doesn't just depend on your code itself. You also have to consider the environment around it, the environment that it operates inside. So when I'm looking at judging the reliability of a DeFi project, some things I really want to know are how many Oracles do they rely on and how many would have to be untrustworthy for there to be some kind of manipulation of the protocol in a way that abuses my funds or the intended use case. So this gets into the kind of like in my pyramid little thing where you've got your known vulnerabilities at the bottom, you've got your application specific stuff in the middle, and you've got your economic model up at the top. This is definitely a blend of steps two and three here where you need to actually model that behavior and think through what could possibly happen. There are some tools that people can use to model that, that are already available, but they're not purpose built for this task. Right? Like you can use tools that come from trailhebits like Echidna and Manticore, which are essentially a little EVM runtime written in Python and written in Haskell that you can use to evaluate your contract with different environmental data being provided to it.
01:03:27.438 - 01:03:54.200, Speaker C: But they're really more meant for finding more code security related issues and less about providing this feedback on the behavior of your code in response to all these weird Oracle things. So I think that's a part where the tooling and the knowledge could get a lot more mature over the next few months or year and it's certainly an area where it's needed, as this incident shows.
01:03:54.970 - 01:05:23.906, Speaker D: Yeah, and I'll just point out that a lot of the exploits that have been responsibly disclosed in the last two, three months have also surrounded either Oracles directly manipulation of the price that the Oracle is getting the information from that even played into the BZX incidents as well. And yeah, again, there are so many different ways that these systems can be outright attacked or have an accidental bug or be manipulated in any of these unexpected behaviors. You have to think about them upfront because otherwise they're going to hit you hard and you're not going to know how to respond, you're not going to be prepared. And that's why I think the overarching theme of this conversation is we're not mature, we're not ready for this. What do people need to do? What do the teams need to do? What does the community need to do to get a little bit better? There's all these little things that they can do to prevent bugs and there's these tools that you can use to write better solidity or check your Viper or whatever it is. But at the end of the day, there's so much going on that at least for me, what I look for is like a team that is really obsessed with security, that's paranoid, that understands that bad things can happen and that they probably don't even know what those bad things are. Because for me, that's the best hope.
01:05:23.906 - 01:05:28.290, Speaker D: If a team's super paranoid, that's the best hope because there's so many unknowns.
01:05:28.630 - 01:06:33.402, Speaker C: That'S my hot tip for figuring out if a company's got a secure product too, is for non blockchain software. I always just pop them open in LinkedIn and I search for security and then their company name and I see how many people they have working for them that actually have a responsibility to secure their company. And if it's zero, then I know that, okay, this whole thing is probably a garbage fire, but am I okay with that? So it really goes back to the same thing of does anybody working for this DeFi project have experience that would indicate they know about security stuff? Did they work in traditional finance at some point to have that sort of background? Or do they have a past history of development or publications or at least public communication that they understand what they're in for as they're building this product? And if no, that's a serious concern. And that's really the underlying most fundamental concern that I could have about the project. Do I trust the owner? And that's a question you can ask from multiple angles. Do I trust them not to run away with all my money? And do I trust them to actually do what's responsible to protect it?
01:06:33.536 - 01:07:05.974, Speaker D: Yeah, exactly. And the answer to that is not ever well, trail of bits, audited them, therefore I trust them. And that's what I think the fundamental, all of these disagreements about audits and what they are and what they're not, why the whole thing is missing the bigger picture, which is there's no one thing that any team can ever do to be perfectly secure. And so throwing it on Dan's head when something goes wrong is preposterous because you're not asking the right questions in the first place. Like, you are not asking the right questions.
01:07:06.172 - 01:07:42.320, Speaker A: Well, so I might not be asking the right question here because I actually so normally, obviously for certain episodes, I don't tell the guests what the questions are. But here I did ask Dan and Taylor to come up with maybe like a checklist of things that they think DeFi protocol teams should do before launching a protocol, because I wanted them to have a good answer ready that would be useful to the teams. But Dan already warned me that he maybe thought my question didn't make sense. So curious to know what your answers are.
01:07:43.250 - 01:07:44.494, Speaker D: Dan, you want to start?
01:07:44.612 - 01:08:36.974, Speaker C: Okay, yeah, sure. Yeah. So I thought about this a lot over the last few days because of this incident with Hedgek, where it can be difficult for an outsider to understand the level of maturity of a project. And that's really what we're trying to get at, is like, what are the long term steps that someone should take to end up arriving at a secure product and how do we evaluate those, how do we communicate those and what are the important steps within them to have actually taken? So, on one hand, we have a set of critical controls that are necessary for DeFi projects to have. They have to have access controls. They have to deal with numbers correctly, like, kind of important. The degree of centralization or decentralization, their documentation and specs, the kind of key management that they use, their security monitoring, the level of testing that they've gone through, those are all kind of indicators.
01:08:36.974 - 01:09:14.314, Speaker C: And what I think we're planning to do for our reports in the future is rank all those critical controls from weak to excellent, where each of them there's no overall rating. There's no, like, hey, this is safe. At the end of the day, if you get like five out of seven, then you're good. But it'll at least provide some information from our team in our expert view, where we think they are in terms of building a defensible system. Now, that's one way to take it. And that's sourced from the threat models. There's another ancient web kind of document that I love to cite.
01:09:14.314 - 01:10:13.114, Speaker C: So if you go back to the year 2000s, there's a guy on the Internet named Joel Spolsky, kind of a famous guy. He created the Fogs Bugs System, one of the best bug tracking managers that people had before, like GitHub and GitLab were about created Trello, and it's kind of just been like a software engineering leader for many years. He came up with this thing called the Joel Test, and it was a set of twelve yes or no questions that you could ask in 30 seconds or less to figure out the maturity of a development team building software. I love that because it took something that was so complicated at the time. Things like the Capability Maturity Model CMM are a kind of really rigorous way to evaluate if a team builds good software. And he managed to simplify it down to a 32nd yes no exercise. So what we've done is we tried to build that same thing for Ethereum, and we could call it the Dan Test, but it's also kind of the Dan Jocelyn test since he came up with a lot of it with me.
01:10:13.114 - 01:10:40.150, Speaker C: But there are some basics here, like, can you compile without warnings on the latest compiler that you're using? Do you import third party libraries from a package manager and track their versions? Have you located and documented every privileged operation in the system? If you can't say yes to those questions, then you're probably not ready to go. So I have a big list of those and I'm going to publish them all next week.
01:10:40.300 - 01:10:44.038, Speaker A: Oh, great. When you do that, send me the link so I can put them in the show notes.
01:10:44.134 - 01:11:38.534, Speaker D: Yeah. I'm so glad you're doing this because it's really tough. And this is what I think that I asked on Twitter two weeks ago. Now, what are the things that every developer should do before having $25 million in their contract on main net? What are the big red flags? And there's a lot of really deep in the weeds type things that I think are really important, but it was actually interesting because some of the responses were very different but also really enlightening. And so one thing that came out of that conversation was if someone doesn't have an audit, that's a really big red flag. Like, if they don't get anyone to look at their code, that's a red flag. But just because they have an audit, it does not mean that they're secure.
01:11:38.534 - 01:12:12.454, Speaker D: It does not mean that they're ready for Mainet. It just means that there's not a red flag in that area. It doesn't put a green one there. It's just not a red flag. And then some of the other ones that I think were really interesting were around the teams and the people and how much effort and time they dedicated to the things that weren't the literal code. So a lot of teams obviously love to focus on the code. They love to focus on the product.
01:12:12.454 - 01:13:40.370, Speaker D: They want to build this awesome system. But did they spec out the project before starting to write that code and figure out what exactly the architecture is going to look like? Did they document the intended behavior? Does the white paper, is it like a marketing piece or is it actually a technical document that dives into all the different situations? Another really interesting one that I can't necessarily call it a red flag today because not a lot of people do it, but certainly would allow me to have more faith in a team is anytime they sort of acknowledge the risks of their project or their code or their system if they've taken the time to especially if they've taken the time to document and share where the bad things are. That could happen. That shows me that they not only have awareness around their code base, they also have awareness that bad things could happen, which is something that is surprisingly missing in this space. And it also shows that they've taken the time to write it down, and that provides an additional level of accountability. And so all of these sort of tools, there's not one thing that's going to make a project trustworthy. There's not one thing that's going to make a project secure.
01:13:40.370 - 01:14:34.482, Speaker D: But if you take them all together, a team that has a better chance of success is a team that, you know, has documents, they've written tests, they have a specification. You know, they're engaged with the community for a long time. They're open to questions. They're open to answering the questions. They're aware that not everything is perfect and glorious all the time and that bad things can and probably will happen. And I'll say, I think the first conversation I ever had with Robert from Compound, I was very skeptical and I was like, so you're just going to have all this money on the smart contract and how are you ever going to know it's secure? And he literally just responded and he was like, well, there's always a non zero risk. There's never going to be a moment where I can go to sleep and be like, everything's perfect, nothing bad will happen.
01:14:34.482 - 01:15:22.398, Speaker D: And it knocked me off my feet because I had been talking to so many people in the space where the answer would have been, oh, well, we had two audits by two different auditors and then we had it formally verified and we have 100% test coverage. But it's actually Robert that gives me more faith in his team that code the compound protocol, because I know that today and tomorrow and the next day, that culture is going to always be on the lookout. Whether that's the lookout for other hacks that may also affect the compound system, whether that's awareness of flash loans coming into existence, whatever it is, they have a better chance of success than even someone that has had all of the audits and used all of the tools.
01:15:22.574 - 01:15:37.650, Speaker A: Right. Yeah, that makes sense. And I love it that his honesty is actually what gave you confidence. All right, well, this has been a fantastic conversation. I've really enjoyed it. Thank you both for coming on Unchained.
01:15:37.730 - 01:15:38.342, Speaker C: Thanks a lot.
01:15:38.396 - 01:15:39.394, Speaker D: Thank you so much, Laura.
01:15:39.442 - 01:15:40.054, Speaker C: Happy to be here.
01:15:40.092 - 01:16:10.190, Speaker A: Thanks for tuning in. To learn more about Dan Taylor and DeFi Security, be sure to check out the links in the show notes of your podcast player. Whatever your favorite crypto meme is lambos, unicorns or the Guy Fox mask, it's probably on the Unchained rabbit hole t shirt. Check it out at shop unchainedpodcast.com. And also be sure to check out our hats, mugs and stickers too. Unchained is produced by Me Laura Shin with help from Fractal recording anthony Yoon, Daniel Ness, Josh Durham and the team at CLK Transcription. Thanks for listening.
