00:00:00.090 - 00:00:15.198, Speaker A: The actual catastrophe scenario for AI. Looks like big advancement in a research lab. The AI there goes over a critical threshold. Could be like, can write the next AI. That snowballs. It gets an immense technological advantage. If it's smart, it doesn't announce itself.
00:00:15.198 - 00:00:35.300, Speaker A: It doesn't tell you that there's a fight going on. It emails out some instructions to one of those labs that'll synthesize proteins from the DNA, builds tiny diamondoid bacteria. Diamondoid bacteria replicate. A couple of days later, everybody on Earth falls over dead in the same second. That's the disaster scenario. If it's as smart as I am, if it's smarter, it might think of a better way to do things.
