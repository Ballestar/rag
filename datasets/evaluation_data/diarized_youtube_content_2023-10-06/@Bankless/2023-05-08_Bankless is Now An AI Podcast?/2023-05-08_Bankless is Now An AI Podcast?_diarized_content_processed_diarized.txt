00:00:00.170 - 00:00:18.702, Speaker A: Bankless is an AI alignment podcast until further notice. Track record so far? Eliezer Yudkowski, 99% chance of doom. Paul Cristiano, 50% chance of doom. I just recorded with is his name. He says there's a 95% chance of doom. Why are we giving this one more special attention? There's all sorts of existential threats, right?
00:00:18.756 - 00:00:21.946, Speaker B: It's the meta existential threat because it can cause all the other existential threats.
00:00:21.978 - 00:00:23.982, Speaker A: To happen if we get it right on the good side.
00:00:24.036 - 00:00:26.726, Speaker B: Okay, I was talking to under the conditions that.
00:00:26.748 - 00:00:27.586, Speaker A: We do solve AI.
00:00:27.618 - 00:00:28.082, Speaker B: Alignment.
00:00:28.146 - 00:00:29.606, Speaker A: It'S not just like, oh, few, we.
00:00:29.628 - 00:00:31.010, Speaker B: Solved AI alignment, we're not dying.
00:00:31.090 - 00:00:31.938, Speaker A: Society starts.
00:00:31.954 - 00:00:33.606, Speaker B: To become literally perfect.
00:00:33.708 - 00:00:35.606, Speaker A: It becomes a utopia because we are.
00:00:35.628 - 00:00:37.380, Speaker B: Working with them and they are producing the heaven that we want.
