00:00:00.090 - 00:00:06.190, Speaker A: If AI stabs you, you can either, like, train it not to do that, or you could be like, oh, wow, we have a real stabby AI in our hands. We should maybe.
00:00:06.340 - 00:00:10.830, Speaker C: We should unflud. Once you find out an AI is particularly stabby, is there something you can do?
00:00:10.900 - 00:00:25.286, Speaker A: There's basically two things. The most obvious one is you say, well, we have an AI on our hands that would, under some conditions, initiate a takeover. And hopefully that is fuel for, like, a let's pause for a while. There's a second thing you can try and do, which you need to be much more careful about. Here's a situation where AI would stab me. Let's just train it not do that.
00:00:25.308 - 00:00:27.266, Speaker B: That doesn't feel like a solution. The latent threat.
00:00:27.298 - 00:00:29.954, Speaker C: Still exists. Yeah, it's still kind of savvy underneath.
00:00:30.002 - 00:00:36.180, Speaker B: And I kind of just want to remind people all of these possible solutions we have. Like, one ish years to implement them.
