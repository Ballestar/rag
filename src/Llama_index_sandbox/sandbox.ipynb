{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "index = main.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-3.5-turbo\"))\n",
    "# service_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4\"))\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=5, service_context=service_context, verbose=True)\n",
    "query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "response = query_engine.query(query_str)\n",
    "logging.info(response)\n",
    "\n",
    "query_str = \"Tell me about LVR\"\n",
    "response = query_engine.query(query_str)\n",
    "logging.info(response)\n",
    "\n",
    "query_str = \"What plagues current AMM designs?\"\n",
    "response = query_engine.query(query_str)\n",
    "logging.info(response)\n",
    "\n",
    "# TODO 2023-09-27: improve the response engine with react agent chatbot.\n",
    "\n",
    "logging.info(response)\n",
    "# chat_engine = index.as_chat_engine(chat_mode=ChatMode.REACT, verbose=True)\n",
    "# response = chat_engine.chat(\"Hi\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "import json\n",
    "\n",
    "data = {}  # Global variable to store the loaded JSON data\n",
    "\n",
    "def pretty_print_json(file_path: str):\n",
    "    global data\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    formatted_json = json.dumps(data, indent=4)\n",
    "\n",
    "    # Define a JavaScript function to make JSON collapsible and editable\n",
    "    js = \"\"\"\n",
    "    function createCollapsible(jsonObj, isTopLevel=true, path=\"\") {\n",
    "        var type = typeof jsonObj;\n",
    "        if (type === \"object\") {\n",
    "            var jsonDiv = document.createElement(\"div\");\n",
    "            jsonDiv.style.marginLeft = isTopLevel ? \"0px\" : \"20px\";\n",
    "            \n",
    "            var keys = Object.keys(jsonObj);\n",
    "            for (var i = 0; i < keys.length; i++) {\n",
    "                var key = keys[i];\n",
    "                var value = jsonObj[key];\n",
    "                \n",
    "                var itemDiv = document.createElement(\"div\");\n",
    "                itemDiv.style.borderLeft = \"1px solid #ccc\";\n",
    "                itemDiv.style.marginTop = \"2px\";\n",
    "                jsonDiv.appendChild(itemDiv);\n",
    "                \n",
    "                var keySpan = document.createElement(\"span\");\n",
    "                keySpan.textContent = key + \": \";\n",
    "                keySpan.style.fontWeight = \"bold\";\n",
    "                itemDiv.appendChild(keySpan);\n",
    "                \n",
    "                var childPath = path + \"['\" + key + \"']\";\n",
    "                \n",
    "                if (typeof value === \"object\") {\n",
    "                    keySpan.addEventListener(\"click\", function() {\n",
    "                        var sibling = this.nextSibling;\n",
    "                        sibling.style.display = sibling.style.display === \"none\" ? \"block\" : \"none\";\n",
    "                    });\n",
    "                    \n",
    "                    var childDiv = createCollapsible(value, false, childPath);\n",
    "                    childDiv.style.display = isTopLevel || childPath.endsWith(\"['response']\") ? \"block\" : \"none\";\n",
    "                    itemDiv.appendChild(childDiv);\n",
    "                } else {\n",
    "                    var valueSpan = document.createElement(\"span\");\n",
    "                    valueSpan.textContent = JSON.stringify(value);\n",
    "                    itemDiv.appendChild(valueSpan);\n",
    "                    \n",
    "                    if (childPath.endsWith(\"['subjective_score']\")) {\n",
    "                        valueSpan.contentEditable = true;\n",
    "                        valueSpan.addEventListener(\"blur\", function() {\n",
    "                            var newValue = this.textContent;\n",
    "                            var pythonCode = `data${childPath} = '\\${newValue}'`;\n",
    "                            IPython.notebook.kernel.execute(pythonCode);\n",
    "                        });\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            return jsonDiv;\n",
    "        } else {\n",
    "            var textDiv = document.createElement(\"div\");\n",
    "            textDiv.textContent = JSON.stringify(jsonObj);\n",
    "            return textDiv;\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a unique ID for the div element to contain the JSON view\n",
    "    div_id = f\"json-div-{hash(formatted_json)}\"\n",
    "    \n",
    "    # Create HTML and JS to display JSON interactively\n",
    "    html = f\"<div id='{div_id}'></div>\"\n",
    "    js += f\"\"\"\n",
    "    var jsonDiv = document.getElementById(\"{div_id}\");\n",
    "    var jsonObj = {formatted_json};\n",
    "    var collapsibleDiv = createCollapsible(jsonObj);\n",
    "    jsonDiv.appendChild(collapsibleDiv);\n",
    "    \"\"\"\n",
    "    \n",
    "    # Display the interactive and collapsible JSON view\n",
    "    display(HTML(html))\n",
    "    display(Javascript(js))\n",
    "\n",
    "def save_json(file_path: str):\n",
    "    global data\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='json-div--9211960727498742552'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n    function createCollapsible(jsonObj, isTopLevel=true, path=\"\") {\n        var type = typeof jsonObj;\n        if (type === \"object\") {\n            var jsonDiv = document.createElement(\"div\");\n            jsonDiv.style.marginLeft = isTopLevel ? \"0px\" : \"20px\";\n            \n            var keys = Object.keys(jsonObj);\n            for (var i = 0; i < keys.length; i++) {\n                var key = keys[i];\n                var value = jsonObj[key];\n                \n                var itemDiv = document.createElement(\"div\");\n                itemDiv.style.borderLeft = \"1px solid #ccc\";\n                itemDiv.style.marginTop = \"2px\";\n                jsonDiv.appendChild(itemDiv);\n                \n                var keySpan = document.createElement(\"span\");\n                keySpan.textContent = key + \": \";\n                keySpan.style.fontWeight = \"bold\";\n                itemDiv.appendChild(keySpan);\n                \n                var childPath = path + \"['\" + key + \"']\";\n                \n                if (typeof value === \"object\") {\n                    keySpan.addEventListener(\"click\", function() {\n                        var sibling = this.nextSibling;\n                        sibling.style.display = sibling.style.display === \"none\" ? \"block\" : \"none\";\n                    });\n                    \n                    var childDiv = createCollapsible(value, false, childPath);\n                    childDiv.style.display = isTopLevel || childPath.endsWith(\"['response']\") ? \"block\" : \"none\";\n                    itemDiv.appendChild(childDiv);\n                } else {\n                    var valueSpan = document.createElement(\"span\");\n                    valueSpan.textContent = JSON.stringify(value);\n                    itemDiv.appendChild(valueSpan);\n                    \n                    if (childPath.endsWith(\"['subjective_score']\")) {\n                        valueSpan.contentEditable = true;\n                        valueSpan.addEventListener(\"blur\", function() {\n                            var newValue = this.textContent;\n                            var pythonCode = `data${childPath} = '\\${newValue}'`;\n                            IPython.notebook.kernel.execute(pythonCode);\n                        });\n                    }\n                }\n            }\n            return jsonDiv;\n        } else {\n            var textDiv = document.createElement(\"div\");\n            textDiv.textContent = JSON.stringify(jsonObj);\n            return textDiv;\n        }\n    }\n    \n    var jsonDiv = document.getElementById(\"json-div--9211960727498742552\");\n    var jsonObj = [\n    {\n        \"subjective_score\": \"Your subjective score here\",\n        \"query_str\": \"Can you tell me about the key concepts for safety finetuning\",\n        \"response\": {\n            \"response\": \"The key concepts for safety finetuning are not mentioned in the provided context information.\",\n            \"source_nodes\": [\n                {\n                    \"node_id\": \"a210354b-bab2-4ac9-9bc3-215f830b5d10\",\n                    \"score\": 0.780430138,\n                    \"text\": \"5.2.2\\nTowards lightweight privacy-preserving FL\\nDespite FL being a data privacy-preserving technology by\\ndesign, research has shown that certain characteristics of the\\nunderlying training data sets can be inferred from the global\\nmodel and that additional privacy-preserving measures\\nare recommended. Our review shows that two classes of\\nsecurity concerns are targeted by the publications, namely\\n(i) leakage of data set characteristics and (ii) disclosure of\\nparticipant identities. Although a substantial number of\\npapers (20 out of 40 publications) address one of these\\nconcerns, only a single paper addresses both [20]. Moreover,\\npreventing data set leakage through DP or MPC in\\ufb02icts\\ntrade-offs. Speci\\ufb01cally, DP comes with a trade-off between\\ndata security and model accuracy, while MPC comes\\nwith a trade-off between data security and computation\\ncomplexity, and it might thus not be applicable with a large\\nnumber of participants [62]. It is worth noting that the\\nmodel accuracy of DP cannot be inherently improved due to\\nintentionally added noise. Hence, it would be important to\\nexplore lightweight MPC algorithms [91] to accommodate a\\nlarge number of clients for privacy-preserving FL.\",\n                    \"metadata\": {\n                        \"total_pages\": 22,\n                        \"source\": \"18\",\n                        \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                        \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                        \"release_date\": \"2022-05-07\"\n                    }\n                },\n                {\n                    \"node_id\": \"ba0ce225-5c3d-4636-a39d-b75ba716c489\",\n                    \"score\": 0.772197425,\n                    \"text\": \"15\\nPrivacy-preserving\\nconcepts in the\\nsurveyed papers\\nUpdate\\nmasking\\n[53], [55],\\n[61], [69]\\nMulti-Party\\nComputation\\n(MPC)\\nGoogle\\u2019s Secure\\nAggregation (SA)\\n[25], [62]\\nYao\\u2019s garbeled\\ncircuits\\nHomomorphic\\nEncryption (HE)\\n[50], [67], [72]\\nPaillier\\n[19], [70]\\nRSA\\nDGHV\\n[20]\\nElgamal\\n[71]\\nDifferential\\nPrivacy (DP)\\n[50],\\n[52], [65]\\nIdentity\\nprotection\\nCombination\\nof HE\\nand/or other\\ncryptographic\\ntechniques\\n[20]: Zero-\\nKnowledge\\nProof (ZKP)\\n[56]: Ring\\nsignature & RSA &\\nRabin & ECC\\n[58]: Pairing-based\\ncryptography &\\nECC\\n[59]: Asymmetric\\ncryptography &\\ndigital signatures\\nFig. 3: Privacy-preserving concepts employed in survey\\npapers. (DGHV = Dijk-Gentry-Halevi-Vaikutanathan Algorithm, ECC =\\nElliptic Curve Cryptography, RSA = Rivest-Shamir-Adleman Cryptosystem.\\nPapers with unspeci\\ufb01ed methods are added to next highest node.)\\nbetween the clients. This affects the performance of the\\nglobal model and adds an additional layer of complexity\\nwith respect to contribution measurement. Hence, how we\\nsimulate non-IID scenarios with open datasets is crucial.\\nIn 11 publications and for various benchmark datasets,\\nnon-IID scenarios were considered. For the example of the\\nMNIST dataset, Witt et al.\\n[22] simulate different levels\\nof non-IID scenarios following the Dirichlet distribution as\\nit can easily model the skewness of data distribution by\\nvarying a single parameter. Martinez et al.\\n[73] split the\\ndataset in overlapping fractions of various sizes, whereas\\nKumar et al.\\n[50] divide the dataset so that each trainer\\nonly possesses data from two of the ten classes. In a less\\nskewed setting, Kumar et al. allocate data from at most four\\nclasses to each trainer, with each class being possessed by\\ntwo devices.\\n4.4.4\\nRQ 4-4: Are additional privacy methods applied?\\nEven\\nthough\\nFL\\u2019s\\ncore\\nobjective\\nis\\nto\\nmaintain\\ncon\\ufb01dentiality\\nthrough\\na\\nprivacy-by-design\\napproach\\nwhere model parameters are aggregated instead of training\\ndata,\\nthere\\nremain\\ninnumerable\\nattack\\nsurfaces\\n[95].\\nTherefore, the presented frameworks employ additional\\nprivacy-preserving mechanisms which can be divided\\ninto two groups. (i) Mechanisms that encrypt or obfuscate\\ngradients and prevent malicious parties to draw conclusions\\nabout the data set. (ii) Mechanisms that hide the identity\\nof participating parties. A classi\\ufb01cation of the employed\\nprivacy-preserving methods can be seen in Fig. 3.\\nThe methods of the \\ufb01rst group can be further divided\\ninto (i) approaches that are based on cryptographic secure\\nMPC, and (ii) approaches that are based on Differential\\nPrivacy (DP).\\nMPC refers to cryptographic methods by which multiple\\nparticipants can jointly compute a function without having\\nto\\nreveal\\ntheir\\nrespective\\ninput\\nvalues\\nto\\nthe\\nother\\nparticipants. MPC approaches include three groups of\\nmethods [91]. (i) Google\\u2019s Secure Aggregation (SA) [91] is\\nspeci\\ufb01cally designed to achieve low communication and\\ncomputation overhead and to be robust towards device\\ndropout. It has been employed by Liu et al.\\n[25] and\\nMa et al. [62]. Beyond implementing SA, the latter develops\\na group-based Shapley-value method for contribution\\nmeasurement,\\nsince\\nthe\\nnative\\nShapley-value\\nmethod\\ncannot be applied to masked gradients. (ii) Yao\\u2019s garbled\\ncircuits have not been applied to any of the analyzed\\nframeworks, but are mentioned here for completeness.\\n(iii) While Yao\\u2019s garbled circuits were developed for 2-\\nparty secure computing, Homomorphic Encryption (HE)\\nallows for higher numbers of participants [91]. As shown\\nin Fig. 3, HE has been employed in several works [19],\\n[20], [67], [71], [70], [72]. For that, different implementations\\nof the homomorphic idea have been chosen, such as\\nthe Pallier cryptosystem, the Elgamal cryptosystem, or\\nthe Dijk-Gentry-Halevu-Vaikutanathan Algorithm (DGHV).\\nLi et al. [71] choose the Elgamal cryptosystem that is less\\ncomputationally expensive than other HE approaches.\\nDP refers to a method where noise is drawn from a\\nprobability density function pnoise(x) with expected value\\nE(pnoise(x)) = 0 obfuscates the individual contribution\\nwith minimal distortion of the aggregation. DP has been\\nemployed by Mugunthan et al. [65], Zhao et al. [52], and\\nKumar et al.\\n[50], with the latter combining the use of\\nHE and DP. However, the fewer clients participate in the\\nDP process, the heavier the distortion of the aggregated\\nmodel, introducing a trade-off between privacy and model\\naccuracy. Zhao et al.\\n[52] mitigate the loss in accuracy\\nby incorporating a novel normalization technique into\\ntheir neural networks instead of using traditional batch\\nnormalization (e.g., [50], [65]). Besides MPC and DP, another\\ntechnique for data set protection is chosen by Qu et al. [78].\\nInstead of the clients sharing masked gradients, the FLF\\nrelies on requesters sharing masked datasets in the model\\nveri\\ufb01cation step. This prevents other workers from copying\\nthe models while testing and evaluating them. HE and\\n2-Party Computation (2PC) are used. Zhang et al.\\n[55],\\nDesai et al. [69], Bao et al. [61], and Rahmadika et al. [53]\\nalso rely on the masking of gradients but do not specify the\\nprivacy-preserving mechanisms.\\nThe\\nsecond\\ngroup\\nof\\nframeworks\\ntargets\\nthe\\nprotection of participants\\u2019 identities through cryptographic\\nmechanisms. For that, Rahmadika et al.\",\n                    \"metadata\": {\n                        \"total_pages\": 22,\n                        \"source\": \"15\",\n                        \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                        \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                        \"release_date\": \"2022-05-07\"\n                    }\n                },\n                {\n                    \"node_id\": \"9231ef91-2866-4c59-aa80-31d84a6d24bf\",\n                    \"score\": 0.771644056,\n                    \"text\": \"16\\n4.4.5\\nRQ 4-5: Is the framework robust against malicious\\nparticipants?\\nThe experiments consider and simulate different types of\\nadversaries, whereas some publications consider multiple\\ntypes of attacks. Four groups of attack patterns were\\nidenti\\ufb01ed in the publications: random model poisoning,\\nsystematic model poisoning, reputation tampering (RT),\\nand BC tampering. The most common attack considered in\\nthe experiments is random model poisoning. This includes\\nattacks, where local models are trained on a randomly\\nmanipulated data set ( [55], [60], [65], [80]) or where random\\nparameter updates are reported ( [68], [22], [60], [52], [59],\\n[70], [79]). For instance, malicious agents in [55] use a\\ntraining dataset with intentionally shuf\\ufb02ed labels, whereas\\nin [70] the parameter updates are randomly perturbed with\\nGaussian noise. Kang et al.\\n[60] analyze the effects of\\na bad or manipulated data set by providing 8% of the\\nworkers with training data where only a few classes are\\npresent, and another 2% of the workers with mislabeled\\ndata. Kang et al. quantify the insuf\\ufb01ciency of the dataset\\nusing the earth mover\\u2019s distance.\\nThe second most commonly simulated type of attack is\\nsystematic model poisoning where the attackers manipulate\\nthe model through well-planned misbehavior. In [69], a\\nfraction of workers collude and manipulates their image\\nclassi\\ufb01cation data sets by introducing a so-called trojan\\npattern: the malicious agent introduces a white cross to a\\ncertain fraction of a class, e.g., to 50% of all dog pictures in\\nan animal classi\\ufb01cation task and re-labels these data points\\nas horse pictures. This creates a backdoor in the model\\nthat cannot be detected by subjecting the model to dog or\\nhorse pictures which will be correctly classi\\ufb01ed. However,\\npictures with the trojan pattern will be misclassi\\ufb01ed. Other\\nforms of systematic model poisoning can be found with\\nWitt et al. [22], Mugunthan et al. [65], Gao et al. [80].\\nThe third type of attack that was simulated is Reputation\\nTampering\\n(RT).\\nHere,\\nmalicious\\nagents\\nintentionally\\nprovide colluding agents with perfect reputation or voting\\nscores [60], [65]. The fourth type of attack is BC tampering\\n[79]. Here, malicious miners intentionally fork the BC and\\nprevail by building a longer branch faster than the honest\\nminers.\\n4.5\\nRQ 5: Summary: What are Lessons Learned?\\nThe inherent complexity of FLF leads to heterogeneity of\\nthe scienti\\ufb01c research across the dimensions (i) application,\\n(ii) overall design, (iii) special focus on open issues, and\\n(iv) details and thoroughness.\\nApplication: Although the majority of analyzed works\\noffer application independent frameworks (classi\\ufb01ed as\\n\\u201cgeneric\\u201d in Table 3) other FLFs are applied across IoT,\\nIndustrial-IoT (IIoT), IoV, and Finance. The heterogeneity\\nof the required properties across those domains causes\\ndifferences in the design choices of function, operations,\\nstorage of BC, contribution measurement, and privacy\\nrequirements.\\nVariety of possible design choices: In addition to\\nthe domain-speci\\ufb01c in\\ufb02uence on the system architecture,\\ndesign choices about the FL algorithms, communication\\nprotocol, applications of BC within the ecosystem, BC\\ntechnology (existing or novel), storage and operation on\\nBC, security trade-offs, mechanism design, contribution\\nmeasurement, etc. add to the complexity and overall variety\\nof such systems. For example, some works apply BC as\\nthe outer complementary layer [54] while BC is the core\\ninfrastructure for coordination, storage, aggregation, and\\npayment in other FLFs [22], [55]. Furthermore, some works\\ndeveloped application-speci\\ufb01c BC systems, while others\\ntried to embed a FLF on top of existing BC frameworks\\nsuch as Ethereum for cheaper and pragmatic deployment.\\nOur survey exposes a similar variety in the choice of the\\ncontribution measurement: The spectrum reaches from the\\ncomputationally lightweight correlation of answers on a\\npublic dataset [22] as a proxy for contribution as opposed\\nto the Shapley value, a measurement with strong theoretical\\nproperties but massive computational overhead [25], [67].\\nSpecial Focus: The aforementioned complexity as well\\nas its novelty results in many open issues across a broad\\nspectrum. Many works, therefore, focus on solving speci\\ufb01c\\nissues such as enhanced privacy [19], [20], [56], [66], novel\\nBC systems [25], [51], bandwidth reduction [68], novel\\ncontribution measurements [22], [25], [68] or game theory\\n(e.g., [21], [60]), as the major contribution which further\\ncomplicates a holistic comparison of FLF.\\nThoroughness: The analyzed papers also vary heavily\\nin provided detail and thoroughness, ranging from \\ufb01rst\\nconcepts, lacking details in terms of important speci\\ufb01cations\\nsuch as performance, speci\\ufb01c function, operation and\\nstorage on BC, contribution measurement, robustness,\\nexperiments and privacy to theoretically detailed and\\nexperimentally tested solutions. None of the analyzed\\npapers are production-ready.\\n4.5.1\\nStandards for better comparability\\nFor\\nbetter\\nreproducibility,\\nimplementability,\\nand\\ncomparability\\nwe\\nsuggest\\nconsidering\\nand\\nde\\ufb01ning\\nthe following elements when designing a FLF.\\nSystem model and architecture:\\n\\u2022\\nAssumed application\\n\\u2022\\nType of FL (i.e., CD vs CS, horizontal vs vertical)\\n\\u2022\\nEntities (including attackers)\\n\\u2022\\nSetup (e.g., who manages a system, who deploys it)\\n\\u2022\\nRole of BC within the FLF (e.g., what part does BC\\nreplace, what functions/operations)\\n\\u2022\\nBC design (e.g., consensus algorithms, BCs, smart\\ncontracts)\\n\\u2022\\nNon-BC design (e.g., off-chain storage, privacy\\nprotection, authentication)\\n\\u2022\\nProcedures (e.g., \\ufb02owcharts and diagrams)\\n\\u2022\\nTheoretical analysis of incentive mechanisms\\n\\u2022\\nSpeci\\ufb01cation of clients\\u2019 contribution measurement\\n\\u2022\\nPossible attacks (e.g., system security, data privacy)\\nPerformance analysis:\\n\\u2022\\nQuantitative performance analysis\\n\\u2022\\nScalability analysis with respect to blockchain and\\ncontribution measurement\\nCost analysis:\",\n                    \"metadata\": {\n                        \"total_pages\": 22,\n                        \"source\": \"16\",\n                        \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                        \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                        \"release_date\": \"2022-05-07\"\n                    }\n                },\n                {\n                    \"node_id\": \"8e905a92-1953-4dc3-9790-c64199a83261\",\n                    \"score\": 0.771276176,\n                    \"text\": \"Besides MPC and DP, another\\ntechnique for data set protection is chosen by Qu et al. [78].\\nInstead of the clients sharing masked gradients, the FLF\\nrelies on requesters sharing masked datasets in the model\\nveri\\ufb01cation step. This prevents other workers from copying\\nthe models while testing and evaluating them. HE and\\n2-Party Computation (2PC) are used. Zhang et al.\\n[55],\\nDesai et al. [69], Bao et al. [61], and Rahmadika et al. [53]\\nalso rely on the masking of gradients but do not specify the\\nprivacy-preserving mechanisms.\\nThe\\nsecond\\ngroup\\nof\\nframeworks\\ntargets\\nthe\\nprotection of participants\\u2019 identities through cryptographic\\nmechanisms. For that, Rahmadika et al.\\n[56] combine\\nring signatures, HE (RSA), Rabin algorithm, and Elliptic\\nCurve\\nCryptography\\n(ECC),\\nwhile\\nChai\\net\\nal.\\n[59]\\nincorporate digital signatures and asymmetric cryptography\\napproaches,\\nand\\nRahmadika\\net\\nal.\\n[58]\\nperform\\nauthentication tasks through pairing-based cryptography\\nand ECC. Only one framework implements measures\\nfor both masking gradients as well as hiding identities.\\nLi et al.\\n[20] use DGHV for masking gradients and\\nZero-Knowledge Proof (ZKP) for identity protection.\\nFinally,\\nHe\\net\\nal.\\n[67]\\nspeci\\ufb01cally\\naddress\\nthe\\nproblem of aligning entities. This problem occurs in\\nvertical federated learning where different parties hold\\ncomplementary information about the same user. The\\nparties have to \\ufb01nd a way of matching this information\\nwithout disclosing the identity of their users. To solve this\\nproblem, He et al. employ Encrypted Entity Alignment\\nwhich is a protocol for privacy-preserving inter-database\\noperations [67].\",\n                    \"metadata\": {\n                        \"total_pages\": 22,\n                        \"source\": \"15\",\n                        \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                        \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                        \"release_date\": \"2022-05-07\"\n                    }\n                },\n                {\n                    \"node_id\": \"b476bdab-b968-4b9a-9e9a-1be866ce86f5\",\n                    \"score\": 0.769855678,\n                    \"text\": \"18\\n5.1.3\\nFramework implementation\\nMost of the papers we reviewed are focused on the\\nalgorithm\\nside.\\nHowever,\\nin\\norder\\nto\\ngo\\nbeyond\\ntheory\\ntowards\\nreal\\nproduction-ready\\ndeployments,\\nimplementation details have to be taken into consideration.\\nFor\\ninstance,\\nincurred\\ndeployment\\nand\\nmaintenance\\ncosts of unproven novel BC systems are often ignored.\\nIntroducing a new, custom-made, and highly complex\\ninfrastructure introduces security risks and it requires a\\nlarge team of experts to run and maintain such a system\\nin practice. Therefore, software/hardware co-design is\\nanother vital topic in FL (e.g., [79], [100], [101], [102]). For\\ninstance, Wang et al. point out that cipher-text operation\\nand encryption parts are major bottlenecks on the FL and\\nproposed a novel Field Programmable Gate Array (FPGA)\\ndesign for it [103]. We believe that there are potential\\nresearch topics in the software/hardware co-design for\\nFL. Interested readers may refer to the survey papers of\\nKhan et al. [100], [101].\\n5.1.4\\nFramework evaluation and comparison\\nWhile\\nmany\\npapers\\nhave\\nconducted\\nperformance\\nevaluation, few showed a comparison with other FLFs.\\nThis hinders the scienti\\ufb01c advancement towards high-\\nperforming frameworks as the different design choices\\nof\\nthe\\npapers\\nremain\\nuncompared.\\nFurthermore,\\nthe\\nframeworks have often not been evaluated in realistic\\nscenarios: (i) relatively well-known benchmark datasets\\nsuch as MNIST and CIFAR-10 are chosen (29 out of 34\\npapers that conducted experiments on classi\\ufb01cation) and\\n(ii) the non-IID setting is only applied in 11 out of 34\\npapers. Furthermore, inconsistencies between the targeted\\nFL setting (i.e., CS, CD) and the number of clients in the\\nexperiments are observed. In particular, FLFs that assume\\nCD should simulate a large number of clients, however,\\nonly Kang et al.\\n[60] and Desai et al. [69] conducted\\nexperiments with 100 participants or more (TABLE 6).\\nTo better evaluate FLFs, we suggest using common\\ndatasets dedicated to FL (e.g., LEAF [104]) as well as\\nsimulating different levels of non-IID data among clients\\n(e.g., Dirichlet distribution [22]). We also suggest deploying\\na FLF on the clusters of inexpensive computers such as\\nRaspberry Pi [105] to realistically simulate large-scale FL\\nscenarios under the CD assumption.\\nMoreover, it is dif\\ufb01cult to simulate the effect of\\ndecentralization and incentivization (e.g., Shapley value and\\ngame-theoretic mechanisms) in a comparable way since\\neach paper uses different assumptions. Therefore, to fairly\\ncompare FLFs, holistic experiments should be designed,\\nwhere the effects of decentralization and incentivization are\\ncaptured by metrics such as overall accuracy, cost, or latency.\\n5.2\\nFunctionalities\\nFuture research should also focus on integrating further\\nfunctionalities into the FLFs. Firstly, most of the proposed\\nFL systems are limited to supervised classi\\ufb01cation, however,\\nother types of ML problems should be considered as\\nwell. Secondly, lightweight privacy-preserving techniques\\nare necessary for some applications that use sensitive\\ninformation (e.g., medical logs and personal \\ufb01nancial\\ninformation).\\nThirdly,\\na\\nfair,\\nnon-manipulable,\\nand\\nlightweight mechanism for contribution measurement has\\nyet to be developed.\\n5.2.1\\nBeyond supervised FL and federated averaging\\nTo expand the applicability of FLFs, machine learning\\ntasks beyond supervised learning should be enabled,\\nsuch\\nas\\nanomaly\\ndetection,\\nreinforcement\\nlearning,\\nnatural language processing, user behavior analysis, and\\nunsupervised learning tasks (e.g., [106], [107]). This will\\nrequire new or adapted model aggregation algorithms and a\\nnew contribution measurement to integrate such tasks with\\nIM and BC.\\nSo far, FedAvg requires the same neural network\\narchitecture\\non\\nall\\ndevices\\nto\\nparticipate.\\nThis\\nmay\\nlead to issues in real-world environments where clients\\nmight have different hardware and bandwidth capabilities.\\nFederated Knowledge Distillation [22] is an interesting\\nnovel FL approach in this context, allowing for a \\ufb02exible\\nneural network architecture and a dramatic reduction\\nin\\nbandwidth\\n[108].\\nHowever,\\nFederated\\nKnowledge\\nDistillation\\nrequires\\na\\npublic\\ndataset\\nto\\ndistill\\nthe\\nknowledge.\\nTraditional deep learning algorithms such as DNNs\\nand Convolutional Neural Networks (CNNs), are generally\\npower-hungry, which is problematic in IoT environment.\\nTo\\naddress\\nthis\\nchallenge,\\nbiological\\nneurons-inspired\\nDNNs called Spiking Neural Networks (SNNs) have been\\nactively studied for edge AI (e.g., [109], [110]). SNNs will\\nenable edge devices to exploit brain-like biophysiological\\nstructure to collaboratively train a global model while\\nhelping preserve privacy. For instance, Lead Federated\\nNeuromorphic Learning (LFNL) is a method to enable\\nSNNs in a federated manner [110]. Furthermore, a leader\\nelection scheme is proposed to elect one device with\\nhigh capability (e.g., computation and communication\\ncapabilities) as a leader to manage model aggregation,\\neliminating a \\ufb01xed central coordinator and avoiding model\\npoisoning attacks.\\n5.2.2\\nTowards lightweight privacy-preserving FL\\nDespite FL being a data privacy-preserving technology by\\ndesign, research has shown that certain characteristics of the\\nunderlying training data sets can be inferred from the global\\nmodel and that additional privacy-preserving measures\\nare recommended. Our review shows that two classes of\\nsecurity concerns are targeted by the publications, namely\\n(i) leakage of data set characteristics and (ii) disclosure of\\nparticipant identities. Although a substantial number of\\npapers (20 out of 40 publications) address one of these\\nconcerns, only a single paper addresses both [20]. Moreover,\\npreventing data set leakage through DP or MPC in\\ufb02icts\\ntrade-offs. Speci\\ufb01cally, DP comes with a trade-off between\\ndata security and model accuracy, while MPC comes\\nwith a trade-off between data security and computation\\ncomplexity, and it might thus not be applicable with a large\\nnumber of participants [62].\",\n                    \"metadata\": {\n                        \"total_pages\": 22,\n                        \"source\": \"18\",\n                        \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                        \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                        \"release_date\": \"2022-05-07\"\n                    }\n                }\n            ],\n            \"metadata\": {\n                \"a210354b-bab2-4ac9-9bc3-215f830b5d10\": {\n                    \"total_pages\": 22,\n                    \"source\": \"18\",\n                    \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                    \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                    \"release_date\": \"2022-05-07\"\n                },\n                \"ba0ce225-5c3d-4636-a39d-b75ba716c489\": {\n                    \"total_pages\": 22,\n                    \"source\": \"15\",\n                    \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                    \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                    \"release_date\": \"2022-05-07\"\n                },\n                \"9231ef91-2866-4c59-aa80-31d84a6d24bf\": {\n                    \"total_pages\": 22,\n                    \"source\": \"16\",\n                    \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                    \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                    \"release_date\": \"2022-05-07\"\n                },\n                \"8e905a92-1953-4dc3-9790-c64199a83261\": {\n                    \"total_pages\": 22,\n                    \"source\": \"15\",\n                    \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                    \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                    \"release_date\": \"2022-05-07\"\n                },\n                \"b476bdab-b968-4b9a-9e9a-1be866ce86f5\": {\n                    \"total_pages\": 22,\n                    \"source\": \"18\",\n                    \"title\": \"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review\",\n                    \"authors\": \"Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, Dan Li\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2205.07855v3\",\n                    \"release_date\": \"2022-05-07\"\n                }\n            }\n        }\n    },\n    {\n        \"subjective_score\": \"Your subjective score here\",\n        \"query_str\": \"Tell me about LVR\",\n        \"response\": {\n            \"response\": \"LVR, or Loss-Versus-Rebalancing, is a term used in the context of Automated Market Maker (AMM) pools. It refers to the potential loss that can occur when rebalancing the reserves of the pool. In the V0LVER protocol, LVR is a measure of the arbitrage opportunity between consecutive blocks in the blockchain. It is calculated by multiplying the difference in reserves between two blocks by the external market price at the time of rebalancing.\\n\\nThe goal of the V0LVER protocol is to minimize LVR and protect the pool from value extraction by block producers. To achieve this, the protocol implements various mechanisms such as LVR rebates and vault token auctions. These mechanisms aim to provide high protection against LVR and user-level MEV (Miner Extractable Value), ensuring the stability and fairness of the AMM pool.\",\n            \"source_nodes\": [\n                {\n                    \"node_id\": \"27557237-1075-45d9-8f5e-d875b6713c5a\",\n                    \"score\": 0.801601112,\n                    \"text\": \"V0LVER\\n13\\ning fees. However, we have thus far only proved that LVR in a V0LVER pool is\\n(1\\u2212\\u03b2()) of the corresponding CFMM pool. As in [13], under competition among\\nblock producers, the LVR rebate function has a strong Nash equilibrium at \\u03b2(0),\\nmeaning LVR is also minimized.\\nTo see this, we can use a backwards induction argument. Consider the \\ufb01rst\\nblock producer allowed to send an update transaction with \\u03b2(H \\u2212 Ha) = 0 for\\na block at height H (meaning Ha = H\\u2032\\na + 1). This block producer can extract\\nall of the LVR, and is required to provide no liquidity to the allocation pool. As\\nLVR is arbitrage, all block producers do this.\\nA block producer at height H \\u2212 1 knows this. Furthermore, extracting (1 \\u2212\\n\\u03b2((H \\u2212 1) \\u2212 Ha)) > 0 of the LVR has positive utility for all block producers,\\nwhile trading with \\u03b2((H \\u2212 1) \\u2212 Ha) > 0 of allocated OCTs around the external\\nmarket price also has a positive utility (Payo\\ufb00 2 in Section 5). As such, sending\\nan update transaction at height H\\u22121 is dominant. Following this argumentation,\\na block producer at height H \\u2212 i \\u2265 Ha always sends an update transaction as\\nthey know the block producer at height (H + 1) \\u2212 i always sends an update\\ntransaction. This means the block producer at height H\\u2032\\na + 1 always sends an\\nupdate transaction \\u2200 H\\u2032\\na, which corresponds to an LVR rebate function value of\\n\\u03b2(0) in equilibrium.\\nIn reality, frictionless arbitrage against the external market price in blockchain-\\nbased protocols is likely not possible, and so LVR extraction has some cost. As\\nsuch, the expected value for \\u03b2() may be less than \\u03b2(0). Deploying V0LVER,\\nand analyzing \\u03b2() across di\\ufb00erent token pairs, and under varying costs for block\\nproducers makes for interesting future work.\\n6\\nDiscussion\\nIf a V0LVER pool allows an OCT to be allocated with \\u03b2() = 0, V0LVER e\\ufb00ec-\\ntively reverts to the corresponding CFMM pool, with MEV-proof batch settle-\\nment for all simultaneously allocated OCTs, albeit without LVR protection for\\nthe pool. To see this, note that as \\u03b2() = 0, the block producer can fully extract\\nany existing LVR opportunity, without requiring a deposit to the allocation pool.\\nAs such, the expected price of the allocation pool is the external market price,\\nwith orders executed directly against the V0LVER reserves at the external mar-\\nket price, excluding fees and impact. Importantly, there is never any way for the\\nblock producer to extract any value from allocated orders. This is because the\\nsettlement price for an OCT is e\\ufb00ectively set when it allocated, before any price\\nor directional information is revealed about the corresponding order.\\nAllocation of tokens to the allocation pool has an opportunity cost for both\\nthe V0LVER pool and the block producer. Given the informational superiority of\\nthe block producer, allocating tokens from the pool requires the upfront payment\\nof a fee to the pool. Doing this anonymously is important to avoid MEV-leakage\\nto the block producer. One possibility is providing an on-chain veri\\ufb01able proof\\nof membership to set of players who have bought pool credits, where a valid\\nproof releases tokens to cover speci\\ufb01c fees, as in [20,12]. Another possibility is\",\n                    \"metadata\": {\n                        \"total_pages\": 15,\n                        \"source\": \"13\",\n                        \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                        \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                        \"release_date\": \"2023-01-31\"\n                    }\n                },\n                {\n                    \"node_id\": \"776e1fe7-4157-4792-896f-1eeb0296e70f\",\n                    \"score\": 0.795176327,\n                    \"text\": \"An Automated Market Maker Minimizing Loss-Versus-Rebalancing\\n5\\nproviding at least the same user experience for typical users as existing AMMs\\nwithout LVR protection.\\nA recent proposed solution to LVR published in a blog-post [10] termed MEV-\\ncapturing AMMs (McAMMs) considers auctioning off the first transaction/series\\nof transaction in an AMM among arbitrageurs, with auction revenue paid in\\nsome form to the protocol. Two important benefits of Diamond compared to the\\nproposed McAMMs are the capturing of realized LVR in Diamond as opposed\\nto predicted LVR in McAMMs, and decentralized access to Diamond compared\\nto a single point of failure in McAMMs.\\nIn McAMMs, bidders are required to predict upcoming movements in the\\nAMM. Bidders with large orders to execute over the period (e.g. private price\\ninformation, private order flow, etc.) have informational advantages over other\\nbidders. Knowing the difference between expected LVR excluding this private\\ninformation vs. true expected LVR allows the bidder to inflict more LVR on\\nthe AMM than is paid for. As this results in better execution for the winner\\u2019s\\norders, this may result in more private order flow, which exacerbates this effect.\\nDiamond extracts a constant percentage of the true LVR, regardless of private in-\\nformation. McAMMs also centralize (first) access control to the winning bidder.\\nIf this bidder fails to respond or is censored, user access to the protocol is prohib-\\nited/more expensive. Diamond is fully decentralized, incentive compatible and\\ncan be programmed to effectively remove LVR in expectancy. Future McAMM\\ndesign improvements based on sub-block time auctions are upper-bounded by\\nthe current protection provided by Diamond.\\n3\\nPreliminaries\\nThis section introduces the key terminology and definitions needed to understand\\nLVR, the Diamond protocol, and the proceeding analysis. In this work we are\\nconcerned with a single swap between token x and token y. We use x and y\\nsubscripts when referring to quantities of the respective tokens. The external\\nmarket price of a swap is denoted by \\u03b5, while pool prices and price functions are\\ndenoted using a lowercase p and uppercase P respectively. The price of a swap\\nis quoted as the quantity of token x per token y.\\nIn this work we treat the block producer and an arbitrageur paying for the\\nright to execute transactions in a block as the same entity. This is because\\nthe the arbitrageur must have full block producer capabilities, and vice versa,\\nwith the payoff for the block producer equal to that of an arbitrageur under\\narbitrageur competition. For consistency, and to emphasize the arbitrage that is\\ntaking place in extracting LVR, we predominantly use the arbitrageur naming\\nconvention. That being said, it is important to remember that this arbitrageur\\nhas exclusive access to building the sub-block of Diamond transactions. Where\\nnecessary, we reiterate that it is the block producer who control the per-block\\nset of Diamond transactions, and as such, the state of the Diamond protocol.\",\n                    \"metadata\": {\n                        \"total_pages\": 20,\n                        \"source\": \"5\",\n                        \"title\": \"An Automated Market Maker Minimizing Loss-Versus-Rebalancing\",\n                        \"authors\": \"Conor McMenamin, Vanesa Daza, Bruno Mazorra\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2210.10601v2\",\n                        \"release_date\": \"2022-10-19\"\n                    }\n                },\n                {\n                    \"node_id\": \"07905f36-011f-47e6-9e84-8df266364760\",\n                    \"score\": 0.789766371,\n                    \"text\": \"V0LVER\\n5\\nfrom the current reserves (Rx,0, Ry,0) \\u2208 C to any other reserves (Rx,1, Ry,1) \\u2208 C\\nif and only if the player provides the di\\ufb00erence (Rx,1 \\u2212 Rx,0, Ry,1 \\u2212 Ry,0).\\nWhenever an arbitrageur interacts with an AMM pool, say at time t with\\nreserves (Rx,t, Ry,t), we assume as in [14] that the arbitrageur always moves\\nthe pool reserves to a point which maximizes arbitrageur pro\\ufb01ts, exploiting the\\ndi\\ufb00erence between P(Rx,t, Ry,t) and the external market price at time t, denoted\\n\\u03f5t. Therefore, the LVR between two blocks Bt and Bt+1 where the reserves of\\nthe AMM at the end of Bt are (Rx,t, Ry,t) and the external market price when\\ncreating block Bt+1 is \\u03f5t+1 is:\\nRx,t \\u2212 Rx,t+1 + (Ry,t \\u2212 Ry,t+1)\\u03f5t+1.\\n(3)\\nIn this paper, we consider only the subset of CFMMs in which, given the LVR ex-\\ntracted in block Bt+1 corresponds to reserves (Rx,t+1, Ry,t+1), P(Rx,t+1, Ry,t+1)\\n= \\u03f5t+1. This holds for Uniswap V2 pools, among others.\\n3.2\\nLVR-resistant AMM\\nWe provide here an overview of the most important features of Diamond [13], an\\nAMM protocol which is proved to provide arbitrarily high LVR protection under\\ncompetition to capture LVR among block producers. In V0LVER, we adapt these\\nfeatures for use on an encrypted transaction mempool.\\nA Diamond pool \\u03a6 is described by reserves (Rx, Ry), a pricing function P(), a\\npool invariant function f(), an LVR-rebate parameter \\u03b2 \\u2208 (0, 1), and conversion\\nfrequency T \\u2208 N. The authors also de\\ufb01ne a corresponding CFMM pool of \\u03a6,\\ndenoted CFMM(\\u03a6). CFMM(\\u03a6) is the CFMM pool with reserves (Rx, Ry) whose\\nfeasible set is described by pool invariant function f() and pool constant k =\\nf(Rx, Ry). Conversely, \\u03a6 is the corresponding V0LVER pool of CFMM(\\u03a6). The\\nauthors note that CFMM(\\u03a6) changes every time the \\u03a6 pool reserves change. The\\nprotocol progresses in blocks, with one reserve update possible per block.\\nFor an arbitrageur wishing to move the price of CFMM(\\u03a6) to p from starting\\nreserves (Rx,0, Ry,0), let this require \\u2206y > 0 tokens to be added to CFMM(\\u03a6),\\nand \\u2206x > 0 tokens to be removed from CFMM(\\u03a6). The same price in \\u03a6 is\\nachieved by the following process:\\n1. Adding (1 \\u2212 \\u03b2)\\u2206y tokens to \\u03a6 and removing (1 \\u2212 \\u03b2)\\u2206x tokens.\\n2. Removing \\u03b4x > 0 tokens such that:\\nP(Rx,0 \\u2212 (1 \\u2212 \\u03b2)\\u2206x \\u2212 \\u03b4x, Ry,0 + (1 \\u2212 \\u03b2)\\u2206y) = p.\\n(4)\\nThese \\u03b4x tokens are added to the vault of \\u03a6.\\nVault tokens are periodically re-entered into \\u03a6 through what is e\\ufb00ectively\\nan auction process, where the tokens being re-added are in a ratio which ap-\\nproximates the external market price at the time. The main result of [13] is the\\nproving that given a block producer interacts with \\u03a6 when the LVR parameter\\nis \\u03b2, and there is an LVR opportunity of LV R in CFMM(\\u03a6), the maximum\\nLVR in \\u03a6 is (1 \\u2212 \\u03b2)LV R. This results is stated formally therein as follows:\",\n                    \"metadata\": {\n                        \"total_pages\": 15,\n                        \"source\": \"5\",\n                        \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                        \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                        \"release_date\": \"2023-01-31\"\n                    }\n                },\n                {\n                    \"node_id\": \"7ba04a85-34f7-4d5d-8275-11571b6ef62d\",\n                    \"score\": 0.789608896,\n                    \"text\": \"6\\nMcMenamin and Daza\\nTheorem 1. For a CFMM pool CFMM(\\u03a6) with LVR of L > 0, the LVR of \\u03a6,\\nthe corresponding pool in Diamond, has expectancy of at most (1 \\u2212 \\u03b2)L.\\nIn this paper we use the same base functionality of Diamond to restrict the\\nLVR of block producers. Given a block producer wants to move the price of\\nCFMM(\\u03a6) to some price p to extract maximal LVR LV R, the maximal LVR\\nin \\u03a6 of (1 \\u2212 \\u03b2)LV R is also achieved by moving the price to p. An important\\npoint to note about applying LVR rebates as done in [13], is that directly after\\ntokens are placed in the vault, the pool constant drops. This must be considered\\nwhen calculating the pro\\ufb01tability of an arbitrageur extracting LVR from a Dia-\\nmond pool. We do this when analyzing the pro\\ufb01tability of V0LVER in Section\\n5. Importantly, tokens are eventually re-added to the pool, and over time the\\nexpected value of the pool constant is increasing, as demonstrated in [13].\\n4\\nOur Protocol\\nWe now outline the model in which we construct V0LVER, followed by a detailed\\ndescription of V0LVER.\\n4.1\\nModel\\nIn this paper we consider a blockchain in which all transactions are attempting\\nto interact with a single V0LVER pool between tokens x and y.\\n1. A transaction submitted by a player for addition to the blockchain while\\nobserving blockchain height H, is \\ufb01nalized in a block of height at most\\nH + T, for some known T > 0.\\n2. The token swap has an external market price \\u03f5, which follows a Martingale\\nprocess.\\n3. There exists a population of arbitrageurs able to frictionlessly trade at exter-\\nnal market prices, who continuously monitor and interact with the blockchain.\\n4. Encrypted orders are equally likely to buy or sell tokens at \\u03f5, distributed\\nsymmetrically around \\u03f5.\\n4.2\\nProtocol Framework\\nThis section outlines the terminology and functionalities used in V0LVER. It is\\nintended as a reference point to understand the core V0LVER protocol. Speci\\ufb01-\\ncally, we describe the possible transactions in V0LVER, the possible states that\\nV0LVER orders/order commitments can be in, and the possible actions of block\\nproducers. As in the protocol of Section 3.2, a V0LVER pool \\u03a6 with reserves\\n(Rx, Ry) is de\\ufb01ned with respect to a CFMM pool, denoted CFMM(\\u03a6), with\\nreserves (Rx, Ry), a pricing function P() under the restrictions of Section 3.1,\\nand a pool invariant function f().\",\n                    \"metadata\": {\n                        \"total_pages\": 15,\n                        \"source\": \"6\",\n                        \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                        \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                        \"release_date\": \"2023-01-31\"\n                    }\n                },\n                {\n                    \"node_id\": \"008e1828-907e-4f37-9ecd-887620b12987\",\n                    \"score\": 0.787442386,\n                    \"text\": \"V0LVER\\n3\\n1.1\\nOur Contribution\\nIn this paper we introduce V0LVER 3, an AMM which provides arbitrarily high\\nprotection against user-level MEV and LVR. V0LVER is the \\ufb01rst AMM to align\\nthe incentives of the three, typically competing, entities in AMMs; the user,\\nthe pool, and the block producer. This is done by ensuring that at all times, a\\nblock producer is incentivized to move the pool to the price maximizing LVR.\\nWhen the block producer chooses a price, the block producer is forced to assert\\nthis is correct, a technique introduced in [13]. Unfortunately, the protocol in\\n[13] gives the block producer total power to extract value from users, due to\\norder information being revealed to the block producer before it is allocated a\\ntrading price in the blockchain. To address this, V0LVER is built on an encrypted\\nmempool. Modern cryptographic tools allow us to encrypt the mempool using\\nzero-knowledge based collateralized commit-reveal protocols [11,3,12,20], delay\\nencryption [5,7] and/or threshold encryption [2]. We assume the existence of\\nsuch a mempool within which all sensitive order information is hidden until\\nthe order has been committed a price against the AMM. Given these encrypted\\norders, we demonstrate that a block producer forced to show liquidity to such an\\norder maximizes her own utility by showing liquidity centred around the external\\nmarket price (bid below the price and o\\ufb00ered above the price).4\\nAs such, the external market price is the price point maximizing the block\\nproducers LVR extraction (due to the replicated LVR protection of [13]), around\\nwhich pro\\ufb01t is maximized when forced to trade against some (varying) percent-\\nage of indistinguishable orders. This strictly incentivizes block producers to move\\nthe price of a V0LVER pool to the external market price. This provides users\\nwith an AMM where the expected trade price in the presence of arbitrageurs is\\nalways the external market price, excluding fees, and the LVR against the pool\\nis minimized when these arbitrageurs are competing. Although batching orders\\nagainst AMM liquidity has been proposed as a defense against LVR [18], naively\\nbatching orders against an AMM still allows a block producer to extract LVR\\nby censoring user orders. In V0LVER, block producers are e\\ufb00ectively forced to\\nimmediately repay LVR, while being incentivized to include order commitments\\nin the blockchain and allocate liquidity to these orders through the AMM.\\n2\\nRelated Work\\nAs the phenomenon of LVR has only recently been identi\\ufb01ed, there are only\\ntwo academic papers on the subject of LVR protection [10,13] to the best of our\\nknowledge, with no work protecting against both LVR and user-level MEV.\\nIn [10], the AMM must receive the price of a swap from a trusted oracle\\nbefore users can interact with the pool. Such sub-block time price data requires\\ncentralized sources which are prone to manipulation, or require the active partic-\\nipation of AMM representatives, a contradiction of the passive nature of AMMs\\n3 near-0 Extractable Value and Loss-Versus-Rebalancing \\u21dd V0LVER\\n4 This holds true in many CFMMs, including the famous Uniswap V2 protocol [1]\",\n                    \"metadata\": {\n                        \"total_pages\": 15,\n                        \"source\": \"3\",\n                        \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                        \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                        \"release_date\": \"2023-01-31\"\n                    }\n                }\n            ],\n            \"metadata\": {\n                \"27557237-1075-45d9-8f5e-d875b6713c5a\": {\n                    \"total_pages\": 15,\n                    \"source\": \"13\",\n                    \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                    \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                    \"release_date\": \"2023-01-31\"\n                },\n                \"776e1fe7-4157-4792-896f-1eeb0296e70f\": {\n                    \"total_pages\": 20,\n                    \"source\": \"5\",\n                    \"title\": \"An Automated Market Maker Minimizing Loss-Versus-Rebalancing\",\n                    \"authors\": \"Conor McMenamin, Vanesa Daza, Bruno Mazorra\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2210.10601v2\",\n                    \"release_date\": \"2022-10-19\"\n                },\n                \"07905f36-011f-47e6-9e84-8df266364760\": {\n                    \"total_pages\": 15,\n                    \"source\": \"5\",\n                    \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                    \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                    \"release_date\": \"2023-01-31\"\n                },\n                \"7ba04a85-34f7-4d5d-8275-11571b6ef62d\": {\n                    \"total_pages\": 15,\n                    \"source\": \"6\",\n                    \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                    \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                    \"release_date\": \"2023-01-31\"\n                },\n                \"008e1828-907e-4f37-9ecd-887620b12987\": {\n                    \"total_pages\": 15,\n                    \"source\": \"3\",\n                    \"title\": \"An AMM minimizing user-level extractable value and loss-versus-rebalancing\",\n                    \"authors\": \"Conor McMenamin, Vanesa Daza\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2301.13599v2\",\n                    \"release_date\": \"2023-01-31\"\n                }\n            }\n        }\n    },\n    {\n        \"subjective_score\": \"Your subjective score here\",\n        \"query_str\": \"What plagues current AMM designs?\",\n        \"response\": {\n            \"response\": \"Current AMM designs suffer from two main issues. The first issue is the \\\"loss-vs-rebalancing\\\" problem, where liquidity providers (LPs) trade at a loss whenever there is a rebalancing event. This means that when the underlying value of the assets changes, the first informed arbitrageur who trades with the AMM earns a profit by aligning the AMM price with the new equilibrium price, resulting in losses for LPs. The second issue is the vulnerability to attacks, particularly sandwich attacks, where attackers exploit traders by front-running their swaps and forcing them to trade at less favorable terms.\",\n            \"source_nodes\": [\n                {\n                    \"node_id\": \"b189a8c3-7fe7-40c2-865b-067ffde62da6\",\n                    \"score\": 0.810437441,\n                    \"text\": \"2 The function-maximizing AMM\\n5\\ntransactions (of which sandwich attacks are an example), especially those that can\\nbe implemented at the smart-contract level (Breidenbach et al., 2018, Gans and\\nHolden, 2022, Canidio and Danos, 2023, Ferreira and Parkes, 2023).4\\nSeveral initial discussions on designing \\u201csurplus maximizing\\u201d or \\u201csurplus captur-\\ning\\u201d AMMs occurred informally on blog and forum posts (see Leupold, 2022, Josojo,\\n2022, Della Penna, 2022). Goyal et al. (2022) provides an axiomatic derivation of\\nthe surplus-maximizing AMM. Relative to their work, our contribution is to place\\nthis new type of AMM in a context with arbitrageurs and other trading venues.\\nSchlegel and Mamageishvili (2022) also study AMM from an axiomatic viewpoint.\\nIn particular, they discuss path independence, which FM-AMMs violate.\\nThe intuition for our main result is closely related to Budish et al. (2015), who\\nstudy the batching of trades in the context of traditional finance as a way to mitigate\\nthe high-frequency-trading (HFT) arms race and protect regular (or slow) traders.\\nThe main result is that batching trades force informed arbitrageurs to compete in\\nprice instead of speed, because the priority of execution within the batch is given\\nbased on price. The intuition in our model is similar, although competition between\\narbitrageurs on the batch is rather in quantity than in price: if the price on an\\nFM-AMM differs from the equilibrium price, competing arbitrageurs will submit\\nadditional trades to exploit the available arbitrage opportunity, but by doing so,\\nthey push the price on the FM-AMM in line with the equilibrium.\\nWe conclude by noting that an FM-AMM is also an oracle: it exploits compe-\\ntition between arbitrageurs to reveal on-chain the price at which these arbitrageurs\\ncan trade off-chain. It is, therefore, related to the problem of Oracle design (as\\ndiscussed, for example, by Chainlink, 2020).\\n2\\nThe function-maximizing AMM\\nIn this section, we first introduce the main concepts of interest using a simple\\nconstant-product function (both for the CFAMM and the FM-AMM), no fees, and\\nkeeping formalities to the minimum. In the next section, we generalize our defini-\\ntions and results and introduce additional elements.\\nAs a preliminary step, we derive the trading function of a constant product\\nAMM, the simplest and most common type of CFAMM. Suppose that there are\\nonly two tokens, ETH and DAI. A constant-product AMM (CPAMM) is willing to\\ntrade as long as the product of its liquidity pools remains constant (see Figure 1\\nfor an illustration). Call Q$ and QE its initial liquidity pools in DAI and ETH,\\nrespectively, and pCPAMM(x) the average price at which the CPAMM is willing\\nto trade x ETH, where x > 0 means that CPAMM is selling ETH while x < 0\\n4 Another strand of the literature studies how to prevent malicious re-ordering of transactions\\nby modifying the infrastructure that underpins how transactions are sent. See, for example, Kelkar\\net al. (2020) and the literature review in Heimbach and Wattenhofer (2022).\",\n                    \"metadata\": {\n                        \"total_pages\": 26,\n                        \"source\": \"5\",\n                        \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                        \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                        \"release_date\": \"2023-07-05\"\n                    }\n                },\n                {\n                    \"node_id\": \"7e7f886f-3f2b-4048-81da-8cdef0f7bf30\",\n                    \"score\": 0.801607311,\n                    \"text\": \"3 Additional considerations\\n12\\nQE\\nQ$\\nQ$\\nQE\\n\\u2212\\u02dcp(x, \\u03c4)\\nQ$ + x\\u02dcp(x, \\u03c4)\\nQE \\u2212 x\\nFig. 3: A positive-fee FM-AMM moves up the curve: effective price for given trade\\nx < 0 (in blue, the FM-AMM level curves for given Q$ and QE).\\nbe other ways to enforce batching, for example, by leveraging proposer-builder sep-\\naration (or PBS). In PBS, block builders (entities that assemble transactions in a\\nblock that are then forwarded to a proposer for inclusion in the blockchain) could\\ncompute the net trades that will reach the FM-AMM during that block. Builders\\nwill then include a message announcing this value at the beginning of the block,\\nwhich the FM-AMM uses to compute the price at which all trades will be executed.\\nIf the proposer\\u2019s announcement turns out to be correct at the end of the block, the\\nFM-AMM will reward the builder (punishments can also be introduced if the block\\nbuilder report is incorrect, see Leupold, 2022).\\nThe frequency of rebalancing is a design choice because of path dependence. For\\nexample, an FM-AMM earns more when it settles one large batch instead of two\\nsmaller batches trading in the same direction. In this case, therefore, less frequent\\nbatches may be beneficial. However, settling a single large batch, in which opposite\\ntrade demands net out, may generate little or no trade (and hence little or no benefit\",\n                    \"metadata\": {\n                        \"total_pages\": 26,\n                        \"source\": \"12\",\n                        \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                        \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                        \"release_date\": \"2023-07-05\"\n                    }\n                },\n                {\n                    \"node_id\": \"c820ab2c-624c-40a6-81ee-f1f5c72de03c\",\n                    \"score\": 0.798133612,\n                    \"text\": \"4 The model\\n13\\nto the FM-AMM), while settling two smaller batches trading in opposite directions\\nmoves the FM-AMM \\u201cup the curve\\u201d each time. In this case, more frequent batches\\nare more beneficial. In the theoretical analysis, to easily compare an FM-AMM\\nwith a traditional CPAMMs, we will assume that the FM-AMM rebalances each\\nblock. However, in the empirical analysis, we will compare the performance of an\\nFM-AMM at different rebalancing intervals.\\n4\\nThe model\\nEquipped with the full description of an FM-AMM, we can now study its behavior in\\nan environment with traders and arbitrageurs. We limit our analysis to the product\\nfunction.\\nThe game comprises n noise traders, each wanting to trade ai units of ETH. We\\nadopt the convention that if ai > 0 trader i wants to buy ETH, while if ai < 0\\ntrader i wants to sell ETH. Call A = \\ufffd\\ni ai the aggregate demand for ETH from\\nnoise traders, assumed small relative to the FM-AMM liquidity pools QE and Q$.6\\nNext to traders, a large number of cash-abundant, competing arbitrageurs, who\\ncan trade as part of the batch and on some external trading venue, assumed much\\nlarger and more liquid than the combination of our n traders and the FM-AMM. The\\nequilibrium price for ETH on this external trading venue is p\\u2217 and is unaffected by\\ntrades on the FM-AMM. Arbitrageurs aim to profit from price differences between\\nthe FM-AMM and the external trading venues.\\nArbitrage opportunities will be\\nintertemporal (over short intervals). Hence, for ease of derivations, we assume that\\narbitrageurs do not discount the future.\\nThe timing of the game is discrete. Even periods are when on-chain transactions\\noccur.\\nEven periods are, therefore, better interpreted as different blocks.\\nOdd\\nperiods are when off-chain events occur.\\nIn these periods, first, the equilibrium\\nprice p\\u2217 may change, and then traders/arbitrageurs can submit trades for inclusion\\nin the batch.\\nWe are now ready to derive our main proposition.\\nProposition 2. Suppose that, at the end of an even period, the pools of the FM-\\nAMM are QE and Q$. In the equilibrium of the subsequent odd period, after p\\u2217 is\\nrealized, noise traders will collectively submit trade A to the batch, and arbitrageurs\\nwill collectively submit trade y(p\\u2217) such that \\u02dcp(A + y(p\\u2217), \\u03c4) = p\\u2217.\\nThe proof of the proposition distinguishes between two cases. The first is p\\u2217 >\\nQ$\\n(1\\u2212\\u03c4)QE or p\\u2217 <\\n(1\\u2212\\u03c4)Q$\\nQE\\n, so that A + y(p\\u2217) \\u0338= 0. There is positive trade on the\\nFM-AMM in equilibrium, and the FM-AMM unique effective price is exactly the\\n6 In practice, we assume that trading A on the FM-AMM has a negligible price impact. Else,\\nwe should treat orders from noise traders as limit orders. In this case, all our results continue to\\nhold at the cost of additional notation.\",\n                    \"metadata\": {\n                        \"total_pages\": 26,\n                        \"source\": \"13\",\n                        \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                        \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                        \"release_date\": \"2023-07-05\"\n                    }\n                },\n                {\n                    \"node_id\": \"5b3a66e5-8d76-4570-b11b-932b601e70b8\",\n                    \"score\": 0.797142148,\n                    \"text\": \"1 Introduction\\n2\\nCFAMM within the same block pay different prices depending on the order in which\\nthey are executed.\\nThis design has two well-recognized flaws. First, liquidity providers (LPs) trade\\nat a loss whenever there is a rebalancing event. More precisely, when the underlying\\nvalue of the assets changes, the first informed arbitrageur who trades with the\\nCFAMM earns a profit by aligning the CFAMM price with the new equilibrium\\nprice. These profits are at the expense of LPs, who suffer a \\u201closs-vs-rebalancing\\u201d\\n(LVR). Second, traders are routinely exploited by attackers, most commonly via\\nsandwich attacks in which an attacker front-runs a victim\\u2019s swap with the same\\nswap and then back-runs it with the opposite swap. Doing so allows the attacker to\\n\\u201cbuy cheap\\u201d and \\u201csell expensive\\u201d while forcing the victim to trade at less favorable\\nterms.\\nThis paper proposes a novel AMM design that avoids both problems. In its\\nsimplest form, we propose that all trades that reach the AMM during a period are\\nbatched together and executed at a price equal to the new marginal price on the\\nAMM \\u2013 that is, the price of executing an arbitrarily small trade after the batch\\ntrades. We derive the trading function of such an AMM and show two interesting\\nequivalences. First, this AMM is function maximizing because, for given prices, it\\nmaximizes the value of a given function subject to a budget constraint. For this\\nreason, we call our design a function-maximizing AMM, or FM-AMM . Also, if the\\nfunction is a standard Cobb-Duglas objective function (i.e., the weighted sum of\\ntwo natural logs), then for given prices, the FM-AMM LPs run a passive investment\\nstrategy: absent trading fees, the total value of the two pools is shared between each\\npool according to some pre-specified weights. Finally, we show that an FM-AMM\\ndoes not satisfy path independence: traders can obtain a better price by splitting\\ntheir trades into smaller orders, which is why batching is required.\\nOur main contribution is to consider the behavior of such an AMM in the pres-\\nence of arbitrageurs, who have private information relative to the equilibrium prices\\n(determined, for example, on some very liquid off-chain location). Competition be-\\ntween arbitrageurs guarantees that the batch always trades at the equilibrium price,\\nand arbitrage profits are eliminated. Intuitively, if this were not the case, some arbi-\\ntrageurs would want to trade with the batch and, by doing so, would push the price\\non the batch in line with the equilibrium. This also eliminates all forms of MEV\\nextraction, such as, for example, sandwich attacks: arbitrageurs will always act so\\nto remove deviations from the equilibrium price, therefore making it impossible to\\nmanipulate the FM-AMM price. The benefit of contributing liquidity to an FM-\\nAMM relative to a traditional CFAMM is that FM-AMM LPs earn the arbitrage\\nprofits generated by rebalancing the CFAMMs. Because these arbitrage profits are\\nlarger for more volatile prices (as they lead to more frequent and larger rebalancing,\\nsee Milionis et al., 2022 and Milionis et al., 2023), holding everything else equal, the\\nbenefit of providing liquidity to an FM-AMM relative to a CFAMM increases with\",\n                    \"metadata\": {\n                        \"total_pages\": 26,\n                        \"source\": \"2\",\n                        \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                        \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                        \"release_date\": \"2023-07-05\"\n                    }\n                },\n                {\n                    \"node_id\": \"74f22003-9bd1-40e1-8d65-a2f73283461d\",\n                    \"score\": 0.796305716,\n                    \"text\": \"3 Additional considerations\\n8\\nQE\\nQ$\\nQ$\\nQE\\n\\u2212p(x)\\nFig. 2: On an FM-AMM, the price at which a given trade x is executed equals the\\nmarginal price after the trade is executed. This implies that an FM-AMM\\n\\u201cmoves up\\u201d the curve with each trade.\\n3\\nAdditional considerations\\n3.1\\nGeneralization of definitions and results\\nWe now generalize our results. First of all, an AMM is an entity that accepts or\\nrejects trades based on a pre-set rule. Such rule can be derived from the AMMs\\nliquidity pools (Q$, QE) \\u2208 R2\\n+ and the AMM function \\u03a8 : R2\\n+ \\u2192 R. We assume that\\nthe AMM function is continuous, it is such that \\u03a8(Q$, 0) = \\u03a8(0, QE) = \\u03a8(0, 0) for\\nall Q$ QE, that it is strictly increasing in both its arguments whenever Q$ > 0 and\\nQE > 0, and that it is strictly quasiconcave. The difference between different types\\nof AMMs is how the function \\u03a8(., .) and the liquidity pools (Q$, QE) determine what\\ntrades will be accepted and rejected by the AMM.\\nDefinition 1 (Constant Function Automated Market Maker). For given liquidity\\npools (Q$, QE) and function \\u03a8 : R2\\n+ \\u2192 R, a constant function automated market\\nmaker (CFAMM) is willing to trade x for y = p(x)x if and only if\\n\\u03a8(Q$ + p(x)x, QE \\u2212 x) = \\u03a8(Q$, QE).\",\n                    \"metadata\": {\n                        \"total_pages\": 26,\n                        \"source\": \"8\",\n                        \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                        \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                        \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                        \"release_date\": \"2023-07-05\"\n                    }\n                }\n            ],\n            \"metadata\": {\n                \"b189a8c3-7fe7-40c2-865b-067ffde62da6\": {\n                    \"total_pages\": 26,\n                    \"source\": \"5\",\n                    \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                    \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                    \"release_date\": \"2023-07-05\"\n                },\n                \"7e7f886f-3f2b-4048-81da-8cdef0f7bf30\": {\n                    \"total_pages\": 26,\n                    \"source\": \"12\",\n                    \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                    \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                    \"release_date\": \"2023-07-05\"\n                },\n                \"c820ab2c-624c-40a6-81ee-f1f5c72de03c\": {\n                    \"total_pages\": 26,\n                    \"source\": \"13\",\n                    \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                    \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                    \"release_date\": \"2023-07-05\"\n                },\n                \"5b3a66e5-8d76-4570-b11b-932b601e70b8\": {\n                    \"total_pages\": 26,\n                    \"source\": \"2\",\n                    \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                    \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                    \"release_date\": \"2023-07-05\"\n                },\n                \"74f22003-9bd1-40e1-8d65-a2f73283461d\": {\n                    \"total_pages\": 26,\n                    \"source\": \"8\",\n                    \"title\": \"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response\",\n                    \"authors\": \"Andrea Canidio, Robin Fritsch\",\n                    \"pdf_link\": \"http://arxiv.org/pdf/2307.02074v2\",\n                    \"release_date\": \"2023-07-05\"\n                }\n            }\n        }\n    }\n];\n    var collapsibleDiv = createCollapsible(jsonObj);\n    jsonDiv.appendChild(collapsibleDiv);\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import root_directory\n",
    "root_dir = root_directory()\n",
    "file_path = f'{root_dir}/datasets/evaluation_results/2023-09-29_text-embedding-ada-002_gpt-3.5-turbo_1536_230.json'\n",
    "pretty_print_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for source_node in response.source_nodes: \n",
    "    print(f\"Node #{i}:\\n \\n{source_node}\\n\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
